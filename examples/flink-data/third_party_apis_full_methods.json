{
  "fullMethodsPaths" : [ {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.read",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.KryoException.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.read", "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.require" ],
    "fullMethods" : [ "@Override\npublic int read() throws KryoException {\n    require(1);\n    return buffer[position++] & 0xff;\n}", "/**\n * Require makes sure that at least required number of bytes are kept in the buffer. If not,\n * then it will load exactly the difference between required and currently available number of\n * bytes. Thus, it will only load the data which is required and never prefetch data.\n *\n * @param required\n * \t\tthe number of bytes being available in the buffer\n * @return The number of bytes remaining in the buffer, which will be at least <code>required\n</code> bytes.\n * @throws KryoException\n */\n@Override\nprotected int require(int required) throws KryoException {\n    // The main change between this and Kryo 5 Input.require is this will never read more bytes\n    // than required.\n    // There are also formatting changes to be compliant with the Flink project styling rules.\n    int remaining = limit - position;\n    if (remaining >= required) {\n        return remaining;\n    }\n    if (required > capacity) {\n        throw new KryoException(((\"Buffer too small: capacity: \" + capacity) + \", required: \") + required);\n    }\n    int count;\n    // Try to fill the buffer.\n    if (remaining > 0) {\n        // Logical change 1 (from Kryo Input.require): \"capacity - limit\" -> \"required - limit\"\n        count = fill(buffer, limit, required - limit);\n        if (count == (-1)) {\n            throw new KryoBufferUnderflowException(\"Buffer underflow.\");\n        }\n        remaining += count;\n        if (remaining >= required) {\n            limit += count;\n            return remaining;\n        }\n    }\n    // Was not enough, compact and try again.\n    System.arraycopy(buffer, position, buffer, 0, remaining);\n    total += position;\n    position = 0;\n    do {\n        // Logical change 2 (from Kryo Input.require): \"capacity - remaining\" -> \"required -\n        // remaining\"\n        count = fill(buffer, remaining, required - remaining);\n        if (count == (-1)) {\n            throw new KryoBufferUnderflowException(\"Buffer underflow.\");\n        }\n        remaining += count;\n    } while (remaining < required );\n    limit = remaining;\n    return remaining;\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.zip.ZipFile.getInputStream",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.zip",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions" ],
    "fullMethods" : [ "public static void extractZipFileWithPermissions(String zipFilePath, String targetPath) throws IOException {\n    try (ZipFile zipFile = new ZipFile(zipFilePath)) {\n        Enumeration<ZipArchiveEntry> entries = zipFile.getEntries();\n        boolean isUnix = isUnix();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        String canonicalTargetPath = new File(targetPath).getCanonicalPath() + File.separator;\n        while (entries.hasMoreElements()) {\n            ZipArchiveEntry entry = entries.nextElement();\n            File outputFile = new File(canonicalTargetPath, entry.getName());\n            if (!outputFile.getCanonicalPath().startsWith(canonicalTargetPath)) {\n                throw new IOException(((\"Expand \" + entry.getName()) + \" would create a file outside of \") + targetPath);\n            }\n            if (entry.isDirectory()) {\n                if (!outputFile.exists()) {\n                    if (!outputFile.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n            } else {\n                File parentDir = outputFile.getParentFile();\n                if (!parentDir.exists()) {\n                    if (!parentDir.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n                if (entry.isUnixSymlink()) {\n                    // the content of the file is the target path of the symlink\n                    baos.reset();\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), baos);\n                    Files.createSymbolicLink(outputFile.toPath(), new File(parentDir, baos.toString()).toPath());\n                } else if (outputFile.createNewFile()) {\n                    OutputStream output = new FileOutputStream(outputFile);\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), output);\n                } else {\n                    throw new IOException((\"Create file: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                }\n            }\n            if (isUnix) {\n                int mode = entry.getUnixMode();\n                if (mode != 0) {\n                    Path outputPath = Paths.get(outputFile.toURI());\n                    Set<PosixFilePermission> permissions = new HashSet<>();\n                    addIfBitSet(mode, 8, permissions, PosixFilePermission.OWNER_READ);\n                    addIfBitSet(mode, 7, permissions, PosixFilePermission.OWNER_WRITE);\n                    addIfBitSet(mode, 6, permissions, PosixFilePermission.OWNER_EXECUTE);\n                    addIfBitSet(mode, 5, permissions, PosixFilePermission.GROUP_READ);\n                    addIfBitSet(mode, 4, permissions, PosixFilePermission.GROUP_WRITE);\n                    addIfBitSet(mode, 3, permissions, PosixFilePermission.GROUP_EXECUTE);\n                    addIfBitSet(mode, 2, permissions, PosixFilePermission.OTHERS_READ);\n                    addIfBitSet(mode, 1, permissions, PosixFilePermission.OTHERS_WRITE);\n                    addIfBitSet(mode, 0, permissions, PosixFilePermission.OTHERS_EXECUTE);\n                    // the permission of the target file will be set to be the same as the\n                    // symlink\n                    // TODO: support setting the permission without following links\n                    try {\n                        Files.setPosixFilePermissions(outputPath, permissions);\n                    } catch (NoSuchFileException e) {\n                        // this may happens when the target file of the symlink is still not\n                        // extracted\n                    }\n                }\n            }\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.createInstance",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.createInstance", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.checkKryoInitialized", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic T createInstance() {\n    if (Modifier.isAbstract(type.getModifiers()) || Modifier.isInterface(type.getModifiers())) {\n        return null;\n    } else {\n        checkKryoInitialized();\n        try {\n            return kryo.newInstance(type);\n        } catch (Throwable e) {\n            return null;\n        }\n    }\n}", "private void checkKryoInitialized() {\n    if (this.kryo == null) {\n        this.kryo = getKryoInstance();\n        // Enable reference tracking.\n        kryo.setReferences(true);\n        // Throwable and all subclasses should be serialized via java serialization\n        // Note: the registered JavaSerializer is Flink's own implementation, and not Kryo's.\n        // This is due to a know issue with Kryo's JavaSerializer. See FLINK-6025 for\n        // details.\n        kryo.addDefaultSerializer(Throwable.class, new JavaSerializer());\n        // Add default serializers first, so that the type registrations without a serializer\n        // are registered with a default serializer\n        for (Map.Entry<Class<?>, SerializableSerializer<?>> entry : defaultSerializers.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue().getSerializer());\n        }\n        for (Map.Entry<Class<?>, Class<? extends Serializer<?>>> entry : defaultSerializerClasses.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue());\n        }\n        KryoUtils.applyRegistrations(this.kryo, kryoRegistrations.values(), flinkChillPackageRegistrar != null ? flinkChillPackageRegistrar.getNextRegistrationId() : kryo.getNextRegistrationId());\n        kryo.setRegistrationRequired(false);\n        kryo.setClassLoader(Thread.currentThread().getContextClassLoader());\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(TypeSerializerSnapshot<T> oldSerializerSnapshot) {\n    if (!(oldSerializerSnapshot instanceof KryoSerializerSnapshot)) {\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    KryoSerializerSnapshot<T> oldKryoSerializerSnapshot = ((KryoSerializerSnapshot<T>) (oldSerializerSnapshot));\n    if (snapshotData.getTypeClass() != oldKryoSerializerSnapshot.snapshotData.getTypeClass()) {\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    return resolveSchemaCompatibility(oldKryoSerializerSnapshot);\n}", "private TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(KryoSerializerSnapshot<T> oldKryoSerializerSnapshot) {\n    // merge the default serializers\n    final MergeResult<Class<?>, SerializableSerializer<?>> reconfiguredDefaultKryoSerializers = mergeRightIntoLeft(oldKryoSerializerSnapshot.snapshotData.getDefaultKryoSerializers(), snapshotData.getDefaultKryoSerializers());\n    if (reconfiguredDefaultKryoSerializers.hasMissingKeys()) {\n        logMissingKeys(reconfiguredDefaultKryoSerializers);\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    // merge default serializer classes\n    final MergeResult<Class<?>, Class<? extends Serializer<?>>> reconfiguredDefaultKryoSerializerClasses = mergeRightIntoLeft(oldKryoSerializerSnapshot.snapshotData.getDefaultKryoSerializerClasses(), snapshotData.getDefaultKryoSerializerClasses());\n    if (reconfiguredDefaultKryoSerializerClasses.hasMissingKeys()) {\n        logMissingKeys(reconfiguredDefaultKryoSerializerClasses);\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    // merge registration\n    final MergeResult<String, KryoRegistration> reconfiguredRegistrations = mergeRightIntoLeft(oldKryoSerializerSnapshot.snapshotData.getKryoRegistrations(), snapshotData.getKryoRegistrations());\n    if (reconfiguredRegistrations.hasMissingKeys()) {\n        logMissingKeys(reconfiguredRegistrations);\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    // there are no missing keys, now we have to decide whether we are compatible as-is or we\n    // require reconfiguration.\n    return resolveSchemaCompatibility(reconfiguredDefaultKryoSerializers, reconfiguredDefaultKryoSerializerClasses, reconfiguredRegistrations);\n}", "private TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(MergeResult<Class<?>, SerializableSerializer<?>> reconfiguredDefaultKryoSerializers, MergeResult<Class<?>, Class<? extends Serializer<?>>> reconfiguredDefaultKryoSerializerClasses, MergeResult<String, KryoRegistration> reconfiguredRegistrations) {\n    if ((reconfiguredDefaultKryoSerializers.isOrderedSubset() && reconfiguredDefaultKryoSerializerClasses.isOrderedSubset()) && reconfiguredRegistrations.isOrderedSubset()) {\n        return TypeSerializerSchemaCompatibility.compatibleAsIs();\n    }\n    // reconfigure a new KryoSerializer\n    KryoSerializer<T> reconfiguredSerializer = new KryoSerializer<>(snapshotData.getTypeClass(), reconfiguredDefaultKryoSerializers.getMerged(), reconfiguredDefaultKryoSerializerClasses.getMerged(), reconfiguredRegistrations.getMerged());\n    return TypeSerializerSchemaCompatibility.compatibleWithReconfiguredSerializer(reconfiguredSerializer);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<init>",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<init>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "// ------------------------------------------------------------------------\npublic KryoSerializer(Class<T> type, SerializerConfig serializerConfig) {\n    this.type = checkNotNull(type);\n    this.defaultSerializers = ((SerializerConfigImpl) (serializerConfig)).getDefaultKryoSerializers();\n    this.defaultSerializerClasses = serializerConfig.getDefaultKryoSerializerClasses();\n    this.kryoRegistrations = buildKryoRegistrations(this.type, serializerConfig.getRegisteredKryoTypes(), serializerConfig.getRegisteredTypesWithKryoSerializerClasses(), ((SerializerConfigImpl) (serializerConfig)).getRegisteredTypesWithKryoSerializers(), serializerConfig.isForceKryoAvroEnabled());\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.restoreSerializer",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.restoreSerializer", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic TypeSerializer<T> restoreSerializer() {\n    return new KryoSerializer<>(snapshotData.getTypeClass(), snapshotData.getDefaultKryoSerializers().unwrapOptionals(), snapshotData.getDefaultKryoSerializerClasses().unwrapOptionals(), snapshotData.getKryoRegistrations().unwrapOptionals());\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic void copy(DataInputView source, DataOutputView target) throws IOException {\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        if (this.copyInstance == null) {\n            this.copyInstance = createInstance();\n        }\n        T tmp = deserialize(copyInstance, source);\n        serialize(tmp, target);\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.deserialize",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.deserialize", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\n@Override\npublic T deserialize(DataInputView source) throws IOException {\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        if (source != previousIn) {\n            DataInputViewStream inputStream = new DataInputViewStream(source);\n            input = new NoFetchingInput(inputStream);\n            previousIn = source;\n        }\n        try {\n            return ((T) (kryo.readClassAndObject(input)));\n        } catch (KryoBufferUnderflowException ke) {\n            // 2023-04-26: Existing Flink code expects a java.io.EOFException in this scenario\n            throw new EOFException(ke.getMessage());\n        } catch (KryoException ke) {\n            Throwable cause = ke.getCause();\n            if (cause instanceof EOFException) {\n                throw ((EOFException) (cause));\n            } else {\n                throw ke;\n            }\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.PojoTypeInfo.createSerializer",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.PojoTypeInfo.createSerializer", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\n@PublicEvolving\n@SuppressWarnings(\"unchecked\")\npublic TypeSerializer<T> createSerializer(SerializerConfig config) {\n    if (config.isForceKryoEnabled()) {\n        return new KryoSerializer<>(getTypeClass(), config);\n    }\n    if (config.isForceAvroEnabled()) {\n        return AvroUtils.getAvroUtils().createAvroSerializer(getTypeClass());\n    }\n    return createPojoSerializer(config);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.GenericTypeInfo.createSerializer",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.GenericTypeInfo.createSerializer", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\n@PublicEvolving\npublic TypeSerializer<T> createSerializer(SerializerConfig config) {\n    if (config.hasGenericTypesDisabled()) {\n        throw new UnsupportedOperationException((\"Generic types have been disabled in the ExecutionConfig and type \" + this.typeClass.getName()) + \" is treated as a generic type.\");\n    }\n    return new KryoSerializer<T>(this.typeClass, config);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.serialize",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.serialize", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic void serialize(T record, DataOutputView target) throws IOException {\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        if (target != previousOut) {\n            DataOutputViewStream outputStream = new DataOutputViewStream(target);\n            output = new Output(outputStream);\n            previousOut = target;\n        }\n        // Sanity check: Make sure that the output is cleared/has been flushed by the last call\n        // otherwise data might be written multiple times in case of a previous EOFException\n        if (output.position() != 0) {\n            throw new IllegalStateException(\"The Kryo Output still contains data from a previous \" + \"serialize call. It has to be flushed or cleared at the end of the serialize call.\");\n        }\n        try {\n            kryo.writeClassAndObject(output, record);\n            output.flush();\n        } catch (KryoException ke) {\n            // make sure that the Kryo output buffer is reset in case that we can recover from\n            // the exception (e.g. EOFException which denotes buffer full)\n            output.reset();\n            Throwable cause = ke.getCause();\n            if (cause instanceof EOFException) {\n                throw ((EOFException) (cause));\n            } else {\n                throw ke;\n            }\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\n@Override\npublic T copy(T from) {\n    if (from == null) {\n        return null;\n    }\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        try {\n            return kryo.copy(from);\n        } catch (KryoException ke) {\n            // kryo was unable to copy it, so we do it through serialization:\n            ByteArrayOutputStream baout = new ByteArrayOutputStream();\n            Output output = new Output(baout);\n            kryo.writeObject(output, from);\n            output.close();\n            ByteArrayInputStream bain = new ByteArrayInputStream(baout.toByteArray());\n            Input input = new Input(bain);\n            return ((T) (kryo.readObject(input, from.getClass())));\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.getKryo",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.getKryo", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.checkKryoInitialized", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@VisibleForTesting\npublic Kryo getKryo() {\n    checkKryoInitialized();\n    return this.kryo;\n}", "private void checkKryoInitialized() {\n    if (this.kryo == null) {\n        this.kryo = getKryoInstance();\n        // Enable reference tracking.\n        kryo.setReferences(true);\n        // Throwable and all subclasses should be serialized via java serialization\n        // Note: the registered JavaSerializer is Flink's own implementation, and not Kryo's.\n        // This is due to a know issue with Kryo's JavaSerializer. See FLINK-6025 for\n        // details.\n        kryo.addDefaultSerializer(Throwable.class, new JavaSerializer());\n        // Add default serializers first, so that the type registrations without a serializer\n        // are registered with a default serializer\n        for (Map.Entry<Class<?>, SerializableSerializer<?>> entry : defaultSerializers.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue().getSerializer());\n        }\n        for (Map.Entry<Class<?>, Class<? extends Serializer<?>>> entry : defaultSerializerClasses.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue());\n        }\n        KryoUtils.applyRegistrations(this.kryo, kryoRegistrations.values(), flinkChillPackageRegistrar != null ? flinkChillPackageRegistrar.getNextRegistrationId() : kryo.getNextRegistrationId());\n        kryo.setRegistrationRequired(false);\n        kryo.setClassLoader(Thread.currentThread().getContextClassLoader());\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.duplicate",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.setLogger",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.duplicate", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic KryoSerializer<T> duplicate() {\n    return new KryoSerializer<>(this);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.YamlParserUtils.FlinkConfigRepresenter.<init>",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.representer.StandardRepresenter.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.representer",
    "path" : [ "org.apache.flink.configuration.YamlParserUtils.FlinkConfigRepresenter.<init>" ],
    "fullMethods" : [ "public FlinkConfigRepresenter(DumpSettings dumpSettings) {\n    super(dumpSettings);\n    representers.put(Duration.class, this::representDuration);\n    representers.put(MemorySize.class, this::representMemorySize);\n    parentClassRepresenters.put(Enum.class, this::representEnum);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.read",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.util.ObjectMap.get",
    "thirdPartyPackage" : "com.esotericsoftware.kryo.util",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.read" ],
    "fullMethods" : [ "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n@Override\npublic T read(Kryo kryo, Input input, Class aClass) {\n    try {\n        ObjectMap graphContext = kryo.getGraphContext();\n        ObjectInputStream objectStream = ((ObjectInputStream) (graphContext.get(this)));\n        if (objectStream == null) {\n            // make sure we use Kryo's classloader\n            objectStream = new InstantiationUtil.ClassLoaderObjectInputStream(input, kryo.getClassLoader());\n            graphContext.put(this, objectStream);\n        }\n        return ((T) (objectStream.readObject()));\n    } catch (Exception ex) {\n        throw new KryoException(\"Error during Java deserialization.\", ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.write",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.util.ObjectMap.get",
    "thirdPartyPackage" : "com.esotericsoftware.kryo.util",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.write" ],
    "fullMethods" : [ "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n@Override\npublic void write(Kryo kryo, Output output, T o) {\n    try {\n        ObjectMap graphContext = kryo.getGraphContext();\n        ObjectOutputStream objectStream = ((ObjectOutputStream) (graphContext.get(this)));\n        if (objectStream == null) {\n            objectStream = new ObjectOutputStream(output);\n            graphContext.put(this, objectStream);\n        }\n        objectStream.writeObject(o);\n        objectStream.flush();\n    } catch (Exception ex) {\n        throw new KryoException(\"Error during Java serialization.\", ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractTarFile",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.tar.TarArchiveEntry.getName",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.tar",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractTarFile", "org.apache.flink.util.CompressionUtils.extractTarFileUsingJava", "org.apache.flink.util.CompressionUtils.unpackEntry" ],
    "fullMethods" : [ "public static void extractTarFile(String inFilePath, String targetDirPath) throws IOException {\n    final File targetDir = new File(targetDirPath);\n    if (!targetDir.mkdirs()) {\n        if (!targetDir.isDirectory()) {\n            throw new IOException(\"Mkdirs failed to create \" + targetDir);\n        }\n    }\n    final boolean gzipped = inFilePath.endsWith(\"gz\");\n    if (isUnix()) {\n        extractTarFileUsingTar(inFilePath, targetDirPath, gzipped);\n    } else {\n        extractTarFileUsingJava(inFilePath, targetDirPath, gzipped);\n    }\n}", "// Follow the pattern suggested in\n// https://commons.apache.org/proper/commons-compress/examples.html\nprivate static void extractTarFileUsingJava(String inFilePath, String targetDirPath, boolean gzipped) throws IOException {\n    try (InputStream fi = Files.newInputStream(Paths.get(inFilePath));InputStream bi = new BufferedInputStream(fi);final TarArchiveInputStream tai = new TarArchiveInputStream(gzipped ? new GzipCompressorInputStream(bi) : bi)) {\n        final File targetDir = new File(targetDirPath);\n        TarArchiveEntry entry;\n        while ((entry = tai.getNextTarEntry()) != null) {\n            unpackEntry(tai, entry, targetDir);\n        } \n    }\n}", "private static void unpackEntry(TarArchiveInputStream tis, TarArchiveEntry entry, File targetDir) throws IOException {\n    String targetDirPath = targetDir.getCanonicalPath() + File.separator;\n    File outputFile = new File(targetDir, entry.getName());\n    if (!outputFile.getCanonicalPath().startsWith(targetDirPath)) {\n        throw new IOException(((\"expanding \" + entry.getName()) + \" would create entry outside of \") + targetDir);\n    }\n    if (entry.isDirectory()) {\n        if ((!outputFile.mkdirs()) && (!outputFile.isDirectory())) {\n            throw new IOException(\"Failed to create directory \" + outputFile);\n        }\n        for (TarArchiveEntry e : entry.getDirectoryEntries()) {\n            unpackEntry(tis, e, outputFile);\n        }\n        return;\n    }\n    if (entry.isSymbolicLink()) {\n        // create symbolic link relative to tar parent dir\n        Files.createSymbolicLink(Paths.get(new File(targetDir, entry.getName()).getCanonicalPath()), Paths.get(entry.getLinkName()));\n        return;\n    }\n    if (!outputFile.getParentFile().exists()) {\n        if (!outputFile.getParentFile().mkdirs()) {\n            throw new IOException(\"Mkdirs failed to create tar internal dir \" + targetDir);\n        }\n    }\n    try (OutputStream o = Files.newOutputStream(Paths.get(outputFile.getCanonicalPath()))) {\n        IOUtils.copyBytes(tis, o, false);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.read",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.KryoException.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.read" ],
    "fullMethods" : [ "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n@Override\npublic T read(Kryo kryo, Input input, Class aClass) {\n    try {\n        ObjectMap graphContext = kryo.getGraphContext();\n        ObjectInputStream objectStream = ((ObjectInputStream) (graphContext.get(this)));\n        if (objectStream == null) {\n            // make sure we use Kryo's classloader\n            objectStream = new InstantiationUtil.ClassLoaderObjectInputStream(input, kryo.getClassLoader());\n            graphContext.put(this, objectStream);\n        }\n        return ((T) (objectStream.readObject()));\n    } catch (Exception ex) {\n        throw new KryoException(\"Error during Java deserialization.\", ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.write",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.KryoException.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.write" ],
    "fullMethods" : [ "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n@Override\npublic void write(Kryo kryo, Output output, T o) {\n    try {\n        ObjectMap graphContext = kryo.getGraphContext();\n        ObjectOutputStream objectStream = ((ObjectOutputStream) (graphContext.get(this)));\n        if (objectStream == null) {\n            objectStream = new ObjectOutputStream(output);\n            graphContext.put(this, objectStream);\n        }\n        objectStream.writeObject(o);\n        objectStream.flush();\n    } catch (Exception ex) {\n        throw new KryoException(\"Error during Java serialization.\", ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.GlobalConfiguration.loadConfiguration",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.GlobalConfiguration.loadConfiguration", "org.apache.flink.configuration.GlobalConfiguration.loadYAMLResource", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "/**\n * Loads the configuration files from the specified directory. If the dynamic properties\n * configuration is not null, then it is added to the loaded configuration.\n *\n * @param configDir\n * \t\tdirectory to load the configuration from\n * @param dynamicProperties\n * \t\tconfiguration file containing the dynamic properties. Null if none.\n * @return The configuration loaded from the given configuration directory\n */\npublic static Configuration loadConfiguration(final String configDir, @Nullable\nfinal Configuration dynamicProperties) {\n    if (configDir == null) {\n        throw new IllegalArgumentException(\"Given configuration directory is null, cannot load configuration\");\n    }\n    final File confDirFile = new File(configDir);\n    if (!confDirFile.exists()) {\n        throw new IllegalConfigurationException((((\"The given configuration directory name '\" + configDir) + \"' (\") + confDirFile.getAbsolutePath()) + \") does not describe an existing directory.\");\n    }\n    // get Flink yaml configuration file\n    Configuration configuration;\n    File yamlConfigFile = new File(confDirFile, FLINK_CONF_FILENAME);\n    if (!yamlConfigFile.exists()) {\n        throw new IllegalConfigurationException((((\"The Flink config file '\" + yamlConfigFile) + \"' (\") + yamlConfigFile.getAbsolutePath()) + \") does not exist.\");\n    } else {\n        LOG.info(\"Using standard YAML parser to load flink configuration file from {}.\", yamlConfigFile.getAbsolutePath());\n        configuration = loadYAMLResource(yamlConfigFile);\n    }\n    logConfiguration(\"Loading\", configuration);\n    if (dynamicProperties != null) {\n        logConfiguration(\"Loading dynamic\", dynamicProperties);\n        configuration.addAll(dynamicProperties);\n    }\n    return configuration;\n}", "/**\n * Loads a YAML-file of key-value pairs.\n *\n * <p>Keys can be expressed either as nested keys or as {@literal KEY_SEPARATOR} separated keys.\n * For example, the following configurations are equivalent:\n *\n * <pre>\n * jobmanager.rpc.address: localhost # network address for communication with the job manager\n * jobmanager.rpc.port   : 6123      # network port to connect to for communication with the job manager\n * taskmanager.rpc.port  : 6122      # network port the task manager expects incoming IPC connections\n * </pre>\n *\n * <pre>\n * jobmanager:\n *     rpc:\n *         address: localhost # network address for communication with the job manager\n *         port: 6123         # network port to connect to for communication with the job manager\n * taskmanager:\n *     rpc:\n *         port: 6122         # network port the task manager expects incoming IPC connections\n * </pre>\n *\n * @param file\n * \t\tthe YAML file to read from\n * @see <a href=\"http://www.yaml.org/spec/1.2/spec.html\">YAML 1.2 specification</a>\n */\nprivate static Configuration loadYAMLResource(File file) {\n    final Configuration config = new Configuration();\n    try {\n        Map<String, Object> configDocument = flatten(YamlParserUtils.loadYamlFile(file));\n        configDocument.forEach((k, v) -> config.setValueInternal(k, v, false));\n        return config;\n    } catch (Exception e) {\n        throw new RuntimeException(\"Error parsing YAML configuration.\", e);\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.YamlParserUtils.convertToObject",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.YamlParserUtils.convertToObject", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "public static synchronized <T> T convertToObject(String value, Class<T> type) {\n    try {\n        return type.cast(loader.loadFromString(value));\n    } catch (MarkedYamlEngineException exception) {\n        throw wrapExceptionToHiddenSensitiveData(exception);\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.YamlParserUtils.convertAndDumpYamlFromFlatMap",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.YamlParserUtils.convertAndDumpYamlFromFlatMap", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "/**\n * Converts a flat map into a nested map structure and outputs the result as a list of\n * YAML-formatted strings. Each item in the list represents a single line of the YAML data. The\n * method is synchronized and thus thread-safe.\n *\n * @param flattenMap\n * \t\tA map containing flattened keys (e.g., \"parent.child.key\") associated with\n * \t\ttheir values.\n * @return A list of strings that represents the YAML data, where each item corresponds to a\nline of the data.\n */\n@SuppressWarnings(\"unchecked\")\npublic static synchronized List<String> convertAndDumpYamlFromFlatMap(Map<String, Object> flattenMap) {\n    try {\n        Map<String, Object> nestedMap = new LinkedHashMap<>();\n        for (Map.Entry<String, Object> entry : flattenMap.entrySet()) {\n            String[] keys = entry.getKey().split(\"\\\\.\");\n            Map<String, Object> currentMap = nestedMap;\n            for (int i = 0; i < (keys.length - 1); i++) {\n                currentMap = ((Map<String, Object>) (currentMap.computeIfAbsent(keys[i], k -> new LinkedHashMap<>())));\n            }\n            currentMap.put(keys[keys.length - 1], entry.getValue());\n        }\n        String data = blockerDumper.dumpToString(nestedMap);\n        String linebreak = blockerDumperSettings.getBestLineBreak();\n        return Arrays.asList(data.split(linebreak));\n    } catch (MarkedYamlEngineException exception) {\n        throw wrapExceptionToHiddenSensitiveData(exception);\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.DelegatingConfiguration.toFileWritableMap",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.DelegatingConfiguration.toFileWritableMap", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "@Override\npublic Map<String, String> toFileWritableMap() {\n    Map<String, String> map = backingConfig.toFileWritableMap();\n    Map<String, String> prefixed = new HashMap<>();\n    for (Map.Entry<String, String> entry : map.entrySet()) {\n        if (entry.getKey().startsWith(prefix)) {\n            String keyWithoutPrefix = entry.getKey().substring(prefix.length());\n            prefixed.put(keyWithoutPrefix, YamlParserUtils.toYAMLString(entry.getValue()));\n        }\n    }\n    return prefixed;\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.ConfigurationUtils.convertConfigToWritableLines",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.ConfigurationUtils.convertConfigToWritableLines", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "/**\n * Converts the provided configuration data into a format suitable for writing to a file, based\n * on the {@code flattenYaml} flag and the {@code standardYaml} attribute of the configuration\n * object.\n *\n * <p>Only when {@code flattenYaml} is set to {@code false} and the configuration object is\n * standard yaml, a nested YAML format is used. Otherwise, a flat key-value pair format is\n * output.\n *\n * <p>Each entry in the returned list represents a single line that can be written directly to a\n * file.\n *\n * <p>Example input (flat map configuration data):\n *\n * <pre>{@code {\n *      \"parent.child\": \"value1\",\n *      \"parent.child2\": \"value2\"\n * }}</pre>\n *\n * <p>Example output when {@code flattenYaml} is {@code false} and the configuration object is\n * standard yaml:\n *\n * <pre>{@code parent:\n *   child: value1\n *   child2: value2}</pre>\n *\n * <p>Otherwise, the Example output is:\n *\n * <pre>{@code parent.child: value1\n * parent.child2: value2}</pre>\n *\n * @param configuration\n * \t\tThe configuration to be converted.\n * @param flattenYaml\n * \t\tA boolean flag indicating if the configuration data should be output in a\n * \t\tflattened format.\n * @return A list of strings, where each string represents a line of the file-writable data in\nthe chosen format.\n */\npublic static List<String> convertConfigToWritableLines(Configuration configuration, boolean flattenYaml) {\n    if (!flattenYaml) {\n        return YamlParserUtils.convertAndDumpYamlFromFlatMap(Collections.unmodifiableMap(configuration.confData));\n    } else {\n        Map<String, String> fileWritableMap = configuration.toFileWritableMap();\n        return fileWritableMap.entrySet().stream().map(entry -> (entry.getKey() + \": \") + entry.getValue()).collect(Collectors.toList());\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.YamlParserUtils.loadYamlFile",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.YamlParserUtils.loadYamlFile", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "/**\n * Loads the contents of the given YAML file into a map.\n *\n * @param file\n * \t\tthe YAML file to load.\n * @return a non-null map representing the YAML content. If the file is empty or only contains\ncomments, an empty map is returned.\n * @throws FileNotFoundException\n * \t\tif the YAML file is not found.\n * @throws YamlEngineException\n * \t\tif the file cannot be parsed.\n * @throws IOException\n * \t\tif an I/O error occurs while reading from the file stream.\n */\n@Nonnull\npublic static synchronized Map<String, Object> loadYamlFile(File file) throws Exception {\n    try (FileInputStream inputStream = new FileInputStream(file)) {\n        Map<String, Object> yamlResult = ((Map<String, Object>) (loader.loadFromInputStream(inputStream)));\n        return yamlResult == null ? new HashMap<>() : yamlResult;\n    } catch (FileNotFoundException e) {\n        LOG.error(\"Failed to find YAML file\", e);\n        throw e;\n    } catch (IOException | YamlEngineException e) {\n        if (e instanceof MarkedYamlEngineException) {\n            YamlEngineException exception = wrapExceptionToHiddenSensitiveData(((MarkedYamlEngineException) (e)));\n            LOG.error(\"Failed to parse YAML configuration\", exception);\n            throw exception;\n        } else {\n            throw e;\n        }\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.ConfigurationUtils.parseMapToString",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.ConfigurationUtils.parseMapToString", "org.apache.flink.configuration.ConfigurationUtils.convertToString", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "public static String parseMapToString(Map<String, String> map) {\n    return convertToString(map);\n}", "static String convertToString(Object o) {\n    if (o.getClass() == String.class) {\n        return ((String) (o));\n    } else {\n        return YamlParserUtils.toYAMLString(o);\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.Configuration.toMap",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.Configuration.toMap", "org.apache.flink.configuration.ConfigurationUtils.convertToString", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "// --------------------------------------------------------------------------------------------\n@Override\npublic Map<String, String> toMap() {\n    synchronized(this.confData) {\n        Map<String, String> ret = CollectionUtil.newHashMapWithExpectedSize(this.confData.size());\n        for (Map.Entry<String, Object> entry : confData.entrySet()) {\n            ret.put(entry.getKey(), ConfigurationUtils.convertToString(entry.getValue()));\n        }\n        return ret;\n    }\n}", "static String convertToString(Object o) {\n    if (o.getClass() == String.class) {\n        return ((String) (o));\n    } else {\n        return YamlParserUtils.toYAMLString(o);\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.YamlParserUtils.toYAMLString",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.YamlParserUtils.toYAMLString", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "/**\n * Converts the given value to a string representation in the YAML syntax. This method uses a\n * YAML parser to convert the object to YAML format.\n *\n * <p>The resulting YAML string may have line breaks at the end of each line. This method\n * removes the line break at the end of the string if it exists.\n *\n * <p>Note: This method may perform escaping on certain characters in the value to ensure proper\n * YAML syntax.\n *\n * @param value\n * \t\tThe value to be converted.\n * @return The string representation of the value in YAML syntax.\n */\npublic static synchronized String toYAMLString(Object value) {\n    try {\n        String output = flowDumper.dumpToString(value);\n        // remove the line break\n        String linebreak = flowDumperSettings.getBestLineBreak();\n        if (output.endsWith(linebreak)) {\n            output = output.substring(0, output.length() - linebreak.length());\n        }\n        return output;\n    } catch (MarkedYamlEngineException exception) {\n        throw wrapExceptionToHiddenSensitiveData(exception);\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.ConfigurationUtils.convertToList",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.ConfigurationUtils.convertToList", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\npublic static <T> T convertToList(Object rawValue, Class<?> atomicClass) {\n    if (rawValue instanceof List) {\n        return ((T) (rawValue));\n    } else {\n        try {\n            List<Object> data = YamlParserUtils.convertToObject(rawValue.toString(), List.class);\n            // The Yaml parser conversion results in data of type List<Map<Object, Object>>,\n            // such as List<Map<Object, Boolean>>. However, ConfigOption currently requires that\n            // the data for Map type be strictly of the type Map<String, String>. Therefore, we\n            // convert each map in the list to Map<String, String>.\n            if (atomicClass == Map.class) {\n                return ((T) (data.stream().map(map -> convertToStringMap(((Map<Object, Object>) (map)))).collect(Collectors.toList())));\n            }\n            return ((T) (data.stream().map(s -> convertValue(s, atomicClass)).collect(Collectors.toList())));\n        } catch (Exception e) {\n            // Fallback to legacy pattern\n            return convertToListWithLegacyProperties(rawValue, atomicClass);\n        }\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.ConfigurationUtils.convertValue",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.ConfigurationUtils.convertValue", "org.apache.flink.configuration.ConfigurationUtils.convertToString", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "// --------------------------------------------------------------------------------------------\n// Type conversion\n// --------------------------------------------------------------------------------------------\n/**\n * Tries to convert the raw value into the provided type.\n *\n * @param rawValue\n * \t\trawValue to convert into the provided type clazz\n * @param clazz\n * \t\tclazz specifying the target type\n * @param <T>\n * \t\ttype of the result\n * @return the converted value if rawValue is of type clazz\n * @throws IllegalArgumentException\n * \t\tif the rawValue cannot be converted in the specified target\n * \t\ttype clazz\n */\n@SuppressWarnings(\"unchecked\")\npublic static <T> T convertValue(Object rawValue, Class<?> clazz) {\n    if (Integer.class.equals(clazz)) {\n        return ((T) (convertToInt(rawValue)));\n    } else if (Long.class.equals(clazz)) {\n        return ((T) (convertToLong(rawValue)));\n    } else if (Boolean.class.equals(clazz)) {\n        return ((T) (convertToBoolean(rawValue)));\n    } else if (Float.class.equals(clazz)) {\n        return ((T) (convertToFloat(rawValue)));\n    } else if (Double.class.equals(clazz)) {\n        return ((T) (convertToDouble(rawValue)));\n    } else if (String.class.equals(clazz)) {\n        return ((T) (convertToString(rawValue)));\n    } else if (clazz.isEnum()) {\n        return ((T) (convertToEnum(rawValue, ((Class<? extends Enum<?>>) (clazz)))));\n    } else if (clazz == Duration.class) {\n        return ((T) (convertToDuration(rawValue)));\n    } else if (clazz == MemorySize.class) {\n        return ((T) (convertToMemorySize(rawValue)));\n    } else if (clazz == Map.class) {\n        return ((T) (convertToProperties(rawValue)));\n    }\n    throw new IllegalArgumentException(\"Unsupported type: \" + clazz);\n}", "static String convertToString(Object o) {\n    if (o.getClass() == String.class) {\n        return ((String) (o));\n    } else {\n        return YamlParserUtils.toYAMLString(o);\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.ConfigurationUtils.parseStringToMap",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.ConfigurationUtils.parseStringToMap", "org.apache.flink.configuration.ConfigurationUtils.convertToProperties", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "/**\n * Parses a string as a map of strings. The expected format of the map to be parsed` by FLINK\n * parser is:\n *\n * <pre>\n * key1:value1,key2:value2\n * </pre>\n *\n * <p>The expected format of the map to be parsed by standard YAML parser is:\n *\n * <pre>\n * {key1: value1, key2: value2}\n * </pre>\n *\n * <p>Parts of the string can be escaped by wrapping with single or double quotes.\n *\n * @param stringSerializedMap\n * \t\ta string to parse\n * @return parsed map\n */\npublic static Map<String, String> parseStringToMap(String stringSerializedMap) {\n    return convertToProperties(stringSerializedMap);\n}", "@SuppressWarnings(\"unchecked\")\nstatic Map<String, String> convertToProperties(Object o) {\n    if (o instanceof Map) {\n        return ((Map<String, String>) (o));\n    } else {\n        try {\n            Map<Object, Object> map = YamlParserUtils.convertToObject(o.toString(), Map.class);\n            return convertToStringMap(map);\n        } catch (Exception e) {\n            // Fallback to legacy pattern\n            return convertToPropertiesWithLegacyPattern(o);\n        }\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.Configuration.toFileWritableMap",
    "thirdPartyMethod" : "org.snakeyaml.engine.v2.api.Dump.<init>",
    "thirdPartyPackage" : "org.snakeyaml.engine.v2.api",
    "path" : [ "org.apache.flink.configuration.Configuration.toFileWritableMap", "org.apache.flink.configuration.YamlParserUtils.<clinit>" ],
    "fullMethods" : [ "/**\n * Convert Config into a {@code Map<String, String>} representation.\n *\n * <p>NOTE: This method is extracted from the {@link Configuration#toMap} method and should be\n * called when Config needs to be written to a file.\n *\n * <p>This method ensures the value is properly escaped when writing the key-value pair to a\n * standard YAML file.\n */\n@Internal\npublic Map<String, String> toFileWritableMap() {\n    synchronized(this.confData) {\n        Map<String, String> ret = CollectionUtil.newHashMapWithExpectedSize(this.confData.size());\n        for (Map.Entry<String, Object> entry : confData.entrySet()) {\n            // Because some character in standard yaml should be escaped by quotes, such as\n            // '*', here we should wrap the value by Yaml pattern\n            ret.put(entry.getKey(), YamlParserUtils.toYAMLString(entry.getValue()));\n        }\n        return ret;\n    }\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractTarFile",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.tar.TarArchiveEntry.isDirectory",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.tar",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractTarFile", "org.apache.flink.util.CompressionUtils.extractTarFileUsingJava", "org.apache.flink.util.CompressionUtils.unpackEntry" ],
    "fullMethods" : [ "public static void extractTarFile(String inFilePath, String targetDirPath) throws IOException {\n    final File targetDir = new File(targetDirPath);\n    if (!targetDir.mkdirs()) {\n        if (!targetDir.isDirectory()) {\n            throw new IOException(\"Mkdirs failed to create \" + targetDir);\n        }\n    }\n    final boolean gzipped = inFilePath.endsWith(\"gz\");\n    if (isUnix()) {\n        extractTarFileUsingTar(inFilePath, targetDirPath, gzipped);\n    } else {\n        extractTarFileUsingJava(inFilePath, targetDirPath, gzipped);\n    }\n}", "// Follow the pattern suggested in\n// https://commons.apache.org/proper/commons-compress/examples.html\nprivate static void extractTarFileUsingJava(String inFilePath, String targetDirPath, boolean gzipped) throws IOException {\n    try (InputStream fi = Files.newInputStream(Paths.get(inFilePath));InputStream bi = new BufferedInputStream(fi);final TarArchiveInputStream tai = new TarArchiveInputStream(gzipped ? new GzipCompressorInputStream(bi) : bi)) {\n        final File targetDir = new File(targetDirPath);\n        TarArchiveEntry entry;\n        while ((entry = tai.getNextTarEntry()) != null) {\n            unpackEntry(tai, entry, targetDir);\n        } \n    }\n}", "private static void unpackEntry(TarArchiveInputStream tis, TarArchiveEntry entry, File targetDir) throws IOException {\n    String targetDirPath = targetDir.getCanonicalPath() + File.separator;\n    File outputFile = new File(targetDir, entry.getName());\n    if (!outputFile.getCanonicalPath().startsWith(targetDirPath)) {\n        throw new IOException(((\"expanding \" + entry.getName()) + \" would create entry outside of \") + targetDir);\n    }\n    if (entry.isDirectory()) {\n        if ((!outputFile.mkdirs()) && (!outputFile.isDirectory())) {\n            throw new IOException(\"Failed to create directory \" + outputFile);\n        }\n        for (TarArchiveEntry e : entry.getDirectoryEntries()) {\n            unpackEntry(tis, e, outputFile);\n        }\n        return;\n    }\n    if (entry.isSymbolicLink()) {\n        // create symbolic link relative to tar parent dir\n        Files.createSymbolicLink(Paths.get(new File(targetDir, entry.getName()).getCanonicalPath()), Paths.get(entry.getLinkName()));\n        return;\n    }\n    if (!outputFile.getParentFile().exists()) {\n        if (!outputFile.getParentFile().mkdirs()) {\n            throw new IOException(\"Mkdirs failed to create tar internal dir \" + targetDir);\n        }\n    }\n    try (OutputStream o = Files.newOutputStream(Paths.get(outputFile.getCanonicalPath()))) {\n        IOUtils.copyBytes(tis, o, false);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.duplicate",
    "thirdPartyMethod" : "org.apache.commons.lang3.exception.CloneFailedException.<init>",
    "thirdPartyPackage" : "org.apache.commons.lang3.exception",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.duplicate", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<init>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.deepCopySerializer" ],
    "fullMethods" : [ "@Override\npublic KryoSerializer<T> duplicate() {\n    return new KryoSerializer<>(this);\n}", "/**\n * Copy-constructor that does not copy transient fields. They will be initialized once required.\n */\nprotected KryoSerializer(KryoSerializer<T> toCopy) {\n    this.type = checkNotNull(toCopy.type, \"Type class cannot be null.\");\n    this.defaultSerializerClasses = toCopy.defaultSerializerClasses;\n    this.defaultSerializers = CollectionUtil.newLinkedHashMapWithExpectedSize(toCopy.defaultSerializers.size());\n    this.kryoRegistrations = CollectionUtil.newLinkedHashMapWithExpectedSize(toCopy.kryoRegistrations.size());\n    // deep copy the serializer instances in defaultSerializers\n    for (Map.Entry<Class<?>, SerializableSerializer<?>> entry : toCopy.defaultSerializers.entrySet()) {\n        this.defaultSerializers.put(entry.getKey(), deepCopySerializer(entry.getValue()));\n    }\n    // deep copy the serializer instances in kryoRegistrations\n    for (Map.Entry<String, KryoRegistration> entry : toCopy.kryoRegistrations.entrySet()) {\n        KryoRegistration kryoRegistration = entry.getValue();\n        if (kryoRegistration.getSerializerDefinitionType() == KryoRegistration.SerializerDefinitionType.INSTANCE) {\n            SerializableSerializer<? extends Serializer<?>> serializerInstance = kryoRegistration.getSerializableSerializerInstance();\n            if (serializerInstance != null) {\n                kryoRegistration = new KryoRegistration(kryoRegistration.getRegisteredClass(), deepCopySerializer(serializerInstance));\n            }\n        }\n        this.kryoRegistrations.put(entry.getKey(), kryoRegistration);\n    }\n}", "private SerializableSerializer<? extends Serializer<?>> deepCopySerializer(SerializableSerializer<? extends Serializer<?>> original) {\n    try {\n        return InstantiationUtil.clone(original, Thread.currentThread().getContextClassLoader());\n    } catch (IOException | ClassNotFoundException ex) {\n        throw new CloneFailedException(\"Could not clone serializer instance of class \" + original.getClass(), ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.common.ExecutionConfig.configure",
    "thirdPartyMethod" : "org.apache.commons.compress.utils.Sets.newHashSet",
    "thirdPartyPackage" : "org.apache.commons.compress.utils",
    "path" : [ "org.apache.flink.api.common.ExecutionConfig.configure", "org.apache.flink.configuration.RestartStrategyOptions.<clinit>", "org.apache.flink.configuration.RestartStrategyOptions.RestartStrategyType.<clinit>" ],
    "fullMethods" : [ "/**\n * Sets all relevant options contained in the {@link ReadableConfig} such as e.g. {@link PipelineOptions#CLOSURE_CLEANER_LEVEL}.\n *\n * <p>It will change the value of a setting only if a corresponding option was set in the {@code configuration}. If a key is not present, the current value of a field will remain untouched.\n *\n * @param configuration\n * \t\ta configuration to read the values from\n * @param classLoader\n * \t\ta class loader to use when loading classes\n */\npublic void configure(ReadableConfig configuration, ClassLoader classLoader) {\n    configuration.getOptional(PipelineOptions.AUTO_GENERATE_UIDS).ifPresent(this::setAutoGeneratedUids);\n    configuration.getOptional(PipelineOptions.AUTO_WATERMARK_INTERVAL).ifPresent(this::setAutoWatermarkInterval);\n    configuration.getOptional(PipelineOptions.CLOSURE_CLEANER_LEVEL).ifPresent(this::setClosureCleanerLevel);\n    configuration.getOptional(PipelineOptions.GLOBAL_JOB_PARAMETERS).ifPresent(this::setGlobalJobParameters);\n    configuration.getOptional(MetricOptions.LATENCY_INTERVAL).ifPresent(interval -> setLatencyTrackingInterval(interval.toMillis()));\n    configuration.getOptional(StateChangelogOptions.PERIODIC_MATERIALIZATION_ENABLED).ifPresent(this::enablePeriodicMaterialize);\n    configuration.getOptional(StateChangelogOptions.PERIODIC_MATERIALIZATION_INTERVAL).ifPresent(this::setPeriodicMaterializeIntervalMillis);\n    configuration.getOptional(StateChangelogOptions.MATERIALIZATION_MAX_FAILURES_ALLOWED).ifPresent(this::setMaterializationMaxAllowedFailures);\n    configuration.getOptional(PipelineOptions.MAX_PARALLELISM).ifPresent(this::setMaxParallelism);\n    configuration.getOptional(CoreOptions.DEFAULT_PARALLELISM).ifPresent(this::setParallelism);\n    configuration.getOptional(PipelineOptions.OBJECT_REUSE).ifPresent(this::setObjectReuse);\n    configuration.getOptional(TaskManagerOptions.TASK_CANCELLATION_INTERVAL).ifPresent(interval -> setTaskCancellationInterval(interval.toMillis()));\n    configuration.getOptional(TaskManagerOptions.TASK_CANCELLATION_TIMEOUT).ifPresent(timeout -> setTaskCancellationTimeout(timeout.toMillis()));\n    configuration.getOptional(ExecutionOptions.SNAPSHOT_COMPRESSION).ifPresent(this::setUseSnapshotCompression);\n    configuration.getOptional(RestartStrategyOptions.RESTART_STRATEGY).ifPresent(s -> this.setRestartStrategy(configuration));\n    configuration.getOptional(JobManagerOptions.SCHEDULER).ifPresent(t -> this.configuration.set(JobManagerOptions.SCHEDULER, t));\n    serializerConfig.configure(configuration, classLoader);\n}", "", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.RestartStrategyOptions.RestartStrategyType.values",
    "thirdPartyMethod" : "org.apache.commons.compress.utils.Sets.newHashSet",
    "thirdPartyPackage" : "org.apache.commons.compress.utils",
    "path" : [ "org.apache.flink.configuration.RestartStrategyOptions.RestartStrategyType.values", "org.apache.flink.configuration.RestartStrategyOptions.RestartStrategyType.<clinit>" ],
    "fullMethods" : [ "{\n    java.lang.Object $stack1;\n    org.apache.flink.configuration.RestartStrategyOptions$RestartStrategyType[] $stack0, $stack2;\n\n\n    $stack0 = <org.apache.flink.configuration.RestartStrategyOptions$RestartStrategyType: org.apache.flink.configuration.RestartStrategyOptions$RestartStrategyType[] $VALUES>;\n    $stack1 = virtualinvoke $stack0.<java.lang.Object: java.lang.Object clone()>();\n    $stack2 = (org.apache.flink.configuration.RestartStrategyOptions$RestartStrategyType[]) $stack1;\n\n    return $stack2;\n}\n", "" ]
  }, {
    "entryPoint" : "org.apache.flink.api.common.RestartStrategyDescriptionUtils.getRestartStrategyDescription",
    "thirdPartyMethod" : "org.apache.commons.compress.utils.Sets.newHashSet",
    "thirdPartyPackage" : "org.apache.commons.compress.utils",
    "path" : [ "org.apache.flink.api.common.RestartStrategyDescriptionUtils.getRestartStrategyDescription", "org.apache.flink.configuration.RestartStrategyOptions.<clinit>", "org.apache.flink.configuration.RestartStrategyOptions.RestartStrategyType.<clinit>" ],
    "fullMethods" : [ "/**\n * Returns a descriptive string of the restart strategy configured in the given Configuration\n * object.\n *\n * @param configuration\n * \t\tthe Configuration to extract the restart strategy from\n * @return a description of the restart strategy\n */\npublic static String getRestartStrategyDescription(Configuration configuration) {\n    final Optional<String> restartStrategyNameOptional = configuration.getOptional(RestartStrategyOptions.RESTART_STRATEGY);\n    return restartStrategyNameOptional.map(restartStrategyName -> {\n        switch (RestartStrategyOptions.RestartStrategyType.of(restartStrategyName.toLowerCase())) {\n            case NO_RESTART_STRATEGY :\n                return \"Restart deactivated.\";\n            case FIXED_DELAY :\n                return getFixedDelayDescription(configuration);\n            case FAILURE_RATE :\n                return getFailureRateDescription(configuration);\n            case EXPONENTIAL_DELAY :\n                return getExponentialDelayDescription(configuration);\n            default :\n                throw new IllegalArgumentException((\"Unknown restart strategy \" + restartStrategyName) + \".\");\n        }\n    }).orElse(\"Cluster level default restart strategy\");\n}", "", "" ]
  }, {
    "entryPoint" : "org.apache.flink.configuration.RestartStrategyOptions.RestartStrategyType.of",
    "thirdPartyMethod" : "org.apache.commons.compress.utils.Sets.newHashSet",
    "thirdPartyPackage" : "org.apache.commons.compress.utils",
    "path" : [ "org.apache.flink.configuration.RestartStrategyOptions.RestartStrategyType.of", "org.apache.flink.configuration.RestartStrategyOptions.RestartStrategyType.<clinit>" ],
    "fullMethods" : [ "/**\n * Return the corresponding RestartStrategyType based on the displayed value.\n */\npublic static RestartStrategyType of(String value) {\n    for (RestartStrategyType restartStrategyType : RestartStrategyType.values()) {\n        if (restartStrategyType.getAllAvailableValues().contains(value)) {\n            return restartStrategyType;\n        }\n    }\n    throw new IllegalArgumentException(String.format(\"%s is an unknown value of RestartStrategyType.\", value));\n}", "" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.serialize",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.io.Output.position",
    "thirdPartyPackage" : "com.esotericsoftware.kryo.io",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.serialize" ],
    "fullMethods" : [ "@Override\npublic void serialize(T record, DataOutputView target) throws IOException {\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        if (target != previousOut) {\n            DataOutputViewStream outputStream = new DataOutputViewStream(target);\n            output = new Output(outputStream);\n            previousOut = target;\n        }\n        // Sanity check: Make sure that the output is cleared/has been flushed by the last call\n        // otherwise data might be written multiple times in case of a previous EOFException\n        if (output.position() != 0) {\n            throw new IllegalStateException(\"The Kryo Output still contains data from a previous \" + \"serialize call. It has to be flushed or cleared at the end of the serialize call.\");\n        }\n        try {\n            kryo.writeClassAndObject(output, record);\n            output.flush();\n        } catch (KryoException ke) {\n            // make sure that the Kryo output buffer is reset in case that we can recover from\n            // the exception (e.g. EOFException which denotes buffer full)\n            output.reset();\n            Throwable cause = ke.getCause();\n            if (cause instanceof EOFException) {\n                throw ((EOFException) (cause));\n            } else {\n                throw ke;\n            }\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.zip.ZipFile.close",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.zip",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions" ],
    "fullMethods" : [ "public static void extractZipFileWithPermissions(String zipFilePath, String targetPath) throws IOException {\n    try (ZipFile zipFile = new ZipFile(zipFilePath)) {\n        Enumeration<ZipArchiveEntry> entries = zipFile.getEntries();\n        boolean isUnix = isUnix();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        String canonicalTargetPath = new File(targetPath).getCanonicalPath() + File.separator;\n        while (entries.hasMoreElements()) {\n            ZipArchiveEntry entry = entries.nextElement();\n            File outputFile = new File(canonicalTargetPath, entry.getName());\n            if (!outputFile.getCanonicalPath().startsWith(canonicalTargetPath)) {\n                throw new IOException(((\"Expand \" + entry.getName()) + \" would create a file outside of \") + targetPath);\n            }\n            if (entry.isDirectory()) {\n                if (!outputFile.exists()) {\n                    if (!outputFile.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n            } else {\n                File parentDir = outputFile.getParentFile();\n                if (!parentDir.exists()) {\n                    if (!parentDir.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n                if (entry.isUnixSymlink()) {\n                    // the content of the file is the target path of the symlink\n                    baos.reset();\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), baos);\n                    Files.createSymbolicLink(outputFile.toPath(), new File(parentDir, baos.toString()).toPath());\n                } else if (outputFile.createNewFile()) {\n                    OutputStream output = new FileOutputStream(outputFile);\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), output);\n                } else {\n                    throw new IOException((\"Create file: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                }\n            }\n            if (isUnix) {\n                int mode = entry.getUnixMode();\n                if (mode != 0) {\n                    Path outputPath = Paths.get(outputFile.toURI());\n                    Set<PosixFilePermission> permissions = new HashSet<>();\n                    addIfBitSet(mode, 8, permissions, PosixFilePermission.OWNER_READ);\n                    addIfBitSet(mode, 7, permissions, PosixFilePermission.OWNER_WRITE);\n                    addIfBitSet(mode, 6, permissions, PosixFilePermission.OWNER_EXECUTE);\n                    addIfBitSet(mode, 5, permissions, PosixFilePermission.GROUP_READ);\n                    addIfBitSet(mode, 4, permissions, PosixFilePermission.GROUP_WRITE);\n                    addIfBitSet(mode, 3, permissions, PosixFilePermission.GROUP_EXECUTE);\n                    addIfBitSet(mode, 2, permissions, PosixFilePermission.OTHERS_READ);\n                    addIfBitSet(mode, 1, permissions, PosixFilePermission.OTHERS_WRITE);\n                    addIfBitSet(mode, 0, permissions, PosixFilePermission.OTHERS_EXECUTE);\n                    // the permission of the target file will be set to be the same as the\n                    // symlink\n                    // TODO: support setting the permission without following links\n                    try {\n                        Files.setPosixFilePermissions(outputPath, permissions);\n                    } catch (NoSuchFileException e) {\n                        // this may happens when the target file of the symlink is still not\n                        // extracted\n                    }\n                }\n            }\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.zip.ZipFile.getEntries",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.zip",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions" ],
    "fullMethods" : [ "public static void extractZipFileWithPermissions(String zipFilePath, String targetPath) throws IOException {\n    try (ZipFile zipFile = new ZipFile(zipFilePath)) {\n        Enumeration<ZipArchiveEntry> entries = zipFile.getEntries();\n        boolean isUnix = isUnix();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        String canonicalTargetPath = new File(targetPath).getCanonicalPath() + File.separator;\n        while (entries.hasMoreElements()) {\n            ZipArchiveEntry entry = entries.nextElement();\n            File outputFile = new File(canonicalTargetPath, entry.getName());\n            if (!outputFile.getCanonicalPath().startsWith(canonicalTargetPath)) {\n                throw new IOException(((\"Expand \" + entry.getName()) + \" would create a file outside of \") + targetPath);\n            }\n            if (entry.isDirectory()) {\n                if (!outputFile.exists()) {\n                    if (!outputFile.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n            } else {\n                File parentDir = outputFile.getParentFile();\n                if (!parentDir.exists()) {\n                    if (!parentDir.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n                if (entry.isUnixSymlink()) {\n                    // the content of the file is the target path of the symlink\n                    baos.reset();\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), baos);\n                    Files.createSymbolicLink(outputFile.toPath(), new File(parentDir, baos.toString()).toPath());\n                } else if (outputFile.createNewFile()) {\n                    OutputStream output = new FileOutputStream(outputFile);\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), output);\n                } else {\n                    throw new IOException((\"Create file: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                }\n            }\n            if (isUnix) {\n                int mode = entry.getUnixMode();\n                if (mode != 0) {\n                    Path outputPath = Paths.get(outputFile.toURI());\n                    Set<PosixFilePermission> permissions = new HashSet<>();\n                    addIfBitSet(mode, 8, permissions, PosixFilePermission.OWNER_READ);\n                    addIfBitSet(mode, 7, permissions, PosixFilePermission.OWNER_WRITE);\n                    addIfBitSet(mode, 6, permissions, PosixFilePermission.OWNER_EXECUTE);\n                    addIfBitSet(mode, 5, permissions, PosixFilePermission.GROUP_READ);\n                    addIfBitSet(mode, 4, permissions, PosixFilePermission.GROUP_WRITE);\n                    addIfBitSet(mode, 3, permissions, PosixFilePermission.GROUP_EXECUTE);\n                    addIfBitSet(mode, 2, permissions, PosixFilePermission.OTHERS_READ);\n                    addIfBitSet(mode, 1, permissions, PosixFilePermission.OTHERS_WRITE);\n                    addIfBitSet(mode, 0, permissions, PosixFilePermission.OTHERS_EXECUTE);\n                    // the permission of the target file will be set to be the same as the\n                    // symlink\n                    // TODO: support setting the permission without following links\n                    try {\n                        Files.setPosixFilePermissions(outputPath, permissions);\n                    } catch (NoSuchFileException e) {\n                        // this may happens when the target file of the symlink is still not\n                        // extracted\n                    }\n                }\n            }\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.read",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.Kryo.getClassLoader",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.read" ],
    "fullMethods" : [ "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n@Override\npublic T read(Kryo kryo, Input input, Class aClass) {\n    try {\n        ObjectMap graphContext = kryo.getGraphContext();\n        ObjectInputStream objectStream = ((ObjectInputStream) (graphContext.get(this)));\n        if (objectStream == null) {\n            // make sure we use Kryo's classloader\n            objectStream = new InstantiationUtil.ClassLoaderObjectInputStream(input, kryo.getClassLoader());\n            graphContext.put(this, objectStream);\n        }\n        return ((T) (objectStream.readObject()));\n    } catch (Exception ex) {\n        throw new KryoException(\"Error during Java deserialization.\", ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.KryoUtils.copy",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.Kryo.copy",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.KryoUtils.copy" ],
    "fullMethods" : [ "/**\n * Tries to copy the given record from using the provided Kryo instance. If this fails, then the\n * record from is copied by serializing it into a byte buffer and deserializing it from there.\n *\n * @param from\n * \t\tElement to copy\n * @param kryo\n * \t\tKryo instance to use\n * @param serializer\n * \t\tTypeSerializer which is used in case of a Kryo failure\n * @param <T>\n * \t\tType of the element to be copied\n * @return Copied element\n */\npublic static <T> T copy(T from, Kryo kryo, TypeSerializer<T> serializer) {\n    try {\n        return kryo.copy(from);\n    } catch (KryoException ke) {\n        // Kryo could not copy the object --> try to serialize/deserialize the object\n        try {\n            byte[] byteArray = InstantiationUtil.serializeToByteArray(serializer, from);\n            return InstantiationUtil.deserializeFromByteArray(serializer, byteArray);\n        } catch (IOException ioe) {\n            throw new RuntimeException(\"Could not copy object by serializing/deserializing\" + \" it.\", ioe);\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.KryoUtils.copy",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.Kryo.copy",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.KryoUtils.copy" ],
    "fullMethods" : [ "/**\n * Tries to copy the given record from using the provided Kryo instance. If this fails, then the\n * record from is copied by serializing it into a byte buffer and deserializing it from there.\n *\n * @param from\n * \t\tElement to copy\n * @param reuse\n * \t\tReuse element for the deserialization\n * @param kryo\n * \t\tKryo instance to use\n * @param serializer\n * \t\tTypeSerializer which is used in case of a Kryo failure\n * @param <T>\n * \t\tType of the element to be copied\n * @return Copied element\n */\npublic static <T> T copy(T from, T reuse, Kryo kryo, TypeSerializer<T> serializer) {\n    try {\n        return kryo.copy(from);\n    } catch (KryoException ke) {\n        // Kryo could not copy the object --> try to serialize/deserialize the object\n        try {\n            byte[] byteArray = InstantiationUtil.serializeToByteArray(serializer, from);\n            return InstantiationUtil.deserializeFromByteArray(serializer, reuse, byteArray);\n        } catch (IOException ioe) {\n            throw new RuntimeException(\"Could not copy object by serializing/deserializing\" + \" it.\", ioe);\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.Kryo.copy",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\n@Override\npublic T copy(T from) {\n    if (from == null) {\n        return null;\n    }\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        try {\n            return kryo.copy(from);\n        } catch (KryoException ke) {\n            // kryo was unable to copy it, so we do it through serialization:\n            ByteArrayOutputStream baout = new ByteArrayOutputStream();\n            Output output = new Output(baout);\n            kryo.writeObject(output, from);\n            output.close();\n            ByteArrayInputStream bain = new ByteArrayInputStream(baout.toByteArray());\n            Input input = new Input(bain);\n            return ((T) (kryo.readObject(input, from.getClass())));\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.<init>",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.io.Input.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.kryo.io",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.<init>" ],
    "fullMethods" : [ "public NoFetchingInput(InputStream inputStream) {\n    super(inputStream, 8);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.common.operators.Keys.ExpressionKeys.toString",
    "thirdPartyMethod" : "org.apache.commons.lang3.StringUtils.join",
    "thirdPartyPackage" : "org.apache.commons.lang3",
    "path" : [ "org.apache.flink.api.common.operators.Keys.ExpressionKeys.toString" ],
    "fullMethods" : [ "@Override\npublic String toString() {\n    return \"ExpressionKeys: \" + StringUtils.join(keyFields, '.');\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.common.io.compression.Bzip2InputStreamFactory.create",
    "thirdPartyMethod" : "org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream.<init>",
    "thirdPartyPackage" : "org.apache.commons.compress.compressors.bzip2",
    "path" : [ "org.apache.flink.api.common.io.compression.Bzip2InputStreamFactory.create" ],
    "fullMethods" : [ "@Override\npublic BZip2CompressorInputStream create(InputStream in) throws IOException {\n    return new BZip2CompressorInputStream(in);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.common.io.compression.XZInputStreamFactory.create",
    "thirdPartyMethod" : "org.apache.commons.compress.compressors.xz.XZCompressorInputStream.<init>",
    "thirdPartyPackage" : "org.apache.commons.compress.compressors.xz",
    "path" : [ "org.apache.flink.api.common.io.compression.XZInputStreamFactory.create" ],
    "fullMethods" : [ "@Override\npublic XZCompressorInputStream create(InputStream in) throws IOException {\n    return new XZCompressorInputStream(in, true);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.ClosureCleaner.clean",
    "thirdPartyMethod" : "org.apache.commons.lang3.ClassUtils.isPrimitiveOrWrapper",
    "thirdPartyPackage" : "org.apache.commons.lang3",
    "path" : [ "org.apache.flink.api.java.ClosureCleaner.clean", "org.apache.flink.api.java.ClosureCleaner.clean" ],
    "fullMethods" : [ "/**\n * Tries to clean the closure of the given object, if the object is a non-static inner class.\n *\n * @param func\n * \t\tThe object whose closure should be cleaned.\n * @param level\n * \t\tthe clean up level.\n * @param checkSerializable\n * \t\tFlag to indicate whether serializability should be checked after the\n * \t\tclosure cleaning attempt.\n * @throws InvalidProgramException\n * \t\tThrown, if 'checkSerializable' is true, and the object was\n * \t\tnot serializable after the closure cleaning.\n * @throws RuntimeException\n * \t\tA RuntimeException may be thrown, if the code of the class could not\n * \t\tbe loaded, in order to process during the closure cleaning.\n */\npublic static void clean(Object func, ExecutionConfig.ClosureCleanerLevel level, boolean checkSerializable) {\n    clean(func, level, checkSerializable, Collections.newSetFromMap(new IdentityHashMap<>()));\n}", "private static void clean(Object func, ExecutionConfig.ClosureCleanerLevel level, boolean checkSerializable, Set<Object> visited) {\n    if (func == null) {\n        return;\n    }\n    if (!visited.add(func)) {\n        return;\n    }\n    final Class<?> cls = func.getClass();\n    if (ClassUtils.isPrimitiveOrWrapper(cls)) {\n        return;\n    }\n    if (usesCustomSerialization(cls)) {\n        return;\n    }\n    if (canBeSerialized(func)) {\n        return;\n    }\n    // serialization failed; try cleaning closure as a fallback\n    // First find the field name of the \"this$0\" field, this can\n    // be \"this$x\" depending on the nesting\n    boolean closureAccessed = false;\n    for (Field f : cls.getDeclaredFields()) {\n        if (f.getName().startsWith(\"this$\")) {\n            // found a closure referencing field - now try to clean\n            closureAccessed |= cleanThis0(func, cls, f.getName());\n        } else {\n            Object fieldObject;\n            try {\n                f.setAccessible(true);\n                fieldObject = f.get(func);\n            } catch (IllegalAccessException e) {\n                throw new RuntimeException(String.format(\"Can not access to the %s field in Class %s\", f.getName(), func.getClass()));\n            }\n            /* we should do a deep clean when we encounter an anonymous class, inner class and local class, but should\n            skip the class with custom serialize method.\n\n            There are five kinds of classes (or interfaces):\n            a) Top level classes\n            b) Nested classes (static member classes)\n            c) Inner classes (non-static member classes)\n            d) Local classes (named classes declared within a method)\n            e) Anonymous classes\n             */\n            if ((level == ExecutionConfig.ClosureCleanerLevel.RECURSIVE) && needsRecursion(f, fieldObject)) {\n                if (LOG.isDebugEnabled()) {\n                    LOG.debug(\"Dig to clean the {}\", fieldObject.getClass().getName());\n                }\n                clean(fieldObject, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true, visited);\n            }\n        }\n    }\n    if (checkSerializable) {\n        try {\n            InstantiationUtil.serializeObject(func);\n        } catch (Exception e) {\n            String functionType = getSuperClassOrInterfaceName(func.getClass());\n            String msg = (functionType == null) ? func + \" is not serializable.\" : (\"The implementation of the \" + functionType) + \" is not serializable.\";\n            if (closureAccessed) {\n                msg += ((\" The implementation accesses fields of its enclosing class, which is \" + \"a common reason for non-serializability. \") + \"A common solution is to make the function a proper (non-inner) class, or \") + \"a static inner class.\";\n            } else {\n                msg += \" The object probably contains or references non serializable fields.\";\n            }\n            throw new InvalidProgramException(msg, e);\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.createInstance",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.createInstance", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.checkKryoInitialized", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@Override\npublic T createInstance() {\n    if (Modifier.isAbstract(type.getModifiers()) || Modifier.isInterface(type.getModifiers())) {\n        return null;\n    } else {\n        checkKryoInitialized();\n        try {\n            return kryo.newInstance(type);\n        } catch (Throwable e) {\n            return null;\n        }\n    }\n}", "private void checkKryoInitialized() {\n    if (this.kryo == null) {\n        this.kryo = getKryoInstance();\n        // Enable reference tracking.\n        kryo.setReferences(true);\n        // Throwable and all subclasses should be serialized via java serialization\n        // Note: the registered JavaSerializer is Flink's own implementation, and not Kryo's.\n        // This is due to a know issue with Kryo's JavaSerializer. See FLINK-6025 for\n        // details.\n        kryo.addDefaultSerializer(Throwable.class, new JavaSerializer());\n        // Add default serializers first, so that the type registrations without a serializer\n        // are registered with a default serializer\n        for (Map.Entry<Class<?>, SerializableSerializer<?>> entry : defaultSerializers.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue().getSerializer());\n        }\n        for (Map.Entry<Class<?>, Class<? extends Serializer<?>>> entry : defaultSerializerClasses.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue());\n        }\n        KryoUtils.applyRegistrations(this.kryo, kryoRegistrations.values(), flinkChillPackageRegistrar != null ? flinkChillPackageRegistrar.getNextRegistrationId() : kryo.getNextRegistrationId());\n        kryo.setRegistrationRequired(false);\n        kryo.setClassLoader(Thread.currentThread().getContextClassLoader());\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@Override\npublic TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(TypeSerializerSnapshot<T> oldSerializerSnapshot) {\n    if (!(oldSerializerSnapshot instanceof KryoSerializerSnapshot)) {\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    KryoSerializerSnapshot<T> oldKryoSerializerSnapshot = ((KryoSerializerSnapshot<T>) (oldSerializerSnapshot));\n    if (snapshotData.getTypeClass() != oldKryoSerializerSnapshot.snapshotData.getTypeClass()) {\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    return resolveSchemaCompatibility(oldKryoSerializerSnapshot);\n}", "private TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(KryoSerializerSnapshot<T> oldKryoSerializerSnapshot) {\n    // merge the default serializers\n    final MergeResult<Class<?>, SerializableSerializer<?>> reconfiguredDefaultKryoSerializers = mergeRightIntoLeft(oldKryoSerializerSnapshot.snapshotData.getDefaultKryoSerializers(), snapshotData.getDefaultKryoSerializers());\n    if (reconfiguredDefaultKryoSerializers.hasMissingKeys()) {\n        logMissingKeys(reconfiguredDefaultKryoSerializers);\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    // merge default serializer classes\n    final MergeResult<Class<?>, Class<? extends Serializer<?>>> reconfiguredDefaultKryoSerializerClasses = mergeRightIntoLeft(oldKryoSerializerSnapshot.snapshotData.getDefaultKryoSerializerClasses(), snapshotData.getDefaultKryoSerializerClasses());\n    if (reconfiguredDefaultKryoSerializerClasses.hasMissingKeys()) {\n        logMissingKeys(reconfiguredDefaultKryoSerializerClasses);\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    // merge registration\n    final MergeResult<String, KryoRegistration> reconfiguredRegistrations = mergeRightIntoLeft(oldKryoSerializerSnapshot.snapshotData.getKryoRegistrations(), snapshotData.getKryoRegistrations());\n    if (reconfiguredRegistrations.hasMissingKeys()) {\n        logMissingKeys(reconfiguredRegistrations);\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    // there are no missing keys, now we have to decide whether we are compatible as-is or we\n    // require reconfiguration.\n    return resolveSchemaCompatibility(reconfiguredDefaultKryoSerializers, reconfiguredDefaultKryoSerializerClasses, reconfiguredRegistrations);\n}", "private TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(MergeResult<Class<?>, SerializableSerializer<?>> reconfiguredDefaultKryoSerializers, MergeResult<Class<?>, Class<? extends Serializer<?>>> reconfiguredDefaultKryoSerializerClasses, MergeResult<String, KryoRegistration> reconfiguredRegistrations) {\n    if ((reconfiguredDefaultKryoSerializers.isOrderedSubset() && reconfiguredDefaultKryoSerializerClasses.isOrderedSubset()) && reconfiguredRegistrations.isOrderedSubset()) {\n        return TypeSerializerSchemaCompatibility.compatibleAsIs();\n    }\n    // reconfigure a new KryoSerializer\n    KryoSerializer<T> reconfiguredSerializer = new KryoSerializer<>(snapshotData.getTypeClass(), reconfiguredDefaultKryoSerializers.getMerged(), reconfiguredDefaultKryoSerializerClasses.getMerged(), reconfiguredRegistrations.getMerged());\n    return TypeSerializerSchemaCompatibility.compatibleWithReconfiguredSerializer(reconfiguredSerializer);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<init>",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<init>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "// ------------------------------------------------------------------------\npublic KryoSerializer(Class<T> type, SerializerConfig serializerConfig) {\n    this.type = checkNotNull(type);\n    this.defaultSerializers = ((SerializerConfigImpl) (serializerConfig)).getDefaultKryoSerializers();\n    this.defaultSerializerClasses = serializerConfig.getDefaultKryoSerializerClasses();\n    this.kryoRegistrations = buildKryoRegistrations(this.type, serializerConfig.getRegisteredKryoTypes(), serializerConfig.getRegisteredTypesWithKryoSerializerClasses(), ((SerializerConfigImpl) (serializerConfig)).getRegisteredTypesWithKryoSerializers(), serializerConfig.isForceKryoAvroEnabled());\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.restoreSerializer",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.restoreSerializer", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@Override\npublic TypeSerializer<T> restoreSerializer() {\n    return new KryoSerializer<>(snapshotData.getTypeClass(), snapshotData.getDefaultKryoSerializers().unwrapOptionals(), snapshotData.getDefaultKryoSerializerClasses().unwrapOptionals(), snapshotData.getKryoRegistrations().unwrapOptionals());\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@Override\npublic void copy(DataInputView source, DataOutputView target) throws IOException {\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        if (this.copyInstance == null) {\n            this.copyInstance = createInstance();\n        }\n        T tmp = deserialize(copyInstance, source);\n        serialize(tmp, target);\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.deserialize",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.deserialize", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\n@Override\npublic T deserialize(DataInputView source) throws IOException {\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        if (source != previousIn) {\n            DataInputViewStream inputStream = new DataInputViewStream(source);\n            input = new NoFetchingInput(inputStream);\n            previousIn = source;\n        }\n        try {\n            return ((T) (kryo.readClassAndObject(input)));\n        } catch (KryoBufferUnderflowException ke) {\n            // 2023-04-26: Existing Flink code expects a java.io.EOFException in this scenario\n            throw new EOFException(ke.getMessage());\n        } catch (KryoException ke) {\n            Throwable cause = ke.getCause();\n            if (cause instanceof EOFException) {\n                throw ((EOFException) (cause));\n            } else {\n                throw ke;\n            }\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.PojoTypeInfo.createSerializer",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.PojoTypeInfo.createSerializer", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@Override\n@PublicEvolving\n@SuppressWarnings(\"unchecked\")\npublic TypeSerializer<T> createSerializer(SerializerConfig config) {\n    if (config.isForceKryoEnabled()) {\n        return new KryoSerializer<>(getTypeClass(), config);\n    }\n    if (config.isForceAvroEnabled()) {\n        return AvroUtils.getAvroUtils().createAvroSerializer(getTypeClass());\n    }\n    return createPojoSerializer(config);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.GenericTypeInfo.createSerializer",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.GenericTypeInfo.createSerializer", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@Override\n@PublicEvolving\npublic TypeSerializer<T> createSerializer(SerializerConfig config) {\n    if (config.hasGenericTypesDisabled()) {\n        throw new UnsupportedOperationException((\"Generic types have been disabled in the ExecutionConfig and type \" + this.typeClass.getName()) + \" is treated as a generic type.\");\n    }\n    return new KryoSerializer<T>(this.typeClass, config);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.serialize",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.serialize", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@Override\npublic void serialize(T record, DataOutputView target) throws IOException {\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        if (target != previousOut) {\n            DataOutputViewStream outputStream = new DataOutputViewStream(target);\n            output = new Output(outputStream);\n            previousOut = target;\n        }\n        // Sanity check: Make sure that the output is cleared/has been flushed by the last call\n        // otherwise data might be written multiple times in case of a previous EOFException\n        if (output.position() != 0) {\n            throw new IllegalStateException(\"The Kryo Output still contains data from a previous \" + \"serialize call. It has to be flushed or cleared at the end of the serialize call.\");\n        }\n        try {\n            kryo.writeClassAndObject(output, record);\n            output.flush();\n        } catch (KryoException ke) {\n            // make sure that the Kryo output buffer is reset in case that we can recover from\n            // the exception (e.g. EOFException which denotes buffer full)\n            output.reset();\n            Throwable cause = ke.getCause();\n            if (cause instanceof EOFException) {\n                throw ((EOFException) (cause));\n            } else {\n                throw ke;\n            }\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\n@Override\npublic T copy(T from) {\n    if (from == null) {\n        return null;\n    }\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        try {\n            return kryo.copy(from);\n        } catch (KryoException ke) {\n            // kryo was unable to copy it, so we do it through serialization:\n            ByteArrayOutputStream baout = new ByteArrayOutputStream();\n            Output output = new Output(baout);\n            kryo.writeObject(output, from);\n            output.close();\n            ByteArrayInputStream bain = new ByteArrayInputStream(baout.toByteArray());\n            Input input = new Input(bain);\n            return ((T) (kryo.readObject(input, from.getClass())));\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.getKryo",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.getKryo", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.checkKryoInitialized", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@VisibleForTesting\npublic Kryo getKryo() {\n    checkKryoInitialized();\n    return this.kryo;\n}", "private void checkKryoInitialized() {\n    if (this.kryo == null) {\n        this.kryo = getKryoInstance();\n        // Enable reference tracking.\n        kryo.setReferences(true);\n        // Throwable and all subclasses should be serialized via java serialization\n        // Note: the registered JavaSerializer is Flink's own implementation, and not Kryo's.\n        // This is due to a know issue with Kryo's JavaSerializer. See FLINK-6025 for\n        // details.\n        kryo.addDefaultSerializer(Throwable.class, new JavaSerializer());\n        // Add default serializers first, so that the type registrations without a serializer\n        // are registered with a default serializer\n        for (Map.Entry<Class<?>, SerializableSerializer<?>> entry : defaultSerializers.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue().getSerializer());\n        }\n        for (Map.Entry<Class<?>, Class<? extends Serializer<?>>> entry : defaultSerializerClasses.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue());\n        }\n        KryoUtils.applyRegistrations(this.kryo, kryoRegistrations.values(), flinkChillPackageRegistrar != null ? flinkChillPackageRegistrar.getNextRegistrationId() : kryo.getNextRegistrationId());\n        kryo.setRegistrationRequired(false);\n        kryo.setClassLoader(Thread.currentThread().getContextClassLoader());\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.duplicate",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.Logger.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.minlog.Log",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.duplicate", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging", "org.apache.flink.api.java.typeutils.runtime.kryo.MinlogForwarder.<init>" ],
    "fullMethods" : [ "@Override\npublic KryoSerializer<T> duplicate() {\n    return new KryoSerializer<>(this);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}", "MinlogForwarder(Logger log) {\n    this.log = checkNotNull(log);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractTarFile",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.tar.TarArchiveEntry.getDirectoryEntries",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.tar",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractTarFile", "org.apache.flink.util.CompressionUtils.extractTarFileUsingJava", "org.apache.flink.util.CompressionUtils.unpackEntry" ],
    "fullMethods" : [ "public static void extractTarFile(String inFilePath, String targetDirPath) throws IOException {\n    final File targetDir = new File(targetDirPath);\n    if (!targetDir.mkdirs()) {\n        if (!targetDir.isDirectory()) {\n            throw new IOException(\"Mkdirs failed to create \" + targetDir);\n        }\n    }\n    final boolean gzipped = inFilePath.endsWith(\"gz\");\n    if (isUnix()) {\n        extractTarFileUsingTar(inFilePath, targetDirPath, gzipped);\n    } else {\n        extractTarFileUsingJava(inFilePath, targetDirPath, gzipped);\n    }\n}", "// Follow the pattern suggested in\n// https://commons.apache.org/proper/commons-compress/examples.html\nprivate static void extractTarFileUsingJava(String inFilePath, String targetDirPath, boolean gzipped) throws IOException {\n    try (InputStream fi = Files.newInputStream(Paths.get(inFilePath));InputStream bi = new BufferedInputStream(fi);final TarArchiveInputStream tai = new TarArchiveInputStream(gzipped ? new GzipCompressorInputStream(bi) : bi)) {\n        final File targetDir = new File(targetDirPath);\n        TarArchiveEntry entry;\n        while ((entry = tai.getNextTarEntry()) != null) {\n            unpackEntry(tai, entry, targetDir);\n        } \n    }\n}", "private static void unpackEntry(TarArchiveInputStream tis, TarArchiveEntry entry, File targetDir) throws IOException {\n    String targetDirPath = targetDir.getCanonicalPath() + File.separator;\n    File outputFile = new File(targetDir, entry.getName());\n    if (!outputFile.getCanonicalPath().startsWith(targetDirPath)) {\n        throw new IOException(((\"expanding \" + entry.getName()) + \" would create entry outside of \") + targetDir);\n    }\n    if (entry.isDirectory()) {\n        if ((!outputFile.mkdirs()) && (!outputFile.isDirectory())) {\n            throw new IOException(\"Failed to create directory \" + outputFile);\n        }\n        for (TarArchiveEntry e : entry.getDirectoryEntries()) {\n            unpackEntry(tis, e, outputFile);\n        }\n        return;\n    }\n    if (entry.isSymbolicLink()) {\n        // create symbolic link relative to tar parent dir\n        Files.createSymbolicLink(Paths.get(new File(targetDir, entry.getName()).getCanonicalPath()), Paths.get(entry.getLinkName()));\n        return;\n    }\n    if (!outputFile.getParentFile().exists()) {\n        if (!outputFile.getParentFile().mkdirs()) {\n            throw new IOException(\"Mkdirs failed to create tar internal dir \" + targetDir);\n        }\n    }\n    try (OutputStream o = Files.newOutputStream(Paths.get(outputFile.getCanonicalPath()))) {\n        IOUtils.copyBytes(tis, o, false);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.common.operators.util.JoinHashMap.insertOrReplace",
    "thirdPartyMethod" : "org.apache.commons.collections.map.AbstractHashedMap.HashEntry.setValue",
    "thirdPartyPackage" : "org.apache.commons.collections.map.AbstractHashedMap",
    "path" : [ "org.apache.flink.api.common.operators.util.JoinHashMap.insertOrReplace" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\npublic void insertOrReplace(BT record) {\n    int hashCode = hash(buildComparator.hash(record));\n    int index = hashIndex(hashCode, data.length);\n    buildComparator.setReference(record);\n    HashEntry entry = data[index];\n    while (entry != null) {\n        if ((entryHashCode(entry) == hashCode) && buildComparator.equalToReference(((BT) (entry.getValue())))) {\n            entry.setValue(record);\n            return;\n        }\n        entry = entryNext(entry);\n    } \n    addMapping(index, hashCode, null, record);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.read",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.KryoException.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.read" ],
    "fullMethods" : [ "@Override\npublic int read(byte[] bytes, int offset, int count) throws KryoException {\n    if (bytes == null) {\n        throw new IllegalArgumentException(\"bytes cannot be null.\");\n    }\n    try {\n        return inputStream.read(bytes, offset, count);\n    } catch (IOException ex) {\n        throw new KryoException(ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.readBytes",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.KryoException.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.readBytes" ],
    "fullMethods" : [ "@Override\npublic void readBytes(byte[] bytes, int offset, int count) throws KryoException {\n    if (bytes == null) {\n        throw new IllegalArgumentException(\"bytes cannot be null.\");\n    }\n    if (count == 0) {\n        return;\n    }\n    try {\n        int bytesRead = 0;\n        int c;\n        while (true) {\n            c = inputStream.read(bytes, offset + bytesRead, count - bytesRead);\n            if (c == (-1)) {\n                throw new KryoException(new EOFException(\"No more bytes left.\"));\n            }\n            bytesRead += c;\n            if (bytesRead == count) {\n                break;\n            }\n        } \n    } catch (IOException ex) {\n        throw new KryoException(ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.skip",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.KryoException.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.NoFetchingInput.skip" ],
    "fullMethods" : [ "@Override\npublic void skip(int count) throws KryoException {\n    try {\n        inputStream.skip(count);\n    } catch (IOException ex) {\n        throw new KryoException(ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.zip.ZipArchiveEntry.getName",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.zip",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions" ],
    "fullMethods" : [ "public static void extractZipFileWithPermissions(String zipFilePath, String targetPath) throws IOException {\n    try (ZipFile zipFile = new ZipFile(zipFilePath)) {\n        Enumeration<ZipArchiveEntry> entries = zipFile.getEntries();\n        boolean isUnix = isUnix();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        String canonicalTargetPath = new File(targetPath).getCanonicalPath() + File.separator;\n        while (entries.hasMoreElements()) {\n            ZipArchiveEntry entry = entries.nextElement();\n            File outputFile = new File(canonicalTargetPath, entry.getName());\n            if (!outputFile.getCanonicalPath().startsWith(canonicalTargetPath)) {\n                throw new IOException(((\"Expand \" + entry.getName()) + \" would create a file outside of \") + targetPath);\n            }\n            if (entry.isDirectory()) {\n                if (!outputFile.exists()) {\n                    if (!outputFile.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n            } else {\n                File parentDir = outputFile.getParentFile();\n                if (!parentDir.exists()) {\n                    if (!parentDir.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n                if (entry.isUnixSymlink()) {\n                    // the content of the file is the target path of the symlink\n                    baos.reset();\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), baos);\n                    Files.createSymbolicLink(outputFile.toPath(), new File(parentDir, baos.toString()).toPath());\n                } else if (outputFile.createNewFile()) {\n                    OutputStream output = new FileOutputStream(outputFile);\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), output);\n                } else {\n                    throw new IOException((\"Create file: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                }\n            }\n            if (isUnix) {\n                int mode = entry.getUnixMode();\n                if (mode != 0) {\n                    Path outputPath = Paths.get(outputFile.toURI());\n                    Set<PosixFilePermission> permissions = new HashSet<>();\n                    addIfBitSet(mode, 8, permissions, PosixFilePermission.OWNER_READ);\n                    addIfBitSet(mode, 7, permissions, PosixFilePermission.OWNER_WRITE);\n                    addIfBitSet(mode, 6, permissions, PosixFilePermission.OWNER_EXECUTE);\n                    addIfBitSet(mode, 5, permissions, PosixFilePermission.GROUP_READ);\n                    addIfBitSet(mode, 4, permissions, PosixFilePermission.GROUP_WRITE);\n                    addIfBitSet(mode, 3, permissions, PosixFilePermission.GROUP_EXECUTE);\n                    addIfBitSet(mode, 2, permissions, PosixFilePermission.OTHERS_READ);\n                    addIfBitSet(mode, 1, permissions, PosixFilePermission.OTHERS_WRITE);\n                    addIfBitSet(mode, 0, permissions, PosixFilePermission.OTHERS_EXECUTE);\n                    // the permission of the target file will be set to be the same as the\n                    // symlink\n                    // TODO: support setting the permission without following links\n                    try {\n                        Files.setPosixFilePermissions(outputPath, permissions);\n                    } catch (NoSuchFileException e) {\n                        // this may happens when the target file of the symlink is still not\n                        // extracted\n                    }\n                }\n            }\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractTarFile",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.tar.TarArchiveInputStream.<init>",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.tar",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractTarFile", "org.apache.flink.util.CompressionUtils.extractTarFileUsingJava" ],
    "fullMethods" : [ "public static void extractTarFile(String inFilePath, String targetDirPath) throws IOException {\n    final File targetDir = new File(targetDirPath);\n    if (!targetDir.mkdirs()) {\n        if (!targetDir.isDirectory()) {\n            throw new IOException(\"Mkdirs failed to create \" + targetDir);\n        }\n    }\n    final boolean gzipped = inFilePath.endsWith(\"gz\");\n    if (isUnix()) {\n        extractTarFileUsingTar(inFilePath, targetDirPath, gzipped);\n    } else {\n        extractTarFileUsingJava(inFilePath, targetDirPath, gzipped);\n    }\n}", "// Follow the pattern suggested in\n// https://commons.apache.org/proper/commons-compress/examples.html\nprivate static void extractTarFileUsingJava(String inFilePath, String targetDirPath, boolean gzipped) throws IOException {\n    try (InputStream fi = Files.newInputStream(Paths.get(inFilePath));InputStream bi = new BufferedInputStream(fi);final TarArchiveInputStream tai = new TarArchiveInputStream(gzipped ? new GzipCompressorInputStream(bi) : bi)) {\n        final File targetDir = new File(targetDirPath);\n        TarArchiveEntry entry;\n        while ((entry = tai.getNextTarEntry()) != null) {\n            unpackEntry(tai, entry, targetDir);\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.zip.ZipFile.<init>",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.zip",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions" ],
    "fullMethods" : [ "public static void extractZipFileWithPermissions(String zipFilePath, String targetPath) throws IOException {\n    try (ZipFile zipFile = new ZipFile(zipFilePath)) {\n        Enumeration<ZipArchiveEntry> entries = zipFile.getEntries();\n        boolean isUnix = isUnix();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        String canonicalTargetPath = new File(targetPath).getCanonicalPath() + File.separator;\n        while (entries.hasMoreElements()) {\n            ZipArchiveEntry entry = entries.nextElement();\n            File outputFile = new File(canonicalTargetPath, entry.getName());\n            if (!outputFile.getCanonicalPath().startsWith(canonicalTargetPath)) {\n                throw new IOException(((\"Expand \" + entry.getName()) + \" would create a file outside of \") + targetPath);\n            }\n            if (entry.isDirectory()) {\n                if (!outputFile.exists()) {\n                    if (!outputFile.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n            } else {\n                File parentDir = outputFile.getParentFile();\n                if (!parentDir.exists()) {\n                    if (!parentDir.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n                if (entry.isUnixSymlink()) {\n                    // the content of the file is the target path of the symlink\n                    baos.reset();\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), baos);\n                    Files.createSymbolicLink(outputFile.toPath(), new File(parentDir, baos.toString()).toPath());\n                } else if (outputFile.createNewFile()) {\n                    OutputStream output = new FileOutputStream(outputFile);\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), output);\n                } else {\n                    throw new IOException((\"Create file: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                }\n            }\n            if (isUnix) {\n                int mode = entry.getUnixMode();\n                if (mode != 0) {\n                    Path outputPath = Paths.get(outputFile.toURI());\n                    Set<PosixFilePermission> permissions = new HashSet<>();\n                    addIfBitSet(mode, 8, permissions, PosixFilePermission.OWNER_READ);\n                    addIfBitSet(mode, 7, permissions, PosixFilePermission.OWNER_WRITE);\n                    addIfBitSet(mode, 6, permissions, PosixFilePermission.OWNER_EXECUTE);\n                    addIfBitSet(mode, 5, permissions, PosixFilePermission.GROUP_READ);\n                    addIfBitSet(mode, 4, permissions, PosixFilePermission.GROUP_WRITE);\n                    addIfBitSet(mode, 3, permissions, PosixFilePermission.GROUP_EXECUTE);\n                    addIfBitSet(mode, 2, permissions, PosixFilePermission.OTHERS_READ);\n                    addIfBitSet(mode, 1, permissions, PosixFilePermission.OTHERS_WRITE);\n                    addIfBitSet(mode, 0, permissions, PosixFilePermission.OTHERS_EXECUTE);\n                    // the permission of the target file will be set to be the same as the\n                    // symlink\n                    // TODO: support setting the permission without following links\n                    try {\n                        Files.setPosixFilePermissions(outputPath, permissions);\n                    } catch (NoSuchFileException e) {\n                        // this may happens when the target file of the symlink is still not\n                        // extracted\n                    }\n                }\n            }\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.<init>",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.Serializer.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.<init>" ],
    "fullMethods" : [ "public JavaSerializer() {\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.Serializers.DummyAvroKryoSerializerClass.<init>",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.Serializer.<init>",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.Serializers.DummyAvroKryoSerializerClass.<init>" ],
    "fullMethods" : [ "DummyAvroKryoSerializerClass() {\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractTarFile",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.tar.TarArchiveEntry.getLinkName",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.tar",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractTarFile", "org.apache.flink.util.CompressionUtils.extractTarFileUsingJava", "org.apache.flink.util.CompressionUtils.unpackEntry" ],
    "fullMethods" : [ "public static void extractTarFile(String inFilePath, String targetDirPath) throws IOException {\n    final File targetDir = new File(targetDirPath);\n    if (!targetDir.mkdirs()) {\n        if (!targetDir.isDirectory()) {\n            throw new IOException(\"Mkdirs failed to create \" + targetDir);\n        }\n    }\n    final boolean gzipped = inFilePath.endsWith(\"gz\");\n    if (isUnix()) {\n        extractTarFileUsingTar(inFilePath, targetDirPath, gzipped);\n    } else {\n        extractTarFileUsingJava(inFilePath, targetDirPath, gzipped);\n    }\n}", "// Follow the pattern suggested in\n// https://commons.apache.org/proper/commons-compress/examples.html\nprivate static void extractTarFileUsingJava(String inFilePath, String targetDirPath, boolean gzipped) throws IOException {\n    try (InputStream fi = Files.newInputStream(Paths.get(inFilePath));InputStream bi = new BufferedInputStream(fi);final TarArchiveInputStream tai = new TarArchiveInputStream(gzipped ? new GzipCompressorInputStream(bi) : bi)) {\n        final File targetDir = new File(targetDirPath);\n        TarArchiveEntry entry;\n        while ((entry = tai.getNextTarEntry()) != null) {\n            unpackEntry(tai, entry, targetDir);\n        } \n    }\n}", "private static void unpackEntry(TarArchiveInputStream tis, TarArchiveEntry entry, File targetDir) throws IOException {\n    String targetDirPath = targetDir.getCanonicalPath() + File.separator;\n    File outputFile = new File(targetDir, entry.getName());\n    if (!outputFile.getCanonicalPath().startsWith(targetDirPath)) {\n        throw new IOException(((\"expanding \" + entry.getName()) + \" would create entry outside of \") + targetDir);\n    }\n    if (entry.isDirectory()) {\n        if ((!outputFile.mkdirs()) && (!outputFile.isDirectory())) {\n            throw new IOException(\"Failed to create directory \" + outputFile);\n        }\n        for (TarArchiveEntry e : entry.getDirectoryEntries()) {\n            unpackEntry(tis, e, outputFile);\n        }\n        return;\n    }\n    if (entry.isSymbolicLink()) {\n        // create symbolic link relative to tar parent dir\n        Files.createSymbolicLink(Paths.get(new File(targetDir, entry.getName()).getCanonicalPath()), Paths.get(entry.getLinkName()));\n        return;\n    }\n    if (!outputFile.getParentFile().exists()) {\n        if (!outputFile.getParentFile().mkdirs()) {\n            throw new IOException(\"Mkdirs failed to create tar internal dir \" + targetDir);\n        }\n    }\n    try (OutputStream o = Files.newOutputStream(Paths.get(outputFile.getCanonicalPath()))) {\n        IOUtils.copyBytes(tis, o, false);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.read",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.util.ObjectMap.put",
    "thirdPartyPackage" : "com.esotericsoftware.kryo.util",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.read" ],
    "fullMethods" : [ "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n@Override\npublic T read(Kryo kryo, Input input, Class aClass) {\n    try {\n        ObjectMap graphContext = kryo.getGraphContext();\n        ObjectInputStream objectStream = ((ObjectInputStream) (graphContext.get(this)));\n        if (objectStream == null) {\n            // make sure we use Kryo's classloader\n            objectStream = new InstantiationUtil.ClassLoaderObjectInputStream(input, kryo.getClassLoader());\n            graphContext.put(this, objectStream);\n        }\n        return ((T) (objectStream.readObject()));\n    } catch (Exception ex) {\n        throw new KryoException(\"Error during Java deserialization.\", ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.write",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.util.ObjectMap.put",
    "thirdPartyPackage" : "com.esotericsoftware.kryo.util",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.write" ],
    "fullMethods" : [ "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n@Override\npublic void write(Kryo kryo, Output output, T o) {\n    try {\n        ObjectMap graphContext = kryo.getGraphContext();\n        ObjectOutputStream objectStream = ((ObjectOutputStream) (graphContext.get(this)));\n        if (objectStream == null) {\n            objectStream = new ObjectOutputStream(output);\n            graphContext.put(this, objectStream);\n        }\n        objectStream.writeObject(o);\n        objectStream.flush();\n    } catch (Exception ex) {\n        throw new KryoException(\"Error during Java serialization.\", ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.common.operators.util.JoinHashMap.Prober.lookupMatch",
    "thirdPartyMethod" : "org.apache.commons.collections.map.AbstractHashedMap.HashEntry.getValue",
    "thirdPartyPackage" : "org.apache.commons.collections.map.AbstractHashedMap",
    "path" : [ "org.apache.flink.api.common.operators.util.JoinHashMap.Prober.lookupMatch" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\npublic BT lookupMatch(PT record) {\n    int hashCode = hash(probeComparator.hash(record));\n    int index = hashIndex(hashCode, data.length);\n    pairComparator.setReference(record);\n    HashEntry entry = data[index];\n    while (entry != null) {\n        if ((entryHashCode(entry) == hashCode) && pairComparator.equalToReference(((BT) (entry.getValue())))) {\n            return ((BT) (entry.getValue()));\n        }\n        entry = entryNext(entry);\n    } \n    return null;\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.common.operators.util.JoinHashMap.insertOrReplace",
    "thirdPartyMethod" : "org.apache.commons.collections.map.AbstractHashedMap.HashEntry.getValue",
    "thirdPartyPackage" : "org.apache.commons.collections.map.AbstractHashedMap",
    "path" : [ "org.apache.flink.api.common.operators.util.JoinHashMap.insertOrReplace" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\npublic void insertOrReplace(BT record) {\n    int hashCode = hash(buildComparator.hash(record));\n    int index = hashIndex(hashCode, data.length);\n    buildComparator.setReference(record);\n    HashEntry entry = data[index];\n    while (entry != null) {\n        if ((entryHashCode(entry) == hashCode) && buildComparator.equalToReference(((BT) (entry.getValue())))) {\n            entry.setValue(record);\n            return;\n        }\n        entry = entryNext(entry);\n    } \n    addMapping(index, hashCode, null, record);\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.read",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.Kryo.getGraphContext",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.read" ],
    "fullMethods" : [ "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n@Override\npublic T read(Kryo kryo, Input input, Class aClass) {\n    try {\n        ObjectMap graphContext = kryo.getGraphContext();\n        ObjectInputStream objectStream = ((ObjectInputStream) (graphContext.get(this)));\n        if (objectStream == null) {\n            // make sure we use Kryo's classloader\n            objectStream = new InstantiationUtil.ClassLoaderObjectInputStream(input, kryo.getClassLoader());\n            graphContext.put(this, objectStream);\n        }\n        return ((T) (objectStream.readObject()));\n    } catch (Exception ex) {\n        throw new KryoException(\"Error during Java deserialization.\", ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.write",
    "thirdPartyMethod" : "com.esotericsoftware.kryo.Kryo.getGraphContext",
    "thirdPartyPackage" : "com.esotericsoftware.kryo",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.JavaSerializer.write" ],
    "fullMethods" : [ "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n@Override\npublic void write(Kryo kryo, Output output, T o) {\n    try {\n        ObjectMap graphContext = kryo.getGraphContext();\n        ObjectOutputStream objectStream = ((ObjectOutputStream) (graphContext.get(this)));\n        if (objectStream == null) {\n            objectStream = new ObjectOutputStream(output);\n            graphContext.put(this, objectStream);\n        }\n        objectStream.writeObject(o);\n        objectStream.flush();\n    } catch (Exception ex) {\n        throw new KryoException(\"Error during Java serialization.\", ex);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractTarFile",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.tar.TarArchiveEntry.isSymbolicLink",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.tar",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractTarFile", "org.apache.flink.util.CompressionUtils.extractTarFileUsingJava", "org.apache.flink.util.CompressionUtils.unpackEntry" ],
    "fullMethods" : [ "public static void extractTarFile(String inFilePath, String targetDirPath) throws IOException {\n    final File targetDir = new File(targetDirPath);\n    if (!targetDir.mkdirs()) {\n        if (!targetDir.isDirectory()) {\n            throw new IOException(\"Mkdirs failed to create \" + targetDir);\n        }\n    }\n    final boolean gzipped = inFilePath.endsWith(\"gz\");\n    if (isUnix()) {\n        extractTarFileUsingTar(inFilePath, targetDirPath, gzipped);\n    } else {\n        extractTarFileUsingJava(inFilePath, targetDirPath, gzipped);\n    }\n}", "// Follow the pattern suggested in\n// https://commons.apache.org/proper/commons-compress/examples.html\nprivate static void extractTarFileUsingJava(String inFilePath, String targetDirPath, boolean gzipped) throws IOException {\n    try (InputStream fi = Files.newInputStream(Paths.get(inFilePath));InputStream bi = new BufferedInputStream(fi);final TarArchiveInputStream tai = new TarArchiveInputStream(gzipped ? new GzipCompressorInputStream(bi) : bi)) {\n        final File targetDir = new File(targetDirPath);\n        TarArchiveEntry entry;\n        while ((entry = tai.getNextTarEntry()) != null) {\n            unpackEntry(tai, entry, targetDir);\n        } \n    }\n}", "private static void unpackEntry(TarArchiveInputStream tis, TarArchiveEntry entry, File targetDir) throws IOException {\n    String targetDirPath = targetDir.getCanonicalPath() + File.separator;\n    File outputFile = new File(targetDir, entry.getName());\n    if (!outputFile.getCanonicalPath().startsWith(targetDirPath)) {\n        throw new IOException(((\"expanding \" + entry.getName()) + \" would create entry outside of \") + targetDir);\n    }\n    if (entry.isDirectory()) {\n        if ((!outputFile.mkdirs()) && (!outputFile.isDirectory())) {\n            throw new IOException(\"Failed to create directory \" + outputFile);\n        }\n        for (TarArchiveEntry e : entry.getDirectoryEntries()) {\n            unpackEntry(tis, e, outputFile);\n        }\n        return;\n    }\n    if (entry.isSymbolicLink()) {\n        // create symbolic link relative to tar parent dir\n        Files.createSymbolicLink(Paths.get(new File(targetDir, entry.getName()).getCanonicalPath()), Paths.get(entry.getLinkName()));\n        return;\n    }\n    if (!outputFile.getParentFile().exists()) {\n        if (!outputFile.getParentFile().mkdirs()) {\n            throw new IOException(\"Mkdirs failed to create tar internal dir \" + targetDir);\n        }\n    }\n    try (OutputStream o = Files.newOutputStream(Paths.get(outputFile.getCanonicalPath()))) {\n        IOUtils.copyBytes(tis, o, false);\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.zip.ZipArchiveEntry.isDirectory",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.zip",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions" ],
    "fullMethods" : [ "public static void extractZipFileWithPermissions(String zipFilePath, String targetPath) throws IOException {\n    try (ZipFile zipFile = new ZipFile(zipFilePath)) {\n        Enumeration<ZipArchiveEntry> entries = zipFile.getEntries();\n        boolean isUnix = isUnix();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        String canonicalTargetPath = new File(targetPath).getCanonicalPath() + File.separator;\n        while (entries.hasMoreElements()) {\n            ZipArchiveEntry entry = entries.nextElement();\n            File outputFile = new File(canonicalTargetPath, entry.getName());\n            if (!outputFile.getCanonicalPath().startsWith(canonicalTargetPath)) {\n                throw new IOException(((\"Expand \" + entry.getName()) + \" would create a file outside of \") + targetPath);\n            }\n            if (entry.isDirectory()) {\n                if (!outputFile.exists()) {\n                    if (!outputFile.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n            } else {\n                File parentDir = outputFile.getParentFile();\n                if (!parentDir.exists()) {\n                    if (!parentDir.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n                if (entry.isUnixSymlink()) {\n                    // the content of the file is the target path of the symlink\n                    baos.reset();\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), baos);\n                    Files.createSymbolicLink(outputFile.toPath(), new File(parentDir, baos.toString()).toPath());\n                } else if (outputFile.createNewFile()) {\n                    OutputStream output = new FileOutputStream(outputFile);\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), output);\n                } else {\n                    throw new IOException((\"Create file: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                }\n            }\n            if (isUnix) {\n                int mode = entry.getUnixMode();\n                if (mode != 0) {\n                    Path outputPath = Paths.get(outputFile.toURI());\n                    Set<PosixFilePermission> permissions = new HashSet<>();\n                    addIfBitSet(mode, 8, permissions, PosixFilePermission.OWNER_READ);\n                    addIfBitSet(mode, 7, permissions, PosixFilePermission.OWNER_WRITE);\n                    addIfBitSet(mode, 6, permissions, PosixFilePermission.OWNER_EXECUTE);\n                    addIfBitSet(mode, 5, permissions, PosixFilePermission.GROUP_READ);\n                    addIfBitSet(mode, 4, permissions, PosixFilePermission.GROUP_WRITE);\n                    addIfBitSet(mode, 3, permissions, PosixFilePermission.GROUP_EXECUTE);\n                    addIfBitSet(mode, 2, permissions, PosixFilePermission.OTHERS_READ);\n                    addIfBitSet(mode, 1, permissions, PosixFilePermission.OTHERS_WRITE);\n                    addIfBitSet(mode, 0, permissions, PosixFilePermission.OTHERS_EXECUTE);\n                    // the permission of the target file will be set to be the same as the\n                    // symlink\n                    // TODO: support setting the permission without following links\n                    try {\n                        Files.setPosixFilePermissions(outputPath, permissions);\n                    } catch (NoSuchFileException e) {\n                        // this may happens when the target file of the symlink is still not\n                        // extracted\n                    }\n                }\n            }\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.zip.ZipArchiveEntry.getUnixMode",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.zip",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions" ],
    "fullMethods" : [ "public static void extractZipFileWithPermissions(String zipFilePath, String targetPath) throws IOException {\n    try (ZipFile zipFile = new ZipFile(zipFilePath)) {\n        Enumeration<ZipArchiveEntry> entries = zipFile.getEntries();\n        boolean isUnix = isUnix();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        String canonicalTargetPath = new File(targetPath).getCanonicalPath() + File.separator;\n        while (entries.hasMoreElements()) {\n            ZipArchiveEntry entry = entries.nextElement();\n            File outputFile = new File(canonicalTargetPath, entry.getName());\n            if (!outputFile.getCanonicalPath().startsWith(canonicalTargetPath)) {\n                throw new IOException(((\"Expand \" + entry.getName()) + \" would create a file outside of \") + targetPath);\n            }\n            if (entry.isDirectory()) {\n                if (!outputFile.exists()) {\n                    if (!outputFile.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n            } else {\n                File parentDir = outputFile.getParentFile();\n                if (!parentDir.exists()) {\n                    if (!parentDir.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n                if (entry.isUnixSymlink()) {\n                    // the content of the file is the target path of the symlink\n                    baos.reset();\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), baos);\n                    Files.createSymbolicLink(outputFile.toPath(), new File(parentDir, baos.toString()).toPath());\n                } else if (outputFile.createNewFile()) {\n                    OutputStream output = new FileOutputStream(outputFile);\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), output);\n                } else {\n                    throw new IOException((\"Create file: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                }\n            }\n            if (isUnix) {\n                int mode = entry.getUnixMode();\n                if (mode != 0) {\n                    Path outputPath = Paths.get(outputFile.toURI());\n                    Set<PosixFilePermission> permissions = new HashSet<>();\n                    addIfBitSet(mode, 8, permissions, PosixFilePermission.OWNER_READ);\n                    addIfBitSet(mode, 7, permissions, PosixFilePermission.OWNER_WRITE);\n                    addIfBitSet(mode, 6, permissions, PosixFilePermission.OWNER_EXECUTE);\n                    addIfBitSet(mode, 5, permissions, PosixFilePermission.GROUP_READ);\n                    addIfBitSet(mode, 4, permissions, PosixFilePermission.GROUP_WRITE);\n                    addIfBitSet(mode, 3, permissions, PosixFilePermission.GROUP_EXECUTE);\n                    addIfBitSet(mode, 2, permissions, PosixFilePermission.OTHERS_READ);\n                    addIfBitSet(mode, 1, permissions, PosixFilePermission.OTHERS_WRITE);\n                    addIfBitSet(mode, 0, permissions, PosixFilePermission.OTHERS_EXECUTE);\n                    // the permission of the target file will be set to be the same as the\n                    // symlink\n                    // TODO: support setting the permission without following links\n                    try {\n                        Files.setPosixFilePermissions(outputPath, permissions);\n                    } catch (NoSuchFileException e) {\n                        // this may happens when the target file of the symlink is still not\n                        // extracted\n                    }\n                }\n            }\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.common.operators.util.JoinHashMap.<init>",
    "thirdPartyMethod" : "org.apache.commons.collections.map.AbstractHashedMap.<init>",
    "thirdPartyPackage" : "org.apache.commons.collections.map",
    "path" : [ "org.apache.flink.api.common.operators.util.JoinHashMap.<init>" ],
    "fullMethods" : [ "public JoinHashMap(TypeSerializer<BT> buildSerializer, TypeComparator<BT> buildComparator) {\n    super(64);\n    this.buildSerializer = buildSerializer;\n    this.buildComparator = buildComparator;\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.Utils.getSerializerTree",
    "thirdPartyMethod" : "org.apache.commons.lang3.StringUtils.repeat",
    "thirdPartyPackage" : "org.apache.commons.lang3",
    "path" : [ "org.apache.flink.util.Utils.getSerializerTree", "org.apache.flink.util.Utils.getSerializerTree" ],
    "fullMethods" : [ "// --------------------------------------------------------------------------------------------\n/**\n * Debugging utility to understand the hierarchy of serializers created by the Java API. Tested\n * in GroupReduceITCase.testGroupByGenericType()\n */\npublic static <T> String getSerializerTree(TypeInformation<T> ti) {\n    return getSerializerTree(ti, 0);\n}", "private static <T> String getSerializerTree(TypeInformation<T> ti, int indent) {\n    String ret = \"\";\n    if (ti instanceof CompositeType) {\n        ret += (StringUtils.repeat(' ', indent) + ti.getClass().getSimpleName()) + \"\\n\";\n        CompositeType<T> cti = ((CompositeType<T>) (ti));\n        String[] fieldNames = cti.getFieldNames();\n        for (int i = 0; i < cti.getArity(); i++) {\n            TypeInformation<?> fieldType = cti.getTypeAt(i);\n            ret += ((StringUtils.repeat(' ', indent + 2) + fieldNames[i]) + \":\") + getSerializerTree(fieldType, indent);\n        }\n    } else if (ti instanceof GenericTypeInfo) {\n        ret += ((StringUtils.repeat(' ', indent) + \"GenericTypeInfo (\") + ti.getTypeClass().getSimpleName()) + \")\\n\";\n        ret += getGenericTypeTree(ti.getTypeClass(), indent + 4);\n    } else {\n        ret += (StringUtils.repeat(' ', indent) + ti.toString()) + \"\\n\";\n    }\n    return ret;\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractTarFile",
    "thirdPartyMethod" : "org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream.<init>",
    "thirdPartyPackage" : "org.apache.commons.compress.compressors.gzip",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractTarFile", "org.apache.flink.util.CompressionUtils.extractTarFileUsingJava" ],
    "fullMethods" : [ "public static void extractTarFile(String inFilePath, String targetDirPath) throws IOException {\n    final File targetDir = new File(targetDirPath);\n    if (!targetDir.mkdirs()) {\n        if (!targetDir.isDirectory()) {\n            throw new IOException(\"Mkdirs failed to create \" + targetDir);\n        }\n    }\n    final boolean gzipped = inFilePath.endsWith(\"gz\");\n    if (isUnix()) {\n        extractTarFileUsingTar(inFilePath, targetDirPath, gzipped);\n    } else {\n        extractTarFileUsingJava(inFilePath, targetDirPath, gzipped);\n    }\n}", "// Follow the pattern suggested in\n// https://commons.apache.org/proper/commons-compress/examples.html\nprivate static void extractTarFileUsingJava(String inFilePath, String targetDirPath, boolean gzipped) throws IOException {\n    try (InputStream fi = Files.newInputStream(Paths.get(inFilePath));InputStream bi = new BufferedInputStream(fi);final TarArchiveInputStream tai = new TarArchiveInputStream(gzipped ? new GzipCompressorInputStream(bi) : bi)) {\n        final File targetDir = new File(targetDirPath);\n        TarArchiveEntry entry;\n        while ((entry = tai.getNextTarEntry()) != null) {\n            unpackEntry(tai, entry, targetDir);\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractTarFile",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.tar",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractTarFile", "org.apache.flink.util.CompressionUtils.extractTarFileUsingJava" ],
    "fullMethods" : [ "public static void extractTarFile(String inFilePath, String targetDirPath) throws IOException {\n    final File targetDir = new File(targetDirPath);\n    if (!targetDir.mkdirs()) {\n        if (!targetDir.isDirectory()) {\n            throw new IOException(\"Mkdirs failed to create \" + targetDir);\n        }\n    }\n    final boolean gzipped = inFilePath.endsWith(\"gz\");\n    if (isUnix()) {\n        extractTarFileUsingTar(inFilePath, targetDirPath, gzipped);\n    } else {\n        extractTarFileUsingJava(inFilePath, targetDirPath, gzipped);\n    }\n}", "// Follow the pattern suggested in\n// https://commons.apache.org/proper/commons-compress/examples.html\nprivate static void extractTarFileUsingJava(String inFilePath, String targetDirPath, boolean gzipped) throws IOException {\n    try (InputStream fi = Files.newInputStream(Paths.get(inFilePath));InputStream bi = new BufferedInputStream(fi);final TarArchiveInputStream tai = new TarArchiveInputStream(gzipped ? new GzipCompressorInputStream(bi) : bi)) {\n        final File targetDir = new File(targetDirPath);\n        TarArchiveEntry entry;\n        while ((entry = tai.getNextTarEntry()) != null) {\n            unpackEntry(tai, entry, targetDir);\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractTarFile",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.tar.TarArchiveInputStream.close",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.tar",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractTarFile", "org.apache.flink.util.CompressionUtils.extractTarFileUsingJava" ],
    "fullMethods" : [ "public static void extractTarFile(String inFilePath, String targetDirPath) throws IOException {\n    final File targetDir = new File(targetDirPath);\n    if (!targetDir.mkdirs()) {\n        if (!targetDir.isDirectory()) {\n            throw new IOException(\"Mkdirs failed to create \" + targetDir);\n        }\n    }\n    final boolean gzipped = inFilePath.endsWith(\"gz\");\n    if (isUnix()) {\n        extractTarFileUsingTar(inFilePath, targetDirPath, gzipped);\n    } else {\n        extractTarFileUsingJava(inFilePath, targetDirPath, gzipped);\n    }\n}", "// Follow the pattern suggested in\n// https://commons.apache.org/proper/commons-compress/examples.html\nprivate static void extractTarFileUsingJava(String inFilePath, String targetDirPath, boolean gzipped) throws IOException {\n    try (InputStream fi = Files.newInputStream(Paths.get(inFilePath));InputStream bi = new BufferedInputStream(fi);final TarArchiveInputStream tai = new TarArchiveInputStream(gzipped ? new GzipCompressorInputStream(bi) : bi)) {\n        final File targetDir = new File(targetDirPath);\n        TarArchiveEntry entry;\n        while ((entry = tai.getNextTarEntry()) != null) {\n            unpackEntry(tai, entry, targetDir);\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions",
    "thirdPartyMethod" : "org.apache.commons.compress.archivers.zip.ZipArchiveEntry.isUnixSymlink",
    "thirdPartyPackage" : "org.apache.commons.compress.archivers.zip",
    "path" : [ "org.apache.flink.util.CompressionUtils.extractZipFileWithPermissions" ],
    "fullMethods" : [ "public static void extractZipFileWithPermissions(String zipFilePath, String targetPath) throws IOException {\n    try (ZipFile zipFile = new ZipFile(zipFilePath)) {\n        Enumeration<ZipArchiveEntry> entries = zipFile.getEntries();\n        boolean isUnix = isUnix();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        String canonicalTargetPath = new File(targetPath).getCanonicalPath() + File.separator;\n        while (entries.hasMoreElements()) {\n            ZipArchiveEntry entry = entries.nextElement();\n            File outputFile = new File(canonicalTargetPath, entry.getName());\n            if (!outputFile.getCanonicalPath().startsWith(canonicalTargetPath)) {\n                throw new IOException(((\"Expand \" + entry.getName()) + \" would create a file outside of \") + targetPath);\n            }\n            if (entry.isDirectory()) {\n                if (!outputFile.exists()) {\n                    if (!outputFile.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n            } else {\n                File parentDir = outputFile.getParentFile();\n                if (!parentDir.exists()) {\n                    if (!parentDir.mkdirs()) {\n                        throw new IOException((\"Create dir: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                    }\n                }\n                if (entry.isUnixSymlink()) {\n                    // the content of the file is the target path of the symlink\n                    baos.reset();\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), baos);\n                    Files.createSymbolicLink(outputFile.toPath(), new File(parentDir, baos.toString()).toPath());\n                } else if (outputFile.createNewFile()) {\n                    OutputStream output = new FileOutputStream(outputFile);\n                    IOUtils.copyBytes(zipFile.getInputStream(entry), output);\n                } else {\n                    throw new IOException((\"Create file: \" + outputFile.getAbsolutePath()) + \" failed!\");\n                }\n            }\n            if (isUnix) {\n                int mode = entry.getUnixMode();\n                if (mode != 0) {\n                    Path outputPath = Paths.get(outputFile.toURI());\n                    Set<PosixFilePermission> permissions = new HashSet<>();\n                    addIfBitSet(mode, 8, permissions, PosixFilePermission.OWNER_READ);\n                    addIfBitSet(mode, 7, permissions, PosixFilePermission.OWNER_WRITE);\n                    addIfBitSet(mode, 6, permissions, PosixFilePermission.OWNER_EXECUTE);\n                    addIfBitSet(mode, 5, permissions, PosixFilePermission.GROUP_READ);\n                    addIfBitSet(mode, 4, permissions, PosixFilePermission.GROUP_WRITE);\n                    addIfBitSet(mode, 3, permissions, PosixFilePermission.GROUP_EXECUTE);\n                    addIfBitSet(mode, 2, permissions, PosixFilePermission.OTHERS_READ);\n                    addIfBitSet(mode, 1, permissions, PosixFilePermission.OTHERS_WRITE);\n                    addIfBitSet(mode, 0, permissions, PosixFilePermission.OTHERS_EXECUTE);\n                    // the permission of the target file will be set to be the same as the\n                    // symlink\n                    // TODO: support setting the permission without following links\n                    try {\n                        Files.setPosixFilePermissions(outputPath, permissions);\n                    } catch (NoSuchFileException e) {\n                        // this may happens when the target file of the symlink is still not\n                        // extracted\n                    }\n                }\n            }\n        } \n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.createInstance",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.createInstance", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.checkKryoInitialized", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic T createInstance() {\n    if (Modifier.isAbstract(type.getModifiers()) || Modifier.isInterface(type.getModifiers())) {\n        return null;\n    } else {\n        checkKryoInitialized();\n        try {\n            return kryo.newInstance(type);\n        } catch (Throwable e) {\n            return null;\n        }\n    }\n}", "private void checkKryoInitialized() {\n    if (this.kryo == null) {\n        this.kryo = getKryoInstance();\n        // Enable reference tracking.\n        kryo.setReferences(true);\n        // Throwable and all subclasses should be serialized via java serialization\n        // Note: the registered JavaSerializer is Flink's own implementation, and not Kryo's.\n        // This is due to a know issue with Kryo's JavaSerializer. See FLINK-6025 for\n        // details.\n        kryo.addDefaultSerializer(Throwable.class, new JavaSerializer());\n        // Add default serializers first, so that the type registrations without a serializer\n        // are registered with a default serializer\n        for (Map.Entry<Class<?>, SerializableSerializer<?>> entry : defaultSerializers.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue().getSerializer());\n        }\n        for (Map.Entry<Class<?>, Class<? extends Serializer<?>>> entry : defaultSerializerClasses.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue());\n        }\n        KryoUtils.applyRegistrations(this.kryo, kryoRegistrations.values(), flinkChillPackageRegistrar != null ? flinkChillPackageRegistrar.getNextRegistrationId() : kryo.getNextRegistrationId());\n        kryo.setRegistrationRequired(false);\n        kryo.setClassLoader(Thread.currentThread().getContextClassLoader());\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.resolveSchemaCompatibility", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(TypeSerializerSnapshot<T> oldSerializerSnapshot) {\n    if (!(oldSerializerSnapshot instanceof KryoSerializerSnapshot)) {\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    KryoSerializerSnapshot<T> oldKryoSerializerSnapshot = ((KryoSerializerSnapshot<T>) (oldSerializerSnapshot));\n    if (snapshotData.getTypeClass() != oldKryoSerializerSnapshot.snapshotData.getTypeClass()) {\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    return resolveSchemaCompatibility(oldKryoSerializerSnapshot);\n}", "private TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(KryoSerializerSnapshot<T> oldKryoSerializerSnapshot) {\n    // merge the default serializers\n    final MergeResult<Class<?>, SerializableSerializer<?>> reconfiguredDefaultKryoSerializers = mergeRightIntoLeft(oldKryoSerializerSnapshot.snapshotData.getDefaultKryoSerializers(), snapshotData.getDefaultKryoSerializers());\n    if (reconfiguredDefaultKryoSerializers.hasMissingKeys()) {\n        logMissingKeys(reconfiguredDefaultKryoSerializers);\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    // merge default serializer classes\n    final MergeResult<Class<?>, Class<? extends Serializer<?>>> reconfiguredDefaultKryoSerializerClasses = mergeRightIntoLeft(oldKryoSerializerSnapshot.snapshotData.getDefaultKryoSerializerClasses(), snapshotData.getDefaultKryoSerializerClasses());\n    if (reconfiguredDefaultKryoSerializerClasses.hasMissingKeys()) {\n        logMissingKeys(reconfiguredDefaultKryoSerializerClasses);\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    // merge registration\n    final MergeResult<String, KryoRegistration> reconfiguredRegistrations = mergeRightIntoLeft(oldKryoSerializerSnapshot.snapshotData.getKryoRegistrations(), snapshotData.getKryoRegistrations());\n    if (reconfiguredRegistrations.hasMissingKeys()) {\n        logMissingKeys(reconfiguredRegistrations);\n        return TypeSerializerSchemaCompatibility.incompatible();\n    }\n    // there are no missing keys, now we have to decide whether we are compatible as-is or we\n    // require reconfiguration.\n    return resolveSchemaCompatibility(reconfiguredDefaultKryoSerializers, reconfiguredDefaultKryoSerializerClasses, reconfiguredRegistrations);\n}", "private TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(MergeResult<Class<?>, SerializableSerializer<?>> reconfiguredDefaultKryoSerializers, MergeResult<Class<?>, Class<? extends Serializer<?>>> reconfiguredDefaultKryoSerializerClasses, MergeResult<String, KryoRegistration> reconfiguredRegistrations) {\n    if ((reconfiguredDefaultKryoSerializers.isOrderedSubset() && reconfiguredDefaultKryoSerializerClasses.isOrderedSubset()) && reconfiguredRegistrations.isOrderedSubset()) {\n        return TypeSerializerSchemaCompatibility.compatibleAsIs();\n    }\n    // reconfigure a new KryoSerializer\n    KryoSerializer<T> reconfiguredSerializer = new KryoSerializer<>(snapshotData.getTypeClass(), reconfiguredDefaultKryoSerializers.getMerged(), reconfiguredDefaultKryoSerializerClasses.getMerged(), reconfiguredRegistrations.getMerged());\n    return TypeSerializerSchemaCompatibility.compatibleWithReconfiguredSerializer(reconfiguredSerializer);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<init>",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<init>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "// ------------------------------------------------------------------------\npublic KryoSerializer(Class<T> type, SerializerConfig serializerConfig) {\n    this.type = checkNotNull(type);\n    this.defaultSerializers = ((SerializerConfigImpl) (serializerConfig)).getDefaultKryoSerializers();\n    this.defaultSerializerClasses = serializerConfig.getDefaultKryoSerializerClasses();\n    this.kryoRegistrations = buildKryoRegistrations(this.type, serializerConfig.getRegisteredKryoTypes(), serializerConfig.getRegisteredTypesWithKryoSerializerClasses(), ((SerializerConfigImpl) (serializerConfig)).getRegisteredTypesWithKryoSerializers(), serializerConfig.isForceKryoAvroEnabled());\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.restoreSerializer",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializerSnapshot.restoreSerializer", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic TypeSerializer<T> restoreSerializer() {\n    return new KryoSerializer<>(snapshotData.getTypeClass(), snapshotData.getDefaultKryoSerializers().unwrapOptionals(), snapshotData.getDefaultKryoSerializerClasses().unwrapOptionals(), snapshotData.getKryoRegistrations().unwrapOptionals());\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic void copy(DataInputView source, DataOutputView target) throws IOException {\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        if (this.copyInstance == null) {\n            this.copyInstance = createInstance();\n        }\n        T tmp = deserialize(copyInstance, source);\n        serialize(tmp, target);\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.deserialize",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.deserialize", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\n@Override\npublic T deserialize(DataInputView source) throws IOException {\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        if (source != previousIn) {\n            DataInputViewStream inputStream = new DataInputViewStream(source);\n            input = new NoFetchingInput(inputStream);\n            previousIn = source;\n        }\n        try {\n            return ((T) (kryo.readClassAndObject(input)));\n        } catch (KryoBufferUnderflowException ke) {\n            // 2023-04-26: Existing Flink code expects a java.io.EOFException in this scenario\n            throw new EOFException(ke.getMessage());\n        } catch (KryoException ke) {\n            Throwable cause = ke.getCause();\n            if (cause instanceof EOFException) {\n                throw ((EOFException) (cause));\n            } else {\n                throw ke;\n            }\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.PojoTypeInfo.createSerializer",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.PojoTypeInfo.createSerializer", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\n@PublicEvolving\n@SuppressWarnings(\"unchecked\")\npublic TypeSerializer<T> createSerializer(SerializerConfig config) {\n    if (config.isForceKryoEnabled()) {\n        return new KryoSerializer<>(getTypeClass(), config);\n    }\n    if (config.isForceAvroEnabled()) {\n        return AvroUtils.getAvroUtils().createAvroSerializer(getTypeClass());\n    }\n    return createPojoSerializer(config);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.GenericTypeInfo.createSerializer",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.GenericTypeInfo.createSerializer", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\n@PublicEvolving\npublic TypeSerializer<T> createSerializer(SerializerConfig config) {\n    if (config.hasGenericTypesDisabled()) {\n        throw new UnsupportedOperationException((\"Generic types have been disabled in the ExecutionConfig and type \" + this.typeClass.getName()) + \" is treated as a generic type.\");\n    }\n    return new KryoSerializer<T>(this.typeClass, config);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.serialize",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.serialize", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic void serialize(T record, DataOutputView target) throws IOException {\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        if (target != previousOut) {\n            DataOutputViewStream outputStream = new DataOutputViewStream(target);\n            output = new Output(outputStream);\n            previousOut = target;\n        }\n        // Sanity check: Make sure that the output is cleared/has been flushed by the last call\n        // otherwise data might be written multiple times in case of a previous EOFException\n        if (output.position() != 0) {\n            throw new IllegalStateException(\"The Kryo Output still contains data from a previous \" + \"serialize call. It has to be flushed or cleared at the end of the serialize call.\");\n        }\n        try {\n            kryo.writeClassAndObject(output, record);\n            output.flush();\n        } catch (KryoException ke) {\n            // make sure that the Kryo output buffer is reset in case that we can recover from\n            // the exception (e.g. EOFException which denotes buffer full)\n            output.reset();\n            Throwable cause = ke.getCause();\n            if (cause instanceof EOFException) {\n                throw ((EOFException) (cause));\n            } else {\n                throw ke;\n            }\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.copy", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@SuppressWarnings(\"unchecked\")\n@Override\npublic T copy(T from) {\n    if (from == null) {\n        return null;\n    }\n    if (CONCURRENT_ACCESS_CHECK) {\n        enterExclusiveThread();\n    }\n    try {\n        checkKryoInitialized();\n        try {\n            return kryo.copy(from);\n        } catch (KryoException ke) {\n            // kryo was unable to copy it, so we do it through serialization:\n            ByteArrayOutputStream baout = new ByteArrayOutputStream();\n            Output output = new Output(baout);\n            kryo.writeObject(output, from);\n            output.close();\n            ByteArrayInputStream bain = new ByteArrayInputStream(baout.toByteArray());\n            Input input = new Input(bain);\n            return ((T) (kryo.readObject(input, from.getClass())));\n        }\n    } finally {\n        if (CONCURRENT_ACCESS_CHECK) {\n            exitExclusiveThread();\n        }\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.getKryo",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.getKryo", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.checkKryoInitialized", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@VisibleForTesting\npublic Kryo getKryo() {\n    checkKryoInitialized();\n    return this.kryo;\n}", "private void checkKryoInitialized() {\n    if (this.kryo == null) {\n        this.kryo = getKryoInstance();\n        // Enable reference tracking.\n        kryo.setReferences(true);\n        // Throwable and all subclasses should be serialized via java serialization\n        // Note: the registered JavaSerializer is Flink's own implementation, and not Kryo's.\n        // This is due to a know issue with Kryo's JavaSerializer. See FLINK-6025 for\n        // details.\n        kryo.addDefaultSerializer(Throwable.class, new JavaSerializer());\n        // Add default serializers first, so that the type registrations without a serializer\n        // are registered with a default serializer\n        for (Map.Entry<Class<?>, SerializableSerializer<?>> entry : defaultSerializers.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue().getSerializer());\n        }\n        for (Map.Entry<Class<?>, Class<? extends Serializer<?>>> entry : defaultSerializerClasses.entrySet()) {\n            kryo.addDefaultSerializer(entry.getKey(), entry.getValue());\n        }\n        KryoUtils.applyRegistrations(this.kryo, kryoRegistrations.values(), flinkChillPackageRegistrar != null ? flinkChillPackageRegistrar.getNextRegistrationId() : kryo.getNextRegistrationId());\n        kryo.setRegistrationRequired(false);\n        kryo.setClassLoader(Thread.currentThread().getContextClassLoader());\n    }\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  }, {
    "entryPoint" : "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.duplicate",
    "thirdPartyMethod" : "com.esotericsoftware.minlog.Log.TRACE",
    "thirdPartyPackage" : "com.esotericsoftware.minlog",
    "path" : [ "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.duplicate", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.<clinit>", "org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.configureKryoLogging" ],
    "fullMethods" : [ "@Override\npublic KryoSerializer<T> duplicate() {\n    return new KryoSerializer<>(this);\n}", "", "static void configureKryoLogging() {\n    // Kryo uses only DEBUG and TRACE levels\n    // we only forward TRACE level, because even DEBUG levels results in\n    // a logging for each object, which is infeasible in Flink.\n    if (LOG.isTraceEnabled()) {\n        Log.setLogger(new MinlogForwarder(LOG));\n        Log.TRACE();\n    }\n}" ]
  } ]
}