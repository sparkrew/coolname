{
  "fullMethodsPaths" : [ {
    "entryPoint" : "com.graphhopper.reader.dem.AbstractTiffElevationProvider.getEle",
    "thirdPartyMethod" : "org.apache.xmlgraphics.image.codec.tiff.TIFFImageDecoder.<init>",
    "thirdPartyPackage" : "org.apache.xmlgraphics.image.codec.tiff",
    "path" : [ "com.graphhopper.reader.dem.AbstractTiffElevationProvider.getEle", "com.graphhopper.reader.dem.GMTEDProvider.readFile" ],
    "fullMethods" : [ "@Override\npublic double getEle(double lat, double lon) {\n    // Return fast, if there is no data available\n    if (isOutsideSupportedArea(lat, lon))\n        return 0;\n\n    lat = ((int) (lat * precision)) / precision;\n    lon = ((int) (lon * precision)) / precision;\n    String name = getFileName(lat, lon);\n    HeightTile demProvider = cacheData.get(name);\n    if (demProvider == null) {\n        if (!cacheDir.exists())\n            cacheDir.mkdirs();\n\n        int minLat = getMinLatForTile(lat);\n        int minLon = getMinLonForTile(lon);\n        // less restrictive against boundary checking\n        demProvider = new HeightTile(minLat, minLon, WIDTH, HEIGHT, LON_DEGREE * precision, LON_DEGREE, LAT_DEGREE);\n        demProvider.setInterpolate(interpolate);\n        cacheData.put(name, demProvider);\n        DataAccess heights = getDirectory().create(name + \".gh\");\n        demProvider.setHeights(heights);\n        boolean loadExisting = false;\n        try {\n            loadExisting = heights.loadExisting();\n        } catch (Exception ex) {\n            logger.warn(((\"cannot load \" + name) + \", error: \") + ex.getMessage());\n        }\n        if (!loadExisting) {\n            File zipFile = new File(cacheDir, new File(getFileNameOfLocalFile(lat, lon)).getName());\n            if (!zipFile.exists())\n                try {\n                    String zippedURL = getDownloadURL(lat, lon);\n                    downloadToFile(zipFile, zippedURL);\n                } catch (SSLException ex) {\n                    throw new IllegalStateException(\"SSL problem with elevation provider \" + getClass().getSimpleName(), ex);\n                } catch (IOException ex) {\n                    demProvider.setSeaLevel(true);\n                    // use small size on disc and in-memory\n                    heights.create(10).flush();\n                    return 0;\n                }\n\n            // short == 2 bytes\n            heights.create((2L * WIDTH) * HEIGHT);\n            Raster raster = readFile(zipFile, name + \".tif\");\n            fillDataAccessWithElevationData(raster, heights, WIDTH);\n        }// loadExisting\n\n    }\n    if (demProvider.isSeaLevel())\n        return 0;\n\n    return demProvider.getHeight(lat, lon);\n}", "@Override\nRaster readFile(File file, String tifName) {\n    SeekableStream ss = null;\n    try {\n        InputStream is = new FileInputStream(file);\n        ss = SeekableStream.wrapInputStream(is, true);\n        TIFFImageDecoder imageDecoder = new TIFFImageDecoder(ss, new TIFFDecodeParam());\n        return imageDecoder.decodeAsRaster();\n    } catch (Exception e) {\n        throw new RuntimeException(\"Can't decode \" + file.getName(), e);\n    } finally {\n        if (ss != null)\n            close(ss);\n\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate",
    "thirdPartyMethod" : "org.locationtech.jts.triangulate.DelaunayTriangulationBuilder.getEdges",
    "thirdPartyPackage" : "org.locationtech.jts.triangulate",
    "path" : [ "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate" ],
    "fullMethods" : [ "public Result triangulate(Snap snap, QueryGraph queryGraph, ShortestPathTree shortestPathTree, ToDoubleFunction<ShortestPathTree.IsoLabel> fz, double tolerance) {\n    final NodeAccess na = queryGraph.getNodeAccess();\n    Collection<Coordinate> sites = new ArrayList<>();\n    shortestPathTree.search(snap.getClosestNode(), label -> {\n        double exploreValue = fz.applyAsDouble(label);\n        double lat = na.getLat(label.node);\n        double lon = na.getLon(label.node);\n        Coordinate site = new Coordinate(lon, lat);\n        site.z = exploreValue;\n        sites.add(site);\n        // add a pillar node to increase precision a bit for longer roads\n        if (label.parent != null) {\n            EdgeIteratorState edge = queryGraph.getEdgeIteratorState(label.edge, label.node);\n            PointList innerPoints = edge.fetchWayGeometry(FetchMode.PILLAR_ONLY);\n            if (innerPoints.size() > 0) {\n                int midIndex = innerPoints.size() / 2;\n                // For edge-based routing we might have explored the same edge in two different directions.\n                // Here we make sure we only include the **same** point twice instead of two different ones.\n                if (((innerPoints.size() % 2) == 0) && edge.get(EdgeIteratorState.REVERSE_STATE))\n                    midIndex -= 1;\n\n                double lat2 = innerPoints.getLat(midIndex);\n                double lon2 = innerPoints.getLon(midIndex);\n                Coordinate site2 = new Coordinate(lon2, lat2);\n                site2.z = exploreValue;\n                sites.add(site2);\n            }\n        }\n    });\n    if (sites.size() > (routerConfig.getMaxVisitedNodes() / 3))\n        throw new IllegalArgumentException((\"Too many nodes would be included in post processing (\" + sites.size()) + \"). Let us know if you need this increased.\");\n\n    // Sites may contain repeated coordinates. Especially for edge-based traversal, that's expected -- we visit\n    // each node multiple times.\n    // But that's okay, the triangulator de-dupes by itself, and it keeps the first z-value it sees, which is\n    // what we want.\n    DelaunayTriangulationBuilder triangulationBuilder = new DelaunayTriangulationBuilder();\n    triangulationBuilder.setSites(sites);\n    triangulationBuilder.setTolerance(tolerance);\n    Geometry convexHull = triangulationBuilder.getEdges(new GeometryFactory()).convexHull();\n    // If there's only one site (and presumably also if the convex hull is otherwise degenerated),\n    // the triangulation only contains the frame, and not the site within the frame. Not sure if I agree with that.\n    // See ConformingDelaunayTriangulator, it does include a buffer for the frame, but that buffer is zero\n    // in these cases.\n    // It leads to the following follow-up defect:\n    // computeIsoline fails (returns an empty Multipolygon). This is clearly wrong, since\n    // the idea is that every real (non-frame) vertex has positive-length-edges around it that can be traversed\n    // to get a non-empty polygon.\n    // So we exclude this case for now (it is indeed only a corner-case).\n    if (!(convexHull instanceof Polygon)) {\n        throw new IllegalArgumentException(\"Too few points found. \" + \"Please try a different 'point' or a larger 'time_limit'.\");\n    }\n    QuadEdgeSubdivision tin = triangulationBuilder.getSubdivision();\n    for (Vertex vertex : ((Collection<Vertex>) (tin.getVertices(true)))) {\n        if (tin.isFrameVertex(vertex)) {\n            vertex.setZ(Double.MAX_VALUE);\n        }\n    }\n    ReadableTriangulation triangulation = ReadableTriangulation.wrap(tin);\n    return new Result(triangulation, triangulation.getEdges());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.equals",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.equals",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.equals" ],
    "fullMethods" : [ "@Override\npublic boolean equals(Object obj) {\n    // this is actually needed, because we build a Set of InternalRestrictions to remove duplicates\n    // no need to compare the actualEdgeKeys\n    if (!(obj instanceof InternalRestriction))\n        return false;\n\n    return ((InternalRestriction) (obj)).viaNodes.equals(viaNodes) && ((InternalRestriction) (obj)).edgeKeys.equals(edgeKeys);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Geometry.convexHull",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate" ],
    "fullMethods" : [ "public Result triangulate(Snap snap, QueryGraph queryGraph, ShortestPathTree shortestPathTree, ToDoubleFunction<ShortestPathTree.IsoLabel> fz, double tolerance) {\n    final NodeAccess na = queryGraph.getNodeAccess();\n    Collection<Coordinate> sites = new ArrayList<>();\n    shortestPathTree.search(snap.getClosestNode(), label -> {\n        double exploreValue = fz.applyAsDouble(label);\n        double lat = na.getLat(label.node);\n        double lon = na.getLon(label.node);\n        Coordinate site = new Coordinate(lon, lat);\n        site.z = exploreValue;\n        sites.add(site);\n        // add a pillar node to increase precision a bit for longer roads\n        if (label.parent != null) {\n            EdgeIteratorState edge = queryGraph.getEdgeIteratorState(label.edge, label.node);\n            PointList innerPoints = edge.fetchWayGeometry(FetchMode.PILLAR_ONLY);\n            if (innerPoints.size() > 0) {\n                int midIndex = innerPoints.size() / 2;\n                // For edge-based routing we might have explored the same edge in two different directions.\n                // Here we make sure we only include the **same** point twice instead of two different ones.\n                if (((innerPoints.size() % 2) == 0) && edge.get(EdgeIteratorState.REVERSE_STATE))\n                    midIndex -= 1;\n\n                double lat2 = innerPoints.getLat(midIndex);\n                double lon2 = innerPoints.getLon(midIndex);\n                Coordinate site2 = new Coordinate(lon2, lat2);\n                site2.z = exploreValue;\n                sites.add(site2);\n            }\n        }\n    });\n    if (sites.size() > (routerConfig.getMaxVisitedNodes() / 3))\n        throw new IllegalArgumentException((\"Too many nodes would be included in post processing (\" + sites.size()) + \"). Let us know if you need this increased.\");\n\n    // Sites may contain repeated coordinates. Especially for edge-based traversal, that's expected -- we visit\n    // each node multiple times.\n    // But that's okay, the triangulator de-dupes by itself, and it keeps the first z-value it sees, which is\n    // what we want.\n    DelaunayTriangulationBuilder triangulationBuilder = new DelaunayTriangulationBuilder();\n    triangulationBuilder.setSites(sites);\n    triangulationBuilder.setTolerance(tolerance);\n    Geometry convexHull = triangulationBuilder.getEdges(new GeometryFactory()).convexHull();\n    // If there's only one site (and presumably also if the convex hull is otherwise degenerated),\n    // the triangulation only contains the frame, and not the site within the frame. Not sure if I agree with that.\n    // See ConformingDelaunayTriangulator, it does include a buffer for the frame, but that buffer is zero\n    // in these cases.\n    // It leads to the following follow-up defect:\n    // computeIsoline fails (returns an empty Multipolygon). This is clearly wrong, since\n    // the idea is that every real (non-frame) vertex has positive-length-edges around it that can be traversed\n    // to get a non-empty polygon.\n    // So we exclude this case for now (it is indeed only a corner-case).\n    if (!(convexHull instanceof Polygon)) {\n        throw new IllegalArgumentException(\"Too few points found. \" + \"Please try a different 'point' or a larger 'time_limit'.\");\n    }\n    QuadEdgeSubdivision tin = triangulationBuilder.getSubdivision();\n    for (Vertex vertex : ((Collection<Vertex>) (tin.getVertices(true)))) {\n        if (tin.isFrameVertex(vertex)) {\n            vertex.setZ(Double.MAX_VALUE);\n        }\n    }\n    ReadableTriangulation triangulation = ReadableTriangulation.wrap(tin);\n    return new Result(triangulation, triangulation.getEdges());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaNode" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to the given via-node.\n * For each way there can be multiple edge IDs and there should be exactly one that is adjacent to the via-node\n * for each way. Otherwise we throw {@link OSMRestrictionException}\n */\npublic NodeResult convertForViaNode(LongArrayList fromWays, int viaNode, LongArrayList toWays) throws OSMRestrictionException {\n    if (fromWays.isEmpty() || toWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    NodeResult result = new NodeResult(fromWays.size(), toWays.size());\n    for (LongCursor fromWay : fromWays)\n        edgesByWay.apply(fromWay.value).forEachRemaining(e -> {\n            if (baseGraph.isAdjacentToNode(e.value, viaNode))\n                result.fromEdges.add(e.value);\n\n        });\n\n    if (result.fromEdges.size() < fromWays.size())\n        throw new OSMRestrictionException(\"has from-member ways that aren't adjacent to the via-member node\");\n    else if (result.fromEdges.size() > fromWays.size())\n        throw new OSMRestrictionException(\"has from-member ways that aren't split at the via-member node\");\n\n    for (LongCursor toWay : toWays)\n        edgesByWay.apply(toWay.value).forEachRemaining(e -> {\n            if (baseGraph.isAdjacentToNode(e.value, viaNode))\n                result.toEdges.add(e.value);\n\n        });\n\n    if (result.toEdges.size() < toWays.size())\n        throw new OSMRestrictionException(\"has to-member ways that aren't adjacent to the via-member node\");\n    else if (result.toEdges.size() > toWays.size())\n        throw new OSMRestrictionException(\"has to-member ways that aren't split at the via-member node\");\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.toString",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.toString" ],
    "fullMethods" : [ "@Override\npublic String toString() {\n    return ((((((((\"found: \" + found) + \", weight: \") + weight) + \", time: \") + time) + \", distance: \") + distance) + \", edges: \") + edgeIds.size();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.<init>" ],
    "fullMethods" : [ "public InternalRestriction(IntArrayList viaNodes, IntArrayList edgeKeys) {\n    this.edgeKeys = edgeKeys;\n    this.viaNodes = viaNodes;\n    this.actualEdgeKeys = ArrayUtil.constant(edgeKeys.size(), -1);\n    this.actualEdgeKeys.set(0, edgeKeys.get(0));\n    this.actualEdgeKeys.set(edgeKeys.size() - 1, edgeKeys.get(edgeKeys.size() - 1));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.toString",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.toString" ],
    "fullMethods" : [ "@Override\npublic String toString() {\n    StringBuilder result = new StringBuilder();\n    for (int i = 0; i < viaNodes.size(); i++)\n        result.append(GHUtility.getEdgeFromEdgeKey(edgeKeys.get(i))).append(\"-(\").append(viaNodes.get(i)).append(\")-\");\n\n    return (result + \"\") + GHUtility.getEdgeFromEdgeKey(edgeKeys.get(edgeKeys.size() - 1));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.setShortcutForPrepareEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.setShortcutForPrepareEdge" ],
    "fullMethods" : [ "public void setShortcutForPrepareEdge(int prepareEdge, int shortcut) {\n    int index = prepareEdge - edges;\n    if (index >= shortcutsByPrepareEdges.size())\n        shortcutsByPrepareEdges.resize(index + 1);\n\n    shortcutsByPrepareEdges.set(index, shortcut);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.GraphHopper.sortGraphForGivenOrdering",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.GraphHopper.sortGraphForGivenOrdering" ],
    "fullMethods" : [ "public static void sortGraphForGivenOrdering(BaseGraph baseGraph, IntArrayList newNodesByOldNodes, IntArrayList newEdgesByOldEdges) {\n    if (!ArrayUtil.isPermutation(newEdgesByOldEdges))\n        throw new IllegalStateException(\"New edges: not a permutation\");\n\n    if (!ArrayUtil.isPermutation(newNodesByOldNodes))\n        throw new IllegalStateException(\"New nodes: not a permutation\");\n\n    logger.info(\"sort graph for fixed ordering...\");\n    StopWatch sw = new StopWatch().start();\n    baseGraph.sortEdges(newEdgesByOldEdges::get);\n    logger.info(\"sorting {} edges took: {}\", Helper.nf(newEdgesByOldEdges.size()), sw.stop().getTimeString());\n    sw = new StopWatch().start();\n    baseGraph.relabelNodes(newNodesByOldNodes::get);\n    logger.info(\"sorting {} nodes took: {}\", Helper.nf(newNodesByOldNodes.size()), sw.stop().getTimeString());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction" ],
    "fullMethods" : [ "/**\n * Converts an OSM restriction to (multiple) single 'no' restrictions to be fed into {@link RestrictionSetter}\n */\npublic static List<RestrictionSetter.Restriction> buildRestrictionsForOSMRestriction(BaseGraph baseGraph, RestrictionTopology topology, RestrictionType type) {\n    List<RestrictionSetter.Restriction> result = new ArrayList<>();\n    if (type == NO) {\n        if (topology.isViaWayRestriction()) {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges()) {\n                    IntArrayList edges = new IntArrayList(topology.getViaEdges().size() + 2);\n                    edges.add(fromEdge.value);\n                    edges.addAll(topology.getViaEdges());\n                    edges.add(toEdge.value);\n                    result.add(RestrictionSetter.createViaEdgeRestriction(edges));\n                }\n\n        } else {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges())\n                    result.add(RestrictionSetter.createViaNodeRestriction(fromEdge.value, topology.getViaNodes().get(0), toEdge.value));\n\n\n        }\n    } else if (type == ONLY) {\n        if ((topology.getFromEdges().size() > 1) || (topology.getToEdges().size() > 1))\n            throw new IllegalArgumentException(\"'Only' restrictions with multiple from- or to- edges are not supported\");\n\n        if (topology.isViaWayRestriction())\n            result.addAll(createRestrictionsForViaEdgeOnlyRestriction(baseGraph, topology));\n        else\n            result.addAll(createRestrictionsForViaNodeOnlyRestriction(baseGraph.createEdgeExplorer(), topology.getFromEdges().get(0), topology.getViaNodes().get(0), topology.getToEdges().get(0)));\n\n    } else\n        throw new IllegalArgumentException(\"Unexpected restriction type: \" + type);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param excludeSingleNodeComponents\n * \t\tif set to true components that only contain a single node will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponents();\n}", "private ConnectedComponents findComponents() {\n    for (int node = 0; node < graph.getNodes(); ++node) {\n        if (nodeIndex[node] != (-1))\n            continue;\n\n        pushFindComponentForNode(node);\n        while (hasNext()) {\n            pop();\n            switch (dfsState) {\n                case BUILD_COMPONENT :\n                    buildComponent(v);\n                    break;\n                case UPDATE :\n                    nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n                    break;\n                case HANDLE_NEIGHBOR :\n                    {\n                        if ((nodeIndex[w] != (-1)) && nodeOnStack.get(w))\n                            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n                        if (nodeIndex[w] == (-1)) {\n                            // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                            pushUpdateLowLinks(v, w);\n                            pushFindComponentForNode(w);\n                        }\n                        break;\n                    }\n                case FIND_COMPONENT :\n                    {\n                        setupNextNode(v);\n                        // we push buildComponent first so it will run *after* we finished traversing the edges\n                        pushBuildComponent(v);\n                        EdgeIterator iter = explorer.setBaseNode(v);\n                        while (iter.next()) {\n                            pushHandleNeighbor(v, iter.getAdjNode());\n                        } \n                        break;\n                    }\n                default :\n                    throw new IllegalStateException(\"Unknown state: \" + dfsState);\n            }\n        } \n    }\n    return components;\n}", "private void buildComponent(int v) {\n    if (nodeLowLink[v] == nodeIndex[v]) {\n        if (tarjanStack.getLast() == v) {\n            tarjanStack.removeLast();\n            nodeOnStack.clear(v);\n            components.numComponents++;\n            components.numNodes++;\n            if (!excludeSingleNodeComponents)\n                components.singleNodeComponents.set(v);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int w = tarjanStack.removeLast();\n                component.add(w);\n                nodeOnStack.clear(w);\n                if (w == v)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numNodes += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays", "com.graphhopper.reader.osm.WayToEdgeConverter.buildResult" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to each other. For example for given\n * from-, via- and to-ways there can be multiple edges associated with each (because each way can be split into\n * multiple edges). We then need to find the from-edge that is connected with one of the via-edges which in turn\n * must be connected with one of the to-edges. We use DFS/backtracking to do this.\n * There can also be *multiple* via-ways, but the concept is the same.\n * Note that there can also be multiple from- or to-*ways*, but only one of each of them should be considered at a\n * time. In contrast to the via-ways there are only multiple from/to-ways, because of restrictions like no_entry or\n * no_exit where there can be multiple from- or to-members. So we need to find one edge-chain for each pair of from-\n * and to-ways.\n * Besides the edge IDs we also return the node IDs that connect the edges, so we can add turn restrictions at these\n * nodes later.\n */\npublic EdgeResult convertForViaWays(LongArrayList fromWays, LongArrayList viaWays, LongArrayList toWays) throws OSMRestrictionException {\n    if ((fromWays.isEmpty() || toWays.isEmpty()) || viaWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from-, via- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    List<IntArrayList> solutions = new ArrayList<>();\n    for (LongCursor fromWay : fromWays)\n        for (LongCursor toWay : toWays)\n            findEdgeChain(fromWay.value, viaWays, toWay.value, solutions);\n\n\n    if (solutions.size() < (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has disconnected member ways\");\n    else if (solutions.size() > (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has member ways that do not form a unique path\");\n\n    return buildResult(solutions, fromWays, viaWays, toWays);\n}", "private static EdgeResult buildResult(List<IntArrayList> edgeChains, LongArrayList fromWays, LongArrayList viaWays, LongArrayList toWays) {\n    EdgeResult result = new EdgeResult(fromWays.size(), viaWays.size(), toWays.size());\n    // we get multiple edge chains, but they are expected to be identical except for their first or last members\n    IntArrayList firstChain = edgeChains.get(0);\n    result.fromEdges.add(firstChain.get(0));\n    for (int i = 1; i < (firstChain.size() - 3); i += 2) {\n        result.nodes.add(firstChain.get(i));\n        result.viaEdges.add(firstChain.get(i + 1));\n    }\n    result.nodes.add(firstChain.get(firstChain.size() - 2));\n    result.toEdges.add(firstChain.get(firstChain.size() - 1));\n    // We keep the first/last elements of all chains in case there are multiple from/to ways\n    List<IntArrayList> otherChains = edgeChains.subList(1, edgeChains.size());\n    if (fromWays.size() > 1) {\n        if (otherChains.stream().anyMatch(chain -> chain.get(chain.size() - 1) != firstChain.get(firstChain.size() - 1)))\n            throw new IllegalArgumentException(((((((\"edge chains were supposed to be the same except for their first elements, but got: \" + edgeChains) + \" - for: \") + fromWays) + \", \") + viaWays) + \", \") + toWays);\n\n        otherChains.forEach(chain -> result.fromEdges.add(chain.get(0)));\n    } else if (toWays.size() > 1) {\n        if (otherChains.stream().anyMatch(chain -> chain.get(0) != firstChain.get(0)))\n            throw new IllegalArgumentException(((((((\"edge chains were supposed to be the same except for their last elements, but got: \" + edgeChains) + \" - for: \") + fromWays) + \", \") + viaWays) + \", \") + toWays);\n\n        otherChains.forEach(chain -> result.toEdges.add(chain.get(chain.size() - 1)));\n    } else if (!otherChains.isEmpty())\n        throw new IllegalStateException(\"If there are multiple chains there must be either multiple from- or to-ways.\");\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.shuffle",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.shuffle" ],
    "fullMethods" : [ "/**\n * Shuffles the elements of the given list in place and returns it\n */\npublic static IntArrayList shuffle(IntArrayList list, Random random) {\n    int maxHalf = list.size() / 2;\n    for (int x1 = 0; x1 < maxHalf; x1++) {\n        int x2 = random.nextInt(maxHalf) + maxHalf;\n        int tmp = list.buffer[x1];\n        list.buffer[x1] = list.buffer[x2];\n        list.buffer[x2] = tmp;\n    }\n    return list;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgesMap.putIfReserved",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgesMap.putIfReserved" ],
    "fullMethods" : [ "public void putIfReserved(long way, int edge) {\n    if (edge < 0)\n        throw new IllegalArgumentException(\"edge must be >= 0, but was: \" + edge);\n\n    if (way != lastWay) {\n        int idx = offsetIndexByWay.indexOf(way);\n        // not reserved yet\n        if (idx < 0)\n            return;\n\n        // already taken\n        if (offsetIndexByWay.indexGet(idx) != RESERVED)\n            throw new IllegalArgumentException((\"You need to add all edges for way: \" + way) + \" consecutively\");\n\n        offsetIndexByWay.indexReplace(idx, offsets.size());\n        offsets.add(this.edges.size());\n        lastWay = way;\n    }\n    this.edges.add(edge);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.prepareForContraction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.prepareForContraction", "com.graphhopper.routing.ch.CHPreparationGraph.OrigGraph.Builder.build", "com.graphhopper.routing.ch.CHPreparationGraph.OrigGraph.Builder.buildFirstEdgesByNode" ],
    "fullMethods" : [ "public void prepareForContraction() {\n    checkNotReady();\n    origGraph = (edgeBased) ? origGraphBuilder.build() : null;\n    origGraphBuilder = null;\n    ready = true;\n}", "{\n    com.carrotsearch.hppc.IntArrayList $stack10, $stack11, $stack12, $stack2, $stack3, $stack7, $stack8, $stack9;\n    com.carrotsearch.hppc.sorting.IndirectComparator #l0;\n    com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator #l1;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph $stack13;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder this;\n    int $stack6;\n    int[] $stack4, sortOrder;\n    java.lang.Object $stack5;\n\n\n    this := @this: com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder;\n    $stack2 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack6 = $stack2.<com.carrotsearch.hppc.IntArrayList: int elementsCount>;\n    $stack5 = new com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator;\n    $stack3 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack4 = $stack3.<com.carrotsearch.hppc.IntArrayList: int[] buffer>;\n    #l1 = (com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator) $stack5;\n    specialinvoke #l1.<com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator: void <init>(int[])>($stack4);\n    #l0 = (com.carrotsearch.hppc.sorting.IndirectComparator) $stack5;\n    sortOrder = staticinvoke <com.carrotsearch.hppc.sorting.IndirectSort: int[] mergesort(int,int,com.carrotsearch.hppc.sorting.IndirectComparator)>(0, $stack6, #l0);\n    $stack7 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack7, sortOrder);\n    $stack8 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack8, sortOrder);\n    $stack9 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack9, sortOrder);\n    $stack13 = new com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph;\n    $stack12 = virtualinvoke this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList buildFirstEdgesByNode()>();\n    $stack11 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    $stack10 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    specialinvoke $stack13.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph: void <init>(com.carrotsearch.hppc.IntArrayList,com.carrotsearch.hppc.IntArrayList,com.carrotsearch.hppc.IntArrayList)>($stack12, $stack11, $stack10);\n\n    return $stack13;\n}\n", "{\n    com.carrotsearch.hppc.IntArrayList $stack7, $stack9, firstEdgesByNode;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder this;\n    int $stack10, $stack6, $stack8, edgeIndex, from, numEdges, numFroms;\n\n\n    this := @this: com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder;\n    $stack6 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxFrom>;\n    numFroms = $stack6 + 1;\n    $stack7 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    numEdges = virtualinvoke $stack7.<com.carrotsearch.hppc.IntArrayList: int size()>();\n    $stack8 = numFroms + 1;\n    firstEdgesByNode = staticinvoke <com.graphhopper.util.ArrayUtil: com.carrotsearch.hppc.IntArrayList zero(int)>($stack8);\n\n    if numFroms != 0 goto label1;\n    virtualinvoke firstEdgesByNode.<com.carrotsearch.hppc.IntArrayList: int set(int,int)>(0, numEdges);\n\n    return firstEdgesByNode;\n\n  label1:\n    edgeIndex = 0;\n    from = 0;\n\n  label2:\n    if from >= numFroms goto label5;\n\n  label3:\n    if edgeIndex >= numEdges goto label4;\n    $stack9 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack10 = virtualinvoke $stack9.<com.carrotsearch.hppc.IntArrayList: int get(int)>(edgeIndex);\n\n    if $stack10 >= from goto label4;\n    edgeIndex = edgeIndex + 1;\n\n    goto label3;\n\n  label4:\n    virtualinvoke firstEdgesByNode.<com.carrotsearch.hppc.IntArrayList: int set(int,int)>(from, edgeIndex);\n    from = from + 1;\n\n    goto label2;\n\n  label5:\n    virtualinvoke firstEdgesByNode.<com.carrotsearch.hppc.IntArrayList: int set(int,int)>(numFroms, numEdges);\n\n    return firstEdgesByNode;\n}\n" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.isPermutation",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.isPermutation" ],
    "fullMethods" : [ "public static boolean isPermutation(IntArrayList arr) {\n    BitSet present = new BitSet(arr.size());\n    for (IntCursor e : arr) {\n        if ((e.value >= arr.size()) || (e.value < 0))\n            return false;\n\n        if (present.get(e.value))\n            return false;\n\n        present.set(e.value);\n    }\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.ArrayEdgeIntAccess.setInt",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ev.ArrayEdgeIntAccess.setInt" ],
    "fullMethods" : [ "@Override\npublic void setInt(int edgeId, int index, int value) {\n    int arrIndex = (edgeId * intsPerEdge) + index;\n    if (arrIndex >= arr.size())\n        arr.resize(arrIndex + 1);\n\n    arr.set(arrIndex, value);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.index.LineIntIndex.store",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.index.LineIntIndex.store", "com.graphhopper.storage.index.LineIntIndex.store" ],
    "fullMethods" : [ "public void store(InMemConstructionIndex inMem) {\n    indexStructureInfo = IndexStructureInfo.create(bounds, minResolutionInMeter);\n    keyAlgo = indexStructureInfo.getKeyAlgo();\n    entries = indexStructureInfo.getEntries();\n    shifts = indexStructureInfo.getShifts();\n    dataAccess.create(64 * 1024);\n    try {\n        store(inMem.root, START_POINTER);\n    } catch (Exception ex) {\n        throw new IllegalStateException(\"Problem while storing location index. \" + Helper.getMemInfo(), ex);\n    }\n    initialized = true;\n}", "private int store(InMemConstructionIndex.InMemEntry entry, int intPointer) {\n    long pointer = ((long) (intPointer)) * 4;\n    if (entry.isLeaf()) {\n        InMemConstructionIndex.InMemLeafEntry leaf = ((InMemConstructionIndex.InMemLeafEntry) (entry));\n        IntArrayList entries = leaf.getResults();\n        int len = entries.size();\n        if (len == 0) {\n            return intPointer;\n        }\n        size += len;\n        intPointer++;\n        leafs++;\n        dataAccess.ensureCapacity(((long) ((intPointer + len) + 1)) * 4);\n        if (len == 1) {\n            // less disc space for single entries\n            dataAccess.setInt(pointer, (-entries.get(0)) - 1);\n        } else {\n            for (int index = 0; index < len; index++ , intPointer++) {\n                dataAccess.setInt(((long) (intPointer)) * 4, entries.get(index));\n            }\n            dataAccess.setInt(pointer, intPointer);\n        }\n    } else {\n        InMemConstructionIndex.InMemTreeEntry treeEntry = ((InMemConstructionIndex.InMemTreeEntry) (entry));\n        int len = treeEntry.subEntries.length;\n        intPointer += len;\n        for (int subCounter = 0; subCounter < len; subCounter++ , pointer += 4) {\n            InMemConstructionIndex.InMemEntry subEntry = treeEntry.subEntries[subCounter];\n            if (subEntry == null) {\n                continue;\n            }\n            dataAccess.ensureCapacity(((long) (intPointer + 1)) * 4);\n            int prevIntPointer = intPointer;\n            intPointer = store(subEntry, prevIntPointer);\n            if (intPointer == prevIntPointer) {\n                dataAccess.setInt(pointer, 0);\n            } else {\n                dataAccess.setInt(pointer, prevIntPointer);\n            }\n        }\n    }\n    return intPointer;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.range",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.range" ],
    "fullMethods" : [ "/**\n * Creates an IntArrayList filled with the integers [startIncl,endExcl[\n */\npublic static IntArrayList range(int startIncl, int endExcl) {\n    IntArrayList result = new IntArrayList(endExcl - startIncl);\n    result.elementsCount = endExcl - startIncl;\n    for (int i = 0; i < result.size(); ++i)\n        result.set(i, startIncl + i);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.ArrayEdgeIntAccess.getInt",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ev.ArrayEdgeIntAccess.getInt" ],
    "fullMethods" : [ "@Override\npublic int getInt(int edgeId, int index) {\n    int arrIndex = (edgeId * intsPerEdge) + index;\n    return arrIndex >= arr.size() ? 0 : arr.get(arrIndex);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.RestrictionTopology.node",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.RestrictionTopology.node", "com.graphhopper.reader.osm.RestrictionTopology.<init>" ],
    "fullMethods" : [ "public static RestrictionTopology node(IntArrayList fromEdges, int viaNode, IntArrayList toEdges) {\n    return new RestrictionTopology(false, IntArrayList.from(viaNode), fromEdges, null, toEdges);\n}", "private RestrictionTopology(boolean isViaWayRestriction, IntArrayList viaNodes, IntArrayList fromEdges, IntArrayList viaEdges, IntArrayList toEdges) {\n    if ((fromEdges.size() > 1) && (toEdges.size() > 1))\n        throw new IllegalArgumentException(\"fromEdges and toEdges cannot be size > 1 at the same time\");\n\n    if (fromEdges.isEmpty() || toEdges.isEmpty())\n        throw new IllegalArgumentException(\"fromEdges and toEdges must not be empty\");\n\n    if ((!isViaWayRestriction) && (viaNodes.size() != 1))\n        throw new IllegalArgumentException(\"for node restrictions there must be exactly one via node\");\n\n    if ((!isViaWayRestriction) && (viaEdges != null))\n        throw new IllegalArgumentException(\"for node restrictions the viaEdges must be null\");\n\n    if (isViaWayRestriction && viaEdges.isEmpty())\n        throw new IllegalArgumentException(\"for way restrictions there must at least one via edge\");\n\n    if (isViaWayRestriction && (viaNodes.size() != (viaEdges.size() + 1)))\n        throw new IllegalArgumentException(\"for way restrictions there must be one via node more than there are via edges\");\n\n    this.isViaWayRestriction = isViaWayRestriction;\n    this.viaNodes = viaNodes;\n    this.fromEdges = fromEdges;\n    this.viaEdges = viaEdges;\n    this.toEdges = toEdges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.calcEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.calcEdges" ],
    "fullMethods" : [ "/**\n * Returns the list of all edges.\n */\npublic List<EdgeIteratorState> calcEdges() {\n    final List<EdgeIteratorState> edges = new ArrayList<>(edgeIds.size());\n    if (edgeIds.isEmpty())\n        return edges;\n\n    forEveryEdge(new EdgeVisitor() {\n        @Override\n        public void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n            edges.add(eb);\n        }\n\n        @Override\n        public void finish() {\n        }\n    });\n    return edges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.calcPoints",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.calcPoints" ],
    "fullMethods" : [ "/**\n * This method calculated a list of points for this path\n * <p>\n *\n * @return the geometry of this path\n */\npublic PointList calcPoints() {\n    final PointList points = new PointList(edgeIds.size() + 1, nodeAccess.is3D());\n    if (edgeIds.isEmpty()) {\n        if (isFound()) {\n            points.add(nodeAccess, endNode);\n        }\n        return points;\n    }\n    int tmpNode = getFromNode();\n    points.add(nodeAccess, tmpNode);\n    forEveryEdge(new EdgeVisitor() {\n        @Override\n        public void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n            PointList pl = eb.fetchWayGeometry(FetchMode.PILLAR_AND_ADJ);\n            for (int j = 0; j < pl.size(); j++) {\n                points.add(pl, j);\n            }\n        }\n\n        @Override\n        public void finish() {\n        }\n    });\n    return points;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentForEdgeKey", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeTransitionFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponentsRecursive();\n}", "private ConnectedComponents findComponentsRecursive() {\n    initForEntireGraph();\n    AllEdgesIterator iter = graph.getAllEdges();\n    while (iter.next()) {\n        int edgeKeyFwd = createEdgeKey(iter, false);\n        if (!edgeKeyIndex.has(edgeKeyFwd))\n            findComponentForEdgeKey(edgeKeyFwd, iter.getAdjNode());\n\n        int edgeKeyBwd = createEdgeKey(iter, true);\n        if (!edgeKeyIndex.has(edgeKeyBwd))\n            findComponentForEdgeKey(edgeKeyBwd, iter.getAdjNode());\n\n    } \n    return components;\n}", "private void findComponentForEdgeKey(int p, int adjNode) {\n    setupNextEdgeKey(p);\n    // we have to create a new explorer on each iteration because of the nested edge iterations\n    final int edge = getEdgeFromEdgeKey(p);\n    EdgeExplorer explorer = graph.createEdgeExplorer();\n    EdgeIterator iter = explorer.setBaseNode(adjNode);\n    while (iter.next()) {\n        if (!edgeTransitionFilter.accept(edge, iter))\n            continue;\n\n        int q = createEdgeKey(iter, false);\n        handleNeighbor(p, q, iter.getAdjNode());\n    } \n    buildComponent(p);\n}", "private void buildComponent(int p) {\n    if (edgeKeyLowLink.get(p) == edgeKeyIndex.get(p)) {\n        if (tarjanStack.getLast() == p) {\n            tarjanStack.removeLast();\n            edgeKeyOnStack.remove(p);\n            components.numComponents++;\n            components.numEdgeKeys++;\n            if (!excludeSingleEdgeComponents)\n                components.singleEdgeComponents.set(p);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int q = tarjanStack.removeLast();\n                component.add(q);\n                edgeKeyOnStack.remove(q);\n                if (q == p)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numEdgeKeys += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.finishSearch",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.finishSearch" ],
    "fullMethods" : [ "public void finishSearch() {\n    // update stats using values of last search\n    stats.numPolls += numPolls;\n    stats.maxPolls = Math.max(stats.maxPolls, numPolls);\n    stats.numExplored += changedEdgeKeys.size();\n    stats.maxExplored = Math.max(stats.maxExplored, changedEdgeKeys.size());\n    stats.numUpdates += numUpdates;\n    stats.maxUpdates = Math.max(stats.maxUpdates, numUpdates);\n    reset();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.getFinalEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.getFinalEdge" ],
    "fullMethods" : [ "/**\n * Yields the final edge of the path\n */\npublic EdgeIteratorState getFinalEdge() {\n    return graph.getEdgeIteratorState(edgeIds.get(edgeIds.size() - 1), endNode);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.reverse",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.reverse" ],
    "fullMethods" : [ "/**\n * Reverses the order of the given list's elements in place and returns it\n */\npublic static IntArrayList reverse(IntArrayList list) {\n    final int[] buffer = list.buffer;\n    int tmp;\n    for (int start = 0, end = list.size() - 1; start < end; start++ , end--) {\n        // swap the values\n        tmp = buffer[start];\n        buffer[start] = buffer[end];\n        buffer[end] = tmp;\n    }\n    return list;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.RestrictionTopology.way",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.RestrictionTopology.way", "com.graphhopper.reader.osm.RestrictionTopology.<init>" ],
    "fullMethods" : [ "public static RestrictionTopology way(IntArrayList fromEdges, IntArrayList viaEdges, IntArrayList toEdges, IntArrayList viaNodes) {\n    return new RestrictionTopology(true, viaNodes, fromEdges, viaEdges, toEdges);\n}", "private RestrictionTopology(boolean isViaWayRestriction, IntArrayList viaNodes, IntArrayList fromEdges, IntArrayList viaEdges, IntArrayList toEdges) {\n    if ((fromEdges.size() > 1) && (toEdges.size() > 1))\n        throw new IllegalArgumentException(\"fromEdges and toEdges cannot be size > 1 at the same time\");\n\n    if (fromEdges.isEmpty() || toEdges.isEmpty())\n        throw new IllegalArgumentException(\"fromEdges and toEdges must not be empty\");\n\n    if ((!isViaWayRestriction) && (viaNodes.size() != 1))\n        throw new IllegalArgumentException(\"for node restrictions there must be exactly one via node\");\n\n    if ((!isViaWayRestriction) && (viaEdges != null))\n        throw new IllegalArgumentException(\"for node restrictions the viaEdges must be null\");\n\n    if (isViaWayRestriction && viaEdges.isEmpty())\n        throw new IllegalArgumentException(\"for way restrictions there must at least one via edge\");\n\n    if (isViaWayRestriction && (viaNodes.size() != (viaEdges.size() + 1)))\n        throw new IllegalArgumentException(\"for way restrictions there must be one via node more than there are via edges\");\n\n    this.isViaWayRestriction = isViaWayRestriction;\n    this.viaNodes = viaNodes;\n    this.fromEdges = fromEdges;\n    this.viaEdges = viaEdges;\n    this.toEdges = toEdges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForEdgeState", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.startSearch", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param edgeTransitionFilter\n * \t\tOnly edge transitions accepted by this filter will be considered when we explore the graph.\n * \t\tIf a turn is not accepted the corresponding path will be ignored (edges that are only connected\n * \t\tby a path with such a turn will not be considered to belong to the same component)\n * @param excludeSingleEdgeComponents\n * \t\tif set to true components that only contain a single edge will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponents();\n}", "private ConnectedComponents findComponents() {\n    initForEntireGraph();\n    AllEdgesIterator iter = graph.getAllEdges();\n    while (iter.next()) {\n        findComponentsForEdgeState(iter);\n    } \n    return components;\n}", "private void findComponentsForEdgeState(EdgeIteratorState edge) {\n    int edgeKeyFwd = createEdgeKey(edge, false);\n    if (!edgeKeyIndex.has(edgeKeyFwd))\n        pushFindComponentForEdgeKey(edgeKeyFwd, edge.getAdjNode());\n\n    startSearch();\n    // We need to start the search for both edge keys of this edge, but its important to check if the second\n    // has already been found by the first search. So we cannot simply push them both and start the search once.\n    int edgeKeyBwd = createEdgeKey(edge, true);\n    if (!edgeKeyIndex.has(edgeKeyBwd))\n        pushFindComponentForEdgeKey(edgeKeyBwd, edge.getAdjNode());\n\n    startSearch();\n}", "private void startSearch() {\n    while (hasNext()) {\n        pop();\n        switch (dfsState) {\n            case BUILD_COMPONENT :\n                buildComponent(p);\n                break;\n            case UPDATE :\n                edgeKeyLowLink.minTo(p, edgeKeyLowLink.get(q));\n                break;\n            case HANDLE_NEIGHBOR :\n                if (edgeKeyIndex.has(q) && edgeKeyOnStack.contains(q))\n                    edgeKeyLowLink.minTo(p, edgeKeyIndex.get(q));\n\n                if (!edgeKeyIndex.has(q)) {\n                    // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                    pushUpdateLowLinks(p, q);\n                    pushFindComponentForEdgeKey(q, adj);\n                }\n                break;\n            case FIND_COMPONENT :\n                setupNextEdgeKey(p);\n                // we push buildComponent first so it will run *after* we finished traversing the edges\n                pushBuildComponent(p);\n                final int edge = getEdgeFromEdgeKey(p);\n                EdgeIterator it = explorer.setBaseNode(adj);\n                while (it.next()) {\n                    if (!edgeTransitionFilter.accept(edge, it))\n                        continue;\n\n                    int q = createEdgeKey(it, false);\n                    pushHandleNeighbor(p, q, it.getAdjNode());\n                } \n                break;\n            default :\n                throw new IllegalStateException(\"Unknown state: \" + dfsState);\n        }\n    } \n}", "private void buildComponent(int p) {\n    if (edgeKeyLowLink.get(p) == edgeKeyIndex.get(p)) {\n        if (tarjanStack.getLast() == p) {\n            tarjanStack.removeLast();\n            edgeKeyOnStack.remove(p);\n            components.numComponents++;\n            components.numEdgeKeys++;\n            if (!excludeSingleEdgeComponents)\n                components.singleEdgeComponents.set(p);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int q = tarjanStack.removeLast();\n                component.add(q);\n                edgeKeyOnStack.remove(q);\n                if (q == p)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numEdgeKeys += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.forEveryEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.forEveryEdge" ],
    "fullMethods" : [ "/**\n * Iterates over all edges in this path sorted from start to end and calls the visitor callback\n * for every edge.\n * <p>\n *\n * @param visitor\n * \t\tcallback to handle every edge. The edge is decoupled from the iterator and can\n * \t\tbe stored.\n */\npublic void forEveryEdge(EdgeVisitor visitor) {\n    int tmpNode = getFromNode();\n    int len = edgeIds.size();\n    int prevEdgeId = EdgeIterator.NO_EDGE;\n    for (int i = 0; i < len; i++) {\n        EdgeIteratorState edgeBase = graph.getEdgeIteratorState(edgeIds.get(i), tmpNode);\n        if (edgeBase == null)\n            throw new IllegalStateException(((((((\"Edge \" + edgeIds.get(i)) + \" was empty when requested with node \") + tmpNode) + \", array index:\") + i) + \", edges:\") + edgeIds.size());\n\n        tmpNode = edgeBase.getBaseNode();\n        // more efficient swap, currently not implemented for virtual edges: visitor.next(edgeBase.detach(true), i);\n        edgeBase = graph.getEdgeIteratorState(edgeBase.getEdge(), tmpNode);\n        visitor.next(edgeBase, i, prevEdgeId);\n        prevEdgeId = edgeBase.getEdge();\n    }\n    visitor.finish();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForEdgeState", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.startSearch", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Like {@link #findComponents(Graph, EdgeTransitionFilter, boolean)}, but the search only starts at the\n * given edges. This does not mean the search cannot expand to other edges, but this can be controlled by the\n * edgeTransitionFilter. This method does not return single edge components (the excludeSingleEdgeComponents option is\n * set to true).\n */\npublic static ConnectedComponents findComponentsForStartEdges(Graph graph, EdgeTransitionFilter edgeTransitionFilter, IntContainer edges) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, true).findComponentsForStartEdges(edges);\n}", "private ConnectedComponents findComponentsForStartEdges(IntContainer startEdges) {\n    initForStartEdges(startEdges.size());\n    for (IntCursor edge : startEdges) {\n        // todo: using getEdgeIteratorState here is not efficient\n        EdgeIteratorState edgeState = graph.getEdgeIteratorState(edge.value, Integer.MIN_VALUE);\n        if (!edgeTransitionFilter.accept(NO_EDGE, edgeState))\n            continue;\n\n        findComponentsForEdgeState(edgeState);\n    }\n    return components;\n}", "private void findComponentsForEdgeState(EdgeIteratorState edge) {\n    int edgeKeyFwd = createEdgeKey(edge, false);\n    if (!edgeKeyIndex.has(edgeKeyFwd))\n        pushFindComponentForEdgeKey(edgeKeyFwd, edge.getAdjNode());\n\n    startSearch();\n    // We need to start the search for both edge keys of this edge, but its important to check if the second\n    // has already been found by the first search. So we cannot simply push them both and start the search once.\n    int edgeKeyBwd = createEdgeKey(edge, true);\n    if (!edgeKeyIndex.has(edgeKeyBwd))\n        pushFindComponentForEdgeKey(edgeKeyBwd, edge.getAdjNode());\n\n    startSearch();\n}", "private void startSearch() {\n    while (hasNext()) {\n        pop();\n        switch (dfsState) {\n            case BUILD_COMPONENT :\n                buildComponent(p);\n                break;\n            case UPDATE :\n                edgeKeyLowLink.minTo(p, edgeKeyLowLink.get(q));\n                break;\n            case HANDLE_NEIGHBOR :\n                if (edgeKeyIndex.has(q) && edgeKeyOnStack.contains(q))\n                    edgeKeyLowLink.minTo(p, edgeKeyIndex.get(q));\n\n                if (!edgeKeyIndex.has(q)) {\n                    // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                    pushUpdateLowLinks(p, q);\n                    pushFindComponentForEdgeKey(q, adj);\n                }\n                break;\n            case FIND_COMPONENT :\n                setupNextEdgeKey(p);\n                // we push buildComponent first so it will run *after* we finished traversing the edges\n                pushBuildComponent(p);\n                final int edge = getEdgeFromEdgeKey(p);\n                EdgeIterator it = explorer.setBaseNode(adj);\n                while (it.next()) {\n                    if (!edgeTransitionFilter.accept(edge, it))\n                        continue;\n\n                    int q = createEdgeKey(it, false);\n                    pushHandleNeighbor(p, q, it.getAdjNode());\n                } \n                break;\n            default :\n                throw new IllegalStateException(\"Unknown state: \" + dfsState);\n        }\n    } \n}", "private void buildComponent(int p) {\n    if (edgeKeyLowLink.get(p) == edgeKeyIndex.get(p)) {\n        if (tarjanStack.getLast() == p) {\n            tarjanStack.removeLast();\n            edgeKeyOnStack.remove(p);\n            components.numComponents++;\n            components.numEdgeKeys++;\n            if (!excludeSingleEdgeComponents)\n                components.singleEdgeComponents.set(p);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int q = tarjanStack.removeLast();\n                component.add(q);\n                edgeKeyOnStack.remove(q);\n                if (q == p)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numEdgeKeys += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.createViaEdgeRestriction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.createViaEdgeRestriction" ],
    "fullMethods" : [ "public static Restriction createViaEdgeRestriction(IntArrayList edges) {\n    if (edges.size() < 3)\n        throw new IllegalArgumentException(\"Via-edge restrictions must have at least three edges, but got: \" + edges.size());\n\n    return new Restriction(edges, -1);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.getLast",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.getLast" ],
    "fullMethods" : [ "public static int getLast(IntArrayList list) {\n    if (list.isEmpty())\n        throw new IllegalArgumentException(\"Cannot get last element of an empty list\");\n\n    return list.get(list.size() - 1);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.calcNodes",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.calcNodes" ],
    "fullMethods" : [ "/**\n *\n * @return the uncached node indices of the tower nodes in this path.\n */\npublic IntIndexedContainer calcNodes() {\n    final IntArrayList nodes = new IntArrayList(edgeIds.size() + 1);\n    if (edgeIds.isEmpty()) {\n        if (isFound()) {\n            nodes.add(endNode);\n        }\n        return nodes;\n    }\n    int tmpNode = getFromNode();\n    nodes.add(tmpNode);\n    forEveryEdge(new EdgeVisitor() {\n        @Override\n        public void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n            nodes.add(eb.getAdjNode());\n        }\n\n        @Override\n        public void finish() {\n        }\n    });\n    return nodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.getEdgeCount",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.getEdgeCount" ],
    "fullMethods" : [ "public int getEdgeCount() {\n    return edgeIds.size();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentForNode", "com.graphhopper.routing.subnetwork.TarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponentsRecursive();\n}", "private ConnectedComponents findComponentsRecursive() {\n    for (int node = 0; node < graph.getNodes(); node++) {\n        if (nodeIndex[node] == (-1)) {\n            findComponentForNode(node);\n        }\n    }\n    return components;\n}", "private void findComponentForNode(int v) {\n    setupNextNode(v);\n    // we have to create a new explorer on each iteration because of the nested edge iterations\n    EdgeExplorer explorer = graph.createEdgeExplorer(edgeFilter);\n    EdgeIterator iter = explorer.setBaseNode(v);\n    while (iter.next()) {\n        int w = iter.getAdjNode();\n        if (nodeIndex[w] == (-1)) {\n            findComponentForNode(w);\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n        } else if (nodeOnStack.get(w))\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n    } \n    buildComponent(v);\n}", "private void buildComponent(int v) {\n    if (nodeLowLink[v] == nodeIndex[v]) {\n        if (tarjanStack.getLast() == v) {\n            tarjanStack.removeLast();\n            nodeOnStack.clear(v);\n            components.numComponents++;\n            components.numNodes++;\n            if (!excludeSingleNodeComponents)\n                components.singleNodeComponents.set(v);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int w = tarjanStack.removeLast();\n                component.add(w);\n                nodeOnStack.clear(w);\n                if (w == v)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numNodes += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.checkIfTopologyIsCompatibleWithRestriction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.checkIfTopologyIsCompatibleWithRestriction" ],
    "fullMethods" : [ "public static void checkIfTopologyIsCompatibleWithRestriction(RestrictionTopology g, String restriction) throws OSMRestrictionException {\n    if ((g.getFromEdges().size() > 1) && (!\"no_entry\".equals(restriction)))\n        throw new OSMRestrictionException(\"has multiple members with role 'from' even though it is not a 'no_entry' restriction\");\n\n    if ((g.getToEdges().size() > 1) && (!\"no_exit\".equals(restriction)))\n        throw new OSMRestrictionException(\"has multiple members with role 'to' even though it is not a 'no_exit' restriction\");\n\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.GHUtility.comparePaths",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.GHUtility.comparePaths", "com.graphhopper.routing.Path.calcNodes" ],
    "fullMethods" : [ "public static List<String> comparePaths(Path refPath, Path path, int source, int target, long seed) {\n    List<String> strictViolations = new ArrayList<>();\n    double refWeight = refPath.getWeight();\n    double weight = path.getWeight();\n    if (Math.abs(refWeight - weight) > 0.01) {\n        LOGGER.warn(\"expected: \" + refPath.calcNodes());\n        LOGGER.warn(\"given:    \" + path.calcNodes());\n        LOGGER.warn(\"seed: \" + seed);\n        fail(((((((((\"wrong weight: \" + source) + \"->\") + target) + \"\\nexpected: \") + refWeight) + \"\\ngiven:    \") + weight) + \"\\nseed: \") + seed);\n    }\n    if (Math.abs(path.getDistance() - refPath.getDistance()) > 0.1) {\n        strictViolations.add(((((((\"wrong distance \" + source) + \"->\") + target) + \", expected: \") + refPath.getDistance()) + \", given: \") + path.getDistance());\n    }\n    if (Math.abs(path.getTime() - refPath.getTime()) > 50) {\n        strictViolations.add(((((((\"wrong time \" + source) + \"->\") + target) + \", expected: \") + refPath.getTime()) + \", given: \") + path.getTime());\n    }\n    IntIndexedContainer refNodes = refPath.calcNodes();\n    IntIndexedContainer pathNodes = path.calcNodes();\n    if (!refNodes.equals(pathNodes)) {\n        // sometimes there are paths including an edge a-c that has the same distance as the two edges a-b-c. in this\n        // case both options are valid best paths. we only check for this most simple and frequent case here...\n        if (path.getGraph() != refPath.getGraph())\n            fail(\"path and refPath graphs are different\");\n\n        if (!pathsEqualExceptOneEdge(path.getGraph(), refNodes, pathNodes))\n            strictViolations.add(((((((\"wrong nodes \" + source) + \"->\") + target) + \"\\nexpected: \") + refNodes) + \"\\ngiven:    \") + pathNodes);\n\n    }\n    return strictViolations;\n}", "/**\n *\n * @return the uncached node indices of the tower nodes in this path.\n */\npublic IntIndexedContainer calcNodes() {\n    final IntArrayList nodes = new IntArrayList(edgeIds.size() + 1);\n    if (edgeIds.isEmpty()) {\n        if (isFound()) {\n            nodes.add(endNode);\n        }\n        return nodes;\n    }\n    int tmpNode = getFromNode();\n    nodes.add(tmpNode);\n    forEveryEdge(new EdgeVisitor() {\n        @Override\n        public void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n            nodes.add(eb.getAdjNode());\n        }\n\n        @Override\n        public void finish() {\n        }\n    });\n    return nodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgesMap.getEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgesMap.getEdges" ],
    "fullMethods" : [ "public Iterator<IntCursor> getEdges(long way) {\n    int idx = offsetIndexByWay.indexOf(way);\n    if (idx < 0)\n        return emptyIterator();\n\n    int offsetIndex = offsetIndexByWay.indexGet(idx);\n    // we reserved this, but did not put a value later\n    if (offsetIndex == RESERVED)\n        return emptyIterator();\n\n    int offsetBegin = offsets.get(offsetIndex);\n    int offsetEnd = ((offsetIndex + 1) < offsets.size()) ? offsets.get(offsetIndex + 1) : edges.size();\n    IntCursor cursor = new IntCursor();\n    cursor.index = -1;\n    return new Iterator<IntCursor>() {\n        @Override\n        public boolean hasNext() {\n            return ((offsetBegin + cursor.index) + 1) < offsetEnd;\n        }\n\n        @Override\n        public IntCursor next() {\n            cursor.index++;\n            cursor.value = edges.get(offsetBegin + cursor.index);\n            return cursor;\n        }\n    };\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build", "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build", "com.graphhopper.routing.querygraph.QueryOverlayBuilder.buildEdgeChangesAtRealNodes", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.build", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.build", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.getNumVirtualNodes" ],
    "fullMethods" : [ "public static QueryOverlay build(int firstVirtualNodeId, int firstVirtualEdgeId, boolean is3D, List<Snap> snaps) {\n    return new QueryOverlayBuilder(firstVirtualNodeId, firstVirtualEdgeId, is3D).build(snaps);\n}", "private QueryOverlay build(List<Snap> resList) {\n    queryOverlay = new QueryOverlay(resList.size(), is3D);\n    buildVirtualEdges(resList);\n    buildEdgeChangesAtRealNodes();\n    return queryOverlay;\n}", "private void buildEdgeChangesAtRealNodes() {\n    EdgeChangeBuilder.build(queryOverlay.getClosestEdges(), queryOverlay.getVirtualEdges(), firstVirtualNodeId, queryOverlay.getEdgeChangesAtRealNodes());\n}", "/**\n * Builds a mapping between real node ids and the set of changes for their adjacent edges.\n *\n * @param edgeChangesAtRealNodes\n * \t\toutput parameter, you need to pass an empty & modifiable map and the results will\n * \t\tbe added to it\n */\nstatic void build(IntArrayList closestEdges, List<VirtualEdgeIteratorState> virtualEdges, int firstVirtualNodeId, IntObjectMap<QueryOverlay.EdgeChanges> edgeChangesAtRealNodes) {\n    new EdgeChangeBuilder(closestEdges, virtualEdges, firstVirtualNodeId, edgeChangesAtRealNodes).build();\n}", "private void build() {\n    final GHIntHashSet towerNodesToChange = new GHIntHashSet(getNumVirtualNodes());\n    // 1. for every real node adjacent to a virtual one we collect the virtual edges, also build a set of\n    // these adjacent real nodes so we can use them in the next step\n    for (int i = 0; i < getNumVirtualNodes(); i++) {\n        // base node\n        EdgeIteratorState baseRevEdge = getVirtualEdge((i * 4) + SNAP_BASE);\n        int towerNode = baseRevEdge.getAdjNode();\n        if (!isVirtualNode(towerNode)) {\n            towerNodesToChange.add(towerNode);\n            addVirtualEdges(true, towerNode, i);\n        }\n        // adj node\n        EdgeIteratorState adjEdge = getVirtualEdge((i * 4) + SNAP_ADJ);\n        towerNode = adjEdge.getAdjNode();\n        if (!isVirtualNode(towerNode)) {\n            towerNodesToChange.add(towerNode);\n            addVirtualEdges(false, towerNode, i);\n        }\n    }\n    // 2. build the list of removed edges for all real nodes adjacent to virtual ones\n    towerNodesToChange.forEach(new IntProcedure() {\n        @Override\n        public void apply(int value) {\n            addRemovedEdges(value);\n        }\n    });\n}", "private int getNumVirtualNodes() {\n    return closestEdges.size();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.invert",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.invert" ],
    "fullMethods" : [ "public static IntArrayList invert(IntArrayList list) {\n    IntArrayList result = new IntArrayList(list.size());\n    result.elementsCount = list.size();\n    for (int i = 0; i < result.elementsCount; ++i)\n        result.set(list.get(i), i);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LandmarkStorage.createLandmarks",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.lm.LandmarkStorage.createLandmarks" ],
    "fullMethods" : [ "/**\n * This method calculates the landmarks and initial weightings to &amp; from them.\n */\npublic void createLandmarks() {\n    if (isInitialized())\n        throw new IllegalStateException(\"Initialize the landmark storage only once!\");\n\n    // fill 'from' and 'to' weights with maximum value\n    long maxBytes = ((long) (graph.getNodes())) * LM_ROW_LENGTH;\n    this.landmarkWeightDA.create(2000);\n    this.landmarkWeightDA.ensureCapacity(maxBytes);\n    for (long pointer = 0; pointer < maxBytes; pointer += 2) {\n        landmarkWeightDA.setShort(pointer, ((short) (SHORT_INFINITY)));\n    }\n    int[] empty = new int[landmarks];\n    Arrays.fill(empty, UNSET_SUBNETWORK);\n    landmarkIDs.add(empty);\n    byte[] subnetworks = new byte[graph.getNodes()];\n    Arrays.fill(subnetworks, ((byte) (UNSET_SUBNETWORK)));\n    String snKey = Subnetwork.key(lmConfig.getName());\n    // TODO We could use EdgeBasedTarjanSCC instead of node-based TarjanSCC here to get the small networks directly,\n    // instead of using the subnetworkEnc from PrepareRoutingSubnetworks.\n    if (!encodedValueLookup.hasEncodedValue(snKey))\n        throw new IllegalArgumentException(((\"EncodedValue '\" + snKey) + \"' does not exist. For Landmarks this is \") + \"currently required (also used in PrepareRoutingSubnetworks). See #2256\");\n\n    // Exclude edges that we previously marked in PrepareRoutingSubnetworks to avoid problems like \"connection not found\".\n    final BooleanEncodedValue edgeInSubnetworkEnc = encodedValueLookup.getBooleanEncodedValue(snKey);\n    final IntHashSet blockedEdges;\n    // We use the areaIndex to split certain areas from each other but do not permanently change the base graph\n    // so that other algorithms still can route through these regions. This is done to increase the density of\n    // landmarks for an area like Europe+Asia, which improves the query speed.\n    if (areaIndex != null) {\n        StopWatch sw = new StopWatch().start();\n        blockedEdges = findBorderEdgeIds(areaIndex);\n        if (logDetails)\n            LOGGER.info(((((\"Made \" + blockedEdges.size()) + \" edges inaccessible. Calculated country cut in \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n\n    } else {\n        blockedEdges = new IntHashSet();\n    }\n    EdgeFilter accessFilter = edge -> (!edge.get(edgeInSubnetworkEnc)) && (!blockedEdges.contains(edge.getEdge()));\n    EdgeFilter tarjanFilter = edge -> accessFilter.accept(edge) && Double.isFinite(weighting.calcEdgeWeight(edge, false));\n    StopWatch sw = new StopWatch().start();\n    ConnectedComponents graphComponents = TarjanSCC.findComponents(graph, tarjanFilter, true);\n    if (logDetails)\n        LOGGER.info(((((\"Calculated \" + graphComponents.getComponents().size()) + \" subnetworks via tarjan in \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n\n    String additionalInfo = \"\";\n    // guess the factor\n    if (factor <= 0) {\n        // A 'factor' is necessary to store the weight in just a short value but without losing too much precision.\n        // This factor is rather delicate to pick, we estimate it from an exploration with some \"test landmarks\",\n        // see estimateMaxWeight. If we pick the distance too big for small areas this could lead to (slightly)\n        // suboptimal routes as there will be too big rounding errors. But picking it too small is bad for performance\n        // e.g. for Germany at least 1500km is very important otherwise speed is at least twice as slow e.g. for 1000km\n        double maxWeight = estimateMaxWeight(graphComponents.getComponents(), accessFilter);\n        setMaximumWeight(maxWeight);\n        additionalInfo = (\", maxWeight:\" + maxWeight) + \" from quick estimation\";\n    }\n    if (logDetails)\n        LOGGER.info((((\"init landmarks for subnetworks with node count greater than \" + minimumNodes) + \" with factor:\") + factor) + additionalInfo);\n\n    int nodes = 0;\n    for (IntArrayList subnetworkIds : graphComponents.getComponents()) {\n        nodes += subnetworkIds.size();\n        if (subnetworkIds.size() < minimumNodes)\n            continue;\n\n        if (factor <= 0)\n            throw new IllegalStateException(((((((\"factor wasn't initialized \" + factor) + \", subnetworks:\") + graphComponents.getComponents().size()) + \", minimumNodes:\") + minimumNodes) + \", current size:\") + subnetworkIds.size());\n\n        int index = subnetworkIds.size() - 1;\n        // ensure start node is reachable from both sides and no subnetwork is associated\n        for (; index >= 0; index--) {\n            int nextStartNode = subnetworkIds.get(index);\n            if (subnetworks[nextStartNode] == UNSET_SUBNETWORK) {\n                if (logDetails) {\n                    GHPoint p = createPoint(graph, nextStartNode);\n                    LOGGER.info((((((((((\"start node: \" + nextStartNode) + \" (\") + p) + \") subnetwork \") + index) + \", subnetwork size: \") + subnetworkIds.size()) + \", \") + Helper.getMemInfo()) + (areaIndex == null ? \"\" : \" area:\" + areaIndex.query(p.lat, p.lon)));\n                }\n                if (createLandmarksForSubnetwork(nextStartNode, subnetworks, accessFilter))\n                    break;\n\n            }\n        }\n        if (index < 0)\n            LOGGER.warn(((((\"next start node not found in big enough network of size \" + subnetworkIds.size()) + \", first element is \") + subnetworkIds.get(0)) + \", \") + createPoint(graph, subnetworkIds.get(0)));\n\n    }\n    int subnetworkCount = landmarkIDs.size();\n    // store all landmark node IDs and one int for the factor itself.\n    this.landmarkWeightDA.ensureCapacity((maxBytes/* landmark weights */\n     + (((long) (subnetworkCount)) * landmarks))/* landmark mapping per subnetwork */\n     + 4);\n    // calculate offset to point into landmark mapping\n    long bytePos = maxBytes;\n    for (int[] landmarks : landmarkIDs) {\n        for (int lmNodeId : landmarks) {\n            landmarkWeightDA.setInt(bytePos, lmNodeId);\n            bytePos += 4L;\n        }\n    }\n    landmarkWeightDA.setHeader(0 * 4, graph.getNodes());\n    landmarkWeightDA.setHeader(1 * 4, this.landmarks);\n    landmarkWeightDA.setHeader(2 * 4, subnetworkCount);\n    if ((factor * DOUBLE_MLTPL) > Integer.MAX_VALUE)\n        throw new UnsupportedOperationException(\"landmark weight factor cannot be bigger than Integer.MAX_VALUE \" + (factor * DOUBLE_MLTPL));\n\n    landmarkWeightDA.setHeader(3 * 4, ((int) (Math.round(factor * DOUBLE_MLTPL))));\n    // serialize fast byte[] into DataAccess\n    subnetworkStorage.create(graph.getNodes());\n    for (int nodeId = 0; nodeId < subnetworks.length; nodeId++) {\n        subnetworkStorage.setSubnetwork(nodeId, subnetworks[nodeId]);\n    }\n    if (logDetails)\n        LOGGER.info(((\"Finished landmark creation. Subnetwork node count sum \" + nodes) + \" vs. nodes \") + graph.getNodes());\n\n    initialized = true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.getToEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.getToEdge" ],
    "fullMethods" : [ "public int getToEdge() {\n    return GHUtility.getEdgeFromEdgeKey(edgeKeys.get(edgeKeys.size() - 1));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntSet.add",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntScatterSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntSet.add" ],
    "fullMethods" : [ "@Override\npublic void add(int key) {\n    set.add(key);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedNodeContractor.calculatePriority",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedNodeContractor.calculatePriority", "com.graphhopper.routing.ch.EdgeBasedNodeContractor.findAndHandlePrepareShortcuts" ],
    "fullMethods" : [ "@Override\npublic float calculatePriority(int node) {\n    activeStats = countingStats;\n    resetEdgeCounters();\n    countPreviousEdges(node);\n    // this node is isolated, maybe it belongs to a removed subnetwork, in any case we can quickly contract it\n    // no shortcuts will be introduced\n    if (numAllEdges == 0)\n        return Float.NEGATIVE_INFINITY;\n\n    stats().stopWatch.start();\n    findAndHandlePrepareShortcuts(node, this::countShortcuts, ((int) (meanDegree * params.maxPollFactorHeuristic)), wpsStatsHeur);\n    stats().stopWatch.stop();\n    // the higher the priority the later (!) this node will be contracted\n    float edgeQuotient = numShortcuts / ((float) (prepareGraph.getDegree(node)));\n    float origEdgeQuotient = numOrigEdges / ((float) (numPrevOrigEdges));\n    int hierarchyDepth = hierarchyDepths[node];\n    float priority = ((params.edgeQuotientWeight * edgeQuotient) + (params.originalEdgeQuotientWeight * origEdgeQuotient)) + (params.hierarchyDepthWeight * hierarchyDepth);\n    if (LOGGER.isTraceEnabled())\n        LOGGER.trace(\"node: {}, eq: {} / {} = {}, oeq: {} / {} = {}, depth: {} --> {}\", node, numShortcuts, numPrevEdges, edgeQuotient, numOrigEdges, numPrevOrigEdges, origEdgeQuotient, hierarchyDepth, priority);\n\n    return priority;\n}", "/**\n * This method performs witness searches between all nodes adjacent to the given node and calls the\n * given handler for all required shortcuts.\n */\nprivate void findAndHandlePrepareShortcuts(int node, PrepareShortcutHandler shortcutHandler, int maxPolls, EdgeBasedWitnessPathSearcher.Stats wpsStats) {\n    stats().nodes++;\n    addedShortcuts.clear();\n    sourceNodes.clear();\n    // traverse incoming edges/shortcuts to find all the source nodes\n    PrepareGraphEdgeIterator incomingEdges = inEdgeExplorer.setBaseNode(node);\n    while (incomingEdges.next()) {\n        final int sourceNode = incomingEdges.getAdjNode();\n        if (sourceNode == node)\n            continue;\n\n        // make sure we process each source node only once\n        if (!sourceNodes.add(sourceNode))\n            continue;\n\n        // for each source node we need to look at every incoming original edge and check which target edges are reachable\n        PrepareGraphOrigEdgeIterator origInIter = sourceNodeOrigInEdgeExplorer.setBaseNode(sourceNode);\n        while (origInIter.next()) {\n            int origInKey = reverseEdgeKey(origInIter.getOrigEdgeKeyLast());\n            // we search 'bridge paths' leading to the target edges\n            IntObjectMap<BridgePathFinder.BridePathEntry> bridgePaths = bridgePathFinder.find(origInKey, sourceNode, node);\n            if (bridgePaths.isEmpty())\n                continue;\n\n            witnessPathSearcher.initSearch(origInKey, sourceNode, node, wpsStats);\n            for (IntObjectCursor<BridgePathFinder.BridePathEntry> bridgePath : bridgePaths) {\n                if (!Double.isFinite(bridgePath.value.weight))\n                    throw new IllegalStateException(\"Bridge entry weights should always be finite\");\n\n                int targetEdgeKey = bridgePath.key;\n                dijkstraSW.start();\n                double weight = witnessPathSearcher.runSearch(bridgePath.value.chEntry.adjNode, targetEdgeKey, bridgePath.value.weight, maxPolls);\n                dijkstraSW.stop();\n                // we found a witness, nothing to do\n                if (weight <= bridgePath.value.weight)\n                    continue;\n\n                PrepareCHEntry root = bridgePath.value.chEntry;\n                while (EdgeIterator.Edge.isValid(root.parent.prepareEdge))\n                    root = root.getParent();\n\n                // we make sure to add each shortcut only once. when we are actually adding shortcuts we check for existing\n                // shortcuts anyway, but at least this is important when we *count* shortcuts.\n                long addedShortcutKey = BitUtil.LITTLE.toLong(root.firstEdgeKey, bridgePath.value.chEntry.incEdgeKey);\n                if (!addedShortcuts.add(addedShortcutKey))\n                    continue;\n\n                double initialTurnCost = prepareGraph.getTurnWeight(origInKey, sourceNode, root.firstEdgeKey);\n                bridgePath.value.chEntry.weight -= initialTurnCost;\n                LOGGER.trace(\"Adding shortcuts for target entry {}\", bridgePath.value.chEntry);\n                // todo: re-implement loop-avoidance heuristic as it existed in GH 1.0? it did not work the\n                // way it was implemented so it was removed at some point\n                shortcutHandler.handleShortcut(root, bridgePath.value.chEntry, bridgePath.value.chEntry.origEdges);\n            }\n            witnessPathSearcher.finishSearch();\n        } \n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode", "com.graphhopper.routing.ch.EdgeBasedNodeContractor.findAndHandlePrepareShortcuts" ],
    "fullMethods" : [ "@Override\npublic IntContainer contractNode(int node) {\n    activeStats = addingStats;\n    stats().stopWatch.start();\n    findAndHandlePrepareShortcuts(node, this::addShortcutsToPrepareGraph, ((int) (meanDegree * params.maxPollFactorContraction)), wpsStatsContr);\n    insertShortcuts(node);\n    IntContainer neighbors = prepareGraph.disconnect(node);\n    // We maintain an approximation of the mean degree which we update after every contracted node.\n    // We do it the same way as for node-based CH for now.\n    meanDegree = ((meanDegree * 2) + neighbors.size()) / 3;\n    updateHierarchyDepthsOfNeighbors(node, neighbors);\n    stats().stopWatch.stop();\n    return neighbors;\n}", "/**\n * This method performs witness searches between all nodes adjacent to the given node and calls the\n * given handler for all required shortcuts.\n */\nprivate void findAndHandlePrepareShortcuts(int node, PrepareShortcutHandler shortcutHandler, int maxPolls, EdgeBasedWitnessPathSearcher.Stats wpsStats) {\n    stats().nodes++;\n    addedShortcuts.clear();\n    sourceNodes.clear();\n    // traverse incoming edges/shortcuts to find all the source nodes\n    PrepareGraphEdgeIterator incomingEdges = inEdgeExplorer.setBaseNode(node);\n    while (incomingEdges.next()) {\n        final int sourceNode = incomingEdges.getAdjNode();\n        if (sourceNode == node)\n            continue;\n\n        // make sure we process each source node only once\n        if (!sourceNodes.add(sourceNode))\n            continue;\n\n        // for each source node we need to look at every incoming original edge and check which target edges are reachable\n        PrepareGraphOrigEdgeIterator origInIter = sourceNodeOrigInEdgeExplorer.setBaseNode(sourceNode);\n        while (origInIter.next()) {\n            int origInKey = reverseEdgeKey(origInIter.getOrigEdgeKeyLast());\n            // we search 'bridge paths' leading to the target edges\n            IntObjectMap<BridgePathFinder.BridePathEntry> bridgePaths = bridgePathFinder.find(origInKey, sourceNode, node);\n            if (bridgePaths.isEmpty())\n                continue;\n\n            witnessPathSearcher.initSearch(origInKey, sourceNode, node, wpsStats);\n            for (IntObjectCursor<BridgePathFinder.BridePathEntry> bridgePath : bridgePaths) {\n                if (!Double.isFinite(bridgePath.value.weight))\n                    throw new IllegalStateException(\"Bridge entry weights should always be finite\");\n\n                int targetEdgeKey = bridgePath.key;\n                dijkstraSW.start();\n                double weight = witnessPathSearcher.runSearch(bridgePath.value.chEntry.adjNode, targetEdgeKey, bridgePath.value.weight, maxPolls);\n                dijkstraSW.stop();\n                // we found a witness, nothing to do\n                if (weight <= bridgePath.value.weight)\n                    continue;\n\n                PrepareCHEntry root = bridgePath.value.chEntry;\n                while (EdgeIterator.Edge.isValid(root.parent.prepareEdge))\n                    root = root.getParent();\n\n                // we make sure to add each shortcut only once. when we are actually adding shortcuts we check for existing\n                // shortcuts anyway, but at least this is important when we *count* shortcuts.\n                long addedShortcutKey = BitUtil.LITTLE.toLong(root.firstEdgeKey, bridgePath.value.chEntry.incEdgeKey);\n                if (!addedShortcuts.add(addedShortcutKey))\n                    continue;\n\n                double initialTurnCost = prepareGraph.getTurnWeight(origInKey, sourceNode, root.firstEdgeKey);\n                bridgePath.value.chEntry.weight -= initialTurnCost;\n                LOGGER.trace(\"Adding shortcuts for target entry {}\", bridgePath.value.chEntry);\n                // todo: re-implement loop-avoidance heuristic as it existed in GH 1.0? it did not work the\n                // way it was implemented so it was removed at some point\n                shortcutHandler.handleShortcut(root, bridgePath.value.chEntry, bridgePath.value.chEntry.origEdges);\n            }\n            witnessPathSearcher.finishSearch();\n        } \n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongLongHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongLongHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongLongHashMap.<init>" ],
    "fullMethods" : [ "public GHLongLongHashMap(int capacity, double loadFactor, HashOrderMixingStrategy hashOrderMixer) {\n    super(capacity, loadFactor, hashOrderMixer);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongLongHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongLongHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongLongHashMap.<init>" ],
    "fullMethods" : [ "public GHLongLongHashMap(int capacity, double loadFactor) {\n    super(capacity, loadFactor, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongLongHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongLongHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongLongHashMap.<init>" ],
    "fullMethods" : [ "public GHLongLongHashMap(int capacity) {\n    super(capacity, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongLongHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongLongHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongLongHashMap.<init>" ],
    "fullMethods" : [ "public GHLongLongHashMap() {\n    super(10, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.EncodedValueSerializer.serializeEncodedValue",
    "thirdPartyMethod" : "com.fasterxml.jackson.core.JsonProcessingException.getMessage",
    "thirdPartyPackage" : "com.fasterxml.jackson.core",
    "path" : [ "com.graphhopper.routing.ev.EncodedValueSerializer.serializeEncodedValue" ],
    "fullMethods" : [ "public static String serializeEncodedValue(EncodedValue encodedValue) {\n    try {\n        JsonNode tree = MAPPER.valueToTree(encodedValue);\n        return MAPPER.writeValueAsString(tree);\n    } catch (JsonProcessingException e) {\n        throw new IllegalStateException(((\"Could not serialize encoded value: \" + encodedValue) + \", error: \") + e.getMessage());\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.EncodedValueSerializer.deserializeEncodedValue",
    "thirdPartyMethod" : "com.fasterxml.jackson.core.JsonProcessingException.getMessage",
    "thirdPartyPackage" : "com.fasterxml.jackson.core",
    "path" : [ "com.graphhopper.routing.ev.EncodedValueSerializer.deserializeEncodedValue" ],
    "fullMethods" : [ "public static EncodedValue deserializeEncodedValue(String serializedEncodedValue) {\n    try {\n        JsonNode jsonNode = MAPPER.readTree(serializedEncodedValue);\n        return MAPPER.treeToValue(jsonNode, EncodedValue.class);\n    } catch (JsonProcessingException e) {\n        throw new IllegalStateException(((\"Could not deserialize encoded value: \" + serializedEncodedValue) + \", error: \") + e.getMessage());\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.dem.AbstractTiffElevationProvider.getEle",
    "thirdPartyMethod" : "org.apache.xmlgraphics.image.codec.tiff.TIFFDecodeParam.<init>",
    "thirdPartyPackage" : "org.apache.xmlgraphics.image.codec.tiff",
    "path" : [ "com.graphhopper.reader.dem.AbstractTiffElevationProvider.getEle", "com.graphhopper.reader.dem.GMTEDProvider.readFile" ],
    "fullMethods" : [ "@Override\npublic double getEle(double lat, double lon) {\n    // Return fast, if there is no data available\n    if (isOutsideSupportedArea(lat, lon))\n        return 0;\n\n    lat = ((int) (lat * precision)) / precision;\n    lon = ((int) (lon * precision)) / precision;\n    String name = getFileName(lat, lon);\n    HeightTile demProvider = cacheData.get(name);\n    if (demProvider == null) {\n        if (!cacheDir.exists())\n            cacheDir.mkdirs();\n\n        int minLat = getMinLatForTile(lat);\n        int minLon = getMinLonForTile(lon);\n        // less restrictive against boundary checking\n        demProvider = new HeightTile(minLat, minLon, WIDTH, HEIGHT, LON_DEGREE * precision, LON_DEGREE, LAT_DEGREE);\n        demProvider.setInterpolate(interpolate);\n        cacheData.put(name, demProvider);\n        DataAccess heights = getDirectory().create(name + \".gh\");\n        demProvider.setHeights(heights);\n        boolean loadExisting = false;\n        try {\n            loadExisting = heights.loadExisting();\n        } catch (Exception ex) {\n            logger.warn(((\"cannot load \" + name) + \", error: \") + ex.getMessage());\n        }\n        if (!loadExisting) {\n            File zipFile = new File(cacheDir, new File(getFileNameOfLocalFile(lat, lon)).getName());\n            if (!zipFile.exists())\n                try {\n                    String zippedURL = getDownloadURL(lat, lon);\n                    downloadToFile(zipFile, zippedURL);\n                } catch (SSLException ex) {\n                    throw new IllegalStateException(\"SSL problem with elevation provider \" + getClass().getSimpleName(), ex);\n                } catch (IOException ex) {\n                    demProvider.setSeaLevel(true);\n                    // use small size on disc and in-memory\n                    heights.create(10).flush();\n                    return 0;\n                }\n\n            // short == 2 bytes\n            heights.create((2L * WIDTH) * HEIGHT);\n            Raster raster = readFile(zipFile, name + \".tif\");\n            fillDataAccessWithElevationData(raster, heights, WIDTH);\n        }// loadExisting\n\n    }\n    if (demProvider.isSeaLevel())\n        return 0;\n\n    return demProvider.getHeight(lat, lon);\n}", "@Override\nRaster readFile(File file, String tifName) {\n    SeekableStream ss = null;\n    try {\n        InputStream is = new FileInputStream(file);\n        ss = SeekableStream.wrapInputStream(is, true);\n        TIFFImageDecoder imageDecoder = new TIFFImageDecoder(ss, new TIFFDecodeParam());\n        return imageDecoder.decodeAsRaster();\n    } catch (Exception e) {\n        throw new RuntimeException(\"Can't decode \" + file.getName(), e);\n    } finally {\n        if (ss != null)\n            close(ss);\n\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntLongHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntLongHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntLongHashMap.<init>" ],
    "fullMethods" : [ "public GHIntLongHashMap(int capacity) {\n    super(capacity, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntLongHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntLongHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntLongHashMap.<init>" ],
    "fullMethods" : [ "public GHIntLongHashMap(int capacity, double loadFactor, HashOrderMixingStrategy hashOrderMixer) {\n    super(capacity, loadFactor, hashOrderMixer);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntLongHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntLongHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntLongHashMap.<init>" ],
    "fullMethods" : [ "public GHIntLongHashMap() {\n    super(10, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntLongHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntLongHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntLongHashMap.<init>" ],
    "fullMethods" : [ "public GHIntLongHashMap(int capacity, double loadFactor) {\n    super(capacity, loadFactor, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.BridgePathFinder.find",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.BridgePathFinder.find" ],
    "fullMethods" : [ "/**\n * Finds all bridge paths starting at a given node and starting edge key.\n *\n * @return a mapping between the target edge keys we can reach via bridge paths and information about the\ncorresponding bridge path\n */\npublic IntObjectMap<BridePathEntry> find(int startInEdgeKey, int startNode, int centerNode) {\n    queue.clear();\n    map.clear();\n    IntObjectMap<BridePathEntry> result = new IntObjectHashMap<>(16, 0.5, HashOrderMixing.constant(123));\n    PrepareCHEntry startEntry = new PrepareCHEntry(NO_EDGE, startInEdgeKey, startInEdgeKey, startNode, 0, 0);\n    map.put(startInEdgeKey, startEntry);\n    queue.add(startEntry);\n    while (!queue.isEmpty()) {\n        PrepareCHEntry currEntry = queue.poll();\n        PrepareGraphEdgeIterator iter = outExplorer.setBaseNode(currEntry.adjNode);\n        while (iter.next()) {\n            if (iter.getAdjNode() == centerNode) {\n                // We arrived at the center node, so we keep expanding the search\n                double weight = (currEntry.weight + graph.getTurnWeight(currEntry.incEdgeKey, currEntry.adjNode, iter.getOrigEdgeKeyFirst())) + iter.getWeight();\n                if (Double.isInfinite(weight))\n                    continue;\n\n                PrepareCHEntry entry = map.get(iter.getOrigEdgeKeyLast());\n                if (entry == null) {\n                    entry = new PrepareCHEntry(iter.getPrepareEdge(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getAdjNode(), weight, currEntry.origEdges + iter.getOrigEdgeCount());\n                    entry.parent = currEntry;\n                    map.put(iter.getOrigEdgeKeyLast(), entry);\n                    queue.add(entry);\n                } else if (weight < entry.weight) {\n                    queue.remove(entry);\n                    entry.prepareEdge = iter.getPrepareEdge();\n                    entry.origEdges = currEntry.origEdges + iter.getOrigEdgeCount();\n                    entry.firstEdgeKey = iter.getOrigEdgeKeyFirst();\n                    entry.weight = weight;\n                    entry.parent = currEntry;\n                    queue.add(entry);\n                }\n            } else if (currEntry.adjNode == centerNode) {\n                // We just left the center node, so we arrived at some neighbor node. Every edge we can reach from\n                // there is a target edge, so we add a bridge path entry for it. We do not continue the search from the\n                // neighbor node anymore\n                double weight = (currEntry.weight + graph.getTurnWeight(currEntry.incEdgeKey, currEntry.adjNode, iter.getOrigEdgeKeyFirst())) + iter.getWeight();\n                if (Double.isInfinite(weight))\n                    continue;\n\n                PrepareGraphOrigEdgeIterator origOutIter = origOutExplorer.setBaseNode(iter.getAdjNode());\n                while (origOutIter.next()) {\n                    double totalWeight = weight + graph.getTurnWeight(iter.getOrigEdgeKeyLast(), iter.getAdjNode(), origOutIter.getOrigEdgeKeyFirst());\n                    if (Double.isInfinite(totalWeight))\n                        continue;\n\n                    BridePathEntry resEntry = result.get(origOutIter.getOrigEdgeKeyFirst());\n                    if (resEntry == null) {\n                        PrepareCHEntry chEntry = new PrepareCHEntry(iter.getPrepareEdge(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getAdjNode(), weight, currEntry.origEdges + iter.getOrigEdgeCount());\n                        chEntry.parent = currEntry;\n                        resEntry = new BridePathEntry(totalWeight, chEntry);\n                        result.put(origOutIter.getOrigEdgeKeyFirst(), resEntry);\n                    } else if (totalWeight < resEntry.weight) {\n                        resEntry.weight = totalWeight;\n                        resEntry.chEntry.prepareEdge = iter.getPrepareEdge();\n                        resEntry.chEntry.firstEdgeKey = iter.getOrigEdgeKeyFirst();\n                        resEntry.chEntry.origEdges = currEntry.origEdges + iter.getOrigEdgeCount();\n                        resEntry.chEntry.incEdgeKey = iter.getOrigEdgeKeyLast();\n                        resEntry.chEntry.weight = weight;\n                        resEntry.chEntry.parent = currEntry;\n                    }\n                } \n            }\n            // We arrived at some node that is not the center node. We do not expand the search as we are only\n            // concerned with finding bridge paths.\n        } \n    } \n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.close",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.close" ],
    "fullMethods" : [ "@Override\npublic void close() {\n    routingCHGraph.close();\n    virtualEdgesAtVirtualNodes.clear();\n    virtualInEdgesAtRealNodes.clear();\n    virtualOutEdgesAtRealNodes.clear();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedNodeContractor.calculatePriority",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedNodeContractor.calculatePriority", "com.graphhopper.routing.ch.EdgeBasedNodeContractor.findAndHandlePrepareShortcuts" ],
    "fullMethods" : [ "@Override\npublic float calculatePriority(int node) {\n    activeStats = countingStats;\n    resetEdgeCounters();\n    countPreviousEdges(node);\n    // this node is isolated, maybe it belongs to a removed subnetwork, in any case we can quickly contract it\n    // no shortcuts will be introduced\n    if (numAllEdges == 0)\n        return Float.NEGATIVE_INFINITY;\n\n    stats().stopWatch.start();\n    findAndHandlePrepareShortcuts(node, this::countShortcuts, ((int) (meanDegree * params.maxPollFactorHeuristic)), wpsStatsHeur);\n    stats().stopWatch.stop();\n    // the higher the priority the later (!) this node will be contracted\n    float edgeQuotient = numShortcuts / ((float) (prepareGraph.getDegree(node)));\n    float origEdgeQuotient = numOrigEdges / ((float) (numPrevOrigEdges));\n    int hierarchyDepth = hierarchyDepths[node];\n    float priority = ((params.edgeQuotientWeight * edgeQuotient) + (params.originalEdgeQuotientWeight * origEdgeQuotient)) + (params.hierarchyDepthWeight * hierarchyDepth);\n    if (LOGGER.isTraceEnabled())\n        LOGGER.trace(\"node: {}, eq: {} / {} = {}, oeq: {} / {} = {}, depth: {} --> {}\", node, numShortcuts, numPrevEdges, edgeQuotient, numOrigEdges, numPrevOrigEdges, origEdgeQuotient, hierarchyDepth, priority);\n\n    return priority;\n}", "/**\n * This method performs witness searches between all nodes adjacent to the given node and calls the\n * given handler for all required shortcuts.\n */\nprivate void findAndHandlePrepareShortcuts(int node, PrepareShortcutHandler shortcutHandler, int maxPolls, EdgeBasedWitnessPathSearcher.Stats wpsStats) {\n    stats().nodes++;\n    addedShortcuts.clear();\n    sourceNodes.clear();\n    // traverse incoming edges/shortcuts to find all the source nodes\n    PrepareGraphEdgeIterator incomingEdges = inEdgeExplorer.setBaseNode(node);\n    while (incomingEdges.next()) {\n        final int sourceNode = incomingEdges.getAdjNode();\n        if (sourceNode == node)\n            continue;\n\n        // make sure we process each source node only once\n        if (!sourceNodes.add(sourceNode))\n            continue;\n\n        // for each source node we need to look at every incoming original edge and check which target edges are reachable\n        PrepareGraphOrigEdgeIterator origInIter = sourceNodeOrigInEdgeExplorer.setBaseNode(sourceNode);\n        while (origInIter.next()) {\n            int origInKey = reverseEdgeKey(origInIter.getOrigEdgeKeyLast());\n            // we search 'bridge paths' leading to the target edges\n            IntObjectMap<BridgePathFinder.BridePathEntry> bridgePaths = bridgePathFinder.find(origInKey, sourceNode, node);\n            if (bridgePaths.isEmpty())\n                continue;\n\n            witnessPathSearcher.initSearch(origInKey, sourceNode, node, wpsStats);\n            for (IntObjectCursor<BridgePathFinder.BridePathEntry> bridgePath : bridgePaths) {\n                if (!Double.isFinite(bridgePath.value.weight))\n                    throw new IllegalStateException(\"Bridge entry weights should always be finite\");\n\n                int targetEdgeKey = bridgePath.key;\n                dijkstraSW.start();\n                double weight = witnessPathSearcher.runSearch(bridgePath.value.chEntry.adjNode, targetEdgeKey, bridgePath.value.weight, maxPolls);\n                dijkstraSW.stop();\n                // we found a witness, nothing to do\n                if (weight <= bridgePath.value.weight)\n                    continue;\n\n                PrepareCHEntry root = bridgePath.value.chEntry;\n                while (EdgeIterator.Edge.isValid(root.parent.prepareEdge))\n                    root = root.getParent();\n\n                // we make sure to add each shortcut only once. when we are actually adding shortcuts we check for existing\n                // shortcuts anyway, but at least this is important when we *count* shortcuts.\n                long addedShortcutKey = BitUtil.LITTLE.toLong(root.firstEdgeKey, bridgePath.value.chEntry.incEdgeKey);\n                if (!addedShortcuts.add(addedShortcutKey))\n                    continue;\n\n                double initialTurnCost = prepareGraph.getTurnWeight(origInKey, sourceNode, root.firstEdgeKey);\n                bridgePath.value.chEntry.weight -= initialTurnCost;\n                LOGGER.trace(\"Adding shortcuts for target entry {}\", bridgePath.value.chEntry);\n                // todo: re-implement loop-avoidance heuristic as it existed in GH 1.0? it did not work the\n                // way it was implemented so it was removed at some point\n                shortcutHandler.handleShortcut(root, bridgePath.value.chEntry, bridgePath.value.chEntry.origEdges);\n            }\n            witnessPathSearcher.finishSearch();\n        } \n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode", "com.graphhopper.routing.ch.EdgeBasedNodeContractor.findAndHandlePrepareShortcuts" ],
    "fullMethods" : [ "@Override\npublic IntContainer contractNode(int node) {\n    activeStats = addingStats;\n    stats().stopWatch.start();\n    findAndHandlePrepareShortcuts(node, this::addShortcutsToPrepareGraph, ((int) (meanDegree * params.maxPollFactorContraction)), wpsStatsContr);\n    insertShortcuts(node);\n    IntContainer neighbors = prepareGraph.disconnect(node);\n    // We maintain an approximation of the mean degree which we update after every contracted node.\n    // We do it the same way as for node-based CH for now.\n    meanDegree = ((meanDegree * 2) + neighbors.size()) / 3;\n    updateHierarchyDepthsOfNeighbors(node, neighbors);\n    stats().stopWatch.stop();\n    return neighbors;\n}", "/**\n * This method performs witness searches between all nodes adjacent to the given node and calls the\n * given handler for all required shortcuts.\n */\nprivate void findAndHandlePrepareShortcuts(int node, PrepareShortcutHandler shortcutHandler, int maxPolls, EdgeBasedWitnessPathSearcher.Stats wpsStats) {\n    stats().nodes++;\n    addedShortcuts.clear();\n    sourceNodes.clear();\n    // traverse incoming edges/shortcuts to find all the source nodes\n    PrepareGraphEdgeIterator incomingEdges = inEdgeExplorer.setBaseNode(node);\n    while (incomingEdges.next()) {\n        final int sourceNode = incomingEdges.getAdjNode();\n        if (sourceNode == node)\n            continue;\n\n        // make sure we process each source node only once\n        if (!sourceNodes.add(sourceNode))\n            continue;\n\n        // for each source node we need to look at every incoming original edge and check which target edges are reachable\n        PrepareGraphOrigEdgeIterator origInIter = sourceNodeOrigInEdgeExplorer.setBaseNode(sourceNode);\n        while (origInIter.next()) {\n            int origInKey = reverseEdgeKey(origInIter.getOrigEdgeKeyLast());\n            // we search 'bridge paths' leading to the target edges\n            IntObjectMap<BridgePathFinder.BridePathEntry> bridgePaths = bridgePathFinder.find(origInKey, sourceNode, node);\n            if (bridgePaths.isEmpty())\n                continue;\n\n            witnessPathSearcher.initSearch(origInKey, sourceNode, node, wpsStats);\n            for (IntObjectCursor<BridgePathFinder.BridePathEntry> bridgePath : bridgePaths) {\n                if (!Double.isFinite(bridgePath.value.weight))\n                    throw new IllegalStateException(\"Bridge entry weights should always be finite\");\n\n                int targetEdgeKey = bridgePath.key;\n                dijkstraSW.start();\n                double weight = witnessPathSearcher.runSearch(bridgePath.value.chEntry.adjNode, targetEdgeKey, bridgePath.value.weight, maxPolls);\n                dijkstraSW.stop();\n                // we found a witness, nothing to do\n                if (weight <= bridgePath.value.weight)\n                    continue;\n\n                PrepareCHEntry root = bridgePath.value.chEntry;\n                while (EdgeIterator.Edge.isValid(root.parent.prepareEdge))\n                    root = root.getParent();\n\n                // we make sure to add each shortcut only once. when we are actually adding shortcuts we check for existing\n                // shortcuts anyway, but at least this is important when we *count* shortcuts.\n                long addedShortcutKey = BitUtil.LITTLE.toLong(root.firstEdgeKey, bridgePath.value.chEntry.incEdgeKey);\n                if (!addedShortcuts.add(addedShortcutKey))\n                    continue;\n\n                double initialTurnCost = prepareGraph.getTurnWeight(origInKey, sourceNode, root.firstEdgeKey);\n                bridgePath.value.chEntry.weight -= initialTurnCost;\n                LOGGER.trace(\"Adding shortcuts for target entry {}\", bridgePath.value.chEntry);\n                // todo: re-implement loop-avoidance heuristic as it existed in GH 1.0? it did not work the\n                // way it was implemented so it was removed at some point\n                shortcutHandler.handleShortcut(root, bridgePath.value.chEntry, bridgePath.value.chEntry.origEdges);\n            }\n            witnessPathSearcher.finishSearch();\n        } \n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build", "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build", "com.graphhopper.routing.querygraph.QueryOverlayBuilder.buildEdgeChangesAtRealNodes", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.build", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.<init>" ],
    "fullMethods" : [ "public static QueryOverlay build(int firstVirtualNodeId, int firstVirtualEdgeId, boolean is3D, List<Snap> snaps) {\n    return new QueryOverlayBuilder(firstVirtualNodeId, firstVirtualEdgeId, is3D).build(snaps);\n}", "private QueryOverlay build(List<Snap> resList) {\n    queryOverlay = new QueryOverlay(resList.size(), is3D);\n    buildVirtualEdges(resList);\n    buildEdgeChangesAtRealNodes();\n    return queryOverlay;\n}", "private void buildEdgeChangesAtRealNodes() {\n    EdgeChangeBuilder.build(queryOverlay.getClosestEdges(), queryOverlay.getVirtualEdges(), firstVirtualNodeId, queryOverlay.getEdgeChangesAtRealNodes());\n}", "/**\n * Builds a mapping between real node ids and the set of changes for their adjacent edges.\n *\n * @param edgeChangesAtRealNodes\n * \t\toutput parameter, you need to pass an empty & modifiable map and the results will\n * \t\tbe added to it\n */\nstatic void build(IntArrayList closestEdges, List<VirtualEdgeIteratorState> virtualEdges, int firstVirtualNodeId, IntObjectMap<QueryOverlay.EdgeChanges> edgeChangesAtRealNodes) {\n    new EdgeChangeBuilder(closestEdges, virtualEdges, firstVirtualNodeId, edgeChangesAtRealNodes).build();\n}", "private EdgeChangeBuilder(IntArrayList closestEdges, List<VirtualEdgeIteratorState> virtualEdges, int firstVirtualNodeId, IntObjectMap<QueryOverlay.EdgeChanges> edgeChangesAtRealNodes) {\n    this.closestEdges = closestEdges;\n    this.virtualEdges = virtualEdges;\n    this.firstVirtualNodeId = firstVirtualNodeId;\n    if (!edgeChangesAtRealNodes.isEmpty()) {\n        throw new IllegalArgumentException(\"real node modifications need to be empty\");\n    }\n    this.edgeChangesAtRealNodes = edgeChangesAtRealNodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaNode" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to the given via-node.\n * For each way there can be multiple edge IDs and there should be exactly one that is adjacent to the via-node\n * for each way. Otherwise we throw {@link OSMRestrictionException}\n */\npublic NodeResult convertForViaNode(LongArrayList fromWays, int viaNode, LongArrayList toWays) throws OSMRestrictionException {\n    if (fromWays.isEmpty() || toWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    NodeResult result = new NodeResult(fromWays.size(), toWays.size());\n    for (LongCursor fromWay : fromWays)\n        edgesByWay.apply(fromWay.value).forEachRemaining(e -> {\n            if (baseGraph.isAdjacentToNode(e.value, viaNode))\n                result.fromEdges.add(e.value);\n\n        });\n\n    if (result.fromEdges.size() < fromWays.size())\n        throw new OSMRestrictionException(\"has from-member ways that aren't adjacent to the via-member node\");\n    else if (result.fromEdges.size() > fromWays.size())\n        throw new OSMRestrictionException(\"has from-member ways that aren't split at the via-member node\");\n\n    for (LongCursor toWay : toWays)\n        edgesByWay.apply(toWay.value).forEachRemaining(e -> {\n            if (baseGraph.isAdjacentToNode(e.value, viaNode))\n                result.toEdges.add(e.value);\n\n        });\n\n    if (result.toEdges.size() < toWays.size())\n        throw new OSMRestrictionException(\"has to-member ways that aren't adjacent to the via-member node\");\n    else if (result.toEdges.size() > toWays.size())\n        throw new OSMRestrictionException(\"has to-member ways that aren't split at the via-member node\");\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WaySegmentParser.Pass1Handler.handleWay",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WaySegmentParser.Pass1Handler.handleWay" ],
    "fullMethods" : [ "@Override\npublic void handleWay(ReaderWay way) {\n    if (!handledWays) {\n        LOGGER.info(\"pass1 - start reading OSM ways\");\n        handledWays = true;\n    }\n    if (handledRelations)\n        throw new IllegalStateException(\"OSM way elements must be located before relation elements in OSM file\");\n\n    if (((++wayCounter) % 10000000) == 0)\n        LOGGER.info(((((((\"pass1 - processed ways: \" + nf(wayCounter)) + \", accepted ways: \") + nf(acceptedWays)) + \", way nodes: \") + nf(nodeData.getNodeCount())) + \", \") + Helper.getMemInfo());\n\n    if (!wayFilter.test(way))\n        return;\n\n    acceptedWays++;\n    for (LongCursor node : way.getNodes()) {\n        final boolean isEnd = (node.index == 0) || (node.index == (way.getNodes().size() - 1));\n        final long osmId = node.value;\n        // connection nodes are those where (only) two OSM ways are connected at their ends\n        nodeData.setOrUpdateNodeType(osmId, isEnd ? END_NODE : INTERMEDIATE_NODE, prev -> (prev == END_NODE) && isEnd ? CONNECTION_NODE : JUNCTION_NODE);\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionTopologyForGraph",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionTopologyForGraph", "com.graphhopper.reader.osm.OSMRestrictionConverter.extractMembers" ],
    "fullMethods" : [ "/**\n * OSM restriction relations specify turn restrictions between OSM ways (of course). This method rebuilds the\n * topology of such a relation in the graph representation, where the turn restrictions are specified in terms of edge/node IDs instead\n * of OSM IDs.\n *\n * @throws OSMRestrictionException\n * \t\tif the given relation is either not valid in some way and/or cannot be handled and\n * \t\tshall be ignored\n */\npublic static Triple<ReaderRelation, RestrictionTopology, RestrictionMembers> buildRestrictionTopologyForGraph(BaseGraph baseGraph, ReaderRelation relation, LongFunction<Iterator<IntCursor>> edgesByWay) throws OSMRestrictionException {\n    if (!isTurnRestriction(relation))\n        throw new IllegalArgumentException(\"expected a turn restriction: \" + relation.getTags());\n\n    RestrictionMembers restrictionMembers = extractMembers(relation);\n    if (!membersExist(restrictionMembers, edgesByWay, relation))\n        throw OSMRestrictionException.withoutWarning();\n\n    // every OSM way might be split into *multiple* edges, so now we need to figure out which edges are the ones\n    // that are actually part of the given relation\n    WayToEdgeConverter wayToEdgeConverter = new WayToEdgeConverter(baseGraph, edgesByWay);\n    if (restrictionMembers.isViaWay()) {\n        // For now let's ignore all via-way restrictions with duplicate from/to/via-members\n        // until we find cases where this is too strict.\n        if (containsDuplicateWays(restrictionMembers))\n            throw new OSMRestrictionException(\"contains duplicate from-/via-/to-members\");\n\n        WayToEdgeConverter.EdgeResult res = wayToEdgeConverter.convertForViaWays(restrictionMembers.getFromWays(), restrictionMembers.getViaWays(), restrictionMembers.getToWays());\n        return new Triple<>(relation, RestrictionTopology.way(res.getFromEdges(), res.getViaEdges(), res.getToEdges(), res.getNodes()), restrictionMembers);\n    } else {\n        int viaNode = relation.getTag(\"graphhopper:via_node\", -1);\n        if (viaNode < 0)\n            throw new IllegalStateException(\"For some reason we did not set graphhopper:via_node for this relation: \" + relation.getId());\n\n        WayToEdgeConverter.NodeResult res = wayToEdgeConverter.convertForViaNode(restrictionMembers.getFromWays(), viaNode, restrictionMembers.getToWays());\n        return new Triple<>(relation, RestrictionTopology.node(res.getFromEdges(), viaNode, res.getToEdges()), restrictionMembers);\n    }\n}", "public static RestrictionMembers extractMembers(ReaderRelation relation) throws OSMRestrictionException {\n    // we use -1 to indicate 'missing', which is fine because we exclude negative OSM IDs (see #2652)\n    long viaOSMNode = -1;\n    LongArrayList fromWays = new LongArrayList();\n    LongArrayList viaWays = new LongArrayList();\n    LongArrayList toWays = new LongArrayList();\n    for (ReaderRelation.Member member : relation.getMembers()) {\n        if (\"from\".equals(member.getRole())) {\n            if (member.getType() != ReaderElement.Type.WAY)\n                throw new OSMRestrictionException((\"has a member with role 'from' and type '\" + member.getType()) + \"', but it should be of type 'way'\");\n\n            fromWays.add(member.getRef());\n        } else if (\"to\".equals(member.getRole())) {\n            if (member.getType() != ReaderElement.Type.WAY)\n                throw new OSMRestrictionException((\"has a member with role 'to' and type '\" + member.getType()) + \"', but it should be of type 'way'\");\n\n            toWays.add(member.getRef());\n        } else if (\"via\".equals(member.getRole())) {\n            if (member.getType() == ReaderElement.Type.NODE) {\n                if (viaOSMNode >= 0)\n                    throw new OSMRestrictionException(\"has multiple members with role 'via' and type 'node', but multiple via-members are only allowed when they are of type: 'way'\");\n\n                // note that we check for combined usage of via nodes and ways later on\n                viaOSMNode = member.getRef();\n            } else if (member.getType() == ReaderElement.Type.WAY) {\n                // note that we check for combined usage of via nodes and ways later on\n                viaWays.add(member.getRef());\n            } else\n                throw new OSMRestrictionException(((\"has a member with role 'via' and\" + \" type '\") + member.getType()) + \"', but it should be of type 'node' or 'way'\");\n\n        } else if (\"location_hint\".equals(member.getRole())) {\n            // location_hint is deprecated and should no longer be used according to the wiki, but we do not warn\n            // about it, or even ignore the relation in this case, because maybe not everyone is happy to remove it.\n        } else if (member.getRole().trim().isEmpty())\n            throw new OSMRestrictionException(\"has a member with an empty role\");\n        else\n            throw new OSMRestrictionException((\"has a member with an unknown role '\" + member.getRole()) + \"'\");\n\n    }\n    if (fromWays.isEmpty() && toWays.isEmpty())\n        throw new OSMRestrictionException(\"has no member with role 'from' and 'to'\");\n    else if (fromWays.isEmpty())\n        throw new OSMRestrictionException(\"has no member with role 'from'\");\n    else if (toWays.isEmpty())\n        throw new OSMRestrictionException(\"has no member with role 'to'\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new OSMRestrictionException(\"has multiple members with role 'from' and 'to'\");\n\n    checkTags(fromWays, toWays, relation.getTags());\n    if ((viaOSMNode >= 0) && (!viaWays.isEmpty()))\n        throw new OSMRestrictionException(\"has members with role 'via' of type 'node' and 'way', but only one type is allowed\");\n    else if (viaOSMNode >= 0)\n        return RestrictionMembers.viaNode(viaOSMNode, fromWays, toWays);\n    else if (!viaWays.isEmpty())\n        return RestrictionMembers.viaWay(fromWays, viaWays, toWays);\n    else\n        throw new OSMRestrictionException(\"has no member with role 'via'\");\n\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to each other. For example for given\n * from-, via- and to-ways there can be multiple edges associated with each (because each way can be split into\n * multiple edges). We then need to find the from-edge that is connected with one of the via-edges which in turn\n * must be connected with one of the to-edges. We use DFS/backtracking to do this.\n * There can also be *multiple* via-ways, but the concept is the same.\n * Note that there can also be multiple from- or to-*ways*, but only one of each of them should be considered at a\n * time. In contrast to the via-ways there are only multiple from/to-ways, because of restrictions like no_entry or\n * no_exit where there can be multiple from- or to-members. So we need to find one edge-chain for each pair of from-\n * and to-ways.\n * Besides the edge IDs we also return the node IDs that connect the edges, so we can add turn restrictions at these\n * nodes later.\n */\npublic EdgeResult convertForViaWays(LongArrayList fromWays, LongArrayList viaWays, LongArrayList toWays) throws OSMRestrictionException {\n    if ((fromWays.isEmpty() || toWays.isEmpty()) || viaWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from-, via- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    List<IntArrayList> solutions = new ArrayList<>();\n    for (LongCursor fromWay : fromWays)\n        for (LongCursor toWay : toWays)\n            findEdgeChain(fromWay.value, viaWays, toWay.value, solutions);\n\n\n    if (solutions.size() < (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has disconnected member ways\");\n    else if (solutions.size() > (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has member ways that do not form a unique path\");\n\n    return buildResult(solutions, fromWays, viaWays, toWays);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.RestrictionMembers.getAllWays",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.RestrictionMembers.getAllWays" ],
    "fullMethods" : [ "public LongArrayList getAllWays() {\n    LongArrayList result = new LongArrayList((fromWays.size() + toWays.size()) + (isViaWay ? viaWays.size() : 0));\n    result.addAll(fromWays);\n    if (isViaWay)\n        result.addAll(viaWays);\n\n    result.addAll(toWays);\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WaySegmentParser.Pass2Handler.handleWay",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WaySegmentParser.Pass2Handler.handleWay" ],
    "fullMethods" : [ "@Override\npublic void handleWay(ReaderWay way) {\n    if (!handledWays) {\n        LOGGER.info(\"pass2 - start reading OSM ways\");\n        handledWays = true;\n    }\n    if (handledRelations)\n        throw new IllegalStateException(\"OSM way elements must be located before relation elements in OSM file\");\n\n    if (((++wayCounter) % 10000000) == 0)\n        LOGGER.info(((\"pass2 - processed ways: \" + nf(wayCounter)) + \", \") + Helper.getMemInfo());\n\n    if (!wayFilter.test(way))\n        return;\n\n    List<SegmentNode> segment = new ArrayList<>(way.getNodes().size());\n    for (LongCursor node : way.getNodes())\n        segment.add(new SegmentNode(node.value, nodeData.getId(node.value), nodeData.getTags(node.value)));\n\n    wayPreprocessor.preprocessWay(way, osmNodeId -> nodeData.getCoordinates(nodeData.getId(osmNodeId)), osmNodeId -> nodeData.getTags(osmNodeId));\n    splitWayAtJunctionsAndEmptySections(segment, way);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.ReaderWay.toString",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.ReaderWay.toString" ],
    "fullMethods" : [ "@Override\npublic String toString() {\n    return ((((\"Way id:\" + getId()) + \", nodes:\") + nodes.size()) + \", tags:\") + super.toString();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.extractMembers",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.extractMembers" ],
    "fullMethods" : [ "public static RestrictionMembers extractMembers(ReaderRelation relation) throws OSMRestrictionException {\n    // we use -1 to indicate 'missing', which is fine because we exclude negative OSM IDs (see #2652)\n    long viaOSMNode = -1;\n    LongArrayList fromWays = new LongArrayList();\n    LongArrayList viaWays = new LongArrayList();\n    LongArrayList toWays = new LongArrayList();\n    for (ReaderRelation.Member member : relation.getMembers()) {\n        if (\"from\".equals(member.getRole())) {\n            if (member.getType() != ReaderElement.Type.WAY)\n                throw new OSMRestrictionException((\"has a member with role 'from' and type '\" + member.getType()) + \"', but it should be of type 'way'\");\n\n            fromWays.add(member.getRef());\n        } else if (\"to\".equals(member.getRole())) {\n            if (member.getType() != ReaderElement.Type.WAY)\n                throw new OSMRestrictionException((\"has a member with role 'to' and type '\" + member.getType()) + \"', but it should be of type 'way'\");\n\n            toWays.add(member.getRef());\n        } else if (\"via\".equals(member.getRole())) {\n            if (member.getType() == ReaderElement.Type.NODE) {\n                if (viaOSMNode >= 0)\n                    throw new OSMRestrictionException(\"has multiple members with role 'via' and type 'node', but multiple via-members are only allowed when they are of type: 'way'\");\n\n                // note that we check for combined usage of via nodes and ways later on\n                viaOSMNode = member.getRef();\n            } else if (member.getType() == ReaderElement.Type.WAY) {\n                // note that we check for combined usage of via nodes and ways later on\n                viaWays.add(member.getRef());\n            } else\n                throw new OSMRestrictionException(((\"has a member with role 'via' and\" + \" type '\") + member.getType()) + \"', but it should be of type 'node' or 'way'\");\n\n        } else if (\"location_hint\".equals(member.getRole())) {\n            // location_hint is deprecated and should no longer be used according to the wiki, but we do not warn\n            // about it, or even ignore the relation in this case, because maybe not everyone is happy to remove it.\n        } else if (member.getRole().trim().isEmpty())\n            throw new OSMRestrictionException(\"has a member with an empty role\");\n        else\n            throw new OSMRestrictionException((\"has a member with an unknown role '\" + member.getRole()) + \"'\");\n\n    }\n    if (fromWays.isEmpty() && toWays.isEmpty())\n        throw new OSMRestrictionException(\"has no member with role 'from' and 'to'\");\n    else if (fromWays.isEmpty())\n        throw new OSMRestrictionException(\"has no member with role 'from'\");\n    else if (toWays.isEmpty())\n        throw new OSMRestrictionException(\"has no member with role 'to'\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new OSMRestrictionException(\"has multiple members with role 'from' and 'to'\");\n\n    checkTags(fromWays, toWays, relation.getTags());\n    if ((viaOSMNode >= 0) && (!viaWays.isEmpty()))\n        throw new OSMRestrictionException(\"has members with role 'via' of type 'node' and 'way', but only one type is allowed\");\n    else if (viaOSMNode >= 0)\n        return RestrictionMembers.viaNode(viaOSMNode, fromWays, toWays);\n    else if (!viaWays.isEmpty())\n        return RestrictionMembers.viaWay(fromWays, viaWays, toWays);\n    else\n        throw new OSMRestrictionException(\"has no member with role 'via'\");\n\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.Polygon.getMaxLat",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Envelope.getMaxY",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.Polygon.getMaxLat" ],
    "fullMethods" : [ "public double getMaxLat() {\n    return envelope.getMaxY();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.BBox.fromEnvelope",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Envelope.getMaxY",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.BBox.fromEnvelope" ],
    "fullMethods" : [ "public static BBox fromEnvelope(Envelope envelope) {\n    return new BBox(envelope.getMinX(), envelope.getMaxX(), envelope.getMinY(), envelope.getMaxY());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHObjectIntHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.ObjectIntAssociativeContainer.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHObjectIntHashMap.<init>" ],
    "fullMethods" : [ "public GHObjectIntHashMap(int capacity) {\n    super(capacity, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity" ],
    "fullMethods" : [ "/**\n *\n * @param radius\n * \t\tin meters\n * @param calcRoadFactor\n * \t\tweighting function. use this to define how different kinds of roads shall contribute to the calculated road density\n * @return the road density in the vicinity of the given edge, i.e. the weighted road length divided by the squared radius\n */\npublic double calcRoadDensity(EdgeIteratorState edge, double radius, ToDoubleFunction<EdgeIteratorState> calcRoadFactor) {\n    visited.clear();\n    deque.head = deque.tail = 0;\n    double totalRoadWeight = 0;\n    NodeAccess na = graph.getNodeAccess();\n    int baseNode = edge.getBaseNode();\n    int adjNode = edge.getAdjNode();\n    GHPoint center = new GHPoint(getLat(na, baseNode, adjNode), getLon(na, baseNode, adjNode));\n    deque.addLast(baseNode);\n    deque.addLast(adjNode);\n    visited.add(baseNode);\n    visited.add(adjNode);\n    // we just do a BFS search and sum up all the road lengths\n    final double radiusNormalized = DIST_PLANE.calcNormalizedDist(radius);\n    // for long tunnels or motorway sections where the distance between the exit points and the\n    // center is larger than the radius it is important to continue the search even outside the radius\n    final int minPolls = ((int) (radius / 2));\n    int polls = 0;\n    while (!deque.isEmpty()) {\n        int node = deque.removeFirst();\n        polls++;\n        double distance = DIST_PLANE.calcNormalizedDist(center.lat, center.lon, na.getLat(node), na.getLon(node));\n        if ((polls > minPolls) && (distance > radiusNormalized))\n            continue;\n\n        EdgeIterator iter = edgeExplorer.setBaseNode(node);\n        while (iter.next()) {\n            if (visited.contains(iter.getAdjNode()))\n                continue;\n\n            visited.add(iter.getAdjNode());\n            if (distance <= radiusNormalized)\n                totalRoadWeight += calcRoadFactor.applyAsDouble(iter);\n\n            deque.addLast(iter.getAdjNode());\n        } \n    } \n    return (totalRoadWeight / radius) / radius;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedNodeContractor.calculatePriority",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedNodeContractor.calculatePriority", "com.graphhopper.routing.ch.EdgeBasedNodeContractor.findAndHandlePrepareShortcuts" ],
    "fullMethods" : [ "@Override\npublic float calculatePriority(int node) {\n    activeStats = countingStats;\n    resetEdgeCounters();\n    countPreviousEdges(node);\n    // this node is isolated, maybe it belongs to a removed subnetwork, in any case we can quickly contract it\n    // no shortcuts will be introduced\n    if (numAllEdges == 0)\n        return Float.NEGATIVE_INFINITY;\n\n    stats().stopWatch.start();\n    findAndHandlePrepareShortcuts(node, this::countShortcuts, ((int) (meanDegree * params.maxPollFactorHeuristic)), wpsStatsHeur);\n    stats().stopWatch.stop();\n    // the higher the priority the later (!) this node will be contracted\n    float edgeQuotient = numShortcuts / ((float) (prepareGraph.getDegree(node)));\n    float origEdgeQuotient = numOrigEdges / ((float) (numPrevOrigEdges));\n    int hierarchyDepth = hierarchyDepths[node];\n    float priority = ((params.edgeQuotientWeight * edgeQuotient) + (params.originalEdgeQuotientWeight * origEdgeQuotient)) + (params.hierarchyDepthWeight * hierarchyDepth);\n    if (LOGGER.isTraceEnabled())\n        LOGGER.trace(\"node: {}, eq: {} / {} = {}, oeq: {} / {} = {}, depth: {} --> {}\", node, numShortcuts, numPrevEdges, edgeQuotient, numOrigEdges, numPrevOrigEdges, origEdgeQuotient, hierarchyDepth, priority);\n\n    return priority;\n}", "/**\n * This method performs witness searches between all nodes adjacent to the given node and calls the\n * given handler for all required shortcuts.\n */\nprivate void findAndHandlePrepareShortcuts(int node, PrepareShortcutHandler shortcutHandler, int maxPolls, EdgeBasedWitnessPathSearcher.Stats wpsStats) {\n    stats().nodes++;\n    addedShortcuts.clear();\n    sourceNodes.clear();\n    // traverse incoming edges/shortcuts to find all the source nodes\n    PrepareGraphEdgeIterator incomingEdges = inEdgeExplorer.setBaseNode(node);\n    while (incomingEdges.next()) {\n        final int sourceNode = incomingEdges.getAdjNode();\n        if (sourceNode == node)\n            continue;\n\n        // make sure we process each source node only once\n        if (!sourceNodes.add(sourceNode))\n            continue;\n\n        // for each source node we need to look at every incoming original edge and check which target edges are reachable\n        PrepareGraphOrigEdgeIterator origInIter = sourceNodeOrigInEdgeExplorer.setBaseNode(sourceNode);\n        while (origInIter.next()) {\n            int origInKey = reverseEdgeKey(origInIter.getOrigEdgeKeyLast());\n            // we search 'bridge paths' leading to the target edges\n            IntObjectMap<BridgePathFinder.BridePathEntry> bridgePaths = bridgePathFinder.find(origInKey, sourceNode, node);\n            if (bridgePaths.isEmpty())\n                continue;\n\n            witnessPathSearcher.initSearch(origInKey, sourceNode, node, wpsStats);\n            for (IntObjectCursor<BridgePathFinder.BridePathEntry> bridgePath : bridgePaths) {\n                if (!Double.isFinite(bridgePath.value.weight))\n                    throw new IllegalStateException(\"Bridge entry weights should always be finite\");\n\n                int targetEdgeKey = bridgePath.key;\n                dijkstraSW.start();\n                double weight = witnessPathSearcher.runSearch(bridgePath.value.chEntry.adjNode, targetEdgeKey, bridgePath.value.weight, maxPolls);\n                dijkstraSW.stop();\n                // we found a witness, nothing to do\n                if (weight <= bridgePath.value.weight)\n                    continue;\n\n                PrepareCHEntry root = bridgePath.value.chEntry;\n                while (EdgeIterator.Edge.isValid(root.parent.prepareEdge))\n                    root = root.getParent();\n\n                // we make sure to add each shortcut only once. when we are actually adding shortcuts we check for existing\n                // shortcuts anyway, but at least this is important when we *count* shortcuts.\n                long addedShortcutKey = BitUtil.LITTLE.toLong(root.firstEdgeKey, bridgePath.value.chEntry.incEdgeKey);\n                if (!addedShortcuts.add(addedShortcutKey))\n                    continue;\n\n                double initialTurnCost = prepareGraph.getTurnWeight(origInKey, sourceNode, root.firstEdgeKey);\n                bridgePath.value.chEntry.weight -= initialTurnCost;\n                LOGGER.trace(\"Adding shortcuts for target entry {}\", bridgePath.value.chEntry);\n                // todo: re-implement loop-avoidance heuristic as it existed in GH 1.0? it did not work the\n                // way it was implemented so it was removed at some point\n                shortcutHandler.handleShortcut(root, bridgePath.value.chEntry, bridgePath.value.chEntry.origEdges);\n            }\n            witnessPathSearcher.finishSearch();\n        } \n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.disconnect",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.disconnect" ],
    "fullMethods" : [ "public IntContainer disconnect(int node) {\n    checkReady();\n    // we use this neighbor set to guarantee a deterministic order of the returned\n    // node ids\n    neighborSet.clear();\n    PrepareEdge currOut = prepareEdgesOut[node];\n    while (currOut != null) {\n        int adjNode = currOut.getNodeB();\n        if (adjNode == node)\n            adjNode = currOut.getNodeA();\n\n        if (adjNode == node) {\n            // this is a loop\n            currOut = currOut.getNextOut(node);\n            continue;\n        }\n        removeInEdge(adjNode, currOut);\n        neighborSet.add(adjNode);\n        currOut = currOut.getNextOut(node);\n    } \n    PrepareEdge currIn = prepareEdgesIn[node];\n    while (currIn != null) {\n        int adjNode = currIn.getNodeB();\n        if (adjNode == node)\n            adjNode = currIn.getNodeA();\n\n        if (adjNode == node) {\n            // this is a loop\n            currIn = currIn.getNextIn(node);\n            continue;\n        }\n        removeOutEdge(adjNode, currIn);\n        neighborSet.add(adjNode);\n        currIn = currIn.getNextIn(node);\n    } \n    prepareEdgesOut[node] = null;\n    prepareEdgesIn[node] = null;\n    degrees[node] = 0;\n    return neighborSet;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.BreadthFirstSearch.start",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.BreadthFirstSearch.start", "com.graphhopper.reader.dem.EdgeElevationInterpolator.checkAdjacent" ],
    "fullMethods" : [ "@Override\npublic void start(EdgeExplorer explorer, int startNode) {\n    SimpleIntDeque fifo = new SimpleIntDeque();\n    GHBitSet visited = createBitSet();\n    visited.add(startNode);\n    fifo.push(startNode);\n    int current;\n    while (!fifo.isEmpty()) {\n        current = fifo.pop();\n        if (!goFurther(current))\n            continue;\n\n        EdgeIterator iter = explorer.setBaseNode(current);\n        while (iter.next()) {\n            int connectedId = iter.getAdjNode();\n            if (checkAdjacent(iter) && (!visited.contains(connectedId))) {\n                visited.add(connectedId);\n                fifo.push(connectedId);\n            }\n        } \n    } \n}", "@Override\nprotected boolean checkAdjacent(EdgeIteratorState edge) {\n    visitedEdgesIds.add(edge.getEdge());\n    final int baseNodeId = edge.getBaseNode();\n    boolean isInterpolatableEdge = isInterpolatableEdge(edge);\n    if (!isInterpolatableEdge) {\n        innerNodeIds.remove(baseNodeId);\n        outerNodeIds.add(baseNodeId);\n    } else if (!outerNodeIds.contains(baseNodeId)) {\n        innerNodeIds.add(baseNodeId);\n    }\n    return isInterpolatableEdge;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode", "com.graphhopper.routing.ch.EdgeBasedNodeContractor.findAndHandlePrepareShortcuts" ],
    "fullMethods" : [ "@Override\npublic IntContainer contractNode(int node) {\n    activeStats = addingStats;\n    stats().stopWatch.start();\n    findAndHandlePrepareShortcuts(node, this::addShortcutsToPrepareGraph, ((int) (meanDegree * params.maxPollFactorContraction)), wpsStatsContr);\n    insertShortcuts(node);\n    IntContainer neighbors = prepareGraph.disconnect(node);\n    // We maintain an approximation of the mean degree which we update after every contracted node.\n    // We do it the same way as for node-based CH for now.\n    meanDegree = ((meanDegree * 2) + neighbors.size()) / 3;\n    updateHierarchyDepthsOfNeighbors(node, neighbors);\n    stats().stopWatch.stop();\n    return neighbors;\n}", "/**\n * This method performs witness searches between all nodes adjacent to the given node and calls the\n * given handler for all required shortcuts.\n */\nprivate void findAndHandlePrepareShortcuts(int node, PrepareShortcutHandler shortcutHandler, int maxPolls, EdgeBasedWitnessPathSearcher.Stats wpsStats) {\n    stats().nodes++;\n    addedShortcuts.clear();\n    sourceNodes.clear();\n    // traverse incoming edges/shortcuts to find all the source nodes\n    PrepareGraphEdgeIterator incomingEdges = inEdgeExplorer.setBaseNode(node);\n    while (incomingEdges.next()) {\n        final int sourceNode = incomingEdges.getAdjNode();\n        if (sourceNode == node)\n            continue;\n\n        // make sure we process each source node only once\n        if (!sourceNodes.add(sourceNode))\n            continue;\n\n        // for each source node we need to look at every incoming original edge and check which target edges are reachable\n        PrepareGraphOrigEdgeIterator origInIter = sourceNodeOrigInEdgeExplorer.setBaseNode(sourceNode);\n        while (origInIter.next()) {\n            int origInKey = reverseEdgeKey(origInIter.getOrigEdgeKeyLast());\n            // we search 'bridge paths' leading to the target edges\n            IntObjectMap<BridgePathFinder.BridePathEntry> bridgePaths = bridgePathFinder.find(origInKey, sourceNode, node);\n            if (bridgePaths.isEmpty())\n                continue;\n\n            witnessPathSearcher.initSearch(origInKey, sourceNode, node, wpsStats);\n            for (IntObjectCursor<BridgePathFinder.BridePathEntry> bridgePath : bridgePaths) {\n                if (!Double.isFinite(bridgePath.value.weight))\n                    throw new IllegalStateException(\"Bridge entry weights should always be finite\");\n\n                int targetEdgeKey = bridgePath.key;\n                dijkstraSW.start();\n                double weight = witnessPathSearcher.runSearch(bridgePath.value.chEntry.adjNode, targetEdgeKey, bridgePath.value.weight, maxPolls);\n                dijkstraSW.stop();\n                // we found a witness, nothing to do\n                if (weight <= bridgePath.value.weight)\n                    continue;\n\n                PrepareCHEntry root = bridgePath.value.chEntry;\n                while (EdgeIterator.Edge.isValid(root.parent.prepareEdge))\n                    root = root.getParent();\n\n                // we make sure to add each shortcut only once. when we are actually adding shortcuts we check for existing\n                // shortcuts anyway, but at least this is important when we *count* shortcuts.\n                long addedShortcutKey = BitUtil.LITTLE.toLong(root.firstEdgeKey, bridgePath.value.chEntry.incEdgeKey);\n                if (!addedShortcuts.add(addedShortcutKey))\n                    continue;\n\n                double initialTurnCost = prepareGraph.getTurnWeight(origInKey, sourceNode, root.firstEdgeKey);\n                bridgePath.value.chEntry.weight -= initialTurnCost;\n                LOGGER.trace(\"Adding shortcuts for target entry {}\", bridgePath.value.chEntry);\n                // todo: re-implement loop-avoidance heuristic as it existed in GH 1.0? it did not work the\n                // way it was implemented so it was removed at some point\n                shortcutHandler.handleShortcut(root, bridgePath.value.chEntry, bridgePath.value.chEntry.origEdges);\n            }\n            witnessPathSearcher.finishSearch();\n        } \n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.RoundTripRouting.calcPaths",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.RoundTripRouting.calcPaths", "com.graphhopper.routing.RoundTripRouting.RoundTripCalculator.calcPath" ],
    "fullMethods" : [ "public static Result calcPaths(List<Snap> snaps, FlexiblePathCalculator pathCalculator) {\n    RoundTripCalculator roundTripCalculator = new RoundTripCalculator(pathCalculator);\n    Result result = new Result(snaps.size() - 1);\n    Snap start = snaps.get(0);\n    for (int snapIndex = 1; snapIndex < snaps.size(); snapIndex++) {\n        // instead getClosestNode (which might be a virtual one and introducing unnecessary tails of the route)\n        // use next tower node -> getBaseNode or getAdjNode\n        // Later: remove potential route tail, maybe we can just enforce the heading at the start and when coming\n        // back, and for tower nodes it does not matter anyway\n        Snap startSnap = snaps.get(snapIndex - 1);\n        int startNode = (startSnap == start) ? startSnap.getClosestNode() : startSnap.getClosestEdge().getBaseNode();\n        Snap endSnap = snaps.get(snapIndex);\n        int endNode = (endSnap == start) ? endSnap.getClosestNode() : endSnap.getClosestEdge().getBaseNode();\n        Path path = roundTripCalculator.calcPath(startNode, endNode);\n        if (snapIndex == 1) {\n            result.wayPoints = new PointList(snaps.size(), path.graph.getNodeAccess().is3D());\n            result.wayPoints.add(path.graph.getNodeAccess(), startNode);\n        }\n        result.wayPoints.add(path.graph.getNodeAccess(), endNode);\n        result.visitedNodes += pathCalculator.getVisitedNodes();\n        result.paths.add(path);\n    }\n    return result;\n}", "Path calcPath(int from, int to) {\n    Path path = pathCalculator.calcPaths(from, to, new EdgeRestrictions()).get(0);\n    // add the edges of this path to the set of previous edges so they will be avoided from now, otherwise\n    // we do not get a nice 'round trip'. note that for this reason we cannot use CH for round-trips currently\n    for (IntCursor c : path.getEdges()) {\n        previousEdges.add(c.value);\n    }\n    return path;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.AlternativeRoute.calcAlternatives",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.AlternativeRoute.calcAlternatives", "com.graphhopper.routing.AlternativeRoute.addToMap" ],
    "fullMethods" : [ "/**\n *\n * @return the information necessary to handle alternative paths. Note that the paths are\nnot yet extracted.\n */\npublic List<AlternativeInfo> calcAlternatives(final Path bestPath, final int maxPaths, double maxWeightFactor, final double weightInfluence, final double maxShareFactor, final double shareInfluence, final double minPlateauFactor, final double plateauInfluence) {\n    final double maxWeight = maxWeightFactor * bestWeight;\n    final GHIntObjectHashMap<IntSet> traversalIdMap = new GHIntObjectHashMap<>();\n    final AtomicInteger startTID = addToMap(traversalIdMap, bestPath);\n    // find all 'good' alternatives from forward-SPT matching the backward-SPT and optimize by\n    // small total weight (1), small share and big plateau (3a+b) and do these expensive calculations\n    // only for plateau start candidates (2)\n    final List<AlternativeInfo> alternatives = new ArrayList<>(maxPaths);\n    double bestPlateau = bestWeight;\n    double bestShare = 0;\n    double sortBy = calcSortBy(weightInfluence, bestWeight, shareInfluence, bestShare, plateauInfluence, bestPlateau);\n    final AlternativeInfo bestAlt = new AlternativeInfo(sortBy, bestPath, bestFwdEntry, bestBwdEntry, bestShare, getAltNames(graph, bestFwdEntry));\n    alternatives.add(bestAlt);\n    AtomicReference<SPTEntry> bestEntry = new AtomicReference<>();\n    bestWeightMapFrom.forEach(new IntObjectPredicate<SPTEntry>() {\n        @Override\n        public boolean apply(final int traversalId, final SPTEntry fromSPTEntry) {\n            SPTEntry toSPTEntry = bestWeightMapTo.get(traversalId);\n            if (toSPTEntry == null)\n                return true;\n\n            // Using the parent is required to avoid duplicate edge in Path.\n            // TODO we miss the turn cost weight (but at least we not duplicate the current edge weight)\n            if (traversalMode.isEdgeBased() && (toSPTEntry.parent != null))\n                toSPTEntry = toSPTEntry.parent;\n\n            // The alternative path is suboptimal if U-turn (after fromSPTEntry)\n            if (fromSPTEntry.edge == toSPTEntry.edge)\n                return true;\n\n            // (1) skip too long paths\n            final double weight = (fromSPTEntry.getWeightOfVisitedPath() + toSPTEntry.getWeightOfVisitedPath()) + weighting.calcTurnWeight(fromSPTEntry.edge, fromSPTEntry.adjNode, toSPTEntry.edge);\n            if (weight > maxWeight)\n                return true;\n\n            if (isBestPath(fromSPTEntry))\n                return true;\n\n            // For edge based traversal we need the next entry to find out the plateau start\n            SPTEntry tmpFromEntry = (traversalMode.isEdgeBased()) ? fromSPTEntry.parent : fromSPTEntry;\n            if ((tmpFromEntry == null) || (tmpFromEntry.parent == null)) {\n                // we can be here only if edge based and only if entry is not part of the best path\n                // e.g. when starting point has two edges and one is part of the best path the other edge is path of an alternative\n                assert traversalMode.isEdgeBased();\n            } else {\n                int nextToTraversalId = traversalMode.createTraversalId(graph.getEdgeIteratorState(tmpFromEntry.edge, tmpFromEntry.parent.adjNode), true);\n                SPTEntry correspondingToEntry = bestWeightMapTo.get(nextToTraversalId);\n                if (correspondingToEntry != null) {\n                    if (traversalMode.isEdgeBased())\n                        correspondingToEntry = correspondingToEntry.parent;\n\n                    if (correspondingToEntry.edge == fromSPTEntry.edge)\n                        return true;\n\n                }\n            }\n            // (3a) calculate plateau, we know we are at the beginning of the 'from'-side of\n            // the plateau A-B-C and go further to B\n            // where B is the next-'from' of A and B is also the previous-'to' of A.\n            // \n            // *<-A-B-C->*\n            // /    \\\n            // start    end\n            // \n            // extend plateau in only one direction necessary (A to B to ...) as we know\n            // that the from-SPTEntry is the start of the plateau or there is no plateau at all\n            // \n            double plateauWeight = 0;\n            SPTEntry prevToSPTEntry = toSPTEntry;\n            SPTEntry prevFrom = fromSPTEntry;\n            while (prevToSPTEntry.parent != null) {\n                int nextFromTraversalId = traversalMode.createTraversalId(graph.getEdgeIteratorState(prevToSPTEntry.edge, prevToSPTEntry.parent.adjNode), false);\n                SPTEntry otherFromEntry = bestWeightMapFrom.get(nextFromTraversalId);\n                // end of a plateau\n                if (((otherFromEntry == null) || (otherFromEntry.parent != prevFrom)) || (otherFromEntry.edge != prevToSPTEntry.edge))\n                    break;\n\n                prevFrom = otherFromEntry;\n                plateauWeight += prevToSPTEntry.getWeightOfVisitedPath() - prevToSPTEntry.parent.getWeightOfVisitedPath();\n                prevToSPTEntry = prevToSPTEntry.parent;\n            } \n            if ((plateauWeight <= 0) || ((plateauWeight / weight) < minPlateauFactor))\n                return true;\n\n            if (fromSPTEntry.parent == null)\n                throw new IllegalStateException(\"not implemented yet. in case of an edge based traversal the parent of fromSPTEntry could be null\");\n\n            // (3b) calculate share\n            SPTEntry fromEE = getFirstShareEE(fromSPTEntry.parent, true);\n            SPTEntry toEE = getFirstShareEE(toSPTEntry.parent, false);\n            double shareWeight = fromEE.getWeightOfVisitedPath() + toEE.getWeightOfVisitedPath();\n            boolean smallShare = (shareWeight / bestWeight) < maxShareFactor;\n            if (smallShare) {\n                List<String> altNames = getAltNames(graph, fromSPTEntry);\n                double sortBy = calcSortBy(weightInfluence, weight, shareInfluence, shareWeight, plateauInfluence, plateauWeight);\n                double worstSortBy = getWorstSortBy();\n                // plateaus.add(new PlateauInfo(altName, plateauEdges));\n                if ((sortBy < worstSortBy) || (alternatives.size() < maxPaths)) {\n                    Path path = DefaultBidirPathExtractor.extractPath(graph, weighting, fromSPTEntry, toSPTEntry, weight);\n                    // for now do not add alternatives to set, if we do we need to remove then on alternatives.clear too (see below)\n                    // AtomicInteger tid = addToMap(traversalIDMap, path);\n                    // int tid = traversalMode.createTraversalId(path.calcEdges().get(0), false);\n                    alternatives.add(new AlternativeInfo(sortBy, path, fromEE, toEE, shareWeight, altNames));\n                    Collections.sort(alternatives, ALT_COMPARATOR);\n                    if (alternatives.get(0) != bestAlt)\n                        throw new IllegalStateException(((\"best path should be always first entry \" + bestAlt.path.getWeight()) + \" vs \") + alternatives.get(0).path.getWeight());\n\n                    if (alternatives.size() > maxPaths)\n                        alternatives.subList(maxPaths, alternatives.size()).clear();\n\n                }\n            }\n            return true;\n        }\n\n        /**\n         * Extract path until we stumble over an existing traversal id\n         */\n        SPTEntry getFirstShareEE(SPTEntry startEE, boolean reverse) {\n            while (startEE.parent != null) {\n                // TODO we could make use of traversal ID directly if stored in SPTEntry\n                int tid = traversalMode.createTraversalId(graph.getEdgeIteratorState(startEE.edge, startEE.parent.adjNode), reverse);\n                if (isAlreadyExisting(tid))\n                    return startEE;\n\n                startEE = startEE.parent;\n            } \n            return startEE;\n        }\n\n        /**\n         * This method returns true if the specified tid is already existent in the\n         * traversalIDMap\n         */\n        boolean isAlreadyExisting(final int tid) {\n            final AtomicBoolean exists = new AtomicBoolean(false);\n            traversalIdMap.forEach(new IntObjectPredicate<IntSet>() {\n                @Override\n                public boolean apply(int key, IntSet set) {\n                    if (set.contains(tid)) {\n                        exists.set(true);\n                        return false;\n                    }\n                    return true;\n                }\n            });\n            return exists.get();\n        }\n\n        /**\n         * Return the current worst weight for all alternatives\n         */\n        double getWorstSortBy() {\n            if (alternatives.isEmpty())\n                throw new IllegalStateException(\"Empty alternative list cannot happen\");\n\n            return alternatives.get(alternatives.size() - 1).sortBy;\n        }\n\n        // returns true if fromSPTEntry is identical to the specified best path\n        boolean isBestPath(SPTEntry fromSPTEntry) {\n            if (traversalMode.isEdgeBased()) {\n                if (GHUtility.getEdgeFromEdgeKey(startTID.get()) == fromSPTEntry.edge) {\n                    if (fromSPTEntry.parent == null)\n                        throw new IllegalStateException(\"best path must have no parent but was non-null: \" + fromSPTEntry);\n\n                    if ((bestEntry.get() != null) && (bestEntry.get().edge != fromSPTEntry.edge))\n                        throw new IllegalStateException(((((\"there can be only one best entry but was \" + fromSPTEntry) + \" vs old: \") + bestEntry.get()) + \" \") + graph.getEdgeIteratorState(fromSPTEntry.edge, fromSPTEntry.adjNode).fetchWayGeometry(FetchMode.ALL));\n\n                    bestEntry.set(fromSPTEntry);\n                    return true;\n                }\n            } else if (fromSPTEntry.parent == null) {\n                if (startTID.get() != fromSPTEntry.adjNode)\n                    throw new IllegalStateException((((\"Start traversal ID has to be identical to root edge entry \" + \"which is the plateau start of the best path but was: \") + startTID) + \" vs. adjNode: \") + fromSPTEntry.adjNode);\n\n                if (bestEntry.get() != null)\n                    throw new IllegalStateException(((((\"there can be only one best entry but was \" + fromSPTEntry) + \" vs old: \") + bestEntry.get()) + \" \") + graph.getEdgeIteratorState(fromSPTEntry.edge, fromSPTEntry.adjNode).fetchWayGeometry(FetchMode.ALL));\n\n                bestEntry.set(fromSPTEntry);\n                return true;\n            }\n            return false;\n        }\n    });\n    return alternatives;\n}", "/**\n * This method adds the traversal IDs of the specified path as set to the specified map.\n */\nAtomicInteger addToMap(GHIntObjectHashMap<IntSet> map, Path path) {\n    IntSet set = new GHIntHashSet();\n    final AtomicInteger startTID = new AtomicInteger(-1);\n    for (EdgeIteratorState iterState : path.calcEdges()) {\n        int tid = traversalMode.createTraversalId(iterState, false);\n        set.add(tid);\n        if (startTID.get() < 0) {\n            // for node based traversal we need to explicitly add base node as starting node and to list\n            if (!traversalMode.isEdgeBased()) {\n                tid = iterState.getBaseNode();\n                set.add(tid);\n            }\n            startTID.set(tid);\n        }\n    }\n    map.put(startTID.get(), set);\n    return startTID;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.addEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.addEdge" ],
    "fullMethods" : [ "public void addEdge(int edge) {\n    edgeIds.add(edge);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction" ],
    "fullMethods" : [ "/**\n * Converts an OSM restriction to (multiple) single 'no' restrictions to be fed into {@link RestrictionSetter}\n */\npublic static List<RestrictionSetter.Restriction> buildRestrictionsForOSMRestriction(BaseGraph baseGraph, RestrictionTopology topology, RestrictionType type) {\n    List<RestrictionSetter.Restriction> result = new ArrayList<>();\n    if (type == NO) {\n        if (topology.isViaWayRestriction()) {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges()) {\n                    IntArrayList edges = new IntArrayList(topology.getViaEdges().size() + 2);\n                    edges.add(fromEdge.value);\n                    edges.addAll(topology.getViaEdges());\n                    edges.add(toEdge.value);\n                    result.add(RestrictionSetter.createViaEdgeRestriction(edges));\n                }\n\n        } else {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges())\n                    result.add(RestrictionSetter.createViaNodeRestriction(fromEdge.value, topology.getViaNodes().get(0), toEdge.value));\n\n\n        }\n    } else if (type == ONLY) {\n        if ((topology.getFromEdges().size() > 1) || (topology.getToEdges().size() > 1))\n            throw new IllegalArgumentException(\"'Only' restrictions with multiple from- or to- edges are not supported\");\n\n        if (topology.isViaWayRestriction())\n            result.addAll(createRestrictionsForViaEdgeOnlyRestriction(baseGraph, topology));\n        else\n            result.addAll(createRestrictionsForViaNodeOnlyRestriction(baseGraph.createEdgeExplorer(), topology.getFromEdges().get(0), topology.getViaNodes().get(0), topology.getToEdges().get(0)));\n\n    } else\n        throw new IllegalArgumentException(\"Unexpected restriction type: \" + type);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ViaRouting.calcPaths",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ViaRouting.calcPaths", "com.graphhopper.routing.ViaRouting.buildEdgeRestrictions" ],
    "fullMethods" : [ "public static Result calcPaths(List<GHPoint> points, QueryGraph queryGraph, List<Snap> snaps, DirectedEdgeFilter directedEdgeFilter, PathCalculator pathCalculator, List<String> curbsides, String curbsideStrictness, List<Double> headings, boolean passThrough) {\n    if ((!curbsides.isEmpty()) && (curbsides.size() != points.size()))\n        throw new IllegalArgumentException((\"If you pass \" + CURBSIDE) + \", you need to pass exactly one curbside for every point, empty curbsides will be ignored\");\n\n    if ((!curbsides.isEmpty()) && (!headings.isEmpty()))\n        throw new IllegalArgumentException(\"You cannot use curbsides and headings or pass_through at the same time\");\n\n    final int legs = snaps.size() - 1;\n    Result result = new Result(legs);\n    for (int leg = 0; leg < legs; ++leg) {\n        Snap fromSnap = snaps.get(leg);\n        Snap toSnap = snaps.get(leg + 1);\n        // enforce headings\n        // at via-nodes and the target node the heading parameter is interpreted as the direction we want\n        // to enforce for arriving (not starting) at this node. the starting direction is not enforced at\n        // all for these points (unless using pass through). see this forum discussion:\n        // https://discuss.graphhopper.com/t/meaning-of-heading-parameter-for-via-routing/5643/6\n        double fromHeading = ((leg == 0) && (!headings.isEmpty())) ? headings.get(0) : Double.NaN;\n        double toHeading = ((snaps.size() == headings.size()) && (!Double.isNaN(headings.get(leg + 1)))) ? headings.get(leg + 1) : Double.NaN;\n        // enforce pass-through\n        int incomingEdge = NO_EDGE;\n        if (leg != 0) {\n            // enforce straight start after via stop\n            Path prevRoute = result.paths.get(leg - 1);\n            if (prevRoute.getEdgeCount() > 0)\n                incomingEdge = prevRoute.getFinalEdge().getEdge();\n\n        }\n        // enforce curbsides\n        final String fromCurbside = (curbsides.isEmpty()) ? CURBSIDE_ANY : curbsides.get(leg);\n        final String toCurbside = (curbsides.isEmpty()) ? CURBSIDE_ANY : curbsides.get(leg + 1);\n        EdgeRestrictions edgeRestrictions = buildEdgeRestrictions(queryGraph, fromSnap, toSnap, fromHeading, toHeading, incomingEdge, passThrough, fromCurbside, toCurbside, directedEdgeFilter);\n        edgeRestrictions.setSourceOutEdge(ignoreThrowOrAcceptImpossibleCurbsides(curbsides, edgeRestrictions.getSourceOutEdge(), leg, curbsideStrictness));\n        edgeRestrictions.setTargetInEdge(ignoreThrowOrAcceptImpossibleCurbsides(curbsides, edgeRestrictions.getTargetInEdge(), leg + 1, curbsideStrictness));\n        // calculate paths\n        List<Path> paths = pathCalculator.calcPaths(fromSnap.getClosestNode(), toSnap.getClosestNode(), edgeRestrictions);\n        result.debug += pathCalculator.getDebugString();\n        // for alternative routing we get multiple paths and add all of them (which is ok, because we do not allow\n        // via-points for alternatives at the moment). otherwise we would have to return a list<list<path>> and find\n        // a good method to decide how to combine the different legs\n        for (int i = 0; i < paths.size(); i++) {\n            Path path = paths.get(i);\n            if (path.getTime() < 0)\n                throw new RuntimeException(((\"Time was negative \" + path.getTime()) + \" for index \") + i);\n\n            result.paths.add(path);\n            result.debug += \", \" + path.getDebugInfo();\n        }\n        result.visitedNodes += pathCalculator.getVisitedNodes();\n        result.debug += \", visited nodes sum: \" + result.visitedNodes;\n    }\n    return result;\n}", "/**\n * Determines restrictions for the start/target edges to account for the heading, pass_through and curbside parameters\n * for a single via-route leg.\n *\n * @param fromHeading\n * \t\tthe heading at the start node of this leg, or NaN if no restriction should be applied\n * @param toHeading\n * \t\tthe heading at the target node (the vehicle's heading when arriving at the target), or NaN if\n * \t\tno restriction should be applied\n * @param incomingEdge\n * \t\tthe last edge of the previous leg (or {@link EdgeIterator#NO_EDGE} if not available\n */\nprivate static EdgeRestrictions buildEdgeRestrictions(QueryGraph queryGraph, Snap fromSnap, Snap toSnap, double fromHeading, double toHeading, int incomingEdge, boolean passThrough, String fromCurbside, String toCurbside, DirectedEdgeFilter edgeFilter) {\n    EdgeRestrictions edgeRestrictions = new EdgeRestrictions();\n    // curbsides\n    if ((!fromCurbside.equals(CURBSIDE_ANY)) || (!toCurbside.equals(CURBSIDE_ANY))) {\n        DirectedEdgeFilter directedEdgeFilter = (edge, reverse) -> {\n            // todo: maybe find a cleaner way to obtain the original edge given a VirtualEdgeIterator (not VirtualEdgeIteratorState)\n            if (queryGraph.isVirtualEdge(edge.getEdge())) {\n                EdgeIteratorState virtualEdge = queryGraph.getEdgeIteratorStateForKey(edge.getEdgeKey());\n                EdgeIteratorState origEdge = queryGraph.getEdgeIteratorStateForKey(((VirtualEdgeIteratorState) (virtualEdge)).getOriginalEdgeKey());\n                return edgeFilter.accept(origEdge, reverse);\n            } else\n                return edgeFilter.accept(edge, reverse);\n\n        };\n        DirectionResolver directionResolver = new DirectionResolver(queryGraph, directedEdgeFilter);\n        DirectionResolverResult fromDirection = directionResolver.resolveDirections(fromSnap.getClosestNode(), fromSnap.getQueryPoint());\n        DirectionResolverResult toDirection = directionResolver.resolveDirections(toSnap.getClosestNode(), toSnap.getQueryPoint());\n        int sourceOutEdge = DirectionResolverResult.getOutEdge(fromDirection, fromCurbside);\n        int targetInEdge = DirectionResolverResult.getInEdge(toDirection, toCurbside);\n        if (fromSnap.getClosestNode() == toSnap.getClosestNode()) {\n            // special case where we go from one point back to itself. for example going from a point A\n            // with curbside right to the same point with curbside right is interpreted as 'being there\n            // already' -> empty path. Similarly if the curbside for the start/target is not even specified\n            // there is no need to drive a loop. However, going from point A/right to point A/left (or the\n            // other way around) means we need to drive some kind of loop to get back to the same location\n            // (arriving on the other side of the road).\n            if ((((Helper.isEmpty(fromCurbside) || Helper.isEmpty(toCurbside)) || fromCurbside.equals(CURBSIDE_ANY)) || toCurbside.equals(CURBSIDE_ANY)) || fromCurbside.equals(toCurbside)) {\n                // we just disable start/target edge constraints to get an empty path\n                sourceOutEdge = ANY_EDGE;\n                targetInEdge = ANY_EDGE;\n            }\n        }\n        edgeRestrictions.setSourceOutEdge(sourceOutEdge);\n        edgeRestrictions.setTargetInEdge(targetInEdge);\n    }\n    // heading\n    if ((!Double.isNaN(fromHeading)) || (!Double.isNaN(toHeading))) {\n        // todo: for heading/pass_through with edge-based routing (especially CH) we have to find the edge closest\n        // to the heading and use it as sourceOutEdge/targetInEdge here. the heading penalty will not be applied\n        // this way (unless we implement this), but this is more or less ok as we can use finite u-turn costs\n        // instead. maybe the hardest part is dealing with headings that cannot be fulfilled, like in one-way\n        // streets. see also #1765\n        HeadingResolver headingResolver = new HeadingResolver(queryGraph);\n        if (!Double.isNaN(fromHeading))\n            edgeRestrictions.getUnfavoredEdges().addAll(headingResolver.getEdgesWithDifferentHeading(fromSnap.getClosestNode(), fromHeading));\n\n        if (!Double.isNaN(toHeading)) {\n            toHeading += 180;\n            if (toHeading > 360)\n                toHeading -= 360;\n\n            edgeRestrictions.getUnfavoredEdges().addAll(headingResolver.getEdgesWithDifferentHeading(toSnap.getClosestNode(), toHeading));\n        }\n    }\n    // pass through\n    if ((incomingEdge != NO_EDGE) && passThrough)\n        edgeRestrictions.getUnfavoredEdges().add(incomingEdge);\n\n    return edgeRestrictions;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param excludeSingleNodeComponents\n * \t\tif set to true components that only contain a single node will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponents();\n}", "private ConnectedComponents findComponents() {\n    for (int node = 0; node < graph.getNodes(); ++node) {\n        if (nodeIndex[node] != (-1))\n            continue;\n\n        pushFindComponentForNode(node);\n        while (hasNext()) {\n            pop();\n            switch (dfsState) {\n                case BUILD_COMPONENT :\n                    buildComponent(v);\n                    break;\n                case UPDATE :\n                    nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n                    break;\n                case HANDLE_NEIGHBOR :\n                    {\n                        if ((nodeIndex[w] != (-1)) && nodeOnStack.get(w))\n                            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n                        if (nodeIndex[w] == (-1)) {\n                            // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                            pushUpdateLowLinks(v, w);\n                            pushFindComponentForNode(w);\n                        }\n                        break;\n                    }\n                case FIND_COMPONENT :\n                    {\n                        setupNextNode(v);\n                        // we push buildComponent first so it will run *after* we finished traversing the edges\n                        pushBuildComponent(v);\n                        EdgeIterator iter = explorer.setBaseNode(v);\n                        while (iter.next()) {\n                            pushHandleNeighbor(v, iter.getAdjNode());\n                        } \n                        break;\n                    }\n                default :\n                    throw new IllegalStateException(\"Unknown state: \" + dfsState);\n            }\n        } \n    }\n    return components;\n}", "private void buildComponent(int v) {\n    if (nodeLowLink[v] == nodeIndex[v]) {\n        if (tarjanStack.getLast() == v) {\n            tarjanStack.removeLast();\n            nodeOnStack.clear(v);\n            components.numComponents++;\n            components.numNodes++;\n            if (!excludeSingleNodeComponents)\n                components.singleNodeComponents.set(v);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int w = tarjanStack.removeLast();\n                component.add(w);\n                nodeOnStack.clear(w);\n                if (w == v)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numNodes += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays", "com.graphhopper.reader.osm.WayToEdgeConverter.findEdgeChain" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to each other. For example for given\n * from-, via- and to-ways there can be multiple edges associated with each (because each way can be split into\n * multiple edges). We then need to find the from-edge that is connected with one of the via-edges which in turn\n * must be connected with one of the to-edges. We use DFS/backtracking to do this.\n * There can also be *multiple* via-ways, but the concept is the same.\n * Note that there can also be multiple from- or to-*ways*, but only one of each of them should be considered at a\n * time. In contrast to the via-ways there are only multiple from/to-ways, because of restrictions like no_entry or\n * no_exit where there can be multiple from- or to-members. So we need to find one edge-chain for each pair of from-\n * and to-ways.\n * Besides the edge IDs we also return the node IDs that connect the edges, so we can add turn restrictions at these\n * nodes later.\n */\npublic EdgeResult convertForViaWays(LongArrayList fromWays, LongArrayList viaWays, LongArrayList toWays) throws OSMRestrictionException {\n    if ((fromWays.isEmpty() || toWays.isEmpty()) || viaWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from-, via- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    List<IntArrayList> solutions = new ArrayList<>();\n    for (LongCursor fromWay : fromWays)\n        for (LongCursor toWay : toWays)\n            findEdgeChain(fromWay.value, viaWays, toWay.value, solutions);\n\n\n    if (solutions.size() < (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has disconnected member ways\");\n    else if (solutions.size() > (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has member ways that do not form a unique path\");\n\n    return buildResult(solutions, fromWays, viaWays, toWays);\n}", "private void findEdgeChain(long fromWay, LongArrayList viaWays, long toWay, List<IntArrayList> solutions) {\n    // For each edge chain there must be one edge associated with the from-way, at least one for each via-way and one\n    // associated with the to-way. We use DFS with backtracking to find all edge chains that connect an edge\n    // associated with the from-way with one associated with the to-way.\n    IntArrayList viaEdgesForViaWays = new IntArrayList(viaWays.size());\n    for (LongCursor c : viaWays) {\n        Iterator<IntCursor> iterator = edgesByWay.apply(c.value);\n        viaEdgesForViaWays.add(iterator.next().value);\n        iterator.forEachRemaining(i -> viaEdgesForViaWays.add(i.value));\n    }\n    IntArrayList toEdges = listFromIterator(edgesByWay.apply(toWay));\n    // the search starts at *every* from edge\n    edgesByWay.apply(fromWay).forEachRemaining(from -> {\n        EdgeIteratorState edge = baseGraph.getEdgeIteratorState(from.value, Integer.MIN_VALUE);\n        explore(viaEdgesForViaWays, toEdges, edge.getBaseNode(), 0, IntArrayList.from(edge.getEdge(), edge.getBaseNode()), solutions);\n        explore(viaEdgesForViaWays, toEdges, edge.getAdjNode(), 0, IntArrayList.from(edge.getEdge(), edge.getAdjNode()), solutions);\n    });\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgesMap.putIfReserved",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgesMap.putIfReserved" ],
    "fullMethods" : [ "public void putIfReserved(long way, int edge) {\n    if (edge < 0)\n        throw new IllegalArgumentException(\"edge must be >= 0, but was: \" + edge);\n\n    if (way != lastWay) {\n        int idx = offsetIndexByWay.indexOf(way);\n        // not reserved yet\n        if (idx < 0)\n            return;\n\n        // already taken\n        if (offsetIndexByWay.indexGet(idx) != RESERVED)\n            throw new IllegalArgumentException((\"You need to add all edges for way: \" + way) + \" consecutively\");\n\n        offsetIndexByWay.indexReplace(idx, offsets.size());\n        offsets.add(this.edges.size());\n        lastWay = way;\n    }\n    this.edges.add(edge);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.EdgeChangeBuilder.apply",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.EdgeChangeBuilder.apply", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.addRemovedEdges" ],
    "fullMethods" : [ "@Override\npublic void apply(int value) {\n    addRemovedEdges(value);\n}", "/**\n * Adds the ids of the removed edges at the real tower nodes. We need to do this such that we cannot 'skip'\n * virtual nodes by just using the original edges and also to prevent u-turns at the real nodes adjacent to the\n * virtual ones.\n */\nprivate void addRemovedEdges(int towerNode) {\n    if (isVirtualNode(towerNode))\n        throw new IllegalStateException(((\"Node should not be virtual:\" + towerNode) + \", \") + edgeChangesAtRealNodes);\n\n    QueryOverlay.EdgeChanges edgeChanges = edgeChangesAtRealNodes.get(towerNode);\n    List<EdgeIteratorState> existingEdges = edgeChanges.getAdditionalEdges();\n    IntArrayList removedEdges = edgeChanges.getRemovedEdges();\n    for (EdgeIteratorState existingEdge : existingEdges) {\n        removedEdges.add(getClosestEdge(existingEdge.getAdjNode()));\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.NodeBasedWitnessPathSearcher.findUpperBound",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.NodeBasedWitnessPathSearcher.findUpperBound" ],
    "fullMethods" : [ "/**\n * Runs or continues a Dijkstra search starting at the startNode and ignoring the ignoreNode given in init().\n * If the shortest path is found we return its weight. However, this method also returns early if any path was\n * found for which the weight is below or equal to the given acceptedWeight, or the given maximum number of settled\n * nodes is exceeded. In these cases the returned weight can be larger than the actual weight of the shortest path.\n * In any case we get an upper bound for the real shortest path weight.\n *\n * @param targetNode\n * \t\tthe target of the search. if this node is settled we return the weight of the shortest path\n * @param acceptedWeight\n * \t\tonce we find a path with weight smaller than or equal to this we return the weight. the\n * \t\treturned weight might be larger than the weight of the real shortest path. if there is\n * \t\tno path with weight smaller than or equal to this we stop the search and return the best\n * \t\tpath we found.\n * @param maxSettledNodes\n * \t\tonce the number of settled nodes exceeds this number we return the currently found best\n * \t\tweight path. in this case we might not have found a path at all.\n * @return the weight of the found path or {@link Double#POSITIVE_INFINITY} if no path was found\n */\npublic double findUpperBound(int targetNode, double acceptedWeight, int maxSettledNodes) {\n    // todo: for historic reasons we count the number of settled nodes for each call of this method\n    // *not* the total number of settled nodes since starting the search (which corresponds\n    // to the size of the settled part of the shortest path tree). it's probably worthwhile\n    // to change this in the future.\n    while (((!heap.isEmpty()) && (settledNodes < maxSettledNodes)) && (heap.peekKey() <= acceptedWeight)) {\n        // we found *a* path to the target node (not necessarily the shortest), and the weight is acceptable, so we stop\n        if (weights[targetNode] <= acceptedWeight)\n            return weights[targetNode];\n\n        int node = heap.poll();\n        PrepareGraphEdgeIterator iter = outEdgeExplorer.setBaseNode(node);\n        while (iter.next()) {\n            int adjNode = iter.getAdjNode();\n            if (adjNode == ignoreNode)\n                continue;\n\n            double weight = weights[node] + iter.getWeight();\n            if (Double.isInfinite(weight))\n                continue;\n\n            double adjWeight = weights[adjNode];\n            if (adjWeight == Double.POSITIVE_INFINITY) {\n                weights[adjNode] = weight;\n                heap.insert(weight, adjNode);\n                changedNodes.add(adjNode);\n            } else if (weight < adjWeight) {\n                weights[adjNode] = weight;\n                heap.update(weight, adjNode);\n            }\n        } \n        settledNodes++;\n        // we have settled the target node, we now know the exact weight of the shortest path and return\n        if (node == targetNode)\n            return weights[node];\n\n    } \n    return weights[targetNode];\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.withoutConsecutiveDuplicates",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.withoutConsecutiveDuplicates" ],
    "fullMethods" : [ "/**\n * Creates a copy of the given list where all consecutive duplicates are removed\n */\npublic static IntIndexedContainer withoutConsecutiveDuplicates(IntIndexedContainer arr) {\n    IntArrayList result = new IntArrayList();\n    if (arr.isEmpty())\n        return result;\n\n    int prev = arr.get(0);\n    result.add(prev);\n    for (int i = 1; i < arr.size(); i++) {\n        int val = arr.get(i);\n        if (val != prev)\n            result.add(val);\n\n        prev = val;\n    }\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.runSearch",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.runSearch" ],
    "fullMethods" : [ "/**\n * Runs a witness path search for a given target edge key. Results of previous searches (the shortest path tree) are\n * reused and the previous search is extended if necessary. Note that you need to call\n * {@link #initSearch(int, int, int, Stats)} before calling this method to initialize the search.\n *\n * @param targetNode\n * \t\tthe neighbor node that should be reached by the path (t)\n * @param targetEdgeKey\n * \t\tthe original edge key outgoing from t where the search ends\n * @param acceptedWeight\n * \t\tOnce we find a path with a weight smaller or equal to this we return the weight. The\n * \t\treturned weight might be larger than the weight of the real shortest path. If there is\n * \t\tno path with weight smaller than or equal to this we stop the search and return the weight\n * \t\tof the best path found so far.\n * @return the weight of the found path or {@link Double#POSITIVE_INFINITY} if no path was found\n */\npublic double runSearch(int targetNode, int targetEdgeKey, double acceptedWeight, int maxPolls) {\n    stats.numSearches++;\n    // first we check if we can already reach the target edge from the shortest path tree we discovered so far\n    PrepareGraphOrigEdgeIterator inIter = origInEdgeExplorer.setBaseNode(targetNode);\n    while (inIter.next()) {\n        final int edgeKey = GHUtility.reverseEdgeKey(inIter.getOrigEdgeKeyLast());\n        if (weights[edgeKey] == Double.POSITIVE_INFINITY)\n            continue;\n\n        double weight = weights[edgeKey] + calcTurnWeight(edgeKey, targetNode, targetEdgeKey);\n        if ((weight < acceptedWeight) || ((weight == acceptedWeight) && ((parents[edgeKey] < 0) || (!isPathToCenter(parents[edgeKey])))))\n            return weight;\n\n    } \n    // run the search\n    while (((!dijkstraHeap.isEmpty()) && (numPolls < maxPolls)) && // we *could* use dijkstraHeap.peekKey() instead, but since it is cast to float this might be smaller than\n    // the actual weight in which case the search might continue and find a false witness path when there is\n    // an adjacent zero weight edge *and* u-turn costs are zero. we could check this explicitly somewhere,,\n    // but we just use the exact weight here instead. #2564\n    (weights[dijkstraHeap.peekElement()] < acceptedWeight)) {\n        int currKey = dijkstraHeap.poll();\n        numPolls++;\n        final int currNode = getAdjNode(currKey);\n        PrepareGraphEdgeIterator iter = outEdgeExplorer.setBaseNode(currNode);\n        double foundWeight = Double.POSITIVE_INFINITY;\n        while (iter.next()) {\n            // in a few very special cases this is needed to prevent paths that start with a zero weight loop from\n            // being recognized as witnesses when there are double zero weight loops at the source node\n            if (((currNode == sourceNode) && (iter.getAdjNode() == sourceNode)) && (iter.getWeight() < MAX_ZERO_WEIGHT_LOOP))\n                continue;\n\n            final double weight = (weights[currKey] + calcTurnWeight(currKey, currNode, iter.getOrigEdgeKeyFirst())) + iter.getWeight();\n            if (Double.isInfinite(weight))\n                continue;\n\n            final int key = iter.getOrigEdgeKeyLast();\n            final boolean isPathToCenter = isPathToCenter(currKey) && (iter.getAdjNode() == centerNode);\n            if (weights[key] == Double.POSITIVE_INFINITY) {\n                weights[key] = weight;\n                parents[key] = currKey;\n                setAdjNodeAndPathToCenter(key, iter.getAdjNode(), isPathToCenter);\n                changedEdgeKeys.add(key);\n                dijkstraHeap.insert(weight, key);\n                if ((iter.getAdjNode() == targetNode) && ((!isPathToCenter(currKey)) || (parents[currKey] < 0)))\n                    foundWeight = Math.min(foundWeight, weight + calcTurnWeight(key, targetNode, targetEdgeKey));\n\n            } else if ((weight < weights[key]) || // if weights are equal make sure we prefer witness paths over bridge paths\n            ((weight == weights[key]) && (!isPathToCenter(currKey)))) {\n                numUpdates++;\n                weights[key] = weight;\n                parents[key] = currKey;\n                setAdjNodeAndPathToCenter(key, iter.getAdjNode(), isPathToCenter);\n                dijkstraHeap.update(weight, key);\n                if ((iter.getAdjNode() == targetNode) && ((!isPathToCenter(currKey)) || (parents[currKey] < 0)))\n                    foundWeight = Math.min(foundWeight, weight + calcTurnWeight(key, targetNode, targetEdgeKey));\n\n            }\n        } \n        // note that we have to finish the iteration for the current node, otherwise we'll never check the\n        // remaining edges again\n        if (foundWeight <= acceptedWeight)\n            return foundWeight;\n\n    } \n    if (numPolls == maxPolls)\n        stats.numCapped++;\n\n    return Double.POSITIVE_INFINITY;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.addEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.addEdge", "com.graphhopper.routing.ch.CHPreparationGraph.OrigGraph.Builder.addEdge" ],
    "fullMethods" : [ "public void addEdge(int from, int to, int edge, double weightFwd, double weightBwd) {\n    checkNotReady();\n    if (from == to)\n        throw new IllegalArgumentException(\"Loop edges are no longer supported since #2862\");\n\n    boolean fwd = Double.isFinite(weightFwd);\n    boolean bwd = Double.isFinite(weightBwd);\n    if ((!fwd) && (!bwd))\n        return;\n\n    PrepareBaseEdge prepareEdge = new PrepareBaseEdge(edge, from, to, ((float) (weightFwd)), ((float) (weightBwd)));\n    if (fwd) {\n        addOutEdge(from, prepareEdge);\n        addInEdge(to, prepareEdge);\n    }\n    if (bwd && (from != to)) {\n        addOutEdge(to, prepareEdge);\n        addInEdge(from, prepareEdge);\n    }\n    if (edgeBased)\n        origGraphBuilder.addEdge(from, to, edge, fwd, bwd);\n\n}", "{\n    boolean bwd, fwd;\n    com.carrotsearch.hppc.IntArrayList $stack16, $stack17, $stack19, $stack6, $stack7, $stack9;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder this;\n    int $stack10, $stack11, $stack12, $stack13, $stack14, $stack15, $stack18, $stack20, $stack21, $stack22, $stack23, $stack24, $stack25, $stack8, edge, from, to;\n\n\n    this := @this: com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder;\n    from := @parameter0: int;\n    to := @parameter1: int;\n    edge := @parameter2: int;\n    fwd := @parameter3: boolean;\n    bwd := @parameter4: boolean;\n    $stack6 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    virtualinvoke $stack6.<com.carrotsearch.hppc.IntArrayList: void add(int)>(from);\n    $stack7 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    $stack8 = staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int getIntWithFlag(int,boolean)>(to, fwd);\n    virtualinvoke $stack7.<com.carrotsearch.hppc.IntArrayList: void add(int)>($stack8);\n    $stack9 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    $stack10 = staticinvoke <com.graphhopper.util.GHUtility: int createEdgeKey(int,boolean)>(edge, 0);\n    $stack11 = staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int getIntWithFlag(int,boolean)>($stack10, bwd);\n    virtualinvoke $stack9.<com.carrotsearch.hppc.IntArrayList: void add(int)>($stack11);\n    $stack12 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxFrom>;\n    $stack13 = staticinvoke <java.lang.Math: int max(int,int)>($stack12, from);\n    this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxFrom> = $stack13;\n    $stack14 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxTo>;\n    $stack15 = staticinvoke <java.lang.Math: int max(int,int)>($stack14, to);\n    this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxTo> = $stack15;\n    $stack16 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    virtualinvoke $stack16.<com.carrotsearch.hppc.IntArrayList: void add(int)>(to);\n    $stack17 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    $stack18 = staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int getIntWithFlag(int,boolean)>(from, bwd);\n    virtualinvoke $stack17.<com.carrotsearch.hppc.IntArrayList: void add(int)>($stack18);\n    $stack19 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    $stack20 = staticinvoke <com.graphhopper.util.GHUtility: int createEdgeKey(int,boolean)>(edge, 1);\n    $stack21 = staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int getIntWithFlag(int,boolean)>($stack20, fwd);\n    virtualinvoke $stack19.<com.carrotsearch.hppc.IntArrayList: void add(int)>($stack21);\n    $stack22 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxFrom>;\n    $stack23 = staticinvoke <java.lang.Math: int max(int,int)>($stack22, to);\n    this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxFrom> = $stack23;\n    $stack24 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxTo>;\n    $stack25 = staticinvoke <java.lang.Math: int max(int,int)>($stack24, from);\n    this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxTo> = $stack25;\n\n    return;\n}\n" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentForEdgeKey", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeTransitionFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponentsRecursive();\n}", "private ConnectedComponents findComponentsRecursive() {\n    initForEntireGraph();\n    AllEdgesIterator iter = graph.getAllEdges();\n    while (iter.next()) {\n        int edgeKeyFwd = createEdgeKey(iter, false);\n        if (!edgeKeyIndex.has(edgeKeyFwd))\n            findComponentForEdgeKey(edgeKeyFwd, iter.getAdjNode());\n\n        int edgeKeyBwd = createEdgeKey(iter, true);\n        if (!edgeKeyIndex.has(edgeKeyBwd))\n            findComponentForEdgeKey(edgeKeyBwd, iter.getAdjNode());\n\n    } \n    return components;\n}", "private void findComponentForEdgeKey(int p, int adjNode) {\n    setupNextEdgeKey(p);\n    // we have to create a new explorer on each iteration because of the nested edge iterations\n    final int edge = getEdgeFromEdgeKey(p);\n    EdgeExplorer explorer = graph.createEdgeExplorer();\n    EdgeIterator iter = explorer.setBaseNode(adjNode);\n    while (iter.next()) {\n        if (!edgeTransitionFilter.accept(edge, iter))\n            continue;\n\n        int q = createEdgeKey(iter, false);\n        handleNeighbor(p, q, iter.getAdjNode());\n    } \n    buildComponent(p);\n}", "private void buildComponent(int p) {\n    if (edgeKeyLowLink.get(p) == edgeKeyIndex.get(p)) {\n        if (tarjanStack.getLast() == p) {\n            tarjanStack.removeLast();\n            edgeKeyOnStack.remove(p);\n            components.numComponents++;\n            components.numEdgeKeys++;\n            if (!excludeSingleEdgeComponents)\n                components.singleEdgeComponents.set(p);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int q = tarjanStack.removeLast();\n                component.add(q);\n                edgeKeyOnStack.remove(q);\n                if (q == p)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numEdgeKeys += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.TurnCostStorage.sortNodes",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.TurnCostStorage.sortNodes" ],
    "fullMethods" : [ "public void sortNodes() {\n    IntArrayList tcFroms = new IntArrayList();\n    IntArrayList tcTos = new IntArrayList();\n    IntArrayList tcFlags = new IntArrayList();\n    IntArrayList tcNexts = new IntArrayList();\n    for (int i = 0; i < turnCostsCount; i++) {\n        long pointer = toPointer(i);\n        tcFroms.add(turnCosts.getInt(pointer + TC_FROM));\n        tcTos.add(turnCosts.getInt(pointer + TC_TO));\n        tcFlags.add(turnCosts.getInt(pointer + TC_FLAGS));\n        tcNexts.add(turnCosts.getInt(pointer + TC_NEXT));\n    }\n    long turnCostsCountBefore = turnCostsCount;\n    turnCostsCount = 0;\n    for (int node = 0; node < baseGraph.getNodes(); node++) {\n        boolean firstForNode = true;\n        int turnCostIndex = baseGraph.getNodeAccess().getTurnCostIndex(node);\n        while (turnCostIndex != NO_TURN_ENTRY) {\n            if (firstForNode) {\n                baseGraph.getNodeAccess().setTurnCostIndex(node, turnCostsCount);\n            } else {\n                long prevPointer = toPointer(turnCostsCount - 1);\n                turnCosts.setInt(prevPointer + TC_NEXT, turnCostsCount);\n            }\n            long pointer = toPointer(turnCostsCount);\n            turnCosts.setInt(pointer + TC_FROM, tcFroms.get(turnCostIndex));\n            turnCosts.setInt(pointer + TC_TO, tcTos.get(turnCostIndex));\n            turnCosts.setInt(pointer + TC_FLAGS, tcFlags.get(turnCostIndex));\n            turnCosts.setInt(pointer + TC_NEXT, NO_TURN_ENTRY);\n            turnCostsCount++;\n            firstForNode = false;\n            turnCostIndex = tcNexts.get(turnCostIndex);\n        } \n    }\n    if (turnCostsCountBefore != turnCostsCount)\n        throw new IllegalStateException(((\"Turn cost count changed unexpectedly: \" + turnCostsCountBefore) + \" -> \") + turnCostsCount);\n\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.initSearch",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.initSearch" ],
    "fullMethods" : [ "/**\n * Deletes the shortest path tree that has been found so far and initializes a new witness path search for a given\n * node to be contracted and source edge key.\n *\n * @param sourceEdgeKey\n * \t\tthe key of the original edge incoming to s from which the search starts\n * @param sourceNode\n * \t\tthe neighbor node from which the search starts (s)\n * @param centerNode\n * \t\tthe node to be contracted (x)\n */\npublic void initSearch(int sourceEdgeKey, int sourceNode, int centerNode, Stats stats) {\n    this.stats = stats;\n    stats.numTrees++;\n    this.sourceNode = sourceNode;\n    this.centerNode = centerNode;\n    // set start entry\n    weights[sourceEdgeKey] = 0;\n    parents[sourceEdgeKey] = -1;\n    setAdjNodeAndPathToCenter(sourceEdgeKey, sourceNode, true);\n    changedEdgeKeys.add(sourceEdgeKey);\n    dijkstraHeap.insert(0, sourceEdgeKey);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForEdgeState", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.startSearch", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param edgeTransitionFilter\n * \t\tOnly edge transitions accepted by this filter will be considered when we explore the graph.\n * \t\tIf a turn is not accepted the corresponding path will be ignored (edges that are only connected\n * \t\tby a path with such a turn will not be considered to belong to the same component)\n * @param excludeSingleEdgeComponents\n * \t\tif set to true components that only contain a single edge will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponents();\n}", "private ConnectedComponents findComponents() {\n    initForEntireGraph();\n    AllEdgesIterator iter = graph.getAllEdges();\n    while (iter.next()) {\n        findComponentsForEdgeState(iter);\n    } \n    return components;\n}", "private void findComponentsForEdgeState(EdgeIteratorState edge) {\n    int edgeKeyFwd = createEdgeKey(edge, false);\n    if (!edgeKeyIndex.has(edgeKeyFwd))\n        pushFindComponentForEdgeKey(edgeKeyFwd, edge.getAdjNode());\n\n    startSearch();\n    // We need to start the search for both edge keys of this edge, but its important to check if the second\n    // has already been found by the first search. So we cannot simply push them both and start the search once.\n    int edgeKeyBwd = createEdgeKey(edge, true);\n    if (!edgeKeyIndex.has(edgeKeyBwd))\n        pushFindComponentForEdgeKey(edgeKeyBwd, edge.getAdjNode());\n\n    startSearch();\n}", "private void startSearch() {\n    while (hasNext()) {\n        pop();\n        switch (dfsState) {\n            case BUILD_COMPONENT :\n                buildComponent(p);\n                break;\n            case UPDATE :\n                edgeKeyLowLink.minTo(p, edgeKeyLowLink.get(q));\n                break;\n            case HANDLE_NEIGHBOR :\n                if (edgeKeyIndex.has(q) && edgeKeyOnStack.contains(q))\n                    edgeKeyLowLink.minTo(p, edgeKeyIndex.get(q));\n\n                if (!edgeKeyIndex.has(q)) {\n                    // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                    pushUpdateLowLinks(p, q);\n                    pushFindComponentForEdgeKey(q, adj);\n                }\n                break;\n            case FIND_COMPONENT :\n                setupNextEdgeKey(p);\n                // we push buildComponent first so it will run *after* we finished traversing the edges\n                pushBuildComponent(p);\n                final int edge = getEdgeFromEdgeKey(p);\n                EdgeIterator it = explorer.setBaseNode(adj);\n                while (it.next()) {\n                    if (!edgeTransitionFilter.accept(edge, it))\n                        continue;\n\n                    int q = createEdgeKey(it, false);\n                    pushHandleNeighbor(p, q, it.getAdjNode());\n                } \n                break;\n            default :\n                throw new IllegalStateException(\"Unknown state: \" + dfsState);\n        }\n    } \n}", "private void buildComponent(int p) {\n    if (edgeKeyLowLink.get(p) == edgeKeyIndex.get(p)) {\n        if (tarjanStack.getLast() == p) {\n            tarjanStack.removeLast();\n            edgeKeyOnStack.remove(p);\n            components.numComponents++;\n            components.numEdgeKeys++;\n            if (!excludeSingleEdgeComponents)\n                components.singleEdgeComponents.set(p);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int q = tarjanStack.removeLast();\n                component.add(q);\n                edgeKeyOnStack.remove(q);\n                if (q == p)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numEdgeKeys += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.next",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.next" ],
    "fullMethods" : [ "@Override\npublic void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n    nodes.add(eb.getAdjNode());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ViaRouting.lookup",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ViaRouting.lookup" ],
    "fullMethods" : [ "/**\n *\n * @throws MultiplePointsNotFoundException\n * \t\tin case one or more points could not be resolved\n */\npublic static List<Snap> lookup(EncodedValueLookup lookup, List<GHPoint> points, EdgeFilter snapFilter, LocationIndex locationIndex, List<String> snapPreventions, List<String> pointHints, DirectedEdgeFilter directedSnapFilter, List<Double> headings) {\n    if (points.size() < 2)\n        throw new IllegalArgumentException(\"At least 2 points have to be specified, but was:\" + points.size());\n\n    final EnumEncodedValue<RoadClass> roadClassEnc = lookup.getEnumEncodedValue(RoadClass.KEY, RoadClass.class);\n    final EnumEncodedValue<RoadEnvironment> roadEnvEnc = lookup.getEnumEncodedValue(RoadEnvironment.KEY, RoadEnvironment.class);\n    EdgeFilter strictEdgeFilter = (snapPreventions.isEmpty()) ? snapFilter : new SnapPreventionEdgeFilter(snapFilter, roadClassEnc, roadEnvEnc, snapPreventions);\n    List<Snap> snaps = new ArrayList<>(points.size());\n    IntArrayList pointsNotFound = new IntArrayList();\n    for (int placeIndex = 0; placeIndex < points.size(); placeIndex++) {\n        GHPoint point = points.get(placeIndex);\n        Snap snap = null;\n        if ((placeIndex < headings.size()) && (!Double.isNaN(headings.get(placeIndex)))) {\n            if ((!pointHints.isEmpty()) && (!Helper.isEmpty(pointHints.get(placeIndex))))\n                throw new IllegalArgumentException((\"Cannot specify heading and point_hint at the same time. \" + \"Make sure you specify either an empty point_hint (String) or a NaN heading (double) for point \") + placeIndex);\n\n            snap = locationIndex.findClosest(point.lat, point.lon, new HeadingEdgeFilter(directedSnapFilter, headings.get(placeIndex), point));\n        } else if (!pointHints.isEmpty()) {\n            snap = locationIndex.findClosest(point.lat, point.lon, new NameSimilarityEdgeFilter(strictEdgeFilter, pointHints.get(placeIndex), point, 170));\n        } else if (!snapPreventions.isEmpty()) {\n            snap = locationIndex.findClosest(point.lat, point.lon, strictEdgeFilter);\n        }\n        if ((snap == null) || (!snap.isValid()))\n            snap = locationIndex.findClosest(point.lat, point.lon, snapFilter);\n\n        if (!snap.isValid())\n            pointsNotFound.add(placeIndex);\n\n        snaps.add(snap);\n    }\n    if (!pointsNotFound.isEmpty())\n        throw new MultiplePointsNotFoundException(pointsNotFound);\n\n    return snaps;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForEdgeState", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.startSearch", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Like {@link #findComponents(Graph, EdgeTransitionFilter, boolean)}, but the search only starts at the\n * given edges. This does not mean the search cannot expand to other edges, but this can be controlled by the\n * edgeTransitionFilter. This method does not return single edge components (the excludeSingleEdgeComponents option is\n * set to true).\n */\npublic static ConnectedComponents findComponentsForStartEdges(Graph graph, EdgeTransitionFilter edgeTransitionFilter, IntContainer edges) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, true).findComponentsForStartEdges(edges);\n}", "private ConnectedComponents findComponentsForStartEdges(IntContainer startEdges) {\n    initForStartEdges(startEdges.size());\n    for (IntCursor edge : startEdges) {\n        // todo: using getEdgeIteratorState here is not efficient\n        EdgeIteratorState edgeState = graph.getEdgeIteratorState(edge.value, Integer.MIN_VALUE);\n        if (!edgeTransitionFilter.accept(NO_EDGE, edgeState))\n            continue;\n\n        findComponentsForEdgeState(edgeState);\n    }\n    return components;\n}", "private void findComponentsForEdgeState(EdgeIteratorState edge) {\n    int edgeKeyFwd = createEdgeKey(edge, false);\n    if (!edgeKeyIndex.has(edgeKeyFwd))\n        pushFindComponentForEdgeKey(edgeKeyFwd, edge.getAdjNode());\n\n    startSearch();\n    // We need to start the search for both edge keys of this edge, but its important to check if the second\n    // has already been found by the first search. So we cannot simply push them both and start the search once.\n    int edgeKeyBwd = createEdgeKey(edge, true);\n    if (!edgeKeyIndex.has(edgeKeyBwd))\n        pushFindComponentForEdgeKey(edgeKeyBwd, edge.getAdjNode());\n\n    startSearch();\n}", "private void startSearch() {\n    while (hasNext()) {\n        pop();\n        switch (dfsState) {\n            case BUILD_COMPONENT :\n                buildComponent(p);\n                break;\n            case UPDATE :\n                edgeKeyLowLink.minTo(p, edgeKeyLowLink.get(q));\n                break;\n            case HANDLE_NEIGHBOR :\n                if (edgeKeyIndex.has(q) && edgeKeyOnStack.contains(q))\n                    edgeKeyLowLink.minTo(p, edgeKeyIndex.get(q));\n\n                if (!edgeKeyIndex.has(q)) {\n                    // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                    pushUpdateLowLinks(p, q);\n                    pushFindComponentForEdgeKey(q, adj);\n                }\n                break;\n            case FIND_COMPONENT :\n                setupNextEdgeKey(p);\n                // we push buildComponent first so it will run *after* we finished traversing the edges\n                pushBuildComponent(p);\n                final int edge = getEdgeFromEdgeKey(p);\n                EdgeIterator it = explorer.setBaseNode(adj);\n                while (it.next()) {\n                    if (!edgeTransitionFilter.accept(edge, it))\n                        continue;\n\n                    int q = createEdgeKey(it, false);\n                    pushHandleNeighbor(p, q, it.getAdjNode());\n                } \n                break;\n            default :\n                throw new IllegalStateException(\"Unknown state: \" + dfsState);\n        }\n    } \n}", "private void buildComponent(int p) {\n    if (edgeKeyLowLink.get(p) == edgeKeyIndex.get(p)) {\n        if (tarjanStack.getLast() == p) {\n            tarjanStack.removeLast();\n            edgeKeyOnStack.remove(p);\n            components.numComponents++;\n            components.numEdgeKeys++;\n            if (!excludeSingleEdgeComponents)\n                components.singleEdgeComponents.set(p);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int q = tarjanStack.removeLast();\n                component.add(q);\n                edgeKeyOnStack.remove(q);\n                if (q == p)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numEdgeKeys += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.index.IndexStructureInfo.create",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.index.IndexStructureInfo.create" ],
    "fullMethods" : [ "public static IndexStructureInfo create(BBox bounds, int minResolutionInMeter) {\n    // I still need to be able to save and load an empty LocationIndex, and I can't when the extent\n    // is zero.\n    if (!bounds.isValid())\n        bounds = new BBox(-10.0, 10.0, -10.0, 10.0);\n\n    double lat = Math.min(Math.abs(bounds.maxLat), Math.abs(bounds.minLat));\n    double maxDistInMeter = Math.max(((bounds.maxLat - bounds.minLat) / 360) * C, ((bounds.maxLon - bounds.minLon) / 360) * DIST_EARTH.calcCircumference(lat));\n    double tmp = maxDistInMeter / minResolutionInMeter;\n    tmp = tmp * tmp;\n    IntArrayList tmpEntries = new IntArrayList();\n    // the last one is always 4 to reduce costs if only a single entry\n    tmp /= 4;\n    while (tmp > 1) {\n        int tmpNo;\n        if (tmp >= 16) {\n            tmpNo = 16;\n        } else if (tmp >= 4) {\n            tmpNo = 4;\n        } else {\n            break;\n        }\n        tmpEntries.add(tmpNo);\n        tmp /= tmpNo;\n    } \n    tmpEntries.add(4);\n    int[] entries = tmpEntries.toArray();\n    if (entries.length < 1) {\n        // at least one depth should have been specified\n        throw new IllegalStateException(\"depth needs to be at least 1\");\n    }\n    int depth = entries.length;\n    byte[] shifts = new byte[depth];\n    int lastEntry = entries[0];\n    for (int i1 = 0; i1 < depth; i1++) {\n        if (lastEntry < entries[i1]) {\n            throw new IllegalStateException(\"entries should decrease or stay but was:\" + Arrays.toString(entries));\n        }\n        lastEntry = entries[i1];\n        shifts[i1] = getShift(entries[i1]);\n    }\n    int shiftSum = 0;\n    long parts = 1;\n    for (int i = 0; i < shifts.length; i++) {\n        shiftSum += shifts[i];\n        parts *= entries[i];\n    }\n    if (shiftSum > 64)\n        throw new IllegalStateException(\"sum of all shifts does not fit into a long variable\");\n\n    parts = ((int) (Math.round(Math.sqrt(parts))));\n    return new IndexStructureInfo(entries, shifts, new PixelGridTraversal(((int) (parts)), bounds), new SpatialKeyAlgo(shiftSum, bounds), bounds, ((int) (parts)));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.NodeBasedWitnessPathSearcher.init",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.NodeBasedWitnessPathSearcher.init" ],
    "fullMethods" : [ "/**\n * Sets up a search for given start node and an ignored node. The shortest path tree will be re-used for different\n * target nodes until this method is called again.\n */\npublic void init(int startNode, int ignoreNode) {\n    reset();\n    this.ignoreNode = ignoreNode;\n    weights[startNode] = 0;\n    changedNodes.add(startNode);\n    heap.insert(0, startNode);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.calcNodes",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.calcNodes" ],
    "fullMethods" : [ "/**\n *\n * @return the uncached node indices of the tower nodes in this path.\n */\npublic IntIndexedContainer calcNodes() {\n    final IntArrayList nodes = new IntArrayList(edgeIds.size() + 1);\n    if (edgeIds.isEmpty()) {\n        if (isFound()) {\n            nodes.add(endNode);\n        }\n        return nodes;\n    }\n    int tmpNode = getFromNode();\n    nodes.add(tmpNode);\n    forEveryEdge(new EdgeVisitor() {\n        @Override\n        public void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n            nodes.add(eb.getAdjNode());\n        }\n\n        @Override\n        public void finish() {\n        }\n    });\n    return nodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentForNode", "com.graphhopper.routing.subnetwork.TarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponentsRecursive();\n}", "private ConnectedComponents findComponentsRecursive() {\n    for (int node = 0; node < graph.getNodes(); node++) {\n        if (nodeIndex[node] == (-1)) {\n            findComponentForNode(node);\n        }\n    }\n    return components;\n}", "private void findComponentForNode(int v) {\n    setupNextNode(v);\n    // we have to create a new explorer on each iteration because of the nested edge iterations\n    EdgeExplorer explorer = graph.createEdgeExplorer(edgeFilter);\n    EdgeIterator iter = explorer.setBaseNode(v);\n    while (iter.next()) {\n        int w = iter.getAdjNode();\n        if (nodeIndex[w] == (-1)) {\n            findComponentForNode(w);\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n        } else if (nodeOnStack.get(w))\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n    } \n    buildComponent(v);\n}", "private void buildComponent(int v) {\n    if (nodeLowLink[v] == nodeIndex[v]) {\n        if (tarjanStack.getLast() == v) {\n            tarjanStack.removeLast();\n            nodeOnStack.clear(v);\n            components.numComponents++;\n            components.numNodes++;\n            if (!excludeSingleNodeComponents)\n                components.singleNodeComponents.set(v);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int w = tarjanStack.removeLast();\n                component.add(w);\n                nodeOnStack.clear(w);\n                if (w == v)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numNodes += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.subList",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.subList" ],
    "fullMethods" : [ "public static IntArrayList subList(IntArrayList list, int fromIndex, int toIndex) {\n    IntArrayList result = new IntArrayList(toIndex - fromIndex);\n    for (int i = fromIndex; i < toIndex; i++)\n        result.add(list.get(i));\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.GHUtility.comparePaths",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.GHUtility.comparePaths", "com.graphhopper.routing.Path.calcNodes" ],
    "fullMethods" : [ "public static List<String> comparePaths(Path refPath, Path path, int source, int target, long seed) {\n    List<String> strictViolations = new ArrayList<>();\n    double refWeight = refPath.getWeight();\n    double weight = path.getWeight();\n    if (Math.abs(refWeight - weight) > 0.01) {\n        LOGGER.warn(\"expected: \" + refPath.calcNodes());\n        LOGGER.warn(\"given:    \" + path.calcNodes());\n        LOGGER.warn(\"seed: \" + seed);\n        fail(((((((((\"wrong weight: \" + source) + \"->\") + target) + \"\\nexpected: \") + refWeight) + \"\\ngiven:    \") + weight) + \"\\nseed: \") + seed);\n    }\n    if (Math.abs(path.getDistance() - refPath.getDistance()) > 0.1) {\n        strictViolations.add(((((((\"wrong distance \" + source) + \"->\") + target) + \", expected: \") + refPath.getDistance()) + \", given: \") + path.getDistance());\n    }\n    if (Math.abs(path.getTime() - refPath.getTime()) > 50) {\n        strictViolations.add(((((((\"wrong time \" + source) + \"->\") + target) + \", expected: \") + refPath.getTime()) + \", given: \") + path.getTime());\n    }\n    IntIndexedContainer refNodes = refPath.calcNodes();\n    IntIndexedContainer pathNodes = path.calcNodes();\n    if (!refNodes.equals(pathNodes)) {\n        // sometimes there are paths including an edge a-c that has the same distance as the two edges a-b-c. in this\n        // case both options are valid best paths. we only check for this most simple and frequent case here...\n        if (path.getGraph() != refPath.getGraph())\n            fail(\"path and refPath graphs are different\");\n\n        if (!pathsEqualExceptOneEdge(path.getGraph(), refNodes, pathNodes))\n            strictViolations.add(((((((\"wrong nodes \" + source) + \"->\") + target) + \"\\nexpected: \") + refNodes) + \"\\ngiven:    \") + pathNodes);\n\n    }\n    return strictViolations;\n}", "/**\n *\n * @return the uncached node indices of the tower nodes in this path.\n */\npublic IntIndexedContainer calcNodes() {\n    final IntArrayList nodes = new IntArrayList(edgeIds.size() + 1);\n    if (edgeIds.isEmpty()) {\n        if (isFound()) {\n            nodes.add(endNode);\n        }\n        return nodes;\n    }\n    int tmpNode = getFromNode();\n    nodes.add(tmpNode);\n    forEveryEdge(new EdgeVisitor() {\n        @Override\n        public void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n            nodes.add(eb.getAdjNode());\n        }\n\n        @Override\n        public void finish() {\n        }\n    });\n    return nodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.HeadingResolver.getEdgesWithDifferentHeading",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.HeadingResolver.getEdgesWithDifferentHeading" ],
    "fullMethods" : [ "/**\n * Returns a list of edge IDs of edges adjacent to the given base node that do *not* have the same or a similar\n * heading as the given heading. If for example the tolerance is 45 degrees this method returns all edges for which\n * the absolute difference to the given heading is greater than 45 degrees. The heading of an edge is defined as\n * the direction of the first segment of an edge (adjacent and facing away from the base node).\n *\n * @param heading\n * \t\tnorth based azimuth, between 0 and 360 degrees\n * @see #setTolerance\n */\npublic IntArrayList getEdgesWithDifferentHeading(int baseNode, double heading) {\n    double xAxisAngle = AngleCalc.ANGLE_CALC.convertAzimuth2xaxisAngle(heading);\n    IntArrayList edges = new IntArrayList(1);\n    EdgeIterator iter = edgeExplorer.setBaseNode(baseNode);\n    while (iter.next()) {\n        PointList points = iter.fetchWayGeometry(FetchMode.ALL);\n        double orientation = AngleCalc.ANGLE_CALC.calcOrientation(points.getLat(0), points.getLon(0), points.getLat(1), points.getLon(1));\n        orientation = AngleCalc.ANGLE_CALC.alignOrientation(xAxisAngle, orientation);\n        double diff = Math.abs(orientation - xAxisAngle);\n        if (diff > toleranceRad)\n            edges.add(iter.getEdge());\n\n    } \n    return edges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve" ],
    "fullMethods" : [ "public static void sortGraphAlongHilbertCurve(BaseGraph graph) {\n    logger.info(\"sorting graph along Hilbert curve...\");\n    StopWatch sw = StopWatch.started();\n    NodeAccess na = graph.getNodeAccess();\n    final int order = 31;// using 15 would allow us to use ints for sortIndices, but this would result in (marginally) slower routing\n\n    LongArrayList sortIndices = new LongArrayList();\n    for (int node = 0; node < graph.getNodes(); node++)\n        sortIndices.add(latLonToHilbertIndex(na.getLat(node), na.getLon(node), order));\n\n    int[] nodeOrder = IndirectSort.mergesort(0, graph.getNodes(), (nodeA, nodeB) -> Long.compare(sortIndices.get(nodeA), sortIndices.get(nodeB)));\n    EdgeExplorer explorer = graph.createEdgeExplorer();\n    int edges = graph.getEdges();\n    IntArrayList edgeOrder = new IntArrayList();\n    BitSet edgesFound = new BitSet(edges);\n    for (int node : nodeOrder) {\n        EdgeIterator iter = explorer.setBaseNode(node);\n        while (iter.next()) {\n            if (!edgesFound.get(iter.getEdge())) {\n                edgeOrder.add(iter.getEdge());\n                edgesFound.set(iter.getEdge());\n            }\n        } \n    }\n    IntArrayList newEdgesByOldEdges = ArrayUtil.invert(edgeOrder);\n    IntArrayList newNodesByOldNodes = IntArrayList.from(ArrayUtil.invert(nodeOrder));\n    logger.info(\"calculating sort order took: \" + sw.stop().getTimeString());\n    sortGraphForGivenOrdering(graph, newNodesByOldNodes, newEdgesByOldEdges);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryOverlayBuilder.apply",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryOverlayBuilder.apply" ],
    "fullMethods" : [ "@Override\npublic boolean apply(int edgeId, List<Snap> results) {\n    // we can expect at least one entry in the results\n    EdgeIteratorState closestEdge = results.get(0).getClosestEdge();\n    final PointList fullPL = closestEdge.fetchWayGeometry(FetchMode.ALL);\n    int baseNode = closestEdge.getBaseNode();\n    Collections.sort(results, new Comparator<Snap>() {\n        @Override\n        public int compare(Snap o1, Snap o2) {\n            int diff = Integer.compare(o1.getWayIndex(), o2.getWayIndex());\n            if (diff == 0) {\n                return Double.compare(distanceOfSnappedPointToPillarNode(o1), distanceOfSnappedPointToPillarNode(o2));\n            } else {\n                return diff;\n            }\n        }\n\n        private double distanceOfSnappedPointToPillarNode(Snap o) {\n            GHPoint snappedPoint = o.getSnappedPoint();\n            double fromLat = fullPL.getLat(o.getWayIndex());\n            double fromLon = fullPL.getLon(o.getWayIndex());\n            return DistancePlaneProjection.DIST_PLANE.calcNormalizedDist(fromLat, fromLon, snappedPoint.lat, snappedPoint.lon);\n        }\n    });\n    GHPoint3D prevPoint = fullPL.get(0);\n    int adjNode = closestEdge.getAdjNode();\n    int origEdgeKey = closestEdge.getEdgeKey();\n    int origRevEdgeKey = closestEdge.getReverseEdgeKey();\n    int prevWayIndex = 1;\n    int prevNodeId = baseNode;\n    int virtNodeId = queryOverlay.getVirtualNodes().size() + firstVirtualNodeId;\n    boolean addedEdges = false;\n    // Create base and adjacent PointLists for all non-equal virtual nodes.\n    // We do so via inserting them at the correct position of fullPL and cutting the\n    // fullPL into the right pieces.\n    for (int i = 0; i < results.size(); i++) {\n        Snap res = results.get(i);\n        if (res.getClosestEdge().getBaseNode() != baseNode)\n            throw new IllegalStateException(((\"Base nodes have to be identical but were not: \" + closestEdge) + \" vs \") + res.getClosestEdge());\n\n        GHPoint3D currSnapped = res.getSnappedPoint();\n        // no new virtual nodes if very close (\"snap\" together)\n        if (Snap.considerEqual(prevPoint.lat, prevPoint.lon, currSnapped.lat, currSnapped.lon)) {\n            res.setClosestNode(prevNodeId);\n            res.setSnappedPoint(prevPoint);\n            res.setWayIndex(i == 0 ? 0 : results.get(i - 1).getWayIndex());\n            res.setSnappedPosition(i == 0 ? Snap.Position.TOWER : results.get(i - 1).getSnappedPosition());\n            res.setQueryDistance(DIST_PLANE.calcDist(prevPoint.lat, prevPoint.lon, res.getQueryPoint().lat, res.getQueryPoint().lon));\n            continue;\n        }\n        queryOverlay.getClosestEdges().add(res.getClosestEdge().getEdge());\n        boolean isPillar = res.getSnappedPosition() == Snap.Position.PILLAR;\n        createEdges(origEdgeKey, origRevEdgeKey, prevPoint, prevWayIndex, isPillar, res.getSnappedPoint(), res.getWayIndex(), fullPL, closestEdge, prevNodeId, virtNodeId);\n        queryOverlay.getVirtualNodes().add(currSnapped.lat, currSnapped.lon, currSnapped.ele);\n        // add edges again to set adjacent edges for newVirtNodeId\n        if (addedEdges) {\n            queryOverlay.addVirtualEdge(queryOverlay.getVirtualEdge(queryOverlay.getNumVirtualEdges() - 2));\n            queryOverlay.addVirtualEdge(queryOverlay.getVirtualEdge(queryOverlay.getNumVirtualEdges() - 2));\n        }\n        addedEdges = true;\n        res.setClosestNode(virtNodeId);\n        prevNodeId = virtNodeId;\n        prevWayIndex = res.getWayIndex() + 1;\n        prevPoint = currSnapped;\n        virtNodeId++;\n    }\n    // two edges between last result and adjacent node are still missing if not all points skipped\n    if (addedEdges)\n        createEdges(origEdgeKey, origRevEdgeKey, prevPoint, prevWayIndex, false, fullPL.get(fullPL.size() - 1), fullPL.size() - 2, fullPL, closestEdge, virtNodeId - 1, adjNode);\n\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.AlternativeRoute.apply",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.AlternativeRoute.apply" ],
    "fullMethods" : [ "@Override\npublic boolean apply(final int traversalId, final SPTEntry fromSPTEntry) {\n    SPTEntry toSPTEntry = bestWeightMapTo.get(traversalId);\n    if (toSPTEntry == null)\n        return true;\n\n    // Using the parent is required to avoid duplicate edge in Path.\n    // TODO we miss the turn cost weight (but at least we not duplicate the current edge weight)\n    if (traversalMode.isEdgeBased() && (toSPTEntry.parent != null))\n        toSPTEntry = toSPTEntry.parent;\n\n    // The alternative path is suboptimal if U-turn (after fromSPTEntry)\n    if (fromSPTEntry.edge == toSPTEntry.edge)\n        return true;\n\n    // (1) skip too long paths\n    final double weight = (fromSPTEntry.getWeightOfVisitedPath() + toSPTEntry.getWeightOfVisitedPath()) + weighting.calcTurnWeight(fromSPTEntry.edge, fromSPTEntry.adjNode, toSPTEntry.edge);\n    if (weight > maxWeight)\n        return true;\n\n    if (isBestPath(fromSPTEntry))\n        return true;\n\n    // For edge based traversal we need the next entry to find out the plateau start\n    SPTEntry tmpFromEntry = (traversalMode.isEdgeBased()) ? fromSPTEntry.parent : fromSPTEntry;\n    if ((tmpFromEntry == null) || (tmpFromEntry.parent == null)) {\n        // we can be here only if edge based and only if entry is not part of the best path\n        // e.g. when starting point has two edges and one is part of the best path the other edge is path of an alternative\n        assert traversalMode.isEdgeBased();\n    } else {\n        int nextToTraversalId = traversalMode.createTraversalId(graph.getEdgeIteratorState(tmpFromEntry.edge, tmpFromEntry.parent.adjNode), true);\n        SPTEntry correspondingToEntry = bestWeightMapTo.get(nextToTraversalId);\n        if (correspondingToEntry != null) {\n            if (traversalMode.isEdgeBased())\n                correspondingToEntry = correspondingToEntry.parent;\n\n            if (correspondingToEntry.edge == fromSPTEntry.edge)\n                return true;\n\n        }\n    }\n    // (3a) calculate plateau, we know we are at the beginning of the 'from'-side of\n    // the plateau A-B-C and go further to B\n    // where B is the next-'from' of A and B is also the previous-'to' of A.\n    // \n    // *<-A-B-C->*\n    // /    \\\n    // start    end\n    // \n    // extend plateau in only one direction necessary (A to B to ...) as we know\n    // that the from-SPTEntry is the start of the plateau or there is no plateau at all\n    // \n    double plateauWeight = 0;\n    SPTEntry prevToSPTEntry = toSPTEntry;\n    SPTEntry prevFrom = fromSPTEntry;\n    while (prevToSPTEntry.parent != null) {\n        int nextFromTraversalId = traversalMode.createTraversalId(graph.getEdgeIteratorState(prevToSPTEntry.edge, prevToSPTEntry.parent.adjNode), false);\n        SPTEntry otherFromEntry = bestWeightMapFrom.get(nextFromTraversalId);\n        // end of a plateau\n        if (((otherFromEntry == null) || (otherFromEntry.parent != prevFrom)) || (otherFromEntry.edge != prevToSPTEntry.edge))\n            break;\n\n        prevFrom = otherFromEntry;\n        plateauWeight += prevToSPTEntry.getWeightOfVisitedPath() - prevToSPTEntry.parent.getWeightOfVisitedPath();\n        prevToSPTEntry = prevToSPTEntry.parent;\n    } \n    if ((plateauWeight <= 0) || ((plateauWeight / weight) < minPlateauFactor))\n        return true;\n\n    if (fromSPTEntry.parent == null)\n        throw new IllegalStateException(\"not implemented yet. in case of an edge based traversal the parent of fromSPTEntry could be null\");\n\n    // (3b) calculate share\n    SPTEntry fromEE = getFirstShareEE(fromSPTEntry.parent, true);\n    SPTEntry toEE = getFirstShareEE(toSPTEntry.parent, false);\n    double shareWeight = fromEE.getWeightOfVisitedPath() + toEE.getWeightOfVisitedPath();\n    boolean smallShare = (shareWeight / bestWeight) < maxShareFactor;\n    if (smallShare) {\n        List<String> altNames = getAltNames(graph, fromSPTEntry);\n        double sortBy = calcSortBy(weightInfluence, weight, shareInfluence, shareWeight, plateauInfluence, plateauWeight);\n        double worstSortBy = getWorstSortBy();\n        // plateaus.add(new PlateauInfo(altName, plateauEdges));\n        if ((sortBy < worstSortBy) || (alternatives.size() < maxPaths)) {\n            Path path = DefaultBidirPathExtractor.extractPath(graph, weighting, fromSPTEntry, toSPTEntry, weight);\n            // for now do not add alternatives to set, if we do we need to remove then on alternatives.clear too (see below)\n            // AtomicInteger tid = addToMap(traversalIDMap, path);\n            // int tid = traversalMode.createTraversalId(path.calcEdges().get(0), false);\n            alternatives.add(new AlternativeInfo(sortBy, path, fromEE, toEE, shareWeight, altNames));\n            Collections.sort(alternatives, ALT_COMPARATOR);\n            if (alternatives.get(0) != bestAlt)\n                throw new IllegalStateException(((\"best path should be always first entry \" + bestAlt.path.getWeight()) + \" vs \") + alternatives.get(0).path.getWeight());\n\n            if (alternatives.size() > maxPaths)\n                alternatives.subList(maxPaths, alternatives.size()).clear();\n\n        }\n    }\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.AbstractBidirAlgo.calcPath",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.AbstractBidirAlgo.calcPath", "com.graphhopper.routing.AbstractBidirAlgo.init", "com.graphhopper.routing.AbstractBidirAlgo.postInit", "com.graphhopper.routing.AbstractBidirAlgo.updateBestPath" ],
    "fullMethods" : [ "@Override\npublic Path calcPath(int from, int to, int fromOutEdge, int toInEdge) {\n    if (((fromOutEdge != ANY_EDGE) || (toInEdge != ANY_EDGE)) && (!traversalMode.isEdgeBased())) {\n        throw new IllegalArgumentException(\"Restricting the start/target edges is only possible for edge-based graph traversal\");\n    }\n    this.fromOutEdge = fromOutEdge;\n    this.toInEdge = toInEdge;\n    checkAlreadyRun();\n    setupFinishTime();\n    init(from, 0, to, 0);\n    runAlgo();\n    return extractPath();\n}", "void init(int from, double fromWeight, int to, double toWeight) {\n    initFrom(from, fromWeight);\n    initTo(to, toWeight);\n    postInit(from, to);\n}", "protected void postInit(int from, int to) {\n    if (!traversalMode.isEdgeBased()) {\n        if (updateBestPath) {\n            bestWeightMapOther = bestWeightMapFrom;\n            updateBestPath(Double.POSITIVE_INFINITY, currFrom, EdgeIterator.NO_EDGE, to, true);\n        }\n    } else if (((from == to) && (fromOutEdge == ANY_EDGE)) && (toInEdge == ANY_EDGE)) {\n        // special handling if start and end are the same and no directions are restricted\n        // the resulting weight should be zero\n        if ((currFrom.weight != 0) || (currTo.weight != 0)) {\n            throw new IllegalStateException(\"If from=to, the starting weight must be zero for from and to\");\n        }\n        bestFwdEntry = currFrom;\n        bestBwdEntry = currTo;\n        bestWeight = 0;\n        finishedFrom = true;\n        finishedTo = true;\n        return;\n    }\n    postInitFrom();\n    postInitTo();\n}", "protected void updateBestPath(double edgeWeight, SPTEntry entry, int origEdgeIdForCH, int traversalId, boolean reverse) {\n    assert traversalMode.isEdgeBased() != Double.isInfinite(edgeWeight);\n    SPTEntry entryOther = bestWeightMapOther.get(traversalId);\n    if (entryOther == null)\n        return;\n\n    // update \n    double weight = entry.getWeightOfVisitedPath() + entryOther.getWeightOfVisitedPath();\n    if (traversalMode.isEdgeBased()) {\n        if (getIncomingEdge(entryOther) != getIncomingEdge(entry))\n            throw new IllegalStateException(\"cannot happen for edge based execution of \" + getName());\n\n        // prevents the path to contain the edge at the meeting point twice and subtracts the weight (excluding turn weight => no previous edge)\n        entry = entry.getParent();\n        weight -= edgeWeight;\n    }\n    if (weight < bestWeight) {\n        bestFwdEntry = (reverse) ? entryOther : entry;\n        bestBwdEntry = (reverse) ? entry : entryOther;\n        bestWeight = weight;\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.AlternativeRoute.searchBest",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.AlternativeRoute.searchBest", "com.graphhopper.routing.AbstractBidirAlgo.runAlgo", "com.graphhopper.routing.AbstractNonCHBidirAlgo.fillEdgesFrom", "com.graphhopper.routing.AbstractNonCHBidirAlgo.fillEdges" ],
    "fullMethods" : [ "public Path searchBest(int from, int to) {\n    init(from, 0, to, 0);\n    // init collections and bestPath.getWeight properly\n    runAlgo();\n    return extractPath();\n}", "protected void runAlgo() {\n    while (((!finished()) && (!isMaxVisitedNodesExceeded())) && (!isTimeoutExceeded())) {\n        if (!finishedFrom)\n            finishedFrom = !fillEdgesFrom();\n\n        if (!finishedTo)\n            finishedTo = !fillEdgesTo();\n\n    } \n}", "@Override\nboolean fillEdgesFrom() {\n    while (true) {\n        if (pqOpenSetFrom.isEmpty())\n            return false;\n\n        currFrom = pqOpenSetFrom.poll();\n        if (!currFrom.isDeleted())\n            break;\n\n    } \n    visitedCountFrom++;\n    if (fromEntryCanBeSkipped()) {\n        return true;\n    }\n    if (fwdSearchCanBeStopped()) {\n        return false;\n    }\n    bestWeightMapOther = bestWeightMapTo;\n    fillEdges(currFrom, pqOpenSetFrom, bestWeightMapFrom, false);\n    return true;\n}", "private void fillEdges(SPTEntry currEdge, PriorityQueue<SPTEntry> prioQueue, IntObjectMap<SPTEntry> bestWeightMap, boolean reverse) {\n    EdgeIterator iter = edgeExplorer.setBaseNode(currEdge.adjNode);\n    while (iter.next()) {\n        if (!accept(iter, currEdge.edge))\n            continue;\n\n        final double weight = calcWeight(iter, currEdge, reverse);\n        if (Double.isInfinite(weight)) {\n            continue;\n        }\n        final int traversalId = traversalMode.createTraversalId(iter, reverse);\n        SPTEntry entry = bestWeightMap.get(traversalId);\n        if (entry == null) {\n            entry = createEntry(iter, weight, currEdge, reverse);\n            bestWeightMap.put(traversalId, entry);\n            prioQueue.add(entry);\n        } else if (entry.getWeightOfVisitedPath() > weight) {\n            // flagging this entry, so it will be ignored when it is polled the next time\n            entry.setDeleted();\n            boolean isBestEntry = (reverse) ? entry == bestBwdEntry : entry == bestFwdEntry;\n            entry = createEntry(iter, weight, currEdge, reverse);\n            bestWeightMap.put(traversalId, entry);\n            prioQueue.add(entry);\n            // if this is the best entry we need to update the best reference as well\n            if (isBestEntry)\n                if (reverse)\n                    bestBwdEntry = entry;\n                else\n                    bestFwdEntry = entry;\n\n\n        } else\n            continue;\n\n        if (updateBestPath) {\n            // only needed for edge-based -> skip the calculation and use dummy value otherwise\n            double edgeWeight = (traversalMode.isEdgeBased()) ? weighting.calcEdgeWeight(iter, reverse) : Double.POSITIVE_INFINITY;\n            // todo: performance - if bestWeightMapOther.get(traversalId) == null, updateBestPath will exit early and we might\n            // have calculated the edgeWeight unnecessarily\n            updateBestPath(edgeWeight, entry, EdgeIterator.NO_EDGE, traversalId, reverse);\n        }\n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Dijkstra.calcPath",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Dijkstra.calcPath", "com.graphhopper.routing.Dijkstra.runAlgo" ],
    "fullMethods" : [ "@Override\npublic Path calcPath(int from, int to) {\n    checkAlreadyRun();\n    setupFinishTime();\n    this.to = to;\n    SPTEntry startEntry = new SPTEntry(from, 0);\n    fromHeap.add(startEntry);\n    if (!traversalMode.isEdgeBased())\n        fromMap.put(from, currEdge);\n\n    runAlgo();\n    return extractPath();\n}", "protected void runAlgo() {\n    while (!fromHeap.isEmpty()) {\n        currEdge = fromHeap.poll();\n        if (currEdge.isDeleted())\n            continue;\n\n        visitedNodes++;\n        if ((isMaxVisitedNodesExceeded() || finished()) || isTimeoutExceeded())\n            break;\n\n        int currNode = currEdge.adjNode;\n        EdgeIterator iter = edgeExplorer.setBaseNode(currNode);\n        while (iter.next()) {\n            if (!accept(iter, currEdge.edge))\n                continue;\n\n            double tmpWeight = GHUtility.calcWeightWithTurnWeight(weighting, iter, false, currEdge.edge) + currEdge.weight;\n            if (Double.isInfinite(tmpWeight)) {\n                continue;\n            }\n            int traversalId = traversalMode.createTraversalId(iter, false);\n            SPTEntry nEdge = fromMap.get(traversalId);\n            if (nEdge == null) {\n                nEdge = new SPTEntry(iter.getEdge(), iter.getAdjNode(), tmpWeight, currEdge);\n                fromMap.put(traversalId, nEdge);\n                fromHeap.add(nEdge);\n            } else if (nEdge.weight > tmpWeight) {\n                nEdge.setDeleted();\n                nEdge = new SPTEntry(iter.getEdge(), iter.getAdjNode(), tmpWeight, currEdge);\n                fromMap.put(traversalId, nEdge);\n                fromHeap.add(nEdge);\n            } else\n                continue;\n\n            updateBestPath(iter, nEdge, traversalId);\n        } \n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.setBaseNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.setBaseNode" ],
    "fullMethods" : [ "@Override\npublic RoutingCHEdgeIterator setBaseNode(int baseNode) {\n    if (isVirtualNode(baseNode)) {\n        List<RoutingCHEdgeIteratorState> virtualEdges = virtualEdgesAtVirtualNodes.get(baseNode - routingCHGraph.getNodes());\n        iterator.reset(virtualEdges);\n        return iterator;\n    } else {\n        List<RoutingCHEdgeIteratorState> virtualEdges = virtualEdgesAtRealNodes.get(baseNode);\n        if (virtualEdges == null) {\n            return explorer.setBaseNode(baseNode);\n        } else {\n            iterator.reset(virtualEdges);\n            return iterator;\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.BridgePathFinder.find",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.BridgePathFinder.find" ],
    "fullMethods" : [ "/**\n * Finds all bridge paths starting at a given node and starting edge key.\n *\n * @return a mapping between the target edge keys we can reach via bridge paths and information about the\ncorresponding bridge path\n */\npublic IntObjectMap<BridePathEntry> find(int startInEdgeKey, int startNode, int centerNode) {\n    queue.clear();\n    map.clear();\n    IntObjectMap<BridePathEntry> result = new IntObjectHashMap<>(16, 0.5, HashOrderMixing.constant(123));\n    PrepareCHEntry startEntry = new PrepareCHEntry(NO_EDGE, startInEdgeKey, startInEdgeKey, startNode, 0, 0);\n    map.put(startInEdgeKey, startEntry);\n    queue.add(startEntry);\n    while (!queue.isEmpty()) {\n        PrepareCHEntry currEntry = queue.poll();\n        PrepareGraphEdgeIterator iter = outExplorer.setBaseNode(currEntry.adjNode);\n        while (iter.next()) {\n            if (iter.getAdjNode() == centerNode) {\n                // We arrived at the center node, so we keep expanding the search\n                double weight = (currEntry.weight + graph.getTurnWeight(currEntry.incEdgeKey, currEntry.adjNode, iter.getOrigEdgeKeyFirst())) + iter.getWeight();\n                if (Double.isInfinite(weight))\n                    continue;\n\n                PrepareCHEntry entry = map.get(iter.getOrigEdgeKeyLast());\n                if (entry == null) {\n                    entry = new PrepareCHEntry(iter.getPrepareEdge(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getAdjNode(), weight, currEntry.origEdges + iter.getOrigEdgeCount());\n                    entry.parent = currEntry;\n                    map.put(iter.getOrigEdgeKeyLast(), entry);\n                    queue.add(entry);\n                } else if (weight < entry.weight) {\n                    queue.remove(entry);\n                    entry.prepareEdge = iter.getPrepareEdge();\n                    entry.origEdges = currEntry.origEdges + iter.getOrigEdgeCount();\n                    entry.firstEdgeKey = iter.getOrigEdgeKeyFirst();\n                    entry.weight = weight;\n                    entry.parent = currEntry;\n                    queue.add(entry);\n                }\n            } else if (currEntry.adjNode == centerNode) {\n                // We just left the center node, so we arrived at some neighbor node. Every edge we can reach from\n                // there is a target edge, so we add a bridge path entry for it. We do not continue the search from the\n                // neighbor node anymore\n                double weight = (currEntry.weight + graph.getTurnWeight(currEntry.incEdgeKey, currEntry.adjNode, iter.getOrigEdgeKeyFirst())) + iter.getWeight();\n                if (Double.isInfinite(weight))\n                    continue;\n\n                PrepareGraphOrigEdgeIterator origOutIter = origOutExplorer.setBaseNode(iter.getAdjNode());\n                while (origOutIter.next()) {\n                    double totalWeight = weight + graph.getTurnWeight(iter.getOrigEdgeKeyLast(), iter.getAdjNode(), origOutIter.getOrigEdgeKeyFirst());\n                    if (Double.isInfinite(totalWeight))\n                        continue;\n\n                    BridePathEntry resEntry = result.get(origOutIter.getOrigEdgeKeyFirst());\n                    if (resEntry == null) {\n                        PrepareCHEntry chEntry = new PrepareCHEntry(iter.getPrepareEdge(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getAdjNode(), weight, currEntry.origEdges + iter.getOrigEdgeCount());\n                        chEntry.parent = currEntry;\n                        resEntry = new BridePathEntry(totalWeight, chEntry);\n                        result.put(origOutIter.getOrigEdgeKeyFirst(), resEntry);\n                    } else if (totalWeight < resEntry.weight) {\n                        resEntry.weight = totalWeight;\n                        resEntry.chEntry.prepareEdge = iter.getPrepareEdge();\n                        resEntry.chEntry.firstEdgeKey = iter.getOrigEdgeKeyFirst();\n                        resEntry.chEntry.origEdges = currEntry.origEdges + iter.getOrigEdgeCount();\n                        resEntry.chEntry.incEdgeKey = iter.getOrigEdgeKeyLast();\n                        resEntry.chEntry.weight = weight;\n                        resEntry.chEntry.parent = currEntry;\n                    }\n                } \n            }\n            // We arrived at some node that is not the center node. We do not expand the search as we are only\n            // concerned with finding bridge paths.\n        } \n    } \n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryGraph.setBaseNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryGraph.setBaseNode" ],
    "fullMethods" : [ "@Override\npublic EdgeIterator setBaseNode(int baseNode) {\n    if (isVirtualNode(baseNode)) {\n        List<EdgeIteratorState> virtualEdges = virtualEdgesAtVirtualNodes.get(baseNode - baseNodes);\n        return virtualEdgeIterator.reset(virtualEdges);\n    } else {\n        List<EdgeIteratorState> virtualEdges = virtualEdgesAtRealNodes.get(baseNode);\n        if (virtualEdges == null) {\n            return mainExplorer.setBaseNode(baseNode);\n        } else {\n            return virtualEdgeIterator.reset(virtualEdges);\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build", "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build", "com.graphhopper.routing.querygraph.QueryOverlayBuilder.buildEdgeChangesAtRealNodes", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.build", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.build", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.addVirtualEdges" ],
    "fullMethods" : [ "public static QueryOverlay build(int firstVirtualNodeId, int firstVirtualEdgeId, boolean is3D, List<Snap> snaps) {\n    return new QueryOverlayBuilder(firstVirtualNodeId, firstVirtualEdgeId, is3D).build(snaps);\n}", "private QueryOverlay build(List<Snap> resList) {\n    queryOverlay = new QueryOverlay(resList.size(), is3D);\n    buildVirtualEdges(resList);\n    buildEdgeChangesAtRealNodes();\n    return queryOverlay;\n}", "private void buildEdgeChangesAtRealNodes() {\n    EdgeChangeBuilder.build(queryOverlay.getClosestEdges(), queryOverlay.getVirtualEdges(), firstVirtualNodeId, queryOverlay.getEdgeChangesAtRealNodes());\n}", "/**\n * Builds a mapping between real node ids and the set of changes for their adjacent edges.\n *\n * @param edgeChangesAtRealNodes\n * \t\toutput parameter, you need to pass an empty & modifiable map and the results will\n * \t\tbe added to it\n */\nstatic void build(IntArrayList closestEdges, List<VirtualEdgeIteratorState> virtualEdges, int firstVirtualNodeId, IntObjectMap<QueryOverlay.EdgeChanges> edgeChangesAtRealNodes) {\n    new EdgeChangeBuilder(closestEdges, virtualEdges, firstVirtualNodeId, edgeChangesAtRealNodes).build();\n}", "private void build() {\n    final GHIntHashSet towerNodesToChange = new GHIntHashSet(getNumVirtualNodes());\n    // 1. for every real node adjacent to a virtual one we collect the virtual edges, also build a set of\n    // these adjacent real nodes so we can use them in the next step\n    for (int i = 0; i < getNumVirtualNodes(); i++) {\n        // base node\n        EdgeIteratorState baseRevEdge = getVirtualEdge((i * 4) + SNAP_BASE);\n        int towerNode = baseRevEdge.getAdjNode();\n        if (!isVirtualNode(towerNode)) {\n            towerNodesToChange.add(towerNode);\n            addVirtualEdges(true, towerNode, i);\n        }\n        // adj node\n        EdgeIteratorState adjEdge = getVirtualEdge((i * 4) + SNAP_ADJ);\n        towerNode = adjEdge.getAdjNode();\n        if (!isVirtualNode(towerNode)) {\n            towerNodesToChange.add(towerNode);\n            addVirtualEdges(false, towerNode, i);\n        }\n    }\n    // 2. build the list of removed edges for all real nodes adjacent to virtual ones\n    towerNodesToChange.forEach(new IntProcedure() {\n        @Override\n        public void apply(int value) {\n            addRemovedEdges(value);\n        }\n    });\n}", "/**\n * Adds the virtual edges adjacent to the real tower nodes\n */\nprivate void addVirtualEdges(boolean base, int node, int virtNode) {\n    QueryOverlay.EdgeChanges edgeChanges = edgeChangesAtRealNodes.get(node);\n    if (edgeChanges == null) {\n        edgeChanges = new QueryOverlay.EdgeChanges(2, 2);\n        edgeChangesAtRealNodes.put(node, edgeChanges);\n    }\n    EdgeIteratorState edge = (base) ? getVirtualEdge((virtNode * 4) + BASE_SNAP) : getVirtualEdge((virtNode * 4) + ADJ_SNAP);\n    edgeChanges.getAdditionalEdges().add(edge);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.EdgeChangeBuilder.apply",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.EdgeChangeBuilder.apply", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.addRemovedEdges" ],
    "fullMethods" : [ "@Override\npublic void apply(int value) {\n    addRemovedEdges(value);\n}", "/**\n * Adds the ids of the removed edges at the real tower nodes. We need to do this such that we cannot 'skip'\n * virtual nodes by just using the original edges and also to prevent u-turns at the real nodes adjacent to the\n * virtual ones.\n */\nprivate void addRemovedEdges(int towerNode) {\n    if (isVirtualNode(towerNode))\n        throw new IllegalStateException(((\"Node should not be virtual:\" + towerNode) + \", \") + edgeChangesAtRealNodes);\n\n    QueryOverlay.EdgeChanges edgeChanges = edgeChangesAtRealNodes.get(towerNode);\n    List<EdgeIteratorState> existingEdges = edgeChanges.getAdditionalEdges();\n    IntArrayList removedEdges = edgeChanges.getRemovedEdges();\n    for (EdgeIteratorState existingEdge : existingEdges) {\n        removedEdges.add(getClosestEdge(existingEdge.getAdjNode()));\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate",
    "thirdPartyMethod" : "org.locationtech.jts.triangulate.quadedge.QuadEdgeSubdivision.getVertices",
    "thirdPartyPackage" : "org.locationtech.jts.triangulate.quadedge",
    "path" : [ "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate" ],
    "fullMethods" : [ "public Result triangulate(Snap snap, QueryGraph queryGraph, ShortestPathTree shortestPathTree, ToDoubleFunction<ShortestPathTree.IsoLabel> fz, double tolerance) {\n    final NodeAccess na = queryGraph.getNodeAccess();\n    Collection<Coordinate> sites = new ArrayList<>();\n    shortestPathTree.search(snap.getClosestNode(), label -> {\n        double exploreValue = fz.applyAsDouble(label);\n        double lat = na.getLat(label.node);\n        double lon = na.getLon(label.node);\n        Coordinate site = new Coordinate(lon, lat);\n        site.z = exploreValue;\n        sites.add(site);\n        // add a pillar node to increase precision a bit for longer roads\n        if (label.parent != null) {\n            EdgeIteratorState edge = queryGraph.getEdgeIteratorState(label.edge, label.node);\n            PointList innerPoints = edge.fetchWayGeometry(FetchMode.PILLAR_ONLY);\n            if (innerPoints.size() > 0) {\n                int midIndex = innerPoints.size() / 2;\n                // For edge-based routing we might have explored the same edge in two different directions.\n                // Here we make sure we only include the **same** point twice instead of two different ones.\n                if (((innerPoints.size() % 2) == 0) && edge.get(EdgeIteratorState.REVERSE_STATE))\n                    midIndex -= 1;\n\n                double lat2 = innerPoints.getLat(midIndex);\n                double lon2 = innerPoints.getLon(midIndex);\n                Coordinate site2 = new Coordinate(lon2, lat2);\n                site2.z = exploreValue;\n                sites.add(site2);\n            }\n        }\n    });\n    if (sites.size() > (routerConfig.getMaxVisitedNodes() / 3))\n        throw new IllegalArgumentException((\"Too many nodes would be included in post processing (\" + sites.size()) + \"). Let us know if you need this increased.\");\n\n    // Sites may contain repeated coordinates. Especially for edge-based traversal, that's expected -- we visit\n    // each node multiple times.\n    // But that's okay, the triangulator de-dupes by itself, and it keeps the first z-value it sees, which is\n    // what we want.\n    DelaunayTriangulationBuilder triangulationBuilder = new DelaunayTriangulationBuilder();\n    triangulationBuilder.setSites(sites);\n    triangulationBuilder.setTolerance(tolerance);\n    Geometry convexHull = triangulationBuilder.getEdges(new GeometryFactory()).convexHull();\n    // If there's only one site (and presumably also if the convex hull is otherwise degenerated),\n    // the triangulation only contains the frame, and not the site within the frame. Not sure if I agree with that.\n    // See ConformingDelaunayTriangulator, it does include a buffer for the frame, but that buffer is zero\n    // in these cases.\n    // It leads to the following follow-up defect:\n    // computeIsoline fails (returns an empty Multipolygon). This is clearly wrong, since\n    // the idea is that every real (non-frame) vertex has positive-length-edges around it that can be traversed\n    // to get a non-empty polygon.\n    // So we exclude this case for now (it is indeed only a corner-case).\n    if (!(convexHull instanceof Polygon)) {\n        throw new IllegalArgumentException(\"Too few points found. \" + \"Please try a different 'point' or a larger 'time_limit'.\");\n    }\n    QuadEdgeSubdivision tin = triangulationBuilder.getSubdivision();\n    for (Vertex vertex : ((Collection<Vertex>) (tin.getVertices(true)))) {\n        if (tin.isFrameVertex(vertex)) {\n            vertex.setZ(Double.MAX_VALUE);\n        }\n    }\n    ReadableTriangulation triangulation = ReadableTriangulation.wrap(tin);\n    return new Result(triangulation, triangulation.getEdges());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayDeque.addLast",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForEdgeState", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.pushFindComponentForEdgeKey" ],
    "fullMethods" : [ "/**\n * Like {@link #findComponents(Graph, EdgeTransitionFilter, boolean)}, but the search only starts at the\n * given edges. This does not mean the search cannot expand to other edges, but this can be controlled by the\n * edgeTransitionFilter. This method does not return single edge components (the excludeSingleEdgeComponents option is\n * set to true).\n */\npublic static ConnectedComponents findComponentsForStartEdges(Graph graph, EdgeTransitionFilter edgeTransitionFilter, IntContainer edges) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, true).findComponentsForStartEdges(edges);\n}", "private ConnectedComponents findComponentsForStartEdges(IntContainer startEdges) {\n    initForStartEdges(startEdges.size());\n    for (IntCursor edge : startEdges) {\n        // todo: using getEdgeIteratorState here is not efficient\n        EdgeIteratorState edgeState = graph.getEdgeIteratorState(edge.value, Integer.MIN_VALUE);\n        if (!edgeTransitionFilter.accept(NO_EDGE, edgeState))\n            continue;\n\n        findComponentsForEdgeState(edgeState);\n    }\n    return components;\n}", "private void findComponentsForEdgeState(EdgeIteratorState edge) {\n    int edgeKeyFwd = createEdgeKey(edge, false);\n    if (!edgeKeyIndex.has(edgeKeyFwd))\n        pushFindComponentForEdgeKey(edgeKeyFwd, edge.getAdjNode());\n\n    startSearch();\n    // We need to start the search for both edge keys of this edge, but its important to check if the second\n    // has already been found by the first search. So we cannot simply push them both and start the search once.\n    int edgeKeyBwd = createEdgeKey(edge, true);\n    if (!edgeKeyIndex.has(edgeKeyBwd))\n        pushFindComponentForEdgeKey(edgeKeyBwd, edge.getAdjNode());\n\n    startSearch();\n}", "private void pushFindComponentForEdgeKey(int p, int adj) {\n    assert (p >= 0) && (adj >= 0);\n    dfsStackPQ.addLast(bitUtil.toLong(p, -1));\n    dfsStackAdj.addLast(adj);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayDeque.addLast",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity" ],
    "fullMethods" : [ "/**\n *\n * @param radius\n * \t\tin meters\n * @param calcRoadFactor\n * \t\tweighting function. use this to define how different kinds of roads shall contribute to the calculated road density\n * @return the road density in the vicinity of the given edge, i.e. the weighted road length divided by the squared radius\n */\npublic double calcRoadDensity(EdgeIteratorState edge, double radius, ToDoubleFunction<EdgeIteratorState> calcRoadFactor) {\n    visited.clear();\n    deque.head = deque.tail = 0;\n    double totalRoadWeight = 0;\n    NodeAccess na = graph.getNodeAccess();\n    int baseNode = edge.getBaseNode();\n    int adjNode = edge.getAdjNode();\n    GHPoint center = new GHPoint(getLat(na, baseNode, adjNode), getLon(na, baseNode, adjNode));\n    deque.addLast(baseNode);\n    deque.addLast(adjNode);\n    visited.add(baseNode);\n    visited.add(adjNode);\n    // we just do a BFS search and sum up all the road lengths\n    final double radiusNormalized = DIST_PLANE.calcNormalizedDist(radius);\n    // for long tunnels or motorway sections where the distance between the exit points and the\n    // center is larger than the radius it is important to continue the search even outside the radius\n    final int minPolls = ((int) (radius / 2));\n    int polls = 0;\n    while (!deque.isEmpty()) {\n        int node = deque.removeFirst();\n        polls++;\n        double distance = DIST_PLANE.calcNormalizedDist(center.lat, center.lon, na.getLat(node), na.getLon(node));\n        if ((polls > minPolls) && (distance > radiusNormalized))\n            continue;\n\n        EdgeIterator iter = edgeExplorer.setBaseNode(node);\n        while (iter.next()) {\n            if (visited.contains(iter.getAdjNode()))\n                continue;\n\n            visited.add(iter.getAdjNode());\n            if (distance <= radiusNormalized)\n                totalRoadWeight += calcRoadFactor.applyAsDouble(iter);\n\n            deque.addLast(iter.getAdjNode());\n        } \n    } \n    return (totalRoadWeight / radius) / radius;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.DepthFirstSearch.start",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayDeque.addLast",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.DepthFirstSearch.start" ],
    "fullMethods" : [ "/**\n * beginning with startNode add all following nodes to LIFO queue. If node has been already\n * explored before, skip reexploration.\n */\n@Override\npublic void start(EdgeExplorer explorer, int startNode) {\n    IntArrayDeque stack = new IntArrayDeque();\n    GHBitSet explored = createBitSet();\n    stack.addLast(startNode);\n    int current;\n    while (stack.size() > 0) {\n        current = stack.removeLast();\n        if ((!explored.contains(current)) && goFurther(current)) {\n            EdgeIterator iter = explorer.setBaseNode(current);\n            while (iter.next()) {\n                int connectedId = iter.getAdjNode();\n                if (checkAdjacent(iter)) {\n                    stack.addLast(connectedId);\n                }\n            } \n            explored.add(current);\n        }\n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayDeque.addLast",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForEdgeState", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.pushFindComponentForEdgeKey" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param edgeTransitionFilter\n * \t\tOnly edge transitions accepted by this filter will be considered when we explore the graph.\n * \t\tIf a turn is not accepted the corresponding path will be ignored (edges that are only connected\n * \t\tby a path with such a turn will not be considered to belong to the same component)\n * @param excludeSingleEdgeComponents\n * \t\tif set to true components that only contain a single edge will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponents();\n}", "private ConnectedComponents findComponents() {\n    initForEntireGraph();\n    AllEdgesIterator iter = graph.getAllEdges();\n    while (iter.next()) {\n        findComponentsForEdgeState(iter);\n    } \n    return components;\n}", "private void findComponentsForEdgeState(EdgeIteratorState edge) {\n    int edgeKeyFwd = createEdgeKey(edge, false);\n    if (!edgeKeyIndex.has(edgeKeyFwd))\n        pushFindComponentForEdgeKey(edgeKeyFwd, edge.getAdjNode());\n\n    startSearch();\n    // We need to start the search for both edge keys of this edge, but its important to check if the second\n    // has already been found by the first search. So we cannot simply push them both and start the search once.\n    int edgeKeyBwd = createEdgeKey(edge, true);\n    if (!edgeKeyIndex.has(edgeKeyBwd))\n        pushFindComponentForEdgeKey(edgeKeyBwd, edge.getAdjNode());\n\n    startSearch();\n}", "private void pushFindComponentForEdgeKey(int p, int adj) {\n    assert (p >= 0) && (adj >= 0);\n    dfsStackPQ.addLast(bitUtil.toLong(p, -1));\n    dfsStackAdj.addLast(adj);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayDeque.addLast",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentForNode", "com.graphhopper.routing.subnetwork.TarjanSCC.setupNextNode" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponentsRecursive();\n}", "private ConnectedComponents findComponentsRecursive() {\n    for (int node = 0; node < graph.getNodes(); node++) {\n        if (nodeIndex[node] == (-1)) {\n            findComponentForNode(node);\n        }\n    }\n    return components;\n}", "private void findComponentForNode(int v) {\n    setupNextNode(v);\n    // we have to create a new explorer on each iteration because of the nested edge iterations\n    EdgeExplorer explorer = graph.createEdgeExplorer(edgeFilter);\n    EdgeIterator iter = explorer.setBaseNode(v);\n    while (iter.next()) {\n        int w = iter.getAdjNode();\n        if (nodeIndex[w] == (-1)) {\n            findComponentForNode(w);\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n        } else if (nodeOnStack.get(w))\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n    } \n    buildComponent(v);\n}", "private void setupNextNode(int v) {\n    nodeIndex[v] = currIndex;\n    nodeLowLink[v] = currIndex;\n    currIndex++;\n    tarjanStack.addLast(v);\n    nodeOnStack.set(v);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayDeque.addLast",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.setupNextNode" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param excludeSingleNodeComponents\n * \t\tif set to true components that only contain a single node will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponents();\n}", "private ConnectedComponents findComponents() {\n    for (int node = 0; node < graph.getNodes(); ++node) {\n        if (nodeIndex[node] != (-1))\n            continue;\n\n        pushFindComponentForNode(node);\n        while (hasNext()) {\n            pop();\n            switch (dfsState) {\n                case BUILD_COMPONENT :\n                    buildComponent(v);\n                    break;\n                case UPDATE :\n                    nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n                    break;\n                case HANDLE_NEIGHBOR :\n                    {\n                        if ((nodeIndex[w] != (-1)) && nodeOnStack.get(w))\n                            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n                        if (nodeIndex[w] == (-1)) {\n                            // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                            pushUpdateLowLinks(v, w);\n                            pushFindComponentForNode(w);\n                        }\n                        break;\n                    }\n                case FIND_COMPONENT :\n                    {\n                        setupNextNode(v);\n                        // we push buildComponent first so it will run *after* we finished traversing the edges\n                        pushBuildComponent(v);\n                        EdgeIterator iter = explorer.setBaseNode(v);\n                        while (iter.next()) {\n                            pushHandleNeighbor(v, iter.getAdjNode());\n                        } \n                        break;\n                    }\n                default :\n                    throw new IllegalStateException(\"Unknown state: \" + dfsState);\n            }\n        } \n    }\n    return components;\n}", "private void setupNextNode(int v) {\n    nodeIndex[v] = currIndex;\n    nodeLowLink[v] = currIndex;\n    currIndex++;\n    tarjanStack.addLast(v);\n    nodeOnStack.set(v);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayDeque.addLast",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentForEdgeKey", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.setupNextEdgeKey" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeTransitionFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponentsRecursive();\n}", "private ConnectedComponents findComponentsRecursive() {\n    initForEntireGraph();\n    AllEdgesIterator iter = graph.getAllEdges();\n    while (iter.next()) {\n        int edgeKeyFwd = createEdgeKey(iter, false);\n        if (!edgeKeyIndex.has(edgeKeyFwd))\n            findComponentForEdgeKey(edgeKeyFwd, iter.getAdjNode());\n\n        int edgeKeyBwd = createEdgeKey(iter, true);\n        if (!edgeKeyIndex.has(edgeKeyBwd))\n            findComponentForEdgeKey(edgeKeyBwd, iter.getAdjNode());\n\n    } \n    return components;\n}", "private void findComponentForEdgeKey(int p, int adjNode) {\n    setupNextEdgeKey(p);\n    // we have to create a new explorer on each iteration because of the nested edge iterations\n    final int edge = getEdgeFromEdgeKey(p);\n    EdgeExplorer explorer = graph.createEdgeExplorer();\n    EdgeIterator iter = explorer.setBaseNode(adjNode);\n    while (iter.next()) {\n        if (!edgeTransitionFilter.accept(edge, iter))\n            continue;\n\n        int q = createEdgeKey(iter, false);\n        handleNeighbor(p, q, iter.getAdjNode());\n    } \n    buildComponent(p);\n}", "private void setupNextEdgeKey(int p) {\n    edgeKeyIndex.set(p, currIndex);\n    edgeKeyLowLink.set(p, currIndex);\n    currIndex++;\n    tarjanStack.addLast(p);\n    edgeKeyOnStack.add(p);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.dem.AbstractTiffElevationProvider.getEle",
    "thirdPartyMethod" : "org.apache.xmlgraphics.image.codec.util.SeekableStream.wrapInputStream",
    "thirdPartyPackage" : "org.apache.xmlgraphics.image.codec.util",
    "path" : [ "com.graphhopper.reader.dem.AbstractTiffElevationProvider.getEle", "com.graphhopper.reader.dem.GMTEDProvider.readFile" ],
    "fullMethods" : [ "@Override\npublic double getEle(double lat, double lon) {\n    // Return fast, if there is no data available\n    if (isOutsideSupportedArea(lat, lon))\n        return 0;\n\n    lat = ((int) (lat * precision)) / precision;\n    lon = ((int) (lon * precision)) / precision;\n    String name = getFileName(lat, lon);\n    HeightTile demProvider = cacheData.get(name);\n    if (demProvider == null) {\n        if (!cacheDir.exists())\n            cacheDir.mkdirs();\n\n        int minLat = getMinLatForTile(lat);\n        int minLon = getMinLonForTile(lon);\n        // less restrictive against boundary checking\n        demProvider = new HeightTile(minLat, minLon, WIDTH, HEIGHT, LON_DEGREE * precision, LON_DEGREE, LAT_DEGREE);\n        demProvider.setInterpolate(interpolate);\n        cacheData.put(name, demProvider);\n        DataAccess heights = getDirectory().create(name + \".gh\");\n        demProvider.setHeights(heights);\n        boolean loadExisting = false;\n        try {\n            loadExisting = heights.loadExisting();\n        } catch (Exception ex) {\n            logger.warn(((\"cannot load \" + name) + \", error: \") + ex.getMessage());\n        }\n        if (!loadExisting) {\n            File zipFile = new File(cacheDir, new File(getFileNameOfLocalFile(lat, lon)).getName());\n            if (!zipFile.exists())\n                try {\n                    String zippedURL = getDownloadURL(lat, lon);\n                    downloadToFile(zipFile, zippedURL);\n                } catch (SSLException ex) {\n                    throw new IllegalStateException(\"SSL problem with elevation provider \" + getClass().getSimpleName(), ex);\n                } catch (IOException ex) {\n                    demProvider.setSeaLevel(true);\n                    // use small size on disc and in-memory\n                    heights.create(10).flush();\n                    return 0;\n                }\n\n            // short == 2 bytes\n            heights.create((2L * WIDTH) * HEIGHT);\n            Raster raster = readFile(zipFile, name + \".tif\");\n            fillDataAccessWithElevationData(raster, heights, WIDTH);\n        }// loadExisting\n\n    }\n    if (demProvider.isSeaLevel())\n        return 0;\n\n    return demProvider.getHeight(lat, lon);\n}", "@Override\nRaster readFile(File file, String tifName) {\n    SeekableStream ss = null;\n    try {\n        InputStream is = new FileInputStream(file);\n        ss = SeekableStream.wrapInputStream(is, true);\n        TIFFImageDecoder imageDecoder = new TIFFImageDecoder(ss, new TIFFDecodeParam());\n        return imageDecoder.decodeAsRaster();\n    } catch (Exception e) {\n        throw new RuntimeException(\"Can't decode \" + file.getName(), e);\n    } finally {\n        if (ss != null)\n            close(ss);\n\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.Restriction.toString",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.toString",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.Restriction.toString" ],
    "fullMethods" : [ "@Override\npublic String toString() {\n    return ((\"edges: \" + edges.toString()) + \", viaNode: \") + viaNode;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.index.InMemConstructionIndex.InMemLeafEntry.toString",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.toString",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.index.InMemConstructionIndex.InMemLeafEntry.toString" ],
    "fullMethods" : [ "@Override\npublic String toString() {\n    return (\"LEAF \" + /* key + */\n    \" \") + super.toString();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.RoadDensityCalculator.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayDeque.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.RoadDensityCalculator.<init>" ],
    "fullMethods" : [ "public RoadDensityCalculator(Graph graph) {\n    this.graph = graph;\n    this.edgeExplorer = graph.createEdgeExplorer();\n    visited = new IntScatterSet();\n    deque = new IntArrayDeque(100);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayDeque.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity" ],
    "fullMethods" : [ "/**\n *\n * @param radius\n * \t\tin meters\n * @param calcRoadFactor\n * \t\tweighting function. use this to define how different kinds of roads shall contribute to the calculated road density\n * @return the road density in the vicinity of the given edge, i.e. the weighted road length divided by the squared radius\n */\npublic double calcRoadDensity(EdgeIteratorState edge, double radius, ToDoubleFunction<EdgeIteratorState> calcRoadFactor) {\n    visited.clear();\n    deque.head = deque.tail = 0;\n    double totalRoadWeight = 0;\n    NodeAccess na = graph.getNodeAccess();\n    int baseNode = edge.getBaseNode();\n    int adjNode = edge.getAdjNode();\n    GHPoint center = new GHPoint(getLat(na, baseNode, adjNode), getLon(na, baseNode, adjNode));\n    deque.addLast(baseNode);\n    deque.addLast(adjNode);\n    visited.add(baseNode);\n    visited.add(adjNode);\n    // we just do a BFS search and sum up all the road lengths\n    final double radiusNormalized = DIST_PLANE.calcNormalizedDist(radius);\n    // for long tunnels or motorway sections where the distance between the exit points and the\n    // center is larger than the radius it is important to continue the search even outside the radius\n    final int minPolls = ((int) (radius / 2));\n    int polls = 0;\n    while (!deque.isEmpty()) {\n        int node = deque.removeFirst();\n        polls++;\n        double distance = DIST_PLANE.calcNormalizedDist(center.lat, center.lon, na.getLat(node), na.getLon(node));\n        if ((polls > minPolls) && (distance > radiusNormalized))\n            continue;\n\n        EdgeIterator iter = edgeExplorer.setBaseNode(node);\n        while (iter.next()) {\n            if (visited.contains(iter.getAdjNode()))\n                continue;\n\n            visited.add(iter.getAdjNode());\n            if (distance <= radiusNormalized)\n                totalRoadWeight += calcRoadFactor.applyAsDouble(iter);\n\n            deque.addLast(iter.getAdjNode());\n        } \n    } \n    return (totalRoadWeight / radius) / radius;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongHashSet.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongHashSet.<init>" ],
    "fullMethods" : [ "public GHLongHashSet() {\n    super(10, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongHashSet.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongHashSet.<init>" ],
    "fullMethods" : [ "public GHLongHashSet(int capacity, double loadFactor) {\n    super(capacity, loadFactor, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongHashSet.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongHashSet.<init>" ],
    "fullMethods" : [ "public GHLongHashSet(int capacity, double loadFactor, HashOrderMixingStrategy hashOrderMixer) {\n    super(capacity, loadFactor, hashOrderMixer);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongHashSet.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongHashSet.<init>" ],
    "fullMethods" : [ "public GHLongHashSet(int capacity) {\n    super(capacity, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanArrayIntSet.contains",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanArrayIntSet.contains" ],
    "fullMethods" : [ "@Override\npublic boolean contains(int key) {\n    return set.get(key);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentForNode" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponentsRecursive();\n}", "private ConnectedComponents findComponentsRecursive() {\n    for (int node = 0; node < graph.getNodes(); node++) {\n        if (nodeIndex[node] == (-1)) {\n            findComponentForNode(node);\n        }\n    }\n    return components;\n}", "private void findComponentForNode(int v) {\n    setupNextNode(v);\n    // we have to create a new explorer on each iteration because of the nested edge iterations\n    EdgeExplorer explorer = graph.createEdgeExplorer(edgeFilter);\n    EdgeIterator iter = explorer.setBaseNode(v);\n    while (iter.next()) {\n        int w = iter.getAdjNode();\n        if (nodeIndex[w] == (-1)) {\n            findComponentForNode(w);\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n        } else if (nodeOnStack.get(w))\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n    } \n    buildComponent(v);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param excludeSingleNodeComponents\n * \t\tif set to true components that only contain a single node will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponents();\n}", "private ConnectedComponents findComponents() {\n    for (int node = 0; node < graph.getNodes(); ++node) {\n        if (nodeIndex[node] != (-1))\n            continue;\n\n        pushFindComponentForNode(node);\n        while (hasNext()) {\n            pop();\n            switch (dfsState) {\n                case BUILD_COMPONENT :\n                    buildComponent(v);\n                    break;\n                case UPDATE :\n                    nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n                    break;\n                case HANDLE_NEIGHBOR :\n                    {\n                        if ((nodeIndex[w] != (-1)) && nodeOnStack.get(w))\n                            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n                        if (nodeIndex[w] == (-1)) {\n                            // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                            pushUpdateLowLinks(v, w);\n                            pushFindComponentForNode(w);\n                        }\n                        break;\n                    }\n                case FIND_COMPONENT :\n                    {\n                        setupNextNode(v);\n                        // we push buildComponent first so it will run *after* we finished traversing the edges\n                        pushBuildComponent(v);\n                        EdgeIterator iter = explorer.setBaseNode(v);\n                        while (iter.next()) {\n                            pushHandleNeighbor(v, iter.getAdjNode());\n                        } \n                        break;\n                    }\n                default :\n                    throw new IllegalStateException(\"Unknown state: \" + dfsState);\n            }\n        } \n    }\n    return components;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.BaseGraphNodesAndEdges.sortEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.BaseGraphNodesAndEdges.sortEdges" ],
    "fullMethods" : [ "public void sortEdges(IntUnaryOperator getNewEdgeForOldEdge) {\n    BitSet visited = new BitSet(getEdges());\n    for (int edge = 0; edge < getEdges(); edge++) {\n        if (visited.get(edge))\n            continue;\n\n        int curr = edge;\n        long pointer = toEdgePointer(curr);\n        int nodeA = getNodeA(pointer);\n        int nodeB = getNodeB(pointer);\n        int linkA = getLinkA(pointer);\n        int linkB = getLinkB(pointer);\n        int dist = edges.getInt(pointer + E_DIST);\n        int kv = getKeyValuesRef(pointer);\n        IntsRef flags = createEdgeFlags();\n        readFlags(pointer, flags);\n        long geo = getGeoRef(pointer);\n        do {\n            visited.set(curr);\n            int newEdge = getNewEdgeForOldEdge.applyAsInt(curr);\n            long newPointer = toEdgePointer(newEdge);\n            int tmpNodeA = getNodeA(newPointer);\n            int tmpNodeB = getNodeB(newPointer);\n            int tmpLinkA = getLinkA(newPointer);\n            int tmpLinkB = getLinkB(newPointer);\n            int tmpDist = edges.getInt(newPointer + E_DIST);\n            int tmpKV = getKeyValuesRef(newPointer);\n            IntsRef tmpFlags = createEdgeFlags();\n            readFlags(newPointer, tmpFlags);\n            long tmpGeo = getGeoRef(newPointer);\n            setNodeA(newPointer, nodeA);\n            setNodeB(newPointer, nodeB);\n            setLinkA(newPointer, linkA == (-1) ? -1 : getNewEdgeForOldEdge.applyAsInt(linkA));\n            setLinkB(newPointer, linkB == (-1) ? -1 : getNewEdgeForOldEdge.applyAsInt(linkB));\n            edges.setInt(newPointer + E_DIST, dist);\n            setKeyValuesRef(newPointer, kv);\n            writeFlags(newPointer, flags);\n            setGeoRef(newPointer, geo);\n            nodeA = tmpNodeA;\n            nodeB = tmpNodeB;\n            linkA = tmpLinkA;\n            linkB = tmpLinkB;\n            dist = tmpDist;\n            kv = tmpKV;\n            flags = tmpFlags;\n            geo = tmpGeo;\n            curr = newEdge;\n        } while (curr != edge );\n    }\n    // update edge references\n    for (int node = 0; node < getNodes(); node++) {\n        long pointer = toNodePointer(node);\n        setEdgeRef(pointer, getNewEdgeForOldEdge.applyAsInt(getEdgeRef(pointer)));\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.BaseGraphNodesAndEdges.relabelNodes",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.BaseGraphNodesAndEdges.relabelNodes" ],
    "fullMethods" : [ "public void relabelNodes(IntUnaryOperator getNewNodeForOldNode) {\n    for (int edge = 0; edge < getEdges(); edge++) {\n        long pointer = toEdgePointer(edge);\n        setNodeA(pointer, getNewNodeForOldNode.applyAsInt(getNodeA(pointer)));\n        setNodeB(pointer, getNewNodeForOldNode.applyAsInt(getNodeB(pointer)));\n    }\n    BitSet visited = new BitSet(getNodes());\n    for (int node = 0; node < getNodes(); node++) {\n        if (visited.get(node))\n            continue;\n\n        int curr = node;\n        long pointer = toNodePointer(node);\n        int edgeRef = getEdgeRef(pointer);\n        double lat = getLat(pointer);\n        double lon = getLon(pointer);\n        double ele = (withElevation()) ? getEle(pointer) : Double.NaN;\n        int tc = (withTurnCosts()) ? getTurnCostRef(pointer) : -1;\n        do {\n            visited.set(curr);\n            int newNode = getNewNodeForOldNode.applyAsInt(curr);\n            long newPointer = toNodePointer(newNode);\n            int tmpEdgeRef = getEdgeRef(newPointer);\n            double tmpLat = getLat(newPointer);\n            double tmpLon = getLon(newPointer);\n            double tmpEle = (withElevation()) ? getEle(newPointer) : Double.NaN;\n            int tmpTC = (withTurnCosts()) ? getTurnCostRef(newPointer) : -1;\n            setEdgeRef(newPointer, edgeRef);\n            setLat(newPointer, lat);\n            setLon(newPointer, lon);\n            if (withElevation())\n                setEle(newPointer, ele);\n\n            if (withTurnCosts())\n                setTurnCostRef(newPointer, tc);\n\n            edgeRef = tmpEdgeRef;\n            lat = tmpLat;\n            lon = tmpLon;\n            ele = tmpEle;\n            tc = tmpTC;\n            curr = newNode;\n        } while (curr != node );\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.PrepareRoutingSubnetworks.doWork",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.PrepareRoutingSubnetworks.doWork" ],
    "fullMethods" : [ "/**\n * Finds and marks all subnetworks according to {@link #setMinNetworkSize(int)}\n *\n * @return the total number of marked edges\n */\npublic int doWork() {\n    if (minNetworkSize <= 0) {\n        logger.info(\"Skipping subnetwork search: prepare.min_network_size: \" + minNetworkSize);\n        return 0;\n    }\n    StopWatch sw = new StopWatch().start();\n    logger.info(((((((((((\"Start marking subnetworks, prepare.min_network_size: \" + minNetworkSize) + \", threads: \") + threads) + \", nodes: \") + Helper.nf(graph.getNodes())) + \", edges: \") + Helper.nf(graph.getEdges())) + \", jobs: \") + prepareJobs) + \", \") + Helper.getMemInfo());\n    AtomicInteger total = new AtomicInteger(0);\n    List<BitSet> flags = Stream.generate(() -> new BitSet(graph.getEdges())).limit(prepareJobs.size()).collect(Collectors.toList());\n    Stream<Runnable> runnables = IntStream.range(0, prepareJobs.size()).mapToObj(i -> () -> {\n        PrepareJob job = prepareJobs.get(i);\n        total.addAndGet(setSubnetworks(job.weighting, job.subnetworkEnc.getName().replaceAll(\"_subnetwork\", \"\"), flags.get(i)));\n    });\n    GHUtility.runConcurrently(runnables, threads);\n    AllEdgesIterator iter = graph.getAllEdges();\n    while (iter.next()) {\n        for (int i = 0; i < prepareJobs.size(); i++) {\n            PrepareJob prepareJob = prepareJobs.get(i);\n            iter.set(prepareJob.subnetworkEnc, flags.get(i).get(iter.getEdge()));\n        }\n    } \n    logger.info(((((\"Finished finding and marking subnetworks for \" + prepareJobs.size()) + \" jobs, took: \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n    return total.get();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve" ],
    "fullMethods" : [ "public static void sortGraphAlongHilbertCurve(BaseGraph graph) {\n    logger.info(\"sorting graph along Hilbert curve...\");\n    StopWatch sw = StopWatch.started();\n    NodeAccess na = graph.getNodeAccess();\n    final int order = 31;// using 15 would allow us to use ints for sortIndices, but this would result in (marginally) slower routing\n\n    LongArrayList sortIndices = new LongArrayList();\n    for (int node = 0; node < graph.getNodes(); node++)\n        sortIndices.add(latLonToHilbertIndex(na.getLat(node), na.getLon(node), order));\n\n    int[] nodeOrder = IndirectSort.mergesort(0, graph.getNodes(), (nodeA, nodeB) -> Long.compare(sortIndices.get(nodeA), sortIndices.get(nodeB)));\n    EdgeExplorer explorer = graph.createEdgeExplorer();\n    int edges = graph.getEdges();\n    IntArrayList edgeOrder = new IntArrayList();\n    BitSet edgesFound = new BitSet(edges);\n    for (int node : nodeOrder) {\n        EdgeIterator iter = explorer.setBaseNode(node);\n        while (iter.next()) {\n            if (!edgesFound.get(iter.getEdge())) {\n                edgeOrder.add(iter.getEdge());\n                edgesFound.set(iter.getEdge());\n            }\n        } \n    }\n    IntArrayList newEdgesByOldEdges = ArrayUtil.invert(edgeOrder);\n    IntArrayList newNodesByOldNodes = IntArrayList.from(ArrayUtil.invert(nodeOrder));\n    logger.info(\"calculating sort order took: \" + sw.stop().getTimeString());\n    sortGraphForGivenOrdering(graph, newNodesByOldNodes, newEdgesByOldEdges);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.isPermutation",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.isPermutation" ],
    "fullMethods" : [ "public static boolean isPermutation(IntArrayList arr) {\n    BitSet present = new BitSet(arr.size());\n    for (IntCursor e : arr) {\n        if ((e.value >= arr.size()) || (e.value < 0))\n            return false;\n\n        if (present.get(e.value))\n            return false;\n\n        present.set(e.value);\n    }\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LandmarkStorage.LandmarkExplorer.setSubnetworks",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.forEach",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.lm.LandmarkStorage.LandmarkExplorer.setSubnetworks" ],
    "fullMethods" : [ "public boolean setSubnetworks(final byte[] subnetworks, final int subnetworkId) {\n    if (subnetworkId > 127)\n        throw new IllegalStateException(\"Too many subnetworks \" + subnetworkId);\n\n    final AtomicBoolean failed = new AtomicBoolean(false);\n    IntObjectMap<SPTEntry> map = (reverse) ? bestWeightMapTo : bestWeightMapFrom;\n    map.forEach(new IntObjectPredicate<SPTEntry>() {\n        @Override\n        public boolean apply(int nodeId, SPTEntry value) {\n            int sn = subnetworks[nodeId];\n            if (sn != subnetworkId) {\n                if ((sn != UNSET_SUBNETWORK) && (sn != UNCLEAR_SUBNETWORK)) {\n                    // this is ugly but can happen in real world, see testWithOnewaySubnetworks\n                    LOGGER.error((((((((\"subnetworkId for node \" + nodeId) + \" (\") + createPoint(graph, nodeId)) + \") already set (\") + sn) + \"). \") + \"Cannot change to \") + subnetworkId);\n                    failed.set(true);\n                    return false;\n                }\n                subnetworks[nodeId] = ((byte) (subnetworkId));\n            }\n            return true;\n        }\n    });\n    return failed.get();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.AlternativeRoute.calcAlternatives",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.forEach",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.AlternativeRoute.calcAlternatives" ],
    "fullMethods" : [ "/**\n *\n * @return the information necessary to handle alternative paths. Note that the paths are\nnot yet extracted.\n */\npublic List<AlternativeInfo> calcAlternatives(final Path bestPath, final int maxPaths, double maxWeightFactor, final double weightInfluence, final double maxShareFactor, final double shareInfluence, final double minPlateauFactor, final double plateauInfluence) {\n    final double maxWeight = maxWeightFactor * bestWeight;\n    final GHIntObjectHashMap<IntSet> traversalIdMap = new GHIntObjectHashMap<>();\n    final AtomicInteger startTID = addToMap(traversalIdMap, bestPath);\n    // find all 'good' alternatives from forward-SPT matching the backward-SPT and optimize by\n    // small total weight (1), small share and big plateau (3a+b) and do these expensive calculations\n    // only for plateau start candidates (2)\n    final List<AlternativeInfo> alternatives = new ArrayList<>(maxPaths);\n    double bestPlateau = bestWeight;\n    double bestShare = 0;\n    double sortBy = calcSortBy(weightInfluence, bestWeight, shareInfluence, bestShare, plateauInfluence, bestPlateau);\n    final AlternativeInfo bestAlt = new AlternativeInfo(sortBy, bestPath, bestFwdEntry, bestBwdEntry, bestShare, getAltNames(graph, bestFwdEntry));\n    alternatives.add(bestAlt);\n    AtomicReference<SPTEntry> bestEntry = new AtomicReference<>();\n    bestWeightMapFrom.forEach(new IntObjectPredicate<SPTEntry>() {\n        @Override\n        public boolean apply(final int traversalId, final SPTEntry fromSPTEntry) {\n            SPTEntry toSPTEntry = bestWeightMapTo.get(traversalId);\n            if (toSPTEntry == null)\n                return true;\n\n            // Using the parent is required to avoid duplicate edge in Path.\n            // TODO we miss the turn cost weight (but at least we not duplicate the current edge weight)\n            if (traversalMode.isEdgeBased() && (toSPTEntry.parent != null))\n                toSPTEntry = toSPTEntry.parent;\n\n            // The alternative path is suboptimal if U-turn (after fromSPTEntry)\n            if (fromSPTEntry.edge == toSPTEntry.edge)\n                return true;\n\n            // (1) skip too long paths\n            final double weight = (fromSPTEntry.getWeightOfVisitedPath() + toSPTEntry.getWeightOfVisitedPath()) + weighting.calcTurnWeight(fromSPTEntry.edge, fromSPTEntry.adjNode, toSPTEntry.edge);\n            if (weight > maxWeight)\n                return true;\n\n            if (isBestPath(fromSPTEntry))\n                return true;\n\n            // For edge based traversal we need the next entry to find out the plateau start\n            SPTEntry tmpFromEntry = (traversalMode.isEdgeBased()) ? fromSPTEntry.parent : fromSPTEntry;\n            if ((tmpFromEntry == null) || (tmpFromEntry.parent == null)) {\n                // we can be here only if edge based and only if entry is not part of the best path\n                // e.g. when starting point has two edges and one is part of the best path the other edge is path of an alternative\n                assert traversalMode.isEdgeBased();\n            } else {\n                int nextToTraversalId = traversalMode.createTraversalId(graph.getEdgeIteratorState(tmpFromEntry.edge, tmpFromEntry.parent.adjNode), true);\n                SPTEntry correspondingToEntry = bestWeightMapTo.get(nextToTraversalId);\n                if (correspondingToEntry != null) {\n                    if (traversalMode.isEdgeBased())\n                        correspondingToEntry = correspondingToEntry.parent;\n\n                    if (correspondingToEntry.edge == fromSPTEntry.edge)\n                        return true;\n\n                }\n            }\n            // (3a) calculate plateau, we know we are at the beginning of the 'from'-side of\n            // the plateau A-B-C and go further to B\n            // where B is the next-'from' of A and B is also the previous-'to' of A.\n            // \n            // *<-A-B-C->*\n            // /    \\\n            // start    end\n            // \n            // extend plateau in only one direction necessary (A to B to ...) as we know\n            // that the from-SPTEntry is the start of the plateau or there is no plateau at all\n            // \n            double plateauWeight = 0;\n            SPTEntry prevToSPTEntry = toSPTEntry;\n            SPTEntry prevFrom = fromSPTEntry;\n            while (prevToSPTEntry.parent != null) {\n                int nextFromTraversalId = traversalMode.createTraversalId(graph.getEdgeIteratorState(prevToSPTEntry.edge, prevToSPTEntry.parent.adjNode), false);\n                SPTEntry otherFromEntry = bestWeightMapFrom.get(nextFromTraversalId);\n                // end of a plateau\n                if (((otherFromEntry == null) || (otherFromEntry.parent != prevFrom)) || (otherFromEntry.edge != prevToSPTEntry.edge))\n                    break;\n\n                prevFrom = otherFromEntry;\n                plateauWeight += prevToSPTEntry.getWeightOfVisitedPath() - prevToSPTEntry.parent.getWeightOfVisitedPath();\n                prevToSPTEntry = prevToSPTEntry.parent;\n            } \n            if ((plateauWeight <= 0) || ((plateauWeight / weight) < minPlateauFactor))\n                return true;\n\n            if (fromSPTEntry.parent == null)\n                throw new IllegalStateException(\"not implemented yet. in case of an edge based traversal the parent of fromSPTEntry could be null\");\n\n            // (3b) calculate share\n            SPTEntry fromEE = getFirstShareEE(fromSPTEntry.parent, true);\n            SPTEntry toEE = getFirstShareEE(toSPTEntry.parent, false);\n            double shareWeight = fromEE.getWeightOfVisitedPath() + toEE.getWeightOfVisitedPath();\n            boolean smallShare = (shareWeight / bestWeight) < maxShareFactor;\n            if (smallShare) {\n                List<String> altNames = getAltNames(graph, fromSPTEntry);\n                double sortBy = calcSortBy(weightInfluence, weight, shareInfluence, shareWeight, plateauInfluence, plateauWeight);\n                double worstSortBy = getWorstSortBy();\n                // plateaus.add(new PlateauInfo(altName, plateauEdges));\n                if ((sortBy < worstSortBy) || (alternatives.size() < maxPaths)) {\n                    Path path = DefaultBidirPathExtractor.extractPath(graph, weighting, fromSPTEntry, toSPTEntry, weight);\n                    // for now do not add alternatives to set, if we do we need to remove then on alternatives.clear too (see below)\n                    // AtomicInteger tid = addToMap(traversalIDMap, path);\n                    // int tid = traversalMode.createTraversalId(path.calcEdges().get(0), false);\n                    alternatives.add(new AlternativeInfo(sortBy, path, fromEE, toEE, shareWeight, altNames));\n                    Collections.sort(alternatives, ALT_COMPARATOR);\n                    if (alternatives.get(0) != bestAlt)\n                        throw new IllegalStateException(((\"best path should be always first entry \" + bestAlt.path.getWeight()) + \" vs \") + alternatives.get(0).path.getWeight());\n\n                    if (alternatives.size() > maxPaths)\n                        alternatives.subList(maxPaths, alternatives.size()).clear();\n\n                }\n            }\n            return true;\n        }\n\n        /**\n         * Extract path until we stumble over an existing traversal id\n         */\n        SPTEntry getFirstShareEE(SPTEntry startEE, boolean reverse) {\n            while (startEE.parent != null) {\n                // TODO we could make use of traversal ID directly if stored in SPTEntry\n                int tid = traversalMode.createTraversalId(graph.getEdgeIteratorState(startEE.edge, startEE.parent.adjNode), reverse);\n                if (isAlreadyExisting(tid))\n                    return startEE;\n\n                startEE = startEE.parent;\n            } \n            return startEE;\n        }\n\n        /**\n         * This method returns true if the specified tid is already existent in the\n         * traversalIDMap\n         */\n        boolean isAlreadyExisting(final int tid) {\n            final AtomicBoolean exists = new AtomicBoolean(false);\n            traversalIdMap.forEach(new IntObjectPredicate<IntSet>() {\n                @Override\n                public boolean apply(int key, IntSet set) {\n                    if (set.contains(tid)) {\n                        exists.set(true);\n                        return false;\n                    }\n                    return true;\n                }\n            });\n            return exists.get();\n        }\n\n        /**\n         * Return the current worst weight for all alternatives\n         */\n        double getWorstSortBy() {\n            if (alternatives.isEmpty())\n                throw new IllegalStateException(\"Empty alternative list cannot happen\");\n\n            return alternatives.get(alternatives.size() - 1).sortBy;\n        }\n\n        // returns true if fromSPTEntry is identical to the specified best path\n        boolean isBestPath(SPTEntry fromSPTEntry) {\n            if (traversalMode.isEdgeBased()) {\n                if (GHUtility.getEdgeFromEdgeKey(startTID.get()) == fromSPTEntry.edge) {\n                    if (fromSPTEntry.parent == null)\n                        throw new IllegalStateException(\"best path must have no parent but was non-null: \" + fromSPTEntry);\n\n                    if ((bestEntry.get() != null) && (bestEntry.get().edge != fromSPTEntry.edge))\n                        throw new IllegalStateException(((((\"there can be only one best entry but was \" + fromSPTEntry) + \" vs old: \") + bestEntry.get()) + \" \") + graph.getEdgeIteratorState(fromSPTEntry.edge, fromSPTEntry.adjNode).fetchWayGeometry(FetchMode.ALL));\n\n                    bestEntry.set(fromSPTEntry);\n                    return true;\n                }\n            } else if (fromSPTEntry.parent == null) {\n                if (startTID.get() != fromSPTEntry.adjNode)\n                    throw new IllegalStateException((((\"Start traversal ID has to be identical to root edge entry \" + \"which is the plateau start of the best path but was: \") + startTID) + \" vs. adjNode: \") + fromSPTEntry.adjNode);\n\n                if (bestEntry.get() != null)\n                    throw new IllegalStateException(((((\"there can be only one best entry but was \" + fromSPTEntry) + \" vs old: \") + bestEntry.get()) + \" \") + graph.getEdgeIteratorState(fromSPTEntry.edge, fromSPTEntry.adjNode).fetchWayGeometry(FetchMode.ALL));\n\n                bestEntry.set(fromSPTEntry);\n                return true;\n            }\n            return false;\n        }\n    });\n    return alternatives;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.minTo",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntIntScatterMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.minTo" ],
    "fullMethods" : [ "@Override\npublic void minTo(int key, int value) {\n    // todo: optimize with map.indexOf(key) etc\n    map.put(key, Math.min(map.getOrDefault(key, -1), value));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.set",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntIntScatterMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.set" ],
    "fullMethods" : [ "@Override\npublic void set(int key, int value) {\n    map.put(key, value);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.Polygon.<init>",
    "thirdPartyMethod" : "org.locationtech.jts.geom.GeometryFactory.<init>",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.Polygon.<init>", "com.graphhopper.util.shapes.Polygon.<clinit>" ],
    "fullMethods" : [ "public Polygon(double[] lats, double[] lons) {\n    if (lats.length != lons.length)\n        throw new IllegalArgumentException(((\"Points must be of equal length but was \" + lats.length) + \" vs. \") + lons.length);\n\n    if (lats.length == 0)\n        throw new IllegalArgumentException(\"Points must not be empty\");\n\n    Coordinate[] coordinates = new Coordinate[lats.length + 1];\n    for (int i = 0; i < lats.length; i++) {\n        coordinates[i] = new Coordinate(lons[i], lats[i]);\n    }\n    coordinates[lats.length] = coordinates[0];\n    this.prepPolygon = new PreparedPolygon(factory.createPolygon(new PackedCoordinateSequence.Double(coordinates, 2)));\n    this.rectangle = prepPolygon.getGeometry().isRectangle();\n    this.envelope = prepPolygon.getGeometry().getEnvelopeInternal();\n    this.bbox = BBox.fromEnvelope(envelope);\n}", "" ]
  }, {
    "entryPoint" : "com.graphhopper.util.GHUtility.createCircle",
    "thirdPartyMethod" : "org.locationtech.jts.geom.GeometryFactory.<init>",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.GHUtility.createCircle" ],
    "fullMethods" : [ "public static JsonFeature createCircle(String id, double centerLat, double centerLon, double radius) {\n    final int n = 36;\n    final double delta = 360.0 / n;\n    Coordinate[] coordinates = IntStream.range(0, n + 1).mapToObj(i -> DIST_EARTH.projectCoordinate(centerLat, centerLon, radius, (i * delta) % 360)).map(p -> new Coordinate(p.lon, p.lat)).toArray(Coordinate[]::new);\n    Polygon polygon = new GeometryFactory().createPolygon(coordinates);\n    JsonFeature result = new JsonFeature();\n    result.setId(id);\n    result.setGeometry(polygon);\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate",
    "thirdPartyMethod" : "org.locationtech.jts.geom.GeometryFactory.<init>",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate" ],
    "fullMethods" : [ "public Result triangulate(Snap snap, QueryGraph queryGraph, ShortestPathTree shortestPathTree, ToDoubleFunction<ShortestPathTree.IsoLabel> fz, double tolerance) {\n    final NodeAccess na = queryGraph.getNodeAccess();\n    Collection<Coordinate> sites = new ArrayList<>();\n    shortestPathTree.search(snap.getClosestNode(), label -> {\n        double exploreValue = fz.applyAsDouble(label);\n        double lat = na.getLat(label.node);\n        double lon = na.getLon(label.node);\n        Coordinate site = new Coordinate(lon, lat);\n        site.z = exploreValue;\n        sites.add(site);\n        // add a pillar node to increase precision a bit for longer roads\n        if (label.parent != null) {\n            EdgeIteratorState edge = queryGraph.getEdgeIteratorState(label.edge, label.node);\n            PointList innerPoints = edge.fetchWayGeometry(FetchMode.PILLAR_ONLY);\n            if (innerPoints.size() > 0) {\n                int midIndex = innerPoints.size() / 2;\n                // For edge-based routing we might have explored the same edge in two different directions.\n                // Here we make sure we only include the **same** point twice instead of two different ones.\n                if (((innerPoints.size() % 2) == 0) && edge.get(EdgeIteratorState.REVERSE_STATE))\n                    midIndex -= 1;\n\n                double lat2 = innerPoints.getLat(midIndex);\n                double lon2 = innerPoints.getLon(midIndex);\n                Coordinate site2 = new Coordinate(lon2, lat2);\n                site2.z = exploreValue;\n                sites.add(site2);\n            }\n        }\n    });\n    if (sites.size() > (routerConfig.getMaxVisitedNodes() / 3))\n        throw new IllegalArgumentException((\"Too many nodes would be included in post processing (\" + sites.size()) + \"). Let us know if you need this increased.\");\n\n    // Sites may contain repeated coordinates. Especially for edge-based traversal, that's expected -- we visit\n    // each node multiple times.\n    // But that's okay, the triangulator de-dupes by itself, and it keeps the first z-value it sees, which is\n    // what we want.\n    DelaunayTriangulationBuilder triangulationBuilder = new DelaunayTriangulationBuilder();\n    triangulationBuilder.setSites(sites);\n    triangulationBuilder.setTolerance(tolerance);\n    Geometry convexHull = triangulationBuilder.getEdges(new GeometryFactory()).convexHull();\n    // If there's only one site (and presumably also if the convex hull is otherwise degenerated),\n    // the triangulation only contains the frame, and not the site within the frame. Not sure if I agree with that.\n    // See ConformingDelaunayTriangulator, it does include a buffer for the frame, but that buffer is zero\n    // in these cases.\n    // It leads to the following follow-up defect:\n    // computeIsoline fails (returns an empty Multipolygon). This is clearly wrong, since\n    // the idea is that every real (non-frame) vertex has positive-length-edges around it that can be traversed\n    // to get a non-empty polygon.\n    // So we exclude this case for now (it is indeed only a corner-case).\n    if (!(convexHull instanceof Polygon)) {\n        throw new IllegalArgumentException(\"Too few points found. \" + \"Please try a different 'point' or a larger 'time_limit'.\");\n    }\n    QuadEdgeSubdivision tin = triangulationBuilder.getSubdivision();\n    for (Vertex vertex : ((Collection<Vertex>) (tin.getVertices(true)))) {\n        if (tin.isFrameVertex(vertex)) {\n            vertex.setZ(Double.MAX_VALUE);\n        }\n    }\n    ReadableTriangulation triangulation = ReadableTriangulation.wrap(tin);\n    return new Result(triangulation, triangulation.getEdges());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.Polygon.create",
    "thirdPartyMethod" : "org.locationtech.jts.geom.GeometryFactory.<init>",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.Polygon.create", "com.graphhopper.util.shapes.Polygon.<clinit>" ],
    "fullMethods" : [ "public static Polygon create(org.locationtech.jts.geom.Polygon polygon) {\n    return new Polygon(new PreparedPolygon(polygon));\n}", "" ]
  }, {
    "entryPoint" : "com.graphhopper.util.GHUtility.createRectangle",
    "thirdPartyMethod" : "org.locationtech.jts.geom.GeometryFactory.<init>",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.GHUtility.createRectangle" ],
    "fullMethods" : [ "public static JsonFeature createRectangle(String id, double minLat, double minLon, double maxLat, double maxLon) {\n    Coordinate[] coordinates = new Coordinate[]{ new Coordinate(minLon, minLat), new Coordinate(minLon, maxLat), new Coordinate(maxLon, maxLat), new Coordinate(maxLon, minLat), new Coordinate(minLon, minLat) };\n    Polygon polygon = new GeometryFactory().createPolygon(coordinates);\n    JsonFeature result = new JsonFeature();\n    result.setId(id);\n    result.setGeometry(polygon);\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.Polygon.contains",
    "thirdPartyMethod" : "org.locationtech.jts.geom.GeometryFactory.<init>",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.Polygon.contains", "com.graphhopper.util.shapes.Polygon.<clinit>" ],
    "fullMethods" : [ "/**\n * Does the point in polygon check.\n *\n * @param lat\n * \t\tLatitude of the point to be checked\n * @param lon\n * \t\tLongitude of the point to be checked\n * @return true if point is inside polygon\n */\npublic boolean contains(double lat, double lon) {\n    return prepPolygon.contains(factory.createPoint(new Coordinate(lon, lat)));\n}", "" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.AreaIndex.<init>",
    "thirdPartyMethod" : "org.locationtech.jts.geom.GeometryFactory.<init>",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.routing.util.AreaIndex.<init>" ],
    "fullMethods" : [ "public AreaIndex(List<T> areas) {\n    gf = new GeometryFactory();\n    index = new STRtree();\n    PreparedGeometryFactory pgf = new PreparedGeometryFactory();\n    for (T area : areas) {\n        for (Polygon border : area.getBorders()) {\n            IndexedCustomArea<T> indexedCustomArea = new IndexedCustomArea<>(area, pgf.create(border));\n            index.insert(border.getEnvelopeInternal(), indexedCustomArea);\n        }\n    }\n    index.build();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntSet.contains",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntScatterSet.contains",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntSet.contains" ],
    "fullMethods" : [ "@Override\npublic boolean contains(int key) {\n    return set.contains(key);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate",
    "thirdPartyMethod" : "org.locationtech.jts.triangulate.DelaunayTriangulationBuilder.getSubdivision",
    "thirdPartyPackage" : "org.locationtech.jts.triangulate",
    "path" : [ "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate" ],
    "fullMethods" : [ "public Result triangulate(Snap snap, QueryGraph queryGraph, ShortestPathTree shortestPathTree, ToDoubleFunction<ShortestPathTree.IsoLabel> fz, double tolerance) {\n    final NodeAccess na = queryGraph.getNodeAccess();\n    Collection<Coordinate> sites = new ArrayList<>();\n    shortestPathTree.search(snap.getClosestNode(), label -> {\n        double exploreValue = fz.applyAsDouble(label);\n        double lat = na.getLat(label.node);\n        double lon = na.getLon(label.node);\n        Coordinate site = new Coordinate(lon, lat);\n        site.z = exploreValue;\n        sites.add(site);\n        // add a pillar node to increase precision a bit for longer roads\n        if (label.parent != null) {\n            EdgeIteratorState edge = queryGraph.getEdgeIteratorState(label.edge, label.node);\n            PointList innerPoints = edge.fetchWayGeometry(FetchMode.PILLAR_ONLY);\n            if (innerPoints.size() > 0) {\n                int midIndex = innerPoints.size() / 2;\n                // For edge-based routing we might have explored the same edge in two different directions.\n                // Here we make sure we only include the **same** point twice instead of two different ones.\n                if (((innerPoints.size() % 2) == 0) && edge.get(EdgeIteratorState.REVERSE_STATE))\n                    midIndex -= 1;\n\n                double lat2 = innerPoints.getLat(midIndex);\n                double lon2 = innerPoints.getLon(midIndex);\n                Coordinate site2 = new Coordinate(lon2, lat2);\n                site2.z = exploreValue;\n                sites.add(site2);\n            }\n        }\n    });\n    if (sites.size() > (routerConfig.getMaxVisitedNodes() / 3))\n        throw new IllegalArgumentException((\"Too many nodes would be included in post processing (\" + sites.size()) + \"). Let us know if you need this increased.\");\n\n    // Sites may contain repeated coordinates. Especially for edge-based traversal, that's expected -- we visit\n    // each node multiple times.\n    // But that's okay, the triangulator de-dupes by itself, and it keeps the first z-value it sees, which is\n    // what we want.\n    DelaunayTriangulationBuilder triangulationBuilder = new DelaunayTriangulationBuilder();\n    triangulationBuilder.setSites(sites);\n    triangulationBuilder.setTolerance(tolerance);\n    Geometry convexHull = triangulationBuilder.getEdges(new GeometryFactory()).convexHull();\n    // If there's only one site (and presumably also if the convex hull is otherwise degenerated),\n    // the triangulation only contains the frame, and not the site within the frame. Not sure if I agree with that.\n    // See ConformingDelaunayTriangulator, it does include a buffer for the frame, but that buffer is zero\n    // in these cases.\n    // It leads to the following follow-up defect:\n    // computeIsoline fails (returns an empty Multipolygon). This is clearly wrong, since\n    // the idea is that every real (non-frame) vertex has positive-length-edges around it that can be traversed\n    // to get a non-empty polygon.\n    // So we exclude this case for now (it is indeed only a corner-case).\n    if (!(convexHull instanceof Polygon)) {\n        throw new IllegalArgumentException(\"Too few points found. \" + \"Please try a different 'point' or a larger 'time_limit'.\");\n    }\n    QuadEdgeSubdivision tin = triangulationBuilder.getSubdivision();\n    for (Vertex vertex : ((Collection<Vertex>) (tin.getVertices(true)))) {\n        if (tin.isFrameVertex(vertex)) {\n            vertex.setZ(Double.MAX_VALUE);\n        }\n    }\n    ReadableTriangulation triangulation = ReadableTriangulation.wrap(tin);\n    return new Result(triangulation, triangulation.getEdges());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate",
    "thirdPartyMethod" : "org.locationtech.jts.triangulate.DelaunayTriangulationBuilder.<init>",
    "thirdPartyPackage" : "org.locationtech.jts.triangulate",
    "path" : [ "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate" ],
    "fullMethods" : [ "public Result triangulate(Snap snap, QueryGraph queryGraph, ShortestPathTree shortestPathTree, ToDoubleFunction<ShortestPathTree.IsoLabel> fz, double tolerance) {\n    final NodeAccess na = queryGraph.getNodeAccess();\n    Collection<Coordinate> sites = new ArrayList<>();\n    shortestPathTree.search(snap.getClosestNode(), label -> {\n        double exploreValue = fz.applyAsDouble(label);\n        double lat = na.getLat(label.node);\n        double lon = na.getLon(label.node);\n        Coordinate site = new Coordinate(lon, lat);\n        site.z = exploreValue;\n        sites.add(site);\n        // add a pillar node to increase precision a bit for longer roads\n        if (label.parent != null) {\n            EdgeIteratorState edge = queryGraph.getEdgeIteratorState(label.edge, label.node);\n            PointList innerPoints = edge.fetchWayGeometry(FetchMode.PILLAR_ONLY);\n            if (innerPoints.size() > 0) {\n                int midIndex = innerPoints.size() / 2;\n                // For edge-based routing we might have explored the same edge in two different directions.\n                // Here we make sure we only include the **same** point twice instead of two different ones.\n                if (((innerPoints.size() % 2) == 0) && edge.get(EdgeIteratorState.REVERSE_STATE))\n                    midIndex -= 1;\n\n                double lat2 = innerPoints.getLat(midIndex);\n                double lon2 = innerPoints.getLon(midIndex);\n                Coordinate site2 = new Coordinate(lon2, lat2);\n                site2.z = exploreValue;\n                sites.add(site2);\n            }\n        }\n    });\n    if (sites.size() > (routerConfig.getMaxVisitedNodes() / 3))\n        throw new IllegalArgumentException((\"Too many nodes would be included in post processing (\" + sites.size()) + \"). Let us know if you need this increased.\");\n\n    // Sites may contain repeated coordinates. Especially for edge-based traversal, that's expected -- we visit\n    // each node multiple times.\n    // But that's okay, the triangulator de-dupes by itself, and it keeps the first z-value it sees, which is\n    // what we want.\n    DelaunayTriangulationBuilder triangulationBuilder = new DelaunayTriangulationBuilder();\n    triangulationBuilder.setSites(sites);\n    triangulationBuilder.setTolerance(tolerance);\n    Geometry convexHull = triangulationBuilder.getEdges(new GeometryFactory()).convexHull();\n    // If there's only one site (and presumably also if the convex hull is otherwise degenerated),\n    // the triangulation only contains the frame, and not the site within the frame. Not sure if I agree with that.\n    // See ConformingDelaunayTriangulator, it does include a buffer for the frame, but that buffer is zero\n    // in these cases.\n    // It leads to the following follow-up defect:\n    // computeIsoline fails (returns an empty Multipolygon). This is clearly wrong, since\n    // the idea is that every real (non-frame) vertex has positive-length-edges around it that can be traversed\n    // to get a non-empty polygon.\n    // So we exclude this case for now (it is indeed only a corner-case).\n    if (!(convexHull instanceof Polygon)) {\n        throw new IllegalArgumentException(\"Too few points found. \" + \"Please try a different 'point' or a larger 'time_limit'.\");\n    }\n    QuadEdgeSubdivision tin = triangulationBuilder.getSubdivision();\n    for (Vertex vertex : ((Collection<Vertex>) (tin.getVertices(true)))) {\n        if (tin.isFrameVertex(vertex)) {\n            vertex.setZ(Double.MAX_VALUE);\n        }\n    }\n    ReadableTriangulation triangulation = ReadableTriangulation.wrap(tin);\n    return new Result(triangulation, triangulation.getEdges());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntObjectHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntObjectHashMap.<init>" ],
    "fullMethods" : [ "public GHIntObjectHashMap() {\n    super(10, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntObjectHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntObjectHashMap.<init>" ],
    "fullMethods" : [ "public GHIntObjectHashMap(int capacity) {\n    super(capacity, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntObjectHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntObjectHashMap.<init>" ],
    "fullMethods" : [ "public GHIntObjectHashMap(int capacity, double loadFactor) {\n    super(capacity, loadFactor, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.BridgePathFinder.find",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.BridgePathFinder.find" ],
    "fullMethods" : [ "/**\n * Finds all bridge paths starting at a given node and starting edge key.\n *\n * @return a mapping between the target edge keys we can reach via bridge paths and information about the\ncorresponding bridge path\n */\npublic IntObjectMap<BridePathEntry> find(int startInEdgeKey, int startNode, int centerNode) {\n    queue.clear();\n    map.clear();\n    IntObjectMap<BridePathEntry> result = new IntObjectHashMap<>(16, 0.5, HashOrderMixing.constant(123));\n    PrepareCHEntry startEntry = new PrepareCHEntry(NO_EDGE, startInEdgeKey, startInEdgeKey, startNode, 0, 0);\n    map.put(startInEdgeKey, startEntry);\n    queue.add(startEntry);\n    while (!queue.isEmpty()) {\n        PrepareCHEntry currEntry = queue.poll();\n        PrepareGraphEdgeIterator iter = outExplorer.setBaseNode(currEntry.adjNode);\n        while (iter.next()) {\n            if (iter.getAdjNode() == centerNode) {\n                // We arrived at the center node, so we keep expanding the search\n                double weight = (currEntry.weight + graph.getTurnWeight(currEntry.incEdgeKey, currEntry.adjNode, iter.getOrigEdgeKeyFirst())) + iter.getWeight();\n                if (Double.isInfinite(weight))\n                    continue;\n\n                PrepareCHEntry entry = map.get(iter.getOrigEdgeKeyLast());\n                if (entry == null) {\n                    entry = new PrepareCHEntry(iter.getPrepareEdge(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getAdjNode(), weight, currEntry.origEdges + iter.getOrigEdgeCount());\n                    entry.parent = currEntry;\n                    map.put(iter.getOrigEdgeKeyLast(), entry);\n                    queue.add(entry);\n                } else if (weight < entry.weight) {\n                    queue.remove(entry);\n                    entry.prepareEdge = iter.getPrepareEdge();\n                    entry.origEdges = currEntry.origEdges + iter.getOrigEdgeCount();\n                    entry.firstEdgeKey = iter.getOrigEdgeKeyFirst();\n                    entry.weight = weight;\n                    entry.parent = currEntry;\n                    queue.add(entry);\n                }\n            } else if (currEntry.adjNode == centerNode) {\n                // We just left the center node, so we arrived at some neighbor node. Every edge we can reach from\n                // there is a target edge, so we add a bridge path entry for it. We do not continue the search from the\n                // neighbor node anymore\n                double weight = (currEntry.weight + graph.getTurnWeight(currEntry.incEdgeKey, currEntry.adjNode, iter.getOrigEdgeKeyFirst())) + iter.getWeight();\n                if (Double.isInfinite(weight))\n                    continue;\n\n                PrepareGraphOrigEdgeIterator origOutIter = origOutExplorer.setBaseNode(iter.getAdjNode());\n                while (origOutIter.next()) {\n                    double totalWeight = weight + graph.getTurnWeight(iter.getOrigEdgeKeyLast(), iter.getAdjNode(), origOutIter.getOrigEdgeKeyFirst());\n                    if (Double.isInfinite(totalWeight))\n                        continue;\n\n                    BridePathEntry resEntry = result.get(origOutIter.getOrigEdgeKeyFirst());\n                    if (resEntry == null) {\n                        PrepareCHEntry chEntry = new PrepareCHEntry(iter.getPrepareEdge(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getAdjNode(), weight, currEntry.origEdges + iter.getOrigEdgeCount());\n                        chEntry.parent = currEntry;\n                        resEntry = new BridePathEntry(totalWeight, chEntry);\n                        result.put(origOutIter.getOrigEdgeKeyFirst(), resEntry);\n                    } else if (totalWeight < resEntry.weight) {\n                        resEntry.weight = totalWeight;\n                        resEntry.chEntry.prepareEdge = iter.getPrepareEdge();\n                        resEntry.chEntry.firstEdgeKey = iter.getOrigEdgeKeyFirst();\n                        resEntry.chEntry.origEdges = currEntry.origEdges + iter.getOrigEdgeCount();\n                        resEntry.chEntry.incEdgeKey = iter.getOrigEdgeKeyLast();\n                        resEntry.chEntry.weight = weight;\n                        resEntry.chEntry.parent = currEntry;\n                    }\n                } \n            }\n            // We arrived at some node that is not the center node. We do not expand the search as we are only\n            // concerned with finding bridge paths.\n        } \n    } \n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntObjectHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntObjectHashMap.<init>" ],
    "fullMethods" : [ "public GHIntObjectHashMap(int capacity, double loadFactor, HashOrderMixingStrategy hashOrderMixer) {\n    super(capacity, loadFactor, hashOrderMixer);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.<init>", "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.buildVirtualEdgesAtRealNodes" ],
    "fullMethods" : [ "public QueryRoutingCHGraph(RoutingCHGraph routingCHGraph, QueryGraph queryGraph) {\n    this.routingCHGraph = routingCHGraph;\n    this.weighting = routingCHGraph.getWeighting();\n    this.queryOverlay = queryGraph.getQueryOverlay();\n    this.queryGraph = queryGraph;\n    this.queryGraphWeighting = queryGraph.wrapWeighting(weighting);\n    virtualOutEdgesAtRealNodes = buildVirtualEdgesAtRealNodes(routingCHGraph.createOutEdgeExplorer());\n    virtualInEdgesAtRealNodes = buildVirtualEdgesAtRealNodes(routingCHGraph.createInEdgeExplorer());\n    virtualEdgesAtVirtualNodes = buildVirtualEdgesAtVirtualNodes();\n    nodes = queryGraph.getNodes();\n}", "private IntObjectMap<List<RoutingCHEdgeIteratorState>> buildVirtualEdgesAtRealNodes(final RoutingCHEdgeExplorer explorer) {\n    final IntObjectMap<List<RoutingCHEdgeIteratorState>> virtualEdgesAtRealNodes = new IntObjectHashMap<>(queryOverlay.getEdgeChangesAtRealNodes().size());\n    queryOverlay.getEdgeChangesAtRealNodes().forEach(new IntObjectProcedure<QueryOverlay.EdgeChanges>() {\n        @Override\n        public void apply(int node, QueryOverlay.EdgeChanges edgeChanges) {\n            List<RoutingCHEdgeIteratorState> virtualEdges = new ArrayList<>();\n            for (EdgeIteratorState v : edgeChanges.getAdditionalEdges()) {\n                assert v.getBaseNode() == node;\n                int edge = v.getEdge();\n                if (queryGraph.isVirtualEdge(edge)) {\n                    edge = shiftVirtualEdgeIDForCH(edge);\n                }\n                virtualEdges.add(buildVirtualCHEdgeState(v, edge));\n            }\n            RoutingCHEdgeIterator iter = explorer.setBaseNode(node);\n            while (iter.next()) {\n                // shortcuts cannot be in the removed edge set because this was determined on the (base) query graph\n                if (iter.isShortcut()) {\n                    virtualEdges.add(new VirtualCHEdgeIteratorState(iter.getEdge(), NO_EDGE, iter.getBaseNode(), iter.getAdjNode(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getSkippedEdge1(), iter.getSkippedEdge2(), iter.getWeight(false), iter.getWeight(true)));\n                } else if (!edgeChanges.getRemovedEdges().contains(iter.getOrigEdge())) {\n                    virtualEdges.add(new VirtualCHEdgeIteratorState(iter.getEdge(), iter.getOrigEdge(), iter.getBaseNode(), iter.getAdjNode(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), NO_EDGE, NO_EDGE, iter.getWeight(false), iter.getWeight(true)));\n                }\n            } \n            virtualEdgesAtRealNodes.put(node, virtualEdges);\n        }\n    });\n    return virtualEdgesAtRealNodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.index.LineIntIndex.query",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.index.LineIntIndex.query" ],
    "fullMethods" : [ "public void query(LocationIndex.TileFilter tileFilter, final LocationIndex.Visitor function) {\n    final IntHashSet set = new IntHashSet();\n    query(START_POINTER, tileFilter, bounds.minLat, bounds.minLon, bounds.maxLat - bounds.minLat, bounds.maxLon - bounds.minLon, new LocationIndex.Visitor() {\n        @Override\n        public boolean isTileInfo() {\n            return function.isTileInfo();\n        }\n\n        @Override\n        public void onTile(BBox bbox, int width) {\n            function.onTile(bbox, width);\n        }\n\n        @Override\n        public void onEdge(int edgeId) {\n            if (set.add(edgeId))\n                function.onEdge(edgeId);\n\n        }\n    }, 0);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.index.LocationIndexTree.findClosest",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.index.LocationIndexTree.findClosest" ],
    "fullMethods" : [ "@Override\npublic Snap findClosest(final double queryLat, final double queryLon, final EdgeFilter edgeFilter) {\n    if (isClosed())\n        throw new IllegalStateException(\"You need to create a new LocationIndex instance as it is already closed\");\n\n    final Snap closestMatch = new Snap(queryLat, queryLon);\n    IntHashSet seenEdges = new IntHashSet();\n    for (int iteration = 0; iteration < maxRegionSearch; iteration++) {\n        lineIntIndex.findEdgeIdsInNeighborhood(queryLat, queryLon, iteration, edgeId -> {\n            EdgeIteratorState edgeIteratorState = graph.getEdgeIteratorStateForKey(edgeId * 2);\n            if (seenEdges.add(edgeId) && edgeFilter.accept(edgeIteratorState)) {\n                // TODO: or reverse?\n                traverseEdge(queryLat, queryLon, edgeIteratorState, (node, normedDist, wayIndex, pos) -> {\n                    if (normedDist < closestMatch.getQueryDistance()) {\n                        closestMatch.setQueryDistance(normedDist);\n                        closestMatch.setClosestNode(node);\n                        closestMatch.setClosestEdge(edgeIteratorState.detach(false));\n                        closestMatch.setWayIndex(wayIndex);\n                        closestMatch.setSnappedPosition(pos);\n                    }\n                });\n            }\n        });\n        if (closestMatch.isValid()) {\n            // Check if we can stop...\n            double rMin = calculateRMin(queryLat, queryLon, iteration);\n            double minDistance = DIST_PLANE.calcDenormalizedDist(closestMatch.getQueryDistance());\n            if (minDistance < rMin) {\n                break;// We can (approximately?) guarantee that no closer edges are anywhere else\n\n            }\n        }\n    }\n    if (closestMatch.isValid()) {\n        closestMatch.calcSnappedPoint(DIST_PLANE);\n        closestMatch.setQueryDistance(DIST_PLANE.calcDist(closestMatch.getSnappedPoint().lat, closestMatch.getSnappedPoint().lon, queryLat, queryLon));\n    }\n    return closestMatch;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LandmarkStorage.createLandmarks",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.lm.LandmarkStorage.createLandmarks" ],
    "fullMethods" : [ "/**\n * This method calculates the landmarks and initial weightings to &amp; from them.\n */\npublic void createLandmarks() {\n    if (isInitialized())\n        throw new IllegalStateException(\"Initialize the landmark storage only once!\");\n\n    // fill 'from' and 'to' weights with maximum value\n    long maxBytes = ((long) (graph.getNodes())) * LM_ROW_LENGTH;\n    this.landmarkWeightDA.create(2000);\n    this.landmarkWeightDA.ensureCapacity(maxBytes);\n    for (long pointer = 0; pointer < maxBytes; pointer += 2) {\n        landmarkWeightDA.setShort(pointer, ((short) (SHORT_INFINITY)));\n    }\n    int[] empty = new int[landmarks];\n    Arrays.fill(empty, UNSET_SUBNETWORK);\n    landmarkIDs.add(empty);\n    byte[] subnetworks = new byte[graph.getNodes()];\n    Arrays.fill(subnetworks, ((byte) (UNSET_SUBNETWORK)));\n    String snKey = Subnetwork.key(lmConfig.getName());\n    // TODO We could use EdgeBasedTarjanSCC instead of node-based TarjanSCC here to get the small networks directly,\n    // instead of using the subnetworkEnc from PrepareRoutingSubnetworks.\n    if (!encodedValueLookup.hasEncodedValue(snKey))\n        throw new IllegalArgumentException(((\"EncodedValue '\" + snKey) + \"' does not exist. For Landmarks this is \") + \"currently required (also used in PrepareRoutingSubnetworks). See #2256\");\n\n    // Exclude edges that we previously marked in PrepareRoutingSubnetworks to avoid problems like \"connection not found\".\n    final BooleanEncodedValue edgeInSubnetworkEnc = encodedValueLookup.getBooleanEncodedValue(snKey);\n    final IntHashSet blockedEdges;\n    // We use the areaIndex to split certain areas from each other but do not permanently change the base graph\n    // so that other algorithms still can route through these regions. This is done to increase the density of\n    // landmarks for an area like Europe+Asia, which improves the query speed.\n    if (areaIndex != null) {\n        StopWatch sw = new StopWatch().start();\n        blockedEdges = findBorderEdgeIds(areaIndex);\n        if (logDetails)\n            LOGGER.info(((((\"Made \" + blockedEdges.size()) + \" edges inaccessible. Calculated country cut in \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n\n    } else {\n        blockedEdges = new IntHashSet();\n    }\n    EdgeFilter accessFilter = edge -> (!edge.get(edgeInSubnetworkEnc)) && (!blockedEdges.contains(edge.getEdge()));\n    EdgeFilter tarjanFilter = edge -> accessFilter.accept(edge) && Double.isFinite(weighting.calcEdgeWeight(edge, false));\n    StopWatch sw = new StopWatch().start();\n    ConnectedComponents graphComponents = TarjanSCC.findComponents(graph, tarjanFilter, true);\n    if (logDetails)\n        LOGGER.info(((((\"Calculated \" + graphComponents.getComponents().size()) + \" subnetworks via tarjan in \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n\n    String additionalInfo = \"\";\n    // guess the factor\n    if (factor <= 0) {\n        // A 'factor' is necessary to store the weight in just a short value but without losing too much precision.\n        // This factor is rather delicate to pick, we estimate it from an exploration with some \"test landmarks\",\n        // see estimateMaxWeight. If we pick the distance too big for small areas this could lead to (slightly)\n        // suboptimal routes as there will be too big rounding errors. But picking it too small is bad for performance\n        // e.g. for Germany at least 1500km is very important otherwise speed is at least twice as slow e.g. for 1000km\n        double maxWeight = estimateMaxWeight(graphComponents.getComponents(), accessFilter);\n        setMaximumWeight(maxWeight);\n        additionalInfo = (\", maxWeight:\" + maxWeight) + \" from quick estimation\";\n    }\n    if (logDetails)\n        LOGGER.info((((\"init landmarks for subnetworks with node count greater than \" + minimumNodes) + \" with factor:\") + factor) + additionalInfo);\n\n    int nodes = 0;\n    for (IntArrayList subnetworkIds : graphComponents.getComponents()) {\n        nodes += subnetworkIds.size();\n        if (subnetworkIds.size() < minimumNodes)\n            continue;\n\n        if (factor <= 0)\n            throw new IllegalStateException(((((((\"factor wasn't initialized \" + factor) + \", subnetworks:\") + graphComponents.getComponents().size()) + \", minimumNodes:\") + minimumNodes) + \", current size:\") + subnetworkIds.size());\n\n        int index = subnetworkIds.size() - 1;\n        // ensure start node is reachable from both sides and no subnetwork is associated\n        for (; index >= 0; index--) {\n            int nextStartNode = subnetworkIds.get(index);\n            if (subnetworks[nextStartNode] == UNSET_SUBNETWORK) {\n                if (logDetails) {\n                    GHPoint p = createPoint(graph, nextStartNode);\n                    LOGGER.info((((((((((\"start node: \" + nextStartNode) + \" (\") + p) + \") subnetwork \") + index) + \", subnetwork size: \") + subnetworkIds.size()) + \", \") + Helper.getMemInfo()) + (areaIndex == null ? \"\" : \" area:\" + areaIndex.query(p.lat, p.lon)));\n                }\n                if (createLandmarksForSubnetwork(nextStartNode, subnetworks, accessFilter))\n                    break;\n\n            }\n        }\n        if (index < 0)\n            LOGGER.warn(((((\"next start node not found in big enough network of size \" + subnetworkIds.size()) + \", first element is \") + subnetworkIds.get(0)) + \", \") + createPoint(graph, subnetworkIds.get(0)));\n\n    }\n    int subnetworkCount = landmarkIDs.size();\n    // store all landmark node IDs and one int for the factor itself.\n    this.landmarkWeightDA.ensureCapacity((maxBytes/* landmark weights */\n     + (((long) (subnetworkCount)) * landmarks))/* landmark mapping per subnetwork */\n     + 4);\n    // calculate offset to point into landmark mapping\n    long bytePos = maxBytes;\n    for (int[] landmarks : landmarkIDs) {\n        for (int lmNodeId : landmarks) {\n            landmarkWeightDA.setInt(bytePos, lmNodeId);\n            bytePos += 4L;\n        }\n    }\n    landmarkWeightDA.setHeader(0 * 4, graph.getNodes());\n    landmarkWeightDA.setHeader(1 * 4, this.landmarks);\n    landmarkWeightDA.setHeader(2 * 4, subnetworkCount);\n    if ((factor * DOUBLE_MLTPL) > Integer.MAX_VALUE)\n        throw new UnsupportedOperationException(\"landmark weight factor cannot be bigger than Integer.MAX_VALUE \" + (factor * DOUBLE_MLTPL));\n\n    landmarkWeightDA.setHeader(3 * 4, ((int) (Math.round(factor * DOUBLE_MLTPL))));\n    // serialize fast byte[] into DataAccess\n    subnetworkStorage.create(graph.getNodes());\n    for (int nodeId = 0; nodeId < subnetworks.length; nodeId++) {\n        subnetworkStorage.setSubnetwork(nodeId, subnetworks[nodeId]);\n    }\n    if (logDetails)\n        LOGGER.info(((\"Finished landmark creation. Subnetwork node count sum \" + nodes) + \" vs. nodes \") + graph.getNodes());\n\n    initialized = true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.RoundTripRouting.calcPaths",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.RoundTripRouting.calcPaths", "com.graphhopper.routing.RoundTripRouting.RoundTripCalculator.<init>" ],
    "fullMethods" : [ "public static Result calcPaths(List<Snap> snaps, FlexiblePathCalculator pathCalculator) {\n    RoundTripCalculator roundTripCalculator = new RoundTripCalculator(pathCalculator);\n    Result result = new Result(snaps.size() - 1);\n    Snap start = snaps.get(0);\n    for (int snapIndex = 1; snapIndex < snaps.size(); snapIndex++) {\n        // instead getClosestNode (which might be a virtual one and introducing unnecessary tails of the route)\n        // use next tower node -> getBaseNode or getAdjNode\n        // Later: remove potential route tail, maybe we can just enforce the heading at the start and when coming\n        // back, and for tower nodes it does not matter anyway\n        Snap startSnap = snaps.get(snapIndex - 1);\n        int startNode = (startSnap == start) ? startSnap.getClosestNode() : startSnap.getClosestEdge().getBaseNode();\n        Snap endSnap = snaps.get(snapIndex);\n        int endNode = (endSnap == start) ? endSnap.getClosestNode() : endSnap.getClosestEdge().getBaseNode();\n        Path path = roundTripCalculator.calcPath(startNode, endNode);\n        if (snapIndex == 1) {\n            result.wayPoints = new PointList(snaps.size(), path.graph.getNodeAccess().is3D());\n            result.wayPoints.add(path.graph.getNodeAccess(), startNode);\n        }\n        result.wayPoints.add(path.graph.getNodeAccess(), endNode);\n        result.visitedNodes += pathCalculator.getVisitedNodes();\n        result.paths.add(path);\n    }\n    return result;\n}", "RoundTripCalculator(FlexiblePathCalculator pathCalculator) {\n    this.pathCalculator = pathCalculator;\n    // we make the path calculator use our avoid edges weighting\n    AvoidEdgesWeighting avoidPreviousPathsWeighting = new AvoidEdgesWeighting(pathCalculator.getWeighting()).setEdgePenaltyFactor(5);\n    avoidPreviousPathsWeighting.setAvoidedEdges(previousEdges);\n    pathCalculator.setWeighting(avoidPreviousPathsWeighting);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.ShortestPathTree.getIsochroneEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.ObjectCollection.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.isochrone.algorithm.ShortestPathTree.getIsochroneEdges" ],
    "fullMethods" : [ "public ArrayList<IsoLabel> getIsochroneEdges(double z) {\n    ArrayList<IsoLabel> result = new ArrayList<>();\n    for (ObjectCursor<IsoLabel> cursor : fromMap.values()) {\n        if ((cursor.value.parent != null) && ((getExploreValue(cursor.value) > z) ^ (getExploreValue(cursor.value.parent) > z))) {\n            result.add(cursor.value);\n        }\n    }\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.dem.AbstractTiffElevationProvider.getEle",
    "thirdPartyMethod" : "org.apache.xmlgraphics.image.codec.tiff.TIFFImageDecoder.decodeAsRaster",
    "thirdPartyPackage" : "org.apache.xmlgraphics.image.codec.tiff",
    "path" : [ "com.graphhopper.reader.dem.AbstractTiffElevationProvider.getEle", "com.graphhopper.reader.dem.GMTEDProvider.readFile" ],
    "fullMethods" : [ "@Override\npublic double getEle(double lat, double lon) {\n    // Return fast, if there is no data available\n    if (isOutsideSupportedArea(lat, lon))\n        return 0;\n\n    lat = ((int) (lat * precision)) / precision;\n    lon = ((int) (lon * precision)) / precision;\n    String name = getFileName(lat, lon);\n    HeightTile demProvider = cacheData.get(name);\n    if (demProvider == null) {\n        if (!cacheDir.exists())\n            cacheDir.mkdirs();\n\n        int minLat = getMinLatForTile(lat);\n        int minLon = getMinLonForTile(lon);\n        // less restrictive against boundary checking\n        demProvider = new HeightTile(minLat, minLon, WIDTH, HEIGHT, LON_DEGREE * precision, LON_DEGREE, LAT_DEGREE);\n        demProvider.setInterpolate(interpolate);\n        cacheData.put(name, demProvider);\n        DataAccess heights = getDirectory().create(name + \".gh\");\n        demProvider.setHeights(heights);\n        boolean loadExisting = false;\n        try {\n            loadExisting = heights.loadExisting();\n        } catch (Exception ex) {\n            logger.warn(((\"cannot load \" + name) + \", error: \") + ex.getMessage());\n        }\n        if (!loadExisting) {\n            File zipFile = new File(cacheDir, new File(getFileNameOfLocalFile(lat, lon)).getName());\n            if (!zipFile.exists())\n                try {\n                    String zippedURL = getDownloadURL(lat, lon);\n                    downloadToFile(zipFile, zippedURL);\n                } catch (SSLException ex) {\n                    throw new IllegalStateException(\"SSL problem with elevation provider \" + getClass().getSimpleName(), ex);\n                } catch (IOException ex) {\n                    demProvider.setSeaLevel(true);\n                    // use small size on disc and in-memory\n                    heights.create(10).flush();\n                    return 0;\n                }\n\n            // short == 2 bytes\n            heights.create((2L * WIDTH) * HEIGHT);\n            Raster raster = readFile(zipFile, name + \".tif\");\n            fillDataAccessWithElevationData(raster, heights, WIDTH);\n        }// loadExisting\n\n    }\n    if (demProvider.isSeaLevel())\n        return 0;\n\n    return demProvider.getHeight(lat, lon);\n}", "@Override\nRaster readFile(File file, String tifName) {\n    SeekableStream ss = null;\n    try {\n        InputStream is = new FileInputStream(file);\n        ss = SeekableStream.wrapInputStream(is, true);\n        TIFFImageDecoder imageDecoder = new TIFFImageDecoder(ss, new TIFFDecodeParam());\n        return imageDecoder.decodeAsRaster();\n    } catch (Exception e) {\n        throw new RuntimeException(\"Can't decode \" + file.getName(), e);\n    } finally {\n        if (ss != null)\n            close(ss);\n\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentForNode", "com.graphhopper.routing.subnetwork.TarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponentsRecursive();\n}", "private ConnectedComponents findComponentsRecursive() {\n    for (int node = 0; node < graph.getNodes(); node++) {\n        if (nodeIndex[node] == (-1)) {\n            findComponentForNode(node);\n        }\n    }\n    return components;\n}", "private void findComponentForNode(int v) {\n    setupNextNode(v);\n    // we have to create a new explorer on each iteration because of the nested edge iterations\n    EdgeExplorer explorer = graph.createEdgeExplorer(edgeFilter);\n    EdgeIterator iter = explorer.setBaseNode(v);\n    while (iter.next()) {\n        int w = iter.getAdjNode();\n        if (nodeIndex[w] == (-1)) {\n            findComponentForNode(w);\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n        } else if (nodeOnStack.get(w))\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n    } \n    buildComponent(v);\n}", "private void buildComponent(int v) {\n    if (nodeLowLink[v] == nodeIndex[v]) {\n        if (tarjanStack.getLast() == v) {\n            tarjanStack.removeLast();\n            nodeOnStack.clear(v);\n            components.numComponents++;\n            components.numNodes++;\n            if (!excludeSingleNodeComponents)\n                components.singleNodeComponents.set(v);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int w = tarjanStack.removeLast();\n                component.add(w);\n                nodeOnStack.clear(w);\n                if (w == v)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numNodes += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param excludeSingleNodeComponents\n * \t\tif set to true components that only contain a single node will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponents();\n}", "private ConnectedComponents findComponents() {\n    for (int node = 0; node < graph.getNodes(); ++node) {\n        if (nodeIndex[node] != (-1))\n            continue;\n\n        pushFindComponentForNode(node);\n        while (hasNext()) {\n            pop();\n            switch (dfsState) {\n                case BUILD_COMPONENT :\n                    buildComponent(v);\n                    break;\n                case UPDATE :\n                    nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n                    break;\n                case HANDLE_NEIGHBOR :\n                    {\n                        if ((nodeIndex[w] != (-1)) && nodeOnStack.get(w))\n                            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n                        if (nodeIndex[w] == (-1)) {\n                            // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                            pushUpdateLowLinks(v, w);\n                            pushFindComponentForNode(w);\n                        }\n                        break;\n                    }\n                case FIND_COMPONENT :\n                    {\n                        setupNextNode(v);\n                        // we push buildComponent first so it will run *after* we finished traversing the edges\n                        pushBuildComponent(v);\n                        EdgeIterator iter = explorer.setBaseNode(v);\n                        while (iter.next()) {\n                            pushHandleNeighbor(v, iter.getAdjNode());\n                        } \n                        break;\n                    }\n                default :\n                    throw new IllegalStateException(\"Unknown state: \" + dfsState);\n            }\n        } \n    }\n    return components;\n}", "private void buildComponent(int v) {\n    if (nodeLowLink[v] == nodeIndex[v]) {\n        if (tarjanStack.getLast() == v) {\n            tarjanStack.removeLast();\n            nodeOnStack.clear(v);\n            components.numComponents++;\n            components.numNodes++;\n            if (!excludeSingleNodeComponents)\n                components.singleNodeComponents.set(v);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int w = tarjanStack.removeLast();\n                component.add(w);\n                nodeOnStack.clear(w);\n                if (w == v)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numNodes += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.ExternalBooleanEncodedValue.setBool",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ev.ExternalBooleanEncodedValue.setBool" ],
    "fullMethods" : [ "@Override\npublic void setBool(boolean reverse, int edgeId, EdgeIntAccess edgeIntAccess, boolean value) {\n    // it'll grow as we go\n    if (value)\n        bits.set(getIndex(edgeId, reverse));\n    else\n        bits.clear(getIndex(edgeId, reverse));\n\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions", "com.graphhopper.routing.util.parsers.RestrictionSetter.disableRedundantRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}", "private void disableRedundantRestrictions(List<InternalRestriction> restrictions, List<BitSet> encBits) {\n    for (int encIdx = 0; encIdx < turnRestrictionEncs.size(); encIdx++) {\n        // first we disable all duplicates\n        Set<InternalRestriction> uniqueRestrictions = new HashSet<>();\n        for (int i = 0; i < restrictions.size(); i++) {\n            if (!encBits.get(i).get(encIdx))\n                continue;\n\n            if (!uniqueRestrictions.add(restrictions.get(i)))\n                encBits.get(i).clear(encIdx);\n\n        }\n        // build an index of restrictions to quickly find all restrictions containing a given edge key\n        IntObjectScatterMap<List<InternalRestriction>> restrictionsByEdgeKeys = new IntObjectScatterMap<>();\n        for (int i = 0; i < restrictions.size(); i++) {\n            if (!encBits.get(i).get(encIdx))\n                continue;\n\n            InternalRestriction restriction = restrictions.get(i);\n            for (IntCursor edgeKey : restriction.edgeKeys) {\n                int idx = restrictionsByEdgeKeys.indexOf(edgeKey.value);\n                if (idx < 0) {\n                    List<InternalRestriction> list = new ArrayList<>();\n                    list.add(restriction);\n                    restrictionsByEdgeKeys.indexInsert(idx, edgeKey.value, list);\n                } else {\n                    restrictionsByEdgeKeys.indexGet(idx).add(restriction);\n                }\n            }\n        }\n        // Only keep restrictions that do not contain another restriction. For example, it would be unnecessary to restrict\n        // 6-8-2 when 6-8 is restricted already\n        for (int i = 0; i < restrictions.size(); i++) {\n            if (!encBits.get(i).get(encIdx))\n                continue;\n\n            if (containsAnotherRestriction(restrictions.get(i), restrictionsByEdgeKeys))\n                encBits.get(i).clear(encIdx);\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanArrayIntSet.remove",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanArrayIntSet.remove" ],
    "fullMethods" : [ "@Override\npublic void remove(int key) {\n    set.clear(key);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongObjectHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongObjectHashMap.<init>" ],
    "fullMethods" : [ "public GHLongObjectHashMap(int capacity, double loadFactor) {\n    super(capacity, loadFactor, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongObjectHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongObjectHashMap.<init>" ],
    "fullMethods" : [ "public GHLongObjectHashMap(int capacity, double loadFactor, HashOrderMixingStrategy hashOrderMixer) {\n    super(capacity, loadFactor, hashOrderMixer);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongObjectHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongObjectHashMap.<init>" ],
    "fullMethods" : [ "public GHLongObjectHashMap() {\n    super(10, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHLongObjectHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHLongObjectHashMap.<init>" ],
    "fullMethods" : [ "public GHLongObjectHashMap(int capacity) {\n    super(capacity, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaNode" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to the given via-node.\n * For each way there can be multiple edge IDs and there should be exactly one that is adjacent to the via-node\n * for each way. Otherwise we throw {@link OSMRestrictionException}\n */\npublic NodeResult convertForViaNode(LongArrayList fromWays, int viaNode, LongArrayList toWays) throws OSMRestrictionException {\n    if (fromWays.isEmpty() || toWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    NodeResult result = new NodeResult(fromWays.size(), toWays.size());\n    for (LongCursor fromWay : fromWays)\n        edgesByWay.apply(fromWay.value).forEachRemaining(e -> {\n            if (baseGraph.isAdjacentToNode(e.value, viaNode))\n                result.fromEdges.add(e.value);\n\n        });\n\n    if (result.fromEdges.size() < fromWays.size())\n        throw new OSMRestrictionException(\"has from-member ways that aren't adjacent to the via-member node\");\n    else if (result.fromEdges.size() > fromWays.size())\n        throw new OSMRestrictionException(\"has from-member ways that aren't split at the via-member node\");\n\n    for (LongCursor toWay : toWays)\n        edgesByWay.apply(toWay.value).forEachRemaining(e -> {\n            if (baseGraph.isAdjacentToNode(e.value, viaNode))\n                result.toEdges.add(e.value);\n\n        });\n\n    if (result.toEdges.size() < toWays.size())\n        throw new OSMRestrictionException(\"has to-member ways that aren't adjacent to the via-member node\");\n    else if (result.toEdges.size() > toWays.size())\n        throw new OSMRestrictionException(\"has to-member ways that aren't split at the via-member node\");\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to each other. For example for given\n * from-, via- and to-ways there can be multiple edges associated with each (because each way can be split into\n * multiple edges). We then need to find the from-edge that is connected with one of the via-edges which in turn\n * must be connected with one of the to-edges. We use DFS/backtracking to do this.\n * There can also be *multiple* via-ways, but the concept is the same.\n * Note that there can also be multiple from- or to-*ways*, but only one of each of them should be considered at a\n * time. In contrast to the via-ways there are only multiple from/to-ways, because of restrictions like no_entry or\n * no_exit where there can be multiple from- or to-members. So we need to find one edge-chain for each pair of from-\n * and to-ways.\n * Besides the edge IDs we also return the node IDs that connect the edges, so we can add turn restrictions at these\n * nodes later.\n */\npublic EdgeResult convertForViaWays(LongArrayList fromWays, LongArrayList viaWays, LongArrayList toWays) throws OSMRestrictionException {\n    if ((fromWays.isEmpty() || toWays.isEmpty()) || viaWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from-, via- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    List<IntArrayList> solutions = new ArrayList<>();\n    for (LongCursor fromWay : fromWays)\n        for (LongCursor toWay : toWays)\n            findEdgeChain(fromWay.value, viaWays, toWay.value, solutions);\n\n\n    if (solutions.size() < (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has disconnected member ways\");\n    else if (solutions.size() > (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has member ways that do not form a unique path\");\n\n    return buildResult(solutions, fromWays, viaWays, toWays);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.extractMembers",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.extractMembers" ],
    "fullMethods" : [ "public static RestrictionMembers extractMembers(ReaderRelation relation) throws OSMRestrictionException {\n    // we use -1 to indicate 'missing', which is fine because we exclude negative OSM IDs (see #2652)\n    long viaOSMNode = -1;\n    LongArrayList fromWays = new LongArrayList();\n    LongArrayList viaWays = new LongArrayList();\n    LongArrayList toWays = new LongArrayList();\n    for (ReaderRelation.Member member : relation.getMembers()) {\n        if (\"from\".equals(member.getRole())) {\n            if (member.getType() != ReaderElement.Type.WAY)\n                throw new OSMRestrictionException((\"has a member with role 'from' and type '\" + member.getType()) + \"', but it should be of type 'way'\");\n\n            fromWays.add(member.getRef());\n        } else if (\"to\".equals(member.getRole())) {\n            if (member.getType() != ReaderElement.Type.WAY)\n                throw new OSMRestrictionException((\"has a member with role 'to' and type '\" + member.getType()) + \"', but it should be of type 'way'\");\n\n            toWays.add(member.getRef());\n        } else if (\"via\".equals(member.getRole())) {\n            if (member.getType() == ReaderElement.Type.NODE) {\n                if (viaOSMNode >= 0)\n                    throw new OSMRestrictionException(\"has multiple members with role 'via' and type 'node', but multiple via-members are only allowed when they are of type: 'way'\");\n\n                // note that we check for combined usage of via nodes and ways later on\n                viaOSMNode = member.getRef();\n            } else if (member.getType() == ReaderElement.Type.WAY) {\n                // note that we check for combined usage of via nodes and ways later on\n                viaWays.add(member.getRef());\n            } else\n                throw new OSMRestrictionException(((\"has a member with role 'via' and\" + \" type '\") + member.getType()) + \"', but it should be of type 'node' or 'way'\");\n\n        } else if (\"location_hint\".equals(member.getRole())) {\n            // location_hint is deprecated and should no longer be used according to the wiki, but we do not warn\n            // about it, or even ignore the relation in this case, because maybe not everyone is happy to remove it.\n        } else if (member.getRole().trim().isEmpty())\n            throw new OSMRestrictionException(\"has a member with an empty role\");\n        else\n            throw new OSMRestrictionException((\"has a member with an unknown role '\" + member.getRole()) + \"'\");\n\n    }\n    if (fromWays.isEmpty() && toWays.isEmpty())\n        throw new OSMRestrictionException(\"has no member with role 'from' and 'to'\");\n    else if (fromWays.isEmpty())\n        throw new OSMRestrictionException(\"has no member with role 'from'\");\n    else if (toWays.isEmpty())\n        throw new OSMRestrictionException(\"has no member with role 'to'\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new OSMRestrictionException(\"has multiple members with role 'from' and 'to'\");\n\n    checkTags(fromWays, toWays, relation.getTags());\n    if ((viaOSMNode >= 0) && (!viaWays.isEmpty()))\n        throw new OSMRestrictionException(\"has members with role 'via' of type 'node' and 'way', but only one type is allowed\");\n    else if (viaOSMNode >= 0)\n        return RestrictionMembers.viaNode(viaOSMNode, fromWays, toWays);\n    else if (!viaWays.isEmpty())\n        return RestrictionMembers.viaWay(fromWays, viaWays, toWays);\n    else\n        throw new OSMRestrictionException(\"has no member with role 'via'\");\n\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.Polygon.getMinLat",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Envelope.getMinY",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.Polygon.getMinLat" ],
    "fullMethods" : [ "public double getMinLat() {\n    return envelope.getMinY();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.BBox.fromEnvelope",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Envelope.getMinY",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.BBox.fromEnvelope" ],
    "fullMethods" : [ "public static BBox fromEnvelope(Envelope envelope) {\n    return new BBox(envelope.getMinX(), envelope.getMaxX(), envelope.getMinY(), envelope.getMaxY());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntHashSet.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntHashSet.<init>" ],
    "fullMethods" : [ "public GHIntHashSet(int capacity, double loadFactor) {\n    super(capacity, loadFactor, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntHashSet.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntHashSet.<init>" ],
    "fullMethods" : [ "public GHIntHashSet(int capacity, double loadFactor, HashOrderMixingStrategy hashOrderMixer) {\n    super(capacity, loadFactor, hashOrderMixer);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntHashSet.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntHashSet.<init>" ],
    "fullMethods" : [ "public GHIntHashSet(int capacity) {\n    super(capacity, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntHashSet.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntHashSet.<init>" ],
    "fullMethods" : [ "public GHIntHashSet() {\n    super(10, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate",
    "thirdPartyMethod" : "org.locationtech.jts.triangulate.quadedge.Vertex.setZ",
    "thirdPartyPackage" : "org.locationtech.jts.triangulate.quadedge",
    "path" : [ "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate" ],
    "fullMethods" : [ "public Result triangulate(Snap snap, QueryGraph queryGraph, ShortestPathTree shortestPathTree, ToDoubleFunction<ShortestPathTree.IsoLabel> fz, double tolerance) {\n    final NodeAccess na = queryGraph.getNodeAccess();\n    Collection<Coordinate> sites = new ArrayList<>();\n    shortestPathTree.search(snap.getClosestNode(), label -> {\n        double exploreValue = fz.applyAsDouble(label);\n        double lat = na.getLat(label.node);\n        double lon = na.getLon(label.node);\n        Coordinate site = new Coordinate(lon, lat);\n        site.z = exploreValue;\n        sites.add(site);\n        // add a pillar node to increase precision a bit for longer roads\n        if (label.parent != null) {\n            EdgeIteratorState edge = queryGraph.getEdgeIteratorState(label.edge, label.node);\n            PointList innerPoints = edge.fetchWayGeometry(FetchMode.PILLAR_ONLY);\n            if (innerPoints.size() > 0) {\n                int midIndex = innerPoints.size() / 2;\n                // For edge-based routing we might have explored the same edge in two different directions.\n                // Here we make sure we only include the **same** point twice instead of two different ones.\n                if (((innerPoints.size() % 2) == 0) && edge.get(EdgeIteratorState.REVERSE_STATE))\n                    midIndex -= 1;\n\n                double lat2 = innerPoints.getLat(midIndex);\n                double lon2 = innerPoints.getLon(midIndex);\n                Coordinate site2 = new Coordinate(lon2, lat2);\n                site2.z = exploreValue;\n                sites.add(site2);\n            }\n        }\n    });\n    if (sites.size() > (routerConfig.getMaxVisitedNodes() / 3))\n        throw new IllegalArgumentException((\"Too many nodes would be included in post processing (\" + sites.size()) + \"). Let us know if you need this increased.\");\n\n    // Sites may contain repeated coordinates. Especially for edge-based traversal, that's expected -- we visit\n    // each node multiple times.\n    // But that's okay, the triangulator de-dupes by itself, and it keeps the first z-value it sees, which is\n    // what we want.\n    DelaunayTriangulationBuilder triangulationBuilder = new DelaunayTriangulationBuilder();\n    triangulationBuilder.setSites(sites);\n    triangulationBuilder.setTolerance(tolerance);\n    Geometry convexHull = triangulationBuilder.getEdges(new GeometryFactory()).convexHull();\n    // If there's only one site (and presumably also if the convex hull is otherwise degenerated),\n    // the triangulation only contains the frame, and not the site within the frame. Not sure if I agree with that.\n    // See ConformingDelaunayTriangulator, it does include a buffer for the frame, but that buffer is zero\n    // in these cases.\n    // It leads to the following follow-up defect:\n    // computeIsoline fails (returns an empty Multipolygon). This is clearly wrong, since\n    // the idea is that every real (non-frame) vertex has positive-length-edges around it that can be traversed\n    // to get a non-empty polygon.\n    // So we exclude this case for now (it is indeed only a corner-case).\n    if (!(convexHull instanceof Polygon)) {\n        throw new IllegalArgumentException(\"Too few points found. \" + \"Please try a different 'point' or a larger 'time_limit'.\");\n    }\n    QuadEdgeSubdivision tin = triangulationBuilder.getSubdivision();\n    for (Vertex vertex : ((Collection<Vertex>) (tin.getVertices(true)))) {\n        if (tin.isFrameVertex(vertex)) {\n            vertex.setZ(Double.MAX_VALUE);\n        }\n    }\n    ReadableTriangulation triangulation = ReadableTriangulation.wrap(tin);\n    return new Result(triangulation, triangulation.getEdges());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LMApproximator.approximate",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.addAll",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.lm.LMApproximator.approximate", "com.graphhopper.routing.lm.LandmarkStorage.chooseActiveLandmarks" ],
    "fullMethods" : [ "@Override\npublic double approximate(final int v) {\n    if (((!recalculateActiveLandmarks) && fallback) || lms.isEmpty())\n        return fallBackApproximation.approximate(v);\n\n    if (v >= maxBaseNodes) {\n        // handle virtual node\n        return 0;\n    }\n    if (v == towerNodeNextToT)\n        return 0;\n\n    // select better active landmarks, LATER: use 'success' statistics about last active landmark\n    // we have to update the priority queues and the maps if done in the middle of the search http://cstheory.stackexchange.com/q/36355/13229\n    if (recalculateActiveLandmarks) {\n        recalculateActiveLandmarks = false;\n        if (lms.chooseActiveLandmarks(v, towerNodeNextToT, activeLandmarkIndices, reverse)) {\n            for (int i = 0; i < activeLandmarkIndices.length; i++) {\n                weightsFromActiveLandmarksToT[i] = lms.getFromWeight(activeLandmarkIndices[i], towerNodeNextToT);\n                weightsFromTToActiveLandmarks[i] = lms.getToWeight(activeLandmarkIndices[i], towerNodeNextToT);\n            }\n        } else {\n            // note: fallback==true means forever true!\n            fallback = true;\n            return fallBackApproximation.approximate(v);\n        }\n    }\n    double lmApproximation = Math.max(0.0, (getRemainingWeightUnderestimationUpToTowerNode(v) - weightFromTToTowerNode) * epsilon);\n    // Since both the LM and the beeline approximations underestimate the real remaining weight the larger one is\n    // more accurate. For example when the speed is reduced for all roads the beeline approximation adjusts automatically\n    // to the reduced global maximum speed, while the LM approximation becomes worse.\n    return Math.max(lmApproximation, beelineApproximation.approximate(v));\n}", "// From all available landmarks pick just a few active ones\nboolean chooseActiveLandmarks(int fromNode, int toNode, int[] activeLandmarkIndices, boolean reverse) {\n    if ((fromNode < 0) || (toNode < 0))\n        throw new IllegalStateException((((\"from \" + fromNode) + \" and to \") + toNode) + \" nodes have to be 0 or positive to init landmarks\");\n\n    int subnetworkFrom = subnetworkStorage.getSubnetwork(fromNode);\n    int subnetworkTo = subnetworkStorage.getSubnetwork(toNode);\n    if ((subnetworkFrom <= UNCLEAR_SUBNETWORK) || (subnetworkTo <= UNCLEAR_SUBNETWORK))\n        return false;\n\n    if (subnetworkFrom != subnetworkTo) {\n        throw new ConnectionNotFoundException(((\"Connection between locations not found. Different subnetworks \" + subnetworkFrom) + \" vs. \") + subnetworkTo, new HashMap<>());\n    }\n    // See the similar formula in LMApproximator.approximateForLandmark\n    List<Map.Entry<Integer, Integer>> list = new ArrayList<>(landmarks);\n    for (int lmIndex = 0; lmIndex < landmarks; lmIndex++) {\n        int fromWeight = getFromWeight(lmIndex, toNode) - getFromWeight(lmIndex, fromNode);\n        int toWeight = getToWeight(lmIndex, fromNode) - getToWeight(lmIndex, toNode);\n        list.add(new MapEntry<>(reverse ? Math.max(-fromWeight, -toWeight) : Math.max(fromWeight, toWeight), lmIndex));\n    }\n    Collections.sort(list, SORT_BY_WEIGHT);\n    if (activeLandmarkIndices[0] >= 0) {\n        IntHashSet set = new IntHashSet(activeLandmarkIndices.length);\n        set.addAll(activeLandmarkIndices);\n        int existingLandmarkCounter = 0;\n        final int COUNT = Math.min(activeLandmarkIndices.length - 2, 2);\n        for (int i = 0; i < activeLandmarkIndices.length; i++) {\n            if (i >= ((activeLandmarkIndices.length - COUNT) + existingLandmarkCounter)) {\n                // keep at least two of the previous landmarks (pick the best)\n                break;\n            } else {\n                activeLandmarkIndices[i] = list.get(i).getValue();\n                if (set.contains(activeLandmarkIndices[i]))\n                    existingLandmarkCounter++;\n\n            }\n        }\n    } else {\n        for (int i = 0; i < activeLandmarkIndices.length; i++) {\n            activeLandmarkIndices[i] = list.get(i).getValue();\n        }\n    }\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate",
    "thirdPartyMethod" : "org.locationtech.jts.triangulate.quadedge.QuadEdgeSubdivision.isFrameVertex",
    "thirdPartyPackage" : "org.locationtech.jts.triangulate.quadedge",
    "path" : [ "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate" ],
    "fullMethods" : [ "public Result triangulate(Snap snap, QueryGraph queryGraph, ShortestPathTree shortestPathTree, ToDoubleFunction<ShortestPathTree.IsoLabel> fz, double tolerance) {\n    final NodeAccess na = queryGraph.getNodeAccess();\n    Collection<Coordinate> sites = new ArrayList<>();\n    shortestPathTree.search(snap.getClosestNode(), label -> {\n        double exploreValue = fz.applyAsDouble(label);\n        double lat = na.getLat(label.node);\n        double lon = na.getLon(label.node);\n        Coordinate site = new Coordinate(lon, lat);\n        site.z = exploreValue;\n        sites.add(site);\n        // add a pillar node to increase precision a bit for longer roads\n        if (label.parent != null) {\n            EdgeIteratorState edge = queryGraph.getEdgeIteratorState(label.edge, label.node);\n            PointList innerPoints = edge.fetchWayGeometry(FetchMode.PILLAR_ONLY);\n            if (innerPoints.size() > 0) {\n                int midIndex = innerPoints.size() / 2;\n                // For edge-based routing we might have explored the same edge in two different directions.\n                // Here we make sure we only include the **same** point twice instead of two different ones.\n                if (((innerPoints.size() % 2) == 0) && edge.get(EdgeIteratorState.REVERSE_STATE))\n                    midIndex -= 1;\n\n                double lat2 = innerPoints.getLat(midIndex);\n                double lon2 = innerPoints.getLon(midIndex);\n                Coordinate site2 = new Coordinate(lon2, lat2);\n                site2.z = exploreValue;\n                sites.add(site2);\n            }\n        }\n    });\n    if (sites.size() > (routerConfig.getMaxVisitedNodes() / 3))\n        throw new IllegalArgumentException((\"Too many nodes would be included in post processing (\" + sites.size()) + \"). Let us know if you need this increased.\");\n\n    // Sites may contain repeated coordinates. Especially for edge-based traversal, that's expected -- we visit\n    // each node multiple times.\n    // But that's okay, the triangulator de-dupes by itself, and it keeps the first z-value it sees, which is\n    // what we want.\n    DelaunayTriangulationBuilder triangulationBuilder = new DelaunayTriangulationBuilder();\n    triangulationBuilder.setSites(sites);\n    triangulationBuilder.setTolerance(tolerance);\n    Geometry convexHull = triangulationBuilder.getEdges(new GeometryFactory()).convexHull();\n    // If there's only one site (and presumably also if the convex hull is otherwise degenerated),\n    // the triangulation only contains the frame, and not the site within the frame. Not sure if I agree with that.\n    // See ConformingDelaunayTriangulator, it does include a buffer for the frame, but that buffer is zero\n    // in these cases.\n    // It leads to the following follow-up defect:\n    // computeIsoline fails (returns an empty Multipolygon). This is clearly wrong, since\n    // the idea is that every real (non-frame) vertex has positive-length-edges around it that can be traversed\n    // to get a non-empty polygon.\n    // So we exclude this case for now (it is indeed only a corner-case).\n    if (!(convexHull instanceof Polygon)) {\n        throw new IllegalArgumentException(\"Too few points found. \" + \"Please try a different 'point' or a larger 'time_limit'.\");\n    }\n    QuadEdgeSubdivision tin = triangulationBuilder.getSubdivision();\n    for (Vertex vertex : ((Collection<Vertex>) (tin.getVertices(true)))) {\n        if (tin.isFrameVertex(vertex)) {\n            vertex.setZ(Double.MAX_VALUE);\n        }\n    }\n    ReadableTriangulation triangulation = ReadableTriangulation.wrap(tin);\n    return new Result(triangulation, triangulation.getEdges());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntSet.remove",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntScatterSet.remove",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntSet.remove" ],
    "fullMethods" : [ "@Override\npublic void remove(int key) {\n    set.remove(key);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity" ],
    "fullMethods" : [ "/**\n *\n * @param radius\n * \t\tin meters\n * @param calcRoadFactor\n * \t\tweighting function. use this to define how different kinds of roads shall contribute to the calculated road density\n * @return the road density in the vicinity of the given edge, i.e. the weighted road length divided by the squared radius\n */\npublic double calcRoadDensity(EdgeIteratorState edge, double radius, ToDoubleFunction<EdgeIteratorState> calcRoadFactor) {\n    visited.clear();\n    deque.head = deque.tail = 0;\n    double totalRoadWeight = 0;\n    NodeAccess na = graph.getNodeAccess();\n    int baseNode = edge.getBaseNode();\n    int adjNode = edge.getAdjNode();\n    GHPoint center = new GHPoint(getLat(na, baseNode, adjNode), getLon(na, baseNode, adjNode));\n    deque.addLast(baseNode);\n    deque.addLast(adjNode);\n    visited.add(baseNode);\n    visited.add(adjNode);\n    // we just do a BFS search and sum up all the road lengths\n    final double radiusNormalized = DIST_PLANE.calcNormalizedDist(radius);\n    // for long tunnels or motorway sections where the distance between the exit points and the\n    // center is larger than the radius it is important to continue the search even outside the radius\n    final int minPolls = ((int) (radius / 2));\n    int polls = 0;\n    while (!deque.isEmpty()) {\n        int node = deque.removeFirst();\n        polls++;\n        double distance = DIST_PLANE.calcNormalizedDist(center.lat, center.lon, na.getLat(node), na.getLon(node));\n        if ((polls > minPolls) && (distance > radiusNormalized))\n            continue;\n\n        EdgeIterator iter = edgeExplorer.setBaseNode(node);\n        while (iter.next()) {\n            if (visited.contains(iter.getAdjNode()))\n                continue;\n\n            visited.add(iter.getAdjNode());\n            if (distance <= radiusNormalized)\n                totalRoadWeight += calcRoadFactor.applyAsDouble(iter);\n\n            deque.addLast(iter.getAdjNode());\n        } \n    } \n    return (totalRoadWeight / radius) / radius;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedNodeContractor.calculatePriority",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedNodeContractor.calculatePriority", "com.graphhopper.routing.ch.EdgeBasedNodeContractor.findAndHandlePrepareShortcuts" ],
    "fullMethods" : [ "@Override\npublic float calculatePriority(int node) {\n    activeStats = countingStats;\n    resetEdgeCounters();\n    countPreviousEdges(node);\n    // this node is isolated, maybe it belongs to a removed subnetwork, in any case we can quickly contract it\n    // no shortcuts will be introduced\n    if (numAllEdges == 0)\n        return Float.NEGATIVE_INFINITY;\n\n    stats().stopWatch.start();\n    findAndHandlePrepareShortcuts(node, this::countShortcuts, ((int) (meanDegree * params.maxPollFactorHeuristic)), wpsStatsHeur);\n    stats().stopWatch.stop();\n    // the higher the priority the later (!) this node will be contracted\n    float edgeQuotient = numShortcuts / ((float) (prepareGraph.getDegree(node)));\n    float origEdgeQuotient = numOrigEdges / ((float) (numPrevOrigEdges));\n    int hierarchyDepth = hierarchyDepths[node];\n    float priority = ((params.edgeQuotientWeight * edgeQuotient) + (params.originalEdgeQuotientWeight * origEdgeQuotient)) + (params.hierarchyDepthWeight * hierarchyDepth);\n    if (LOGGER.isTraceEnabled())\n        LOGGER.trace(\"node: {}, eq: {} / {} = {}, oeq: {} / {} = {}, depth: {} --> {}\", node, numShortcuts, numPrevEdges, edgeQuotient, numOrigEdges, numPrevOrigEdges, origEdgeQuotient, hierarchyDepth, priority);\n\n    return priority;\n}", "/**\n * This method performs witness searches between all nodes adjacent to the given node and calls the\n * given handler for all required shortcuts.\n */\nprivate void findAndHandlePrepareShortcuts(int node, PrepareShortcutHandler shortcutHandler, int maxPolls, EdgeBasedWitnessPathSearcher.Stats wpsStats) {\n    stats().nodes++;\n    addedShortcuts.clear();\n    sourceNodes.clear();\n    // traverse incoming edges/shortcuts to find all the source nodes\n    PrepareGraphEdgeIterator incomingEdges = inEdgeExplorer.setBaseNode(node);\n    while (incomingEdges.next()) {\n        final int sourceNode = incomingEdges.getAdjNode();\n        if (sourceNode == node)\n            continue;\n\n        // make sure we process each source node only once\n        if (!sourceNodes.add(sourceNode))\n            continue;\n\n        // for each source node we need to look at every incoming original edge and check which target edges are reachable\n        PrepareGraphOrigEdgeIterator origInIter = sourceNodeOrigInEdgeExplorer.setBaseNode(sourceNode);\n        while (origInIter.next()) {\n            int origInKey = reverseEdgeKey(origInIter.getOrigEdgeKeyLast());\n            // we search 'bridge paths' leading to the target edges\n            IntObjectMap<BridgePathFinder.BridePathEntry> bridgePaths = bridgePathFinder.find(origInKey, sourceNode, node);\n            if (bridgePaths.isEmpty())\n                continue;\n\n            witnessPathSearcher.initSearch(origInKey, sourceNode, node, wpsStats);\n            for (IntObjectCursor<BridgePathFinder.BridePathEntry> bridgePath : bridgePaths) {\n                if (!Double.isFinite(bridgePath.value.weight))\n                    throw new IllegalStateException(\"Bridge entry weights should always be finite\");\n\n                int targetEdgeKey = bridgePath.key;\n                dijkstraSW.start();\n                double weight = witnessPathSearcher.runSearch(bridgePath.value.chEntry.adjNode, targetEdgeKey, bridgePath.value.weight, maxPolls);\n                dijkstraSW.stop();\n                // we found a witness, nothing to do\n                if (weight <= bridgePath.value.weight)\n                    continue;\n\n                PrepareCHEntry root = bridgePath.value.chEntry;\n                while (EdgeIterator.Edge.isValid(root.parent.prepareEdge))\n                    root = root.getParent();\n\n                // we make sure to add each shortcut only once. when we are actually adding shortcuts we check for existing\n                // shortcuts anyway, but at least this is important when we *count* shortcuts.\n                long addedShortcutKey = BitUtil.LITTLE.toLong(root.firstEdgeKey, bridgePath.value.chEntry.incEdgeKey);\n                if (!addedShortcuts.add(addedShortcutKey))\n                    continue;\n\n                double initialTurnCost = prepareGraph.getTurnWeight(origInKey, sourceNode, root.firstEdgeKey);\n                bridgePath.value.chEntry.weight -= initialTurnCost;\n                LOGGER.trace(\"Adding shortcuts for target entry {}\", bridgePath.value.chEntry);\n                // todo: re-implement loop-avoidance heuristic as it existed in GH 1.0? it did not work the\n                // way it was implemented so it was removed at some point\n                shortcutHandler.handleShortcut(root, bridgePath.value.chEntry, bridgePath.value.chEntry.origEdges);\n            }\n            witnessPathSearcher.finishSearch();\n        } \n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.disconnect",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.disconnect" ],
    "fullMethods" : [ "public IntContainer disconnect(int node) {\n    checkReady();\n    // we use this neighbor set to guarantee a deterministic order of the returned\n    // node ids\n    neighborSet.clear();\n    PrepareEdge currOut = prepareEdgesOut[node];\n    while (currOut != null) {\n        int adjNode = currOut.getNodeB();\n        if (adjNode == node)\n            adjNode = currOut.getNodeA();\n\n        if (adjNode == node) {\n            // this is a loop\n            currOut = currOut.getNextOut(node);\n            continue;\n        }\n        removeInEdge(adjNode, currOut);\n        neighborSet.add(adjNode);\n        currOut = currOut.getNextOut(node);\n    } \n    PrepareEdge currIn = prepareEdgesIn[node];\n    while (currIn != null) {\n        int adjNode = currIn.getNodeB();\n        if (adjNode == node)\n            adjNode = currIn.getNodeA();\n\n        if (adjNode == node) {\n            // this is a loop\n            currIn = currIn.getNextIn(node);\n            continue;\n        }\n        removeOutEdge(adjNode, currIn);\n        neighborSet.add(adjNode);\n        currIn = currIn.getNextIn(node);\n    } \n    prepareEdgesOut[node] = null;\n    prepareEdgesIn[node] = null;\n    degrees[node] = 0;\n    return neighborSet;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.clear",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode", "com.graphhopper.routing.ch.EdgeBasedNodeContractor.findAndHandlePrepareShortcuts" ],
    "fullMethods" : [ "@Override\npublic IntContainer contractNode(int node) {\n    activeStats = addingStats;\n    stats().stopWatch.start();\n    findAndHandlePrepareShortcuts(node, this::addShortcutsToPrepareGraph, ((int) (meanDegree * params.maxPollFactorContraction)), wpsStatsContr);\n    insertShortcuts(node);\n    IntContainer neighbors = prepareGraph.disconnect(node);\n    // We maintain an approximation of the mean degree which we update after every contracted node.\n    // We do it the same way as for node-based CH for now.\n    meanDegree = ((meanDegree * 2) + neighbors.size()) / 3;\n    updateHierarchyDepthsOfNeighbors(node, neighbors);\n    stats().stopWatch.stop();\n    return neighbors;\n}", "/**\n * This method performs witness searches between all nodes adjacent to the given node and calls the\n * given handler for all required shortcuts.\n */\nprivate void findAndHandlePrepareShortcuts(int node, PrepareShortcutHandler shortcutHandler, int maxPolls, EdgeBasedWitnessPathSearcher.Stats wpsStats) {\n    stats().nodes++;\n    addedShortcuts.clear();\n    sourceNodes.clear();\n    // traverse incoming edges/shortcuts to find all the source nodes\n    PrepareGraphEdgeIterator incomingEdges = inEdgeExplorer.setBaseNode(node);\n    while (incomingEdges.next()) {\n        final int sourceNode = incomingEdges.getAdjNode();\n        if (sourceNode == node)\n            continue;\n\n        // make sure we process each source node only once\n        if (!sourceNodes.add(sourceNode))\n            continue;\n\n        // for each source node we need to look at every incoming original edge and check which target edges are reachable\n        PrepareGraphOrigEdgeIterator origInIter = sourceNodeOrigInEdgeExplorer.setBaseNode(sourceNode);\n        while (origInIter.next()) {\n            int origInKey = reverseEdgeKey(origInIter.getOrigEdgeKeyLast());\n            // we search 'bridge paths' leading to the target edges\n            IntObjectMap<BridgePathFinder.BridePathEntry> bridgePaths = bridgePathFinder.find(origInKey, sourceNode, node);\n            if (bridgePaths.isEmpty())\n                continue;\n\n            witnessPathSearcher.initSearch(origInKey, sourceNode, node, wpsStats);\n            for (IntObjectCursor<BridgePathFinder.BridePathEntry> bridgePath : bridgePaths) {\n                if (!Double.isFinite(bridgePath.value.weight))\n                    throw new IllegalStateException(\"Bridge entry weights should always be finite\");\n\n                int targetEdgeKey = bridgePath.key;\n                dijkstraSW.start();\n                double weight = witnessPathSearcher.runSearch(bridgePath.value.chEntry.adjNode, targetEdgeKey, bridgePath.value.weight, maxPolls);\n                dijkstraSW.stop();\n                // we found a witness, nothing to do\n                if (weight <= bridgePath.value.weight)\n                    continue;\n\n                PrepareCHEntry root = bridgePath.value.chEntry;\n                while (EdgeIterator.Edge.isValid(root.parent.prepareEdge))\n                    root = root.getParent();\n\n                // we make sure to add each shortcut only once. when we are actually adding shortcuts we check for existing\n                // shortcuts anyway, but at least this is important when we *count* shortcuts.\n                long addedShortcutKey = BitUtil.LITTLE.toLong(root.firstEdgeKey, bridgePath.value.chEntry.incEdgeKey);\n                if (!addedShortcuts.add(addedShortcutKey))\n                    continue;\n\n                double initialTurnCost = prepareGraph.getTurnWeight(origInKey, sourceNode, root.firstEdgeKey);\n                bridgePath.value.chEntry.weight -= initialTurnCost;\n                LOGGER.trace(\"Adding shortcuts for target entry {}\", bridgePath.value.chEntry);\n                // todo: re-implement loop-avoidance heuristic as it existed in GH 1.0? it did not work the\n                // way it was implemented so it was removed at some point\n                shortcutHandler.handleShortcut(root, bridgePath.value.chEntry, bridgePath.value.chEntry.origEdges);\n            }\n            witnessPathSearcher.finishSearch();\n        } \n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.pbf.PbfBlobDecoder.run",
    "thirdPartyMethod" : "org.openstreetmap.osmosis.osmbinary.Fileformat.Blob.hasRaw",
    "thirdPartyPackage" : "org.openstreetmap.osmosis.osmbinary.Fileformat",
    "path" : [ "com.graphhopper.reader.osm.pbf.PbfBlobDecoder.run", "com.graphhopper.reader.osm.pbf.PbfBlobDecoder.runAndTrapExceptions", "com.graphhopper.reader.osm.pbf.PbfBlobDecoder.readBlobContent" ],
    "fullMethods" : [ "@Override\npublic void run() {\n    try {\n        runAndTrapExceptions();\n        listener.complete(decodedEntities);\n    } catch (RuntimeException e) {\n        // exception is properly rethrown in PbfDecoder.sendResultsToSink\n        listener.error(e);\n    }\n}", "private void runAndTrapExceptions() {\n    try {\n        decodedEntities = new ArrayList<>();\n        if (\"OSMHeader\".equals(blobType)) {\n            processOsmHeader(readBlobContent());\n        } else if (\"OSMData\".equals(blobType)) {\n            processOsmPrimitives(readBlobContent());\n        } else if (log.isDebugEnabled())\n            log.debug(\"Skipping unrecognised blob type \" + blobType);\n\n    } catch (IOException e) {\n        throw new RuntimeException(\"Unable to process PBF blob\", e);\n    }\n}", "private byte[] readBlobContent() throws IOException {\n    Fileformat.Blob blob = Fileformat.Blob.parseFrom(rawBlob);\n    byte[] blobData;\n    if (blob.hasRaw()) {\n        blobData = blob.getRaw().toByteArray();\n    } else if (blob.hasZlibData()) {\n        Inflater inflater = new Inflater();\n        inflater.setInput(blob.getZlibData().toByteArray());\n        blobData = new byte[blob.getRawSize()];\n        try {\n            inflater.inflate(blobData);\n        } catch (DataFormatException e) {\n            throw new RuntimeException(\"Unable to decompress PBF blob.\", e);\n        }\n        if (!inflater.finished()) {\n            throw new RuntimeException(\"PBF blob contains incomplete compressed data.\");\n        }\n        inflater.end();\n    } else {\n        throw new RuntimeException(\"PBF blob uses unsupported compression, only raw or zlib may be used.\");\n    }\n    return blobData;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.<init>", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.ConnectedComponents.<init>" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param edgeTransitionFilter\n * \t\tOnly edge transitions accepted by this filter will be considered when we explore the graph.\n * \t\tIf a turn is not accepted the corresponding path will be ignored (edges that are only connected\n * \t\tby a path with such a turn will not be considered to belong to the same component)\n * @param excludeSingleEdgeComponents\n * \t\tif set to true components that only contain a single edge will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponents();\n}", "private EdgeBasedTarjanSCC(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    this.graph = graph;\n    this.edgeTransitionFilter = edgeTransitionFilter;\n    this.explorer = graph.createEdgeExplorer();\n    tarjanStack = new IntArrayDeque();\n    dfsStackPQ = new LongArrayDeque();\n    dfsStackAdj = new IntArrayDeque();\n    components = new ConnectedComponents(excludeSingleEdgeComponents ? -1 : 2 * graph.getEdges());\n    this.excludeSingleEdgeComponents = excludeSingleEdgeComponents;\n}", "ConnectedComponents(int edgeKeys) {\n    components = new ArrayList<>();\n    singleEdgeComponents = new BitSet(Math.max(edgeKeys, 0));\n    if (!singleEdgeComponents.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    biggestComponent = new IntArrayList();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.<init>", "com.graphhopper.routing.subnetwork.TarjanSCC.ConnectedComponents.<init>" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param excludeSingleNodeComponents\n * \t\tif set to true components that only contain a single node will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponents();\n}", "private TarjanSCC(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    this.graph = graph;\n    this.edgeFilter = edgeFilter;\n    explorer = graph.createEdgeExplorer(edgeFilter);\n    nodeIndex = new int[graph.getNodes()];\n    nodeLowLink = new int[graph.getNodes()];\n    Arrays.fill(nodeIndex, -1);\n    Arrays.fill(nodeLowLink, -1);\n    nodeOnStack = new BitSet(graph.getNodes());\n    if (!nodeOnStack.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    tarjanStack = new IntArrayDeque();\n    dfsStack = new LongArrayDeque();\n    components = new ConnectedComponents(excludeSingleNodeComponents ? -1 : graph.getNodes());\n    this.excludeSingleNodeComponents = excludeSingleNodeComponents;\n}", "ConnectedComponents(int nodes) {\n    components = new ArrayList<>();\n    singleNodeComponents = new BitSet(Math.max(nodes, 0));\n    if (!singleNodeComponents.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    biggestComponent = new IntArrayList();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays", "com.graphhopper.reader.osm.WayToEdgeConverter.findEdgeChain", "com.graphhopper.reader.osm.WayToEdgeConverter.listFromIterator" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to each other. For example for given\n * from-, via- and to-ways there can be multiple edges associated with each (because each way can be split into\n * multiple edges). We then need to find the from-edge that is connected with one of the via-edges which in turn\n * must be connected with one of the to-edges. We use DFS/backtracking to do this.\n * There can also be *multiple* via-ways, but the concept is the same.\n * Note that there can also be multiple from- or to-*ways*, but only one of each of them should be considered at a\n * time. In contrast to the via-ways there are only multiple from/to-ways, because of restrictions like no_entry or\n * no_exit where there can be multiple from- or to-members. So we need to find one edge-chain for each pair of from-\n * and to-ways.\n * Besides the edge IDs we also return the node IDs that connect the edges, so we can add turn restrictions at these\n * nodes later.\n */\npublic EdgeResult convertForViaWays(LongArrayList fromWays, LongArrayList viaWays, LongArrayList toWays) throws OSMRestrictionException {\n    if ((fromWays.isEmpty() || toWays.isEmpty()) || viaWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from-, via- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    List<IntArrayList> solutions = new ArrayList<>();\n    for (LongCursor fromWay : fromWays)\n        for (LongCursor toWay : toWays)\n            findEdgeChain(fromWay.value, viaWays, toWay.value, solutions);\n\n\n    if (solutions.size() < (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has disconnected member ways\");\n    else if (solutions.size() > (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has member ways that do not form a unique path\");\n\n    return buildResult(solutions, fromWays, viaWays, toWays);\n}", "private void findEdgeChain(long fromWay, LongArrayList viaWays, long toWay, List<IntArrayList> solutions) {\n    // For each edge chain there must be one edge associated with the from-way, at least one for each via-way and one\n    // associated with the to-way. We use DFS with backtracking to find all edge chains that connect an edge\n    // associated with the from-way with one associated with the to-way.\n    IntArrayList viaEdgesForViaWays = new IntArrayList(viaWays.size());\n    for (LongCursor c : viaWays) {\n        Iterator<IntCursor> iterator = edgesByWay.apply(c.value);\n        viaEdgesForViaWays.add(iterator.next().value);\n        iterator.forEachRemaining(i -> viaEdgesForViaWays.add(i.value));\n    }\n    IntArrayList toEdges = listFromIterator(edgesByWay.apply(toWay));\n    // the search starts at *every* from edge\n    edgesByWay.apply(fromWay).forEachRemaining(from -> {\n        EdgeIteratorState edge = baseGraph.getEdgeIteratorState(from.value, Integer.MIN_VALUE);\n        explore(viaEdgesForViaWays, toEdges, edge.getBaseNode(), 0, IntArrayList.from(edge.getEdge(), edge.getBaseNode()), solutions);\n        explore(viaEdgesForViaWays, toEdges, edge.getAdjNode(), 0, IntArrayList.from(edge.getEdge(), edge.getAdjNode()), solutions);\n    });\n}", "private static IntArrayList listFromIterator(Iterator<IntCursor> iterator) {\n    IntArrayList result = new IntArrayList();\n    iterator.forEachRemaining(c -> result.add(c.value));\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.ArrayEdgeIntAccess.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ev.ArrayEdgeIntAccess.<init>" ],
    "fullMethods" : [ "public ArrayEdgeIntAccess(int intsPerEdge) {\n    this.intsPerEdge = intsPerEdge;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ViaRouting.lookup",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ViaRouting.lookup" ],
    "fullMethods" : [ "/**\n *\n * @throws MultiplePointsNotFoundException\n * \t\tin case one or more points could not be resolved\n */\npublic static List<Snap> lookup(EncodedValueLookup lookup, List<GHPoint> points, EdgeFilter snapFilter, LocationIndex locationIndex, List<String> snapPreventions, List<String> pointHints, DirectedEdgeFilter directedSnapFilter, List<Double> headings) {\n    if (points.size() < 2)\n        throw new IllegalArgumentException(\"At least 2 points have to be specified, but was:\" + points.size());\n\n    final EnumEncodedValue<RoadClass> roadClassEnc = lookup.getEnumEncodedValue(RoadClass.KEY, RoadClass.class);\n    final EnumEncodedValue<RoadEnvironment> roadEnvEnc = lookup.getEnumEncodedValue(RoadEnvironment.KEY, RoadEnvironment.class);\n    EdgeFilter strictEdgeFilter = (snapPreventions.isEmpty()) ? snapFilter : new SnapPreventionEdgeFilter(snapFilter, roadClassEnc, roadEnvEnc, snapPreventions);\n    List<Snap> snaps = new ArrayList<>(points.size());\n    IntArrayList pointsNotFound = new IntArrayList();\n    for (int placeIndex = 0; placeIndex < points.size(); placeIndex++) {\n        GHPoint point = points.get(placeIndex);\n        Snap snap = null;\n        if ((placeIndex < headings.size()) && (!Double.isNaN(headings.get(placeIndex)))) {\n            if ((!pointHints.isEmpty()) && (!Helper.isEmpty(pointHints.get(placeIndex))))\n                throw new IllegalArgumentException((\"Cannot specify heading and point_hint at the same time. \" + \"Make sure you specify either an empty point_hint (String) or a NaN heading (double) for point \") + placeIndex);\n\n            snap = locationIndex.findClosest(point.lat, point.lon, new HeadingEdgeFilter(directedSnapFilter, headings.get(placeIndex), point));\n        } else if (!pointHints.isEmpty()) {\n            snap = locationIndex.findClosest(point.lat, point.lon, new NameSimilarityEdgeFilter(strictEdgeFilter, pointHints.get(placeIndex), point, 170));\n        } else if (!snapPreventions.isEmpty()) {\n            snap = locationIndex.findClosest(point.lat, point.lon, strictEdgeFilter);\n        }\n        if ((snap == null) || (!snap.isValid()))\n            snap = locationIndex.findClosest(point.lat, point.lon, snapFilter);\n\n        if (!snap.isValid())\n            pointsNotFound.add(placeIndex);\n\n        snaps.add(snap);\n    }\n    if (!pointsNotFound.isEmpty())\n        throw new MultiplePointsNotFoundException(pointsNotFound);\n\n    return snaps;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.<init>", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.ConnectedComponents.<init>" ],
    "fullMethods" : [ "/**\n * Like {@link #findComponents(Graph, EdgeTransitionFilter, boolean)}, but the search only starts at the\n * given edges. This does not mean the search cannot expand to other edges, but this can be controlled by the\n * edgeTransitionFilter. This method does not return single edge components (the excludeSingleEdgeComponents option is\n * set to true).\n */\npublic static ConnectedComponents findComponentsForStartEdges(Graph graph, EdgeTransitionFilter edgeTransitionFilter, IntContainer edges) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, true).findComponentsForStartEdges(edges);\n}", "private EdgeBasedTarjanSCC(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    this.graph = graph;\n    this.edgeTransitionFilter = edgeTransitionFilter;\n    this.explorer = graph.createEdgeExplorer();\n    tarjanStack = new IntArrayDeque();\n    dfsStackPQ = new LongArrayDeque();\n    dfsStackAdj = new IntArrayDeque();\n    components = new ConnectedComponents(excludeSingleEdgeComponents ? -1 : 2 * graph.getEdges());\n    this.excludeSingleEdgeComponents = excludeSingleEdgeComponents;\n}", "ConnectedComponents(int edgeKeys) {\n    components = new ArrayList<>();\n    singleEdgeComponents = new BitSet(Math.max(edgeKeys, 0));\n    if (!singleEdgeComponents.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    biggestComponent = new IntArrayList();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.edgeBased",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.edgeBased", "com.graphhopper.routing.ch.CHPreparationGraph.<init>" ],
    "fullMethods" : [ "public static CHPreparationGraph edgeBased(int nodes, int edges, TurnCostFunction turnCostFunction) {\n    return new CHPreparationGraph(nodes, edges, true, turnCostFunction);\n}", "/**\n *\n * @param nodes\n * \t\t(fixed) number of nodes of the graph\n * @param edges\n * \t\tthe maximum number of (non-shortcut) edges in this graph. edges-1 is the maximum edge id that may\n * \t\tbe used.\n */\nprivate CHPreparationGraph(int nodes, int edges, boolean edgeBased, TurnCostFunction turnCostFunction) {\n    this.turnCostFunction = turnCostFunction;\n    this.nodes = nodes;\n    this.edges = edges;\n    this.edgeBased = edgeBased;\n    prepareEdgesOut = new PrepareEdge[nodes];\n    prepareEdgesIn = new PrepareEdge[nodes];\n    shortcutsByPrepareEdges = new IntArrayList();\n    degrees = new int[nodes];\n    origGraphBuilder = (edgeBased) ? new OrigGraph.Builder() : null;\n    neighborSet = new IntScatterSet();\n    nextShortcutId = edges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.index.IndexStructureInfo.create",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.index.IndexStructureInfo.create" ],
    "fullMethods" : [ "public static IndexStructureInfo create(BBox bounds, int minResolutionInMeter) {\n    // I still need to be able to save and load an empty LocationIndex, and I can't when the extent\n    // is zero.\n    if (!bounds.isValid())\n        bounds = new BBox(-10.0, 10.0, -10.0, 10.0);\n\n    double lat = Math.min(Math.abs(bounds.maxLat), Math.abs(bounds.minLat));\n    double maxDistInMeter = Math.max(((bounds.maxLat - bounds.minLat) / 360) * C, ((bounds.maxLon - bounds.minLon) / 360) * DIST_EARTH.calcCircumference(lat));\n    double tmp = maxDistInMeter / minResolutionInMeter;\n    tmp = tmp * tmp;\n    IntArrayList tmpEntries = new IntArrayList();\n    // the last one is always 4 to reduce costs if only a single entry\n    tmp /= 4;\n    while (tmp > 1) {\n        int tmpNo;\n        if (tmp >= 16) {\n            tmpNo = 16;\n        } else if (tmp >= 4) {\n            tmpNo = 4;\n        } else {\n            break;\n        }\n        tmpEntries.add(tmpNo);\n        tmp /= tmpNo;\n    } \n    tmpEntries.add(4);\n    int[] entries = tmpEntries.toArray();\n    if (entries.length < 1) {\n        // at least one depth should have been specified\n        throw new IllegalStateException(\"depth needs to be at least 1\");\n    }\n    int depth = entries.length;\n    byte[] shifts = new byte[depth];\n    int lastEntry = entries[0];\n    for (int i1 = 0; i1 < depth; i1++) {\n        if (lastEntry < entries[i1]) {\n            throw new IllegalStateException(\"entries should decrease or stay but was:\" + Arrays.toString(entries));\n        }\n        lastEntry = entries[i1];\n        shifts[i1] = getShift(entries[i1]);\n    }\n    int shiftSum = 0;\n    long parts = 1;\n    for (int i = 0; i < shifts.length; i++) {\n        shiftSum += shifts[i];\n        parts *= entries[i];\n    }\n    if (shiftSum > 64)\n        throw new IllegalStateException(\"sum of all shifts does not fit into a long variable\");\n\n    parts = ((int) (Math.round(Math.sqrt(parts))));\n    return new IndexStructureInfo(entries, shifts, new PixelGridTraversal(((int) (parts)), bounds), new SpatialKeyAlgo(shiftSum, bounds), bounds, ((int) (parts)));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.withoutConsecutiveDuplicates",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.withoutConsecutiveDuplicates" ],
    "fullMethods" : [ "/**\n * Creates a copy of the given list where all consecutive duplicates are removed\n */\npublic static IntIndexedContainer withoutConsecutiveDuplicates(IntIndexedContainer arr) {\n    IntArrayList result = new IntArrayList();\n    if (arr.isEmpty())\n        return result;\n\n    int prev = arr.get(0);\n    result.add(prev);\n    for (int i = 1; i < arr.size(); i++) {\n        int val = arr.get(i);\n        if (val != prev)\n            result.add(val);\n\n        prev = val;\n    }\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.<init>", "com.graphhopper.routing.subnetwork.TarjanSCC.ConnectedComponents.<init>" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponentsRecursive();\n}", "private TarjanSCC(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    this.graph = graph;\n    this.edgeFilter = edgeFilter;\n    explorer = graph.createEdgeExplorer(edgeFilter);\n    nodeIndex = new int[graph.getNodes()];\n    nodeLowLink = new int[graph.getNodes()];\n    Arrays.fill(nodeIndex, -1);\n    Arrays.fill(nodeLowLink, -1);\n    nodeOnStack = new BitSet(graph.getNodes());\n    if (!nodeOnStack.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    tarjanStack = new IntArrayDeque();\n    dfsStack = new LongArrayDeque();\n    components = new ConnectedComponents(excludeSingleNodeComponents ? -1 : graph.getNodes());\n    this.excludeSingleNodeComponents = excludeSingleNodeComponents;\n}", "ConnectedComponents(int nodes) {\n    components = new ArrayList<>();\n    singleNodeComponents = new BitSet(Math.max(nodes, 0));\n    if (!singleNodeComponents.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    biggestComponent = new IntArrayList();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgesMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgesMap.<init>" ],
    "fullMethods" : [ "WayToEdgesMap() {\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.<init>" ],
    "fullMethods" : [ "public Path(Graph graph) {\n    this.graph = graph;\n    this.nodeAccess = graph.getNodeAccess();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.GHUtility.comparePaths",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.GHUtility.comparePaths", "com.graphhopper.util.GHUtility.pathsEqualExceptOneEdge" ],
    "fullMethods" : [ "public static List<String> comparePaths(Path refPath, Path path, int source, int target, long seed) {\n    List<String> strictViolations = new ArrayList<>();\n    double refWeight = refPath.getWeight();\n    double weight = path.getWeight();\n    if (Math.abs(refWeight - weight) > 0.01) {\n        LOGGER.warn(\"expected: \" + refPath.calcNodes());\n        LOGGER.warn(\"given:    \" + path.calcNodes());\n        LOGGER.warn(\"seed: \" + seed);\n        fail(((((((((\"wrong weight: \" + source) + \"->\") + target) + \"\\nexpected: \") + refWeight) + \"\\ngiven:    \") + weight) + \"\\nseed: \") + seed);\n    }\n    if (Math.abs(path.getDistance() - refPath.getDistance()) > 0.1) {\n        strictViolations.add(((((((\"wrong distance \" + source) + \"->\") + target) + \", expected: \") + refPath.getDistance()) + \", given: \") + path.getDistance());\n    }\n    if (Math.abs(path.getTime() - refPath.getTime()) > 50) {\n        strictViolations.add(((((((\"wrong time \" + source) + \"->\") + target) + \", expected: \") + refPath.getTime()) + \", given: \") + path.getTime());\n    }\n    IntIndexedContainer refNodes = refPath.calcNodes();\n    IntIndexedContainer pathNodes = path.calcNodes();\n    if (!refNodes.equals(pathNodes)) {\n        // sometimes there are paths including an edge a-c that has the same distance as the two edges a-b-c. in this\n        // case both options are valid best paths. we only check for this most simple and frequent case here...\n        if (path.getGraph() != refPath.getGraph())\n            fail(\"path and refPath graphs are different\");\n\n        if (!pathsEqualExceptOneEdge(path.getGraph(), refNodes, pathNodes))\n            strictViolations.add(((((((\"wrong nodes \" + source) + \"->\") + target) + \"\\nexpected: \") + refNodes) + \"\\ngiven:    \") + pathNodes);\n\n    }\n    return strictViolations;\n}", "/**\n * Sometimes the graph can contain edges like this:\n * A--C\n * \\-B|\n * where A-C is the same distance as A-B-C. In this case the shortest path is not well defined in terms of nodes.\n * This method checks if two node-paths are equal except for such an edge.\n */\nprivate static boolean pathsEqualExceptOneEdge(Graph graph, IntIndexedContainer p1, IntIndexedContainer p2) {\n    if (p1.equals(p2))\n        throw new IllegalArgumentException(\"paths are equal\");\n\n    if (Math.abs(p1.size() - p2.size()) != 1)\n        return false;\n\n    IntIndexedContainer shorterPath = (p1.size() < p2.size()) ? p1 : p2;\n    IntIndexedContainer longerPath = (p1.size() < p2.size()) ? p2 : p1;\n    if (shorterPath.size() < 2)\n        return false;\n\n    IntArrayList indicesWithDifferentNodes = new IntArrayList();\n    for (int i = 1; i < shorterPath.size(); i++) {\n        if (shorterPath.get(i - indicesWithDifferentNodes.size()) != longerPath.get(i)) {\n            indicesWithDifferentNodes.add(i);\n        }\n    }\n    if (indicesWithDifferentNodes.size() != 1)\n        return false;\n\n    int b = indicesWithDifferentNodes.get(0);\n    int a = b - 1;\n    int c = b + 1;\n    assert shorterPath.get(a) == longerPath.get(a);\n    assert shorterPath.get(b) != longerPath.get(b);\n    if (shorterPath.get(b) != longerPath.get(c))\n        return false;\n\n    double distABC = getMinDist(graph, longerPath.get(a), longerPath.get(b)) + getMinDist(graph, longerPath.get(b), longerPath.get(c));\n    double distAC = getMinDist(graph, shorterPath.get(a), longerPath.get(c));\n    if (Math.abs(distABC - distAC) > 0.1)\n        return false;\n\n    LOGGER.info(((((((((((\"Distance \" + shorterPath.get(a)) + \"-\") + longerPath.get(c)) + \" is the same as distance \") + longerPath.get(a)) + \"-\") + longerPath.get(b)) + \"-\") + longerPath.get(c)) + \" -> there are multiple possibilities \") + \"for shortest paths\");\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.<init>", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.ConnectedComponents.<init>" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeTransitionFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponentsRecursive();\n}", "private EdgeBasedTarjanSCC(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    this.graph = graph;\n    this.edgeTransitionFilter = edgeTransitionFilter;\n    this.explorer = graph.createEdgeExplorer();\n    tarjanStack = new IntArrayDeque();\n    dfsStackPQ = new LongArrayDeque();\n    dfsStackAdj = new IntArrayDeque();\n    components = new ConnectedComponents(excludeSingleEdgeComponents ? -1 : 2 * graph.getEdges());\n    this.excludeSingleEdgeComponents = excludeSingleEdgeComponents;\n}", "ConnectedComponents(int edgeKeys) {\n    components = new ArrayList<>();\n    singleEdgeComponents = new BitSet(Math.max(edgeKeys, 0));\n    if (!singleEdgeComponents.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    biggestComponent = new IntArrayList();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.NodeBasedWitnessPathSearcher.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.NodeBasedWitnessPathSearcher.<init>" ],
    "fullMethods" : [ "public NodeBasedWitnessPathSearcher(CHPreparationGraph graph) {\n    outEdgeExplorer = graph.createOutEdgeExplorer();\n    weights = new double[graph.getNodes()];\n    Arrays.fill(weights, Double.POSITIVE_INFINITY);\n    heap = new IntFloatBinaryHeap(1000);\n    changedNodes = new IntArrayList();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.TurnCostStorage.sortNodes",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.TurnCostStorage.sortNodes" ],
    "fullMethods" : [ "public void sortNodes() {\n    IntArrayList tcFroms = new IntArrayList();\n    IntArrayList tcTos = new IntArrayList();\n    IntArrayList tcFlags = new IntArrayList();\n    IntArrayList tcNexts = new IntArrayList();\n    for (int i = 0; i < turnCostsCount; i++) {\n        long pointer = toPointer(i);\n        tcFroms.add(turnCosts.getInt(pointer + TC_FROM));\n        tcTos.add(turnCosts.getInt(pointer + TC_TO));\n        tcFlags.add(turnCosts.getInt(pointer + TC_FLAGS));\n        tcNexts.add(turnCosts.getInt(pointer + TC_NEXT));\n    }\n    long turnCostsCountBefore = turnCostsCount;\n    turnCostsCount = 0;\n    for (int node = 0; node < baseGraph.getNodes(); node++) {\n        boolean firstForNode = true;\n        int turnCostIndex = baseGraph.getNodeAccess().getTurnCostIndex(node);\n        while (turnCostIndex != NO_TURN_ENTRY) {\n            if (firstForNode) {\n                baseGraph.getNodeAccess().setTurnCostIndex(node, turnCostsCount);\n            } else {\n                long prevPointer = toPointer(turnCostsCount - 1);\n                turnCosts.setInt(prevPointer + TC_NEXT, turnCostsCount);\n            }\n            long pointer = toPointer(turnCostsCount);\n            turnCosts.setInt(pointer + TC_FROM, tcFroms.get(turnCostIndex));\n            turnCosts.setInt(pointer + TC_TO, tcTos.get(turnCostIndex));\n            turnCosts.setInt(pointer + TC_FLAGS, tcFlags.get(turnCostIndex));\n            turnCosts.setInt(pointer + TC_NEXT, NO_TURN_ENTRY);\n            turnCostsCount++;\n            firstForNode = false;\n            turnCostIndex = tcNexts.get(turnCostIndex);\n        } \n    }\n    if (turnCostsCountBefore != turnCostsCount)\n        throw new IllegalStateException(((\"Turn cost count changed unexpectedly: \" + turnCostsCountBefore) + \" -> \") + turnCostsCount);\n\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve" ],
    "fullMethods" : [ "public static void sortGraphAlongHilbertCurve(BaseGraph graph) {\n    logger.info(\"sorting graph along Hilbert curve...\");\n    StopWatch sw = StopWatch.started();\n    NodeAccess na = graph.getNodeAccess();\n    final int order = 31;// using 15 would allow us to use ints for sortIndices, but this would result in (marginally) slower routing\n\n    LongArrayList sortIndices = new LongArrayList();\n    for (int node = 0; node < graph.getNodes(); node++)\n        sortIndices.add(latLonToHilbertIndex(na.getLat(node), na.getLon(node), order));\n\n    int[] nodeOrder = IndirectSort.mergesort(0, graph.getNodes(), (nodeA, nodeB) -> Long.compare(sortIndices.get(nodeA), sortIndices.get(nodeB)));\n    EdgeExplorer explorer = graph.createEdgeExplorer();\n    int edges = graph.getEdges();\n    IntArrayList edgeOrder = new IntArrayList();\n    BitSet edgesFound = new BitSet(edges);\n    for (int node : nodeOrder) {\n        EdgeIterator iter = explorer.setBaseNode(node);\n        while (iter.next()) {\n            if (!edgesFound.get(iter.getEdge())) {\n                edgeOrder.add(iter.getEdge());\n                edgesFound.set(iter.getEdge());\n            }\n        } \n    }\n    IntArrayList newEdgesByOldEdges = ArrayUtil.invert(edgeOrder);\n    IntArrayList newNodesByOldNodes = IntArrayList.from(ArrayUtil.invert(nodeOrder));\n    logger.info(\"calculating sort order took: \" + sw.stop().getTimeString());\n    sortGraphForGivenOrdering(graph, newNodesByOldNodes, newEdgesByOldEdges);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.DijkstraOneToMany.IntArrayListWithCap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.DijkstraOneToMany.IntArrayListWithCap.<init>" ],
    "fullMethods" : [ "public IntArrayListWithCap() {\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.nodeBased",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.nodeBased", "com.graphhopper.routing.ch.CHPreparationGraph.<init>" ],
    "fullMethods" : [ "public static CHPreparationGraph nodeBased(int nodes, int edges) {\n    return new CHPreparationGraph(nodes, edges, false, (in, via, out) -> 0);\n}", "/**\n *\n * @param nodes\n * \t\t(fixed) number of nodes of the graph\n * @param edges\n * \t\tthe maximum number of (non-shortcut) edges in this graph. edges-1 is the maximum edge id that may\n * \t\tbe used.\n */\nprivate CHPreparationGraph(int nodes, int edges, boolean edgeBased, TurnCostFunction turnCostFunction) {\n    this.turnCostFunction = turnCostFunction;\n    this.nodes = nodes;\n    this.edges = edges;\n    this.edgeBased = edgeBased;\n    prepareEdgesOut = new PrepareEdge[nodes];\n    prepareEdgesIn = new PrepareEdge[nodes];\n    shortcutsByPrepareEdges = new IntArrayList();\n    degrees = new int[nodes];\n    origGraphBuilder = (edgeBased) ? new OrigGraph.Builder() : null;\n    neighborSet = new IntScatterSet();\n    nextShortcutId = edges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaNode" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to the given via-node.\n * For each way there can be multiple edge IDs and there should be exactly one that is adjacent to the via-node\n * for each way. Otherwise we throw {@link OSMRestrictionException}\n */\npublic NodeResult convertForViaNode(LongArrayList fromWays, int viaNode, LongArrayList toWays) throws OSMRestrictionException {\n    if (fromWays.isEmpty() || toWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    NodeResult result = new NodeResult(fromWays.size(), toWays.size());\n    for (LongCursor fromWay : fromWays)\n        edgesByWay.apply(fromWay.value).forEachRemaining(e -> {\n            if (baseGraph.isAdjacentToNode(e.value, viaNode))\n                result.fromEdges.add(e.value);\n\n        });\n\n    if (result.fromEdges.size() < fromWays.size())\n        throw new OSMRestrictionException(\"has from-member ways that aren't adjacent to the via-member node\");\n    else if (result.fromEdges.size() > fromWays.size())\n        throw new OSMRestrictionException(\"has from-member ways that aren't split at the via-member node\");\n\n    for (LongCursor toWay : toWays)\n        edgesByWay.apply(toWay.value).forEachRemaining(e -> {\n            if (baseGraph.isAdjacentToNode(e.value, viaNode))\n                result.toEdges.add(e.value);\n\n        });\n\n    if (result.toEdges.size() < toWays.size())\n        throw new OSMRestrictionException(\"has to-member ways that aren't adjacent to the via-member node\");\n    else if (result.toEdges.size() > toWays.size())\n        throw new OSMRestrictionException(\"has to-member ways that aren't split at the via-member node\");\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WaySegmentParser.Pass1Handler.handleWay",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WaySegmentParser.Pass1Handler.handleWay" ],
    "fullMethods" : [ "@Override\npublic void handleWay(ReaderWay way) {\n    if (!handledWays) {\n        LOGGER.info(\"pass1 - start reading OSM ways\");\n        handledWays = true;\n    }\n    if (handledRelations)\n        throw new IllegalStateException(\"OSM way elements must be located before relation elements in OSM file\");\n\n    if (((++wayCounter) % 10000000) == 0)\n        LOGGER.info(((((((\"pass1 - processed ways: \" + nf(wayCounter)) + \", accepted ways: \") + nf(acceptedWays)) + \", way nodes: \") + nf(nodeData.getNodeCount())) + \", \") + Helper.getMemInfo());\n\n    if (!wayFilter.test(way))\n        return;\n\n    acceptedWays++;\n    for (LongCursor node : way.getNodes()) {\n        final boolean isEnd = (node.index == 0) || (node.index == (way.getNodes().size() - 1));\n        final long osmId = node.value;\n        // connection nodes are those where (only) two OSM ways are connected at their ends\n        nodeData.setOrUpdateNodeType(osmId, isEnd ? END_NODE : INTERMEDIATE_NODE, prev -> (prev == END_NODE) && isEnd ? CONNECTION_NODE : JUNCTION_NODE);\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionTopologyForGraph",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionTopologyForGraph", "com.graphhopper.reader.osm.OSMRestrictionConverter.membersExist" ],
    "fullMethods" : [ "/**\n * OSM restriction relations specify turn restrictions between OSM ways (of course). This method rebuilds the\n * topology of such a relation in the graph representation, where the turn restrictions are specified in terms of edge/node IDs instead\n * of OSM IDs.\n *\n * @throws OSMRestrictionException\n * \t\tif the given relation is either not valid in some way and/or cannot be handled and\n * \t\tshall be ignored\n */\npublic static Triple<ReaderRelation, RestrictionTopology, RestrictionMembers> buildRestrictionTopologyForGraph(BaseGraph baseGraph, ReaderRelation relation, LongFunction<Iterator<IntCursor>> edgesByWay) throws OSMRestrictionException {\n    if (!isTurnRestriction(relation))\n        throw new IllegalArgumentException(\"expected a turn restriction: \" + relation.getTags());\n\n    RestrictionMembers restrictionMembers = extractMembers(relation);\n    if (!membersExist(restrictionMembers, edgesByWay, relation))\n        throw OSMRestrictionException.withoutWarning();\n\n    // every OSM way might be split into *multiple* edges, so now we need to figure out which edges are the ones\n    // that are actually part of the given relation\n    WayToEdgeConverter wayToEdgeConverter = new WayToEdgeConverter(baseGraph, edgesByWay);\n    if (restrictionMembers.isViaWay()) {\n        // For now let's ignore all via-way restrictions with duplicate from/to/via-members\n        // until we find cases where this is too strict.\n        if (containsDuplicateWays(restrictionMembers))\n            throw new OSMRestrictionException(\"contains duplicate from-/via-/to-members\");\n\n        WayToEdgeConverter.EdgeResult res = wayToEdgeConverter.convertForViaWays(restrictionMembers.getFromWays(), restrictionMembers.getViaWays(), restrictionMembers.getToWays());\n        return new Triple<>(relation, RestrictionTopology.way(res.getFromEdges(), res.getViaEdges(), res.getToEdges(), res.getNodes()), restrictionMembers);\n    } else {\n        int viaNode = relation.getTag(\"graphhopper:via_node\", -1);\n        if (viaNode < 0)\n            throw new IllegalStateException(\"For some reason we did not set graphhopper:via_node for this relation: \" + relation.getId());\n\n        WayToEdgeConverter.NodeResult res = wayToEdgeConverter.convertForViaNode(restrictionMembers.getFromWays(), viaNode, restrictionMembers.getToWays());\n        return new Triple<>(relation, RestrictionTopology.node(res.getFromEdges(), viaNode, res.getToEdges()), restrictionMembers);\n    }\n}", "private static boolean membersExist(RestrictionMembers members, LongFunction<Iterator<IntCursor>> edgesByWay, ReaderRelation relation) {\n    for (LongCursor c : members.getAllWays())\n        if (!edgesByWay.apply(c.value).hasNext()) {\n            // this happens for example at the map borders or when certain ways like footways are excluded\n            LOGGER.debug((((\"Restriction relation \" + relation.getId()) + \" uses excluded way \") + c.value) + \". Relation ignored.\");\n            return false;\n        }\n\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to each other. For example for given\n * from-, via- and to-ways there can be multiple edges associated with each (because each way can be split into\n * multiple edges). We then need to find the from-edge that is connected with one of the via-edges which in turn\n * must be connected with one of the to-edges. We use DFS/backtracking to do this.\n * There can also be *multiple* via-ways, but the concept is the same.\n * Note that there can also be multiple from- or to-*ways*, but only one of each of them should be considered at a\n * time. In contrast to the via-ways there are only multiple from/to-ways, because of restrictions like no_entry or\n * no_exit where there can be multiple from- or to-members. So we need to find one edge-chain for each pair of from-\n * and to-ways.\n * Besides the edge IDs we also return the node IDs that connect the edges, so we can add turn restrictions at these\n * nodes later.\n */\npublic EdgeResult convertForViaWays(LongArrayList fromWays, LongArrayList viaWays, LongArrayList toWays) throws OSMRestrictionException {\n    if ((fromWays.isEmpty() || toWays.isEmpty()) || viaWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from-, via- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    List<IntArrayList> solutions = new ArrayList<>();\n    for (LongCursor fromWay : fromWays)\n        for (LongCursor toWay : toWays)\n            findEdgeChain(fromWay.value, viaWays, toWay.value, solutions);\n\n\n    if (solutions.size() < (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has disconnected member ways\");\n    else if (solutions.size() > (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has member ways that do not form a unique path\");\n\n    return buildResult(solutions, fromWays, viaWays, toWays);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WaySegmentParser.Pass2Handler.handleWay",
    "thirdPartyMethod" : "com.carrotsearch.hppc.LongArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WaySegmentParser.Pass2Handler.handleWay" ],
    "fullMethods" : [ "@Override\npublic void handleWay(ReaderWay way) {\n    if (!handledWays) {\n        LOGGER.info(\"pass2 - start reading OSM ways\");\n        handledWays = true;\n    }\n    if (handledRelations)\n        throw new IllegalStateException(\"OSM way elements must be located before relation elements in OSM file\");\n\n    if (((++wayCounter) % 10000000) == 0)\n        LOGGER.info(((\"pass2 - processed ways: \" + nf(wayCounter)) + \", \") + Helper.getMemInfo());\n\n    if (!wayFilter.test(way))\n        return;\n\n    List<SegmentNode> segment = new ArrayList<>(way.getNodes().size());\n    for (LongCursor node : way.getNodes())\n        segment.add(new SegmentNode(node.value, nodeData.getId(node.value), nodeData.getTags(node.value)));\n\n    wayPreprocessor.preprocessWay(way, osmNodeId -> nodeData.getCoordinates(nodeData.getId(osmNodeId)), osmNodeId -> nodeData.getTags(osmNodeId));\n    splitWayAtJunctionsAndEmptySections(segment, way);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.hashCode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.hashCode",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.hashCode" ],
    "fullMethods" : [ "@Override\npublic int hashCode() {\n    return (31 * viaNodes.hashCode()) + edgeKeys.hashCode();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayDeque.removeFirst",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity" ],
    "fullMethods" : [ "/**\n *\n * @param radius\n * \t\tin meters\n * @param calcRoadFactor\n * \t\tweighting function. use this to define how different kinds of roads shall contribute to the calculated road density\n * @return the road density in the vicinity of the given edge, i.e. the weighted road length divided by the squared radius\n */\npublic double calcRoadDensity(EdgeIteratorState edge, double radius, ToDoubleFunction<EdgeIteratorState> calcRoadFactor) {\n    visited.clear();\n    deque.head = deque.tail = 0;\n    double totalRoadWeight = 0;\n    NodeAccess na = graph.getNodeAccess();\n    int baseNode = edge.getBaseNode();\n    int adjNode = edge.getAdjNode();\n    GHPoint center = new GHPoint(getLat(na, baseNode, adjNode), getLon(na, baseNode, adjNode));\n    deque.addLast(baseNode);\n    deque.addLast(adjNode);\n    visited.add(baseNode);\n    visited.add(adjNode);\n    // we just do a BFS search and sum up all the road lengths\n    final double radiusNormalized = DIST_PLANE.calcNormalizedDist(radius);\n    // for long tunnels or motorway sections where the distance between the exit points and the\n    // center is larger than the radius it is important to continue the search even outside the radius\n    final int minPolls = ((int) (radius / 2));\n    int polls = 0;\n    while (!deque.isEmpty()) {\n        int node = deque.removeFirst();\n        polls++;\n        double distance = DIST_PLANE.calcNormalizedDist(center.lat, center.lon, na.getLat(node), na.getLon(node));\n        if ((polls > minPolls) && (distance > radiusNormalized))\n            continue;\n\n        EdgeIterator iter = edgeExplorer.setBaseNode(node);\n        while (iter.next()) {\n            if (visited.contains(iter.getAdjNode()))\n                continue;\n\n            visited.add(iter.getAdjNode());\n            if (distance <= radiusNormalized)\n                totalRoadWeight += calcRoadFactor.applyAsDouble(iter);\n\n            deque.addLast(iter.getAdjNode());\n        } \n    } \n    return (totalRoadWeight / radius) / radius;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.Triangulation.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.isochrone.algorithm.Triangulation.<init>" ],
    "fullMethods" : [ "Triangulation() {\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.pbf.PbfBlobDecoder.run",
    "thirdPartyMethod" : "org.openstreetmap.osmosis.osmbinary.Fileformat.Blob.hasZlibData",
    "thirdPartyPackage" : "org.openstreetmap.osmosis.osmbinary.Fileformat",
    "path" : [ "com.graphhopper.reader.osm.pbf.PbfBlobDecoder.run", "com.graphhopper.reader.osm.pbf.PbfBlobDecoder.runAndTrapExceptions", "com.graphhopper.reader.osm.pbf.PbfBlobDecoder.readBlobContent" ],
    "fullMethods" : [ "@Override\npublic void run() {\n    try {\n        runAndTrapExceptions();\n        listener.complete(decodedEntities);\n    } catch (RuntimeException e) {\n        // exception is properly rethrown in PbfDecoder.sendResultsToSink\n        listener.error(e);\n    }\n}", "private void runAndTrapExceptions() {\n    try {\n        decodedEntities = new ArrayList<>();\n        if (\"OSMHeader\".equals(blobType)) {\n            processOsmHeader(readBlobContent());\n        } else if (\"OSMData\".equals(blobType)) {\n            processOsmPrimitives(readBlobContent());\n        } else if (log.isDebugEnabled())\n            log.debug(\"Skipping unrecognised blob type \" + blobType);\n\n    } catch (IOException e) {\n        throw new RuntimeException(\"Unable to process PBF blob\", e);\n    }\n}", "private byte[] readBlobContent() throws IOException {\n    Fileformat.Blob blob = Fileformat.Blob.parseFrom(rawBlob);\n    byte[] blobData;\n    if (blob.hasRaw()) {\n        blobData = blob.getRaw().toByteArray();\n    } else if (blob.hasZlibData()) {\n        Inflater inflater = new Inflater();\n        inflater.setInput(blob.getZlibData().toByteArray());\n        blobData = new byte[blob.getRawSize()];\n        try {\n            inflater.inflate(blobData);\n        } catch (DataFormatException e) {\n            throw new RuntimeException(\"Unable to decompress PBF blob.\", e);\n        }\n        if (!inflater.finished()) {\n            throw new RuntimeException(\"PBF blob contains incomplete compressed data.\");\n        }\n        inflater.end();\n    } else {\n        throw new RuntimeException(\"PBF blob uses unsupported compression, only raw or zlib may be used.\");\n    }\n    return blobData;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate",
    "thirdPartyMethod" : "org.locationtech.jts.triangulate.DelaunayTriangulationBuilder.setTolerance",
    "thirdPartyPackage" : "org.locationtech.jts.triangulate",
    "path" : [ "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate" ],
    "fullMethods" : [ "public Result triangulate(Snap snap, QueryGraph queryGraph, ShortestPathTree shortestPathTree, ToDoubleFunction<ShortestPathTree.IsoLabel> fz, double tolerance) {\n    final NodeAccess na = queryGraph.getNodeAccess();\n    Collection<Coordinate> sites = new ArrayList<>();\n    shortestPathTree.search(snap.getClosestNode(), label -> {\n        double exploreValue = fz.applyAsDouble(label);\n        double lat = na.getLat(label.node);\n        double lon = na.getLon(label.node);\n        Coordinate site = new Coordinate(lon, lat);\n        site.z = exploreValue;\n        sites.add(site);\n        // add a pillar node to increase precision a bit for longer roads\n        if (label.parent != null) {\n            EdgeIteratorState edge = queryGraph.getEdgeIteratorState(label.edge, label.node);\n            PointList innerPoints = edge.fetchWayGeometry(FetchMode.PILLAR_ONLY);\n            if (innerPoints.size() > 0) {\n                int midIndex = innerPoints.size() / 2;\n                // For edge-based routing we might have explored the same edge in two different directions.\n                // Here we make sure we only include the **same** point twice instead of two different ones.\n                if (((innerPoints.size() % 2) == 0) && edge.get(EdgeIteratorState.REVERSE_STATE))\n                    midIndex -= 1;\n\n                double lat2 = innerPoints.getLat(midIndex);\n                double lon2 = innerPoints.getLon(midIndex);\n                Coordinate site2 = new Coordinate(lon2, lat2);\n                site2.z = exploreValue;\n                sites.add(site2);\n            }\n        }\n    });\n    if (sites.size() > (routerConfig.getMaxVisitedNodes() / 3))\n        throw new IllegalArgumentException((\"Too many nodes would be included in post processing (\" + sites.size()) + \"). Let us know if you need this increased.\");\n\n    // Sites may contain repeated coordinates. Especially for edge-based traversal, that's expected -- we visit\n    // each node multiple times.\n    // But that's okay, the triangulator de-dupes by itself, and it keeps the first z-value it sees, which is\n    // what we want.\n    DelaunayTriangulationBuilder triangulationBuilder = new DelaunayTriangulationBuilder();\n    triangulationBuilder.setSites(sites);\n    triangulationBuilder.setTolerance(tolerance);\n    Geometry convexHull = triangulationBuilder.getEdges(new GeometryFactory()).convexHull();\n    // If there's only one site (and presumably also if the convex hull is otherwise degenerated),\n    // the triangulation only contains the frame, and not the site within the frame. Not sure if I agree with that.\n    // See ConformingDelaunayTriangulator, it does include a buffer for the frame, but that buffer is zero\n    // in these cases.\n    // It leads to the following follow-up defect:\n    // computeIsoline fails (returns an empty Multipolygon). This is clearly wrong, since\n    // the idea is that every real (non-frame) vertex has positive-length-edges around it that can be traversed\n    // to get a non-empty polygon.\n    // So we exclude this case for now (it is indeed only a corner-case).\n    if (!(convexHull instanceof Polygon)) {\n        throw new IllegalArgumentException(\"Too few points found. \" + \"Please try a different 'point' or a larger 'time_limit'.\");\n    }\n    QuadEdgeSubdivision tin = triangulationBuilder.getSubdivision();\n    for (Vertex vertex : ((Collection<Vertex>) (tin.getVertices(true)))) {\n        if (tin.isFrameVertex(vertex)) {\n            vertex.setZ(Double.MAX_VALUE);\n        }\n    }\n    ReadableTriangulation triangulation = ReadableTriangulation.wrap(tin);\n    return new Result(triangulation, triangulation.getEdges());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.Polygon.getMaxLon",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Envelope.getMaxX",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.Polygon.getMaxLon" ],
    "fullMethods" : [ "public double getMaxLon() {\n    return envelope.getMaxX();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.BBox.fromEnvelope",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Envelope.getMaxX",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.BBox.fromEnvelope" ],
    "fullMethods" : [ "public static BBox fromEnvelope(Envelope envelope) {\n    return new BBox(envelope.getMinX(), envelope.getMaxX(), envelope.getMinY(), envelope.getMaxY());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.Polygon.toString",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Geometry.getNumPoints",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.Polygon.toString" ],
    "fullMethods" : [ "@Override\npublic String toString() {\n    return (((\"polygon (\" + prepPolygon.getGeometry().getNumPoints()) + \" points,\") + prepPolygon.getGeometry().getNumGeometries()) + \" geometries)\";\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.edgeBased",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntScatterSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.edgeBased", "com.graphhopper.routing.ch.CHPreparationGraph.<init>" ],
    "fullMethods" : [ "public static CHPreparationGraph edgeBased(int nodes, int edges, TurnCostFunction turnCostFunction) {\n    return new CHPreparationGraph(nodes, edges, true, turnCostFunction);\n}", "/**\n *\n * @param nodes\n * \t\t(fixed) number of nodes of the graph\n * @param edges\n * \t\tthe maximum number of (non-shortcut) edges in this graph. edges-1 is the maximum edge id that may\n * \t\tbe used.\n */\nprivate CHPreparationGraph(int nodes, int edges, boolean edgeBased, TurnCostFunction turnCostFunction) {\n    this.turnCostFunction = turnCostFunction;\n    this.nodes = nodes;\n    this.edges = edges;\n    this.edgeBased = edgeBased;\n    prepareEdgesOut = new PrepareEdge[nodes];\n    prepareEdgesIn = new PrepareEdge[nodes];\n    shortcutsByPrepareEdges = new IntArrayList();\n    degrees = new int[nodes];\n    origGraphBuilder = (edgeBased) ? new OrigGraph.Builder() : null;\n    neighborSet = new IntScatterSet();\n    nextShortcutId = edges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.RoadDensityCalculator.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntScatterSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.RoadDensityCalculator.<init>" ],
    "fullMethods" : [ "public RoadDensityCalculator(Graph graph) {\n    this.graph = graph;\n    this.edgeExplorer = graph.createEdgeExplorer();\n    visited = new IntScatterSet();\n    deque = new IntArrayDeque(100);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntScatterSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.nodeBased",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntScatterSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.nodeBased", "com.graphhopper.routing.ch.CHPreparationGraph.<init>" ],
    "fullMethods" : [ "public static CHPreparationGraph nodeBased(int nodes, int edges) {\n    return new CHPreparationGraph(nodes, edges, false, (in, via, out) -> 0);\n}", "/**\n *\n * @param nodes\n * \t\t(fixed) number of nodes of the graph\n * @param edges\n * \t\tthe maximum number of (non-shortcut) edges in this graph. edges-1 is the maximum edge id that may\n * \t\tbe used.\n */\nprivate CHPreparationGraph(int nodes, int edges, boolean edgeBased, TurnCostFunction turnCostFunction) {\n    this.turnCostFunction = turnCostFunction;\n    this.nodes = nodes;\n    this.edges = edges;\n    this.edgeBased = edgeBased;\n    prepareEdgesOut = new PrepareEdge[nodes];\n    prepareEdgesIn = new PrepareEdge[nodes];\n    shortcutsByPrepareEdges = new IntArrayList();\n    degrees = new int[nodes];\n    origGraphBuilder = (edgeBased) ? new OrigGraph.Builder() : null;\n    neighborSet = new IntScatterSet();\n    nextShortcutId = edges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.AbstractBidirAlgo.calcPath",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.AbstractBidirAlgo.calcPath", "com.graphhopper.routing.AbstractBidirAlgo.init", "com.graphhopper.routing.AbstractBidirAlgo.initFrom" ],
    "fullMethods" : [ "@Override\npublic Path calcPath(int from, int to, int fromOutEdge, int toInEdge) {\n    if (((fromOutEdge != ANY_EDGE) || (toInEdge != ANY_EDGE)) && (!traversalMode.isEdgeBased())) {\n        throw new IllegalArgumentException(\"Restricting the start/target edges is only possible for edge-based graph traversal\");\n    }\n    this.fromOutEdge = fromOutEdge;\n    this.toInEdge = toInEdge;\n    checkAlreadyRun();\n    setupFinishTime();\n    init(from, 0, to, 0);\n    runAlgo();\n    return extractPath();\n}", "void init(int from, double fromWeight, int to, double toWeight) {\n    initFrom(from, fromWeight);\n    initTo(to, toWeight);\n    postInit(from, to);\n}", "protected void initFrom(int from, double weight) {\n    this.from = from;\n    currFrom = createStartEntry(from, weight, false);\n    pqOpenSetFrom.add(currFrom);\n    if (!traversalMode.isEdgeBased()) {\n        bestWeightMapFrom.put(from, currFrom);\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.AlternativeRoute.searchBest",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.AlternativeRoute.searchBest", "com.graphhopper.routing.AbstractBidirAlgo.runAlgo", "com.graphhopper.routing.AbstractNonCHBidirAlgo.fillEdgesFrom", "com.graphhopper.routing.AbstractNonCHBidirAlgo.fillEdges" ],
    "fullMethods" : [ "public Path searchBest(int from, int to) {\n    init(from, 0, to, 0);\n    // init collections and bestPath.getWeight properly\n    runAlgo();\n    return extractPath();\n}", "protected void runAlgo() {\n    while (((!finished()) && (!isMaxVisitedNodesExceeded())) && (!isTimeoutExceeded())) {\n        if (!finishedFrom)\n            finishedFrom = !fillEdgesFrom();\n\n        if (!finishedTo)\n            finishedTo = !fillEdgesTo();\n\n    } \n}", "@Override\nboolean fillEdgesFrom() {\n    while (true) {\n        if (pqOpenSetFrom.isEmpty())\n            return false;\n\n        currFrom = pqOpenSetFrom.poll();\n        if (!currFrom.isDeleted())\n            break;\n\n    } \n    visitedCountFrom++;\n    if (fromEntryCanBeSkipped()) {\n        return true;\n    }\n    if (fwdSearchCanBeStopped()) {\n        return false;\n    }\n    bestWeightMapOther = bestWeightMapTo;\n    fillEdges(currFrom, pqOpenSetFrom, bestWeightMapFrom, false);\n    return true;\n}", "private void fillEdges(SPTEntry currEdge, PriorityQueue<SPTEntry> prioQueue, IntObjectMap<SPTEntry> bestWeightMap, boolean reverse) {\n    EdgeIterator iter = edgeExplorer.setBaseNode(currEdge.adjNode);\n    while (iter.next()) {\n        if (!accept(iter, currEdge.edge))\n            continue;\n\n        final double weight = calcWeight(iter, currEdge, reverse);\n        if (Double.isInfinite(weight)) {\n            continue;\n        }\n        final int traversalId = traversalMode.createTraversalId(iter, reverse);\n        SPTEntry entry = bestWeightMap.get(traversalId);\n        if (entry == null) {\n            entry = createEntry(iter, weight, currEdge, reverse);\n            bestWeightMap.put(traversalId, entry);\n            prioQueue.add(entry);\n        } else if (entry.getWeightOfVisitedPath() > weight) {\n            // flagging this entry, so it will be ignored when it is polled the next time\n            entry.setDeleted();\n            boolean isBestEntry = (reverse) ? entry == bestBwdEntry : entry == bestFwdEntry;\n            entry = createEntry(iter, weight, currEdge, reverse);\n            bestWeightMap.put(traversalId, entry);\n            prioQueue.add(entry);\n            // if this is the best entry we need to update the best reference as well\n            if (isBestEntry)\n                if (reverse)\n                    bestBwdEntry = entry;\n                else\n                    bestFwdEntry = entry;\n\n\n        } else\n            continue;\n\n        if (updateBestPath) {\n            // only needed for edge-based -> skip the calculation and use dummy value otherwise\n            double edgeWeight = (traversalMode.isEdgeBased()) ? weighting.calcEdgeWeight(iter, reverse) : Double.POSITIVE_INFINITY;\n            // todo: performance - if bestWeightMapOther.get(traversalId) == null, updateBestPath will exit early and we might\n            // have calculated the edgeWeight unnecessarily\n            updateBestPath(edgeWeight, entry, EdgeIterator.NO_EDGE, traversalId, reverse);\n        }\n    } \n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Dijkstra.calcPath",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Dijkstra.calcPath" ],
    "fullMethods" : [ "@Override\npublic Path calcPath(int from, int to) {\n    checkAlreadyRun();\n    setupFinishTime();\n    this.to = to;\n    SPTEntry startEntry = new SPTEntry(from, 0);\n    fromHeap.add(startEntry);\n    if (!traversalMode.isEdgeBased())\n        fromMap.put(from, currEdge);\n\n    runAlgo();\n    return extractPath();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LandmarkStorage.LandmarkExplorer.setStartNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.lm.LandmarkStorage.LandmarkExplorer.setStartNode", "com.graphhopper.routing.AbstractBidirAlgo.initTo" ],
    "fullMethods" : [ "public void setStartNode(int startNode) {\n    if (reverse)\n        initTo(startNode, 0);\n    else\n        initFrom(startNode, 0);\n\n}", "protected void initTo(int to, double weight) {\n    this.to = to;\n    currTo = createStartEntry(to, weight, true);\n    pqOpenSetTo.add(currTo);\n    if (!traversalMode.isEdgeBased()) {\n        bestWeightMapTo.put(to, currTo);\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryGraph.apply",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryGraph.apply" ],
    "fullMethods" : [ "@Override\npublic void apply(int node, QueryOverlay.EdgeChanges edgeChanges) {\n    List<EdgeIteratorState> virtualEdges = new ArrayList<>(edgeChanges.getAdditionalEdges());\n    EdgeIterator mainIter = mainExplorer.setBaseNode(node);\n    while (mainIter.next()) {\n        if (!edgeChanges.getRemovedEdges().contains(mainIter.getEdge())) {\n            virtualEdges.add(mainIter.detach(false));\n        }\n    } \n    virtualEdgesAtRealNodes.put(node, virtualEdges);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.BridgePathFinder.find",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.BridgePathFinder.find" ],
    "fullMethods" : [ "/**\n * Finds all bridge paths starting at a given node and starting edge key.\n *\n * @return a mapping between the target edge keys we can reach via bridge paths and information about the\ncorresponding bridge path\n */\npublic IntObjectMap<BridePathEntry> find(int startInEdgeKey, int startNode, int centerNode) {\n    queue.clear();\n    map.clear();\n    IntObjectMap<BridePathEntry> result = new IntObjectHashMap<>(16, 0.5, HashOrderMixing.constant(123));\n    PrepareCHEntry startEntry = new PrepareCHEntry(NO_EDGE, startInEdgeKey, startInEdgeKey, startNode, 0, 0);\n    map.put(startInEdgeKey, startEntry);\n    queue.add(startEntry);\n    while (!queue.isEmpty()) {\n        PrepareCHEntry currEntry = queue.poll();\n        PrepareGraphEdgeIterator iter = outExplorer.setBaseNode(currEntry.adjNode);\n        while (iter.next()) {\n            if (iter.getAdjNode() == centerNode) {\n                // We arrived at the center node, so we keep expanding the search\n                double weight = (currEntry.weight + graph.getTurnWeight(currEntry.incEdgeKey, currEntry.adjNode, iter.getOrigEdgeKeyFirst())) + iter.getWeight();\n                if (Double.isInfinite(weight))\n                    continue;\n\n                PrepareCHEntry entry = map.get(iter.getOrigEdgeKeyLast());\n                if (entry == null) {\n                    entry = new PrepareCHEntry(iter.getPrepareEdge(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getAdjNode(), weight, currEntry.origEdges + iter.getOrigEdgeCount());\n                    entry.parent = currEntry;\n                    map.put(iter.getOrigEdgeKeyLast(), entry);\n                    queue.add(entry);\n                } else if (weight < entry.weight) {\n                    queue.remove(entry);\n                    entry.prepareEdge = iter.getPrepareEdge();\n                    entry.origEdges = currEntry.origEdges + iter.getOrigEdgeCount();\n                    entry.firstEdgeKey = iter.getOrigEdgeKeyFirst();\n                    entry.weight = weight;\n                    entry.parent = currEntry;\n                    queue.add(entry);\n                }\n            } else if (currEntry.adjNode == centerNode) {\n                // We just left the center node, so we arrived at some neighbor node. Every edge we can reach from\n                // there is a target edge, so we add a bridge path entry for it. We do not continue the search from the\n                // neighbor node anymore\n                double weight = (currEntry.weight + graph.getTurnWeight(currEntry.incEdgeKey, currEntry.adjNode, iter.getOrigEdgeKeyFirst())) + iter.getWeight();\n                if (Double.isInfinite(weight))\n                    continue;\n\n                PrepareGraphOrigEdgeIterator origOutIter = origOutExplorer.setBaseNode(iter.getAdjNode());\n                while (origOutIter.next()) {\n                    double totalWeight = weight + graph.getTurnWeight(iter.getOrigEdgeKeyLast(), iter.getAdjNode(), origOutIter.getOrigEdgeKeyFirst());\n                    if (Double.isInfinite(totalWeight))\n                        continue;\n\n                    BridePathEntry resEntry = result.get(origOutIter.getOrigEdgeKeyFirst());\n                    if (resEntry == null) {\n                        PrepareCHEntry chEntry = new PrepareCHEntry(iter.getPrepareEdge(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getAdjNode(), weight, currEntry.origEdges + iter.getOrigEdgeCount());\n                        chEntry.parent = currEntry;\n                        resEntry = new BridePathEntry(totalWeight, chEntry);\n                        result.put(origOutIter.getOrigEdgeKeyFirst(), resEntry);\n                    } else if (totalWeight < resEntry.weight) {\n                        resEntry.weight = totalWeight;\n                        resEntry.chEntry.prepareEdge = iter.getPrepareEdge();\n                        resEntry.chEntry.firstEdgeKey = iter.getOrigEdgeKeyFirst();\n                        resEntry.chEntry.origEdges = currEntry.origEdges + iter.getOrigEdgeCount();\n                        resEntry.chEntry.incEdgeKey = iter.getOrigEdgeKeyLast();\n                        resEntry.chEntry.weight = weight;\n                        resEntry.chEntry.parent = currEntry;\n                    }\n                } \n            }\n            // We arrived at some node that is not the center node. We do not expand the search as we are only\n            // concerned with finding bridge paths.\n        } \n    } \n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.apply",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.apply" ],
    "fullMethods" : [ "@Override\npublic void apply(int node, QueryOverlay.EdgeChanges edgeChanges) {\n    List<RoutingCHEdgeIteratorState> virtualEdges = new ArrayList<>();\n    for (EdgeIteratorState v : edgeChanges.getAdditionalEdges()) {\n        assert v.getBaseNode() == node;\n        int edge = v.getEdge();\n        if (queryGraph.isVirtualEdge(edge)) {\n            edge = shiftVirtualEdgeIDForCH(edge);\n        }\n        virtualEdges.add(buildVirtualCHEdgeState(v, edge));\n    }\n    RoutingCHEdgeIterator iter = explorer.setBaseNode(node);\n    while (iter.next()) {\n        // shortcuts cannot be in the removed edge set because this was determined on the (base) query graph\n        if (iter.isShortcut()) {\n            virtualEdges.add(new VirtualCHEdgeIteratorState(iter.getEdge(), NO_EDGE, iter.getBaseNode(), iter.getAdjNode(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getSkippedEdge1(), iter.getSkippedEdge2(), iter.getWeight(false), iter.getWeight(true)));\n        } else if (!edgeChanges.getRemovedEdges().contains(iter.getOrigEdge())) {\n            virtualEdges.add(new VirtualCHEdgeIteratorState(iter.getEdge(), iter.getOrigEdge(), iter.getBaseNode(), iter.getAdjNode(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), NO_EDGE, NO_EDGE, iter.getWeight(false), iter.getWeight(true)));\n        }\n    } \n    virtualEdgesAtRealNodes.put(node, virtualEdges);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build", "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build", "com.graphhopper.routing.querygraph.QueryOverlayBuilder.buildEdgeChangesAtRealNodes", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.build", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.build", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.addVirtualEdges" ],
    "fullMethods" : [ "public static QueryOverlay build(int firstVirtualNodeId, int firstVirtualEdgeId, boolean is3D, List<Snap> snaps) {\n    return new QueryOverlayBuilder(firstVirtualNodeId, firstVirtualEdgeId, is3D).build(snaps);\n}", "private QueryOverlay build(List<Snap> resList) {\n    queryOverlay = new QueryOverlay(resList.size(), is3D);\n    buildVirtualEdges(resList);\n    buildEdgeChangesAtRealNodes();\n    return queryOverlay;\n}", "private void buildEdgeChangesAtRealNodes() {\n    EdgeChangeBuilder.build(queryOverlay.getClosestEdges(), queryOverlay.getVirtualEdges(), firstVirtualNodeId, queryOverlay.getEdgeChangesAtRealNodes());\n}", "/**\n * Builds a mapping between real node ids and the set of changes for their adjacent edges.\n *\n * @param edgeChangesAtRealNodes\n * \t\toutput parameter, you need to pass an empty & modifiable map and the results will\n * \t\tbe added to it\n */\nstatic void build(IntArrayList closestEdges, List<VirtualEdgeIteratorState> virtualEdges, int firstVirtualNodeId, IntObjectMap<QueryOverlay.EdgeChanges> edgeChangesAtRealNodes) {\n    new EdgeChangeBuilder(closestEdges, virtualEdges, firstVirtualNodeId, edgeChangesAtRealNodes).build();\n}", "private void build() {\n    final GHIntHashSet towerNodesToChange = new GHIntHashSet(getNumVirtualNodes());\n    // 1. for every real node adjacent to a virtual one we collect the virtual edges, also build a set of\n    // these adjacent real nodes so we can use them in the next step\n    for (int i = 0; i < getNumVirtualNodes(); i++) {\n        // base node\n        EdgeIteratorState baseRevEdge = getVirtualEdge((i * 4) + SNAP_BASE);\n        int towerNode = baseRevEdge.getAdjNode();\n        if (!isVirtualNode(towerNode)) {\n            towerNodesToChange.add(towerNode);\n            addVirtualEdges(true, towerNode, i);\n        }\n        // adj node\n        EdgeIteratorState adjEdge = getVirtualEdge((i * 4) + SNAP_ADJ);\n        towerNode = adjEdge.getAdjNode();\n        if (!isVirtualNode(towerNode)) {\n            towerNodesToChange.add(towerNode);\n            addVirtualEdges(false, towerNode, i);\n        }\n    }\n    // 2. build the list of removed edges for all real nodes adjacent to virtual ones\n    towerNodesToChange.forEach(new IntProcedure() {\n        @Override\n        public void apply(int value) {\n            addRemovedEdges(value);\n        }\n    });\n}", "/**\n * Adds the virtual edges adjacent to the real tower nodes\n */\nprivate void addVirtualEdges(boolean base, int node, int virtNode) {\n    QueryOverlay.EdgeChanges edgeChanges = edgeChangesAtRealNodes.get(node);\n    if (edgeChanges == null) {\n        edgeChanges = new QueryOverlay.EdgeChanges(2, 2);\n        edgeChangesAtRealNodes.put(node, edgeChanges);\n    }\n    EdgeIteratorState edge = (base) ? getVirtualEdge((virtNode * 4) + BASE_SNAP) : getVirtualEdge((virtNode * 4) + ADJ_SNAP);\n    edgeChanges.getAdditionalEdges().add(edge);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.put",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.weighting.custom.CustomModelParser.createWeightingParameters",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Geometry.getGeometryType",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.routing.weighting.custom.CustomModelParser.createWeightingParameters", "com.graphhopper.routing.weighting.custom.CustomModelParser.createClazz", "com.graphhopper.routing.weighting.custom.CustomModelParser.createClassTemplate" ],
    "fullMethods" : [ "/**\n * This method compiles a new subclass of CustomWeightingHelper composed of the provided CustomModel caches this\n * and returns an instance.\n */\npublic static CustomWeighting.Parameters createWeightingParameters(CustomModel customModel, EncodedValueLookup lookup) {\n    String key = customModel.toString();\n    Class<?> clazz = (customModel.isInternal()) ? INTERNAL_CACHE.get(key) : null;\n    if ((CACHE_SIZE > 0) && (clazz == null))\n        clazz = CACHE.get(key);\n\n    if (clazz == null) {\n        clazz = createClazz(customModel, lookup);\n        if (customModel.isInternal()) {\n            INTERNAL_CACHE.put(key, clazz);\n            if (INTERNAL_CACHE.size() > 100) {\n                CACHE.putAll(INTERNAL_CACHE);\n                INTERNAL_CACHE.clear();\n                LoggerFactory.getLogger(CustomModelParser.class).warn((\"Internal cache must stay small but was \" + INTERNAL_CACHE.size()) + \". Cleared it. Misuse of CustomModel::internal?\");\n            }\n        } else if (CACHE_SIZE > 0) {\n            CACHE.put(key, clazz);\n        }\n    }\n    try {\n        // The class does not need to be thread-safe as we create an instance per request\n        CustomWeightingHelper prio = ((CustomWeightingHelper) (clazz.getDeclaredConstructor().newInstance()));\n        prio.init(customModel, lookup, CustomModel.getAreasAsMap(customModel.getAreas()));\n        return new CustomWeighting.Parameters(prio::getSpeed, prio::calcMaxSpeed, prio::getPriority, prio::calcMaxPriority, prio::getTurnPenalty, customModel.getDistanceInfluence() == null ? 0 : customModel.getDistanceInfluence(), customModel.getHeadingPenalty() == null ? Parameters.Routing.DEFAULT_HEADING_PENALTY : customModel.getHeadingPenalty());\n    } catch (ReflectiveOperationException ex) {\n        throw new IllegalArgumentException(\"Cannot compile expression \" + ex.getMessage(), ex);\n    }\n}", "/**\n * This method does the following:\n * <ul>\n * <li>\n *     1. parse the value expressions (RHS) to know about additional encoded values ('findVariables')\n *     and check for multiplications with negative values.\n * </li>\n * <li>2. parse conditional expression of priority and speed statements -> done in ConditionalExpressionVisitor (don't parse RHS expressions again)\n * </li>\n * <li>3. create class template as String, inject the created statements and create the Class\n * </li>\n * </ul>\n */\nprivate static Class<?> createClazz(CustomModel customModel, EncodedValueLookup lookup) {\n    try {\n        Set<String> priorityVariables = ValueExpressionVisitor.findVariables(customModel.getPriority(), lookup);\n        List<Java.BlockStatement> priorityStatements = createGetPriorityStatements(priorityVariables, customModel, lookup);\n        if (customModel.getSpeed().isEmpty())\n            throw new IllegalArgumentException(\"At least one initial statement under 'speed' is required.\");\n\n        List<Statement> firstGroup = splitIntoGroup(customModel.getSpeed()).get(0);\n        if (firstGroup.size() > 1) {\n            Statement lastSt = firstGroup.get(firstGroup.size() - 1);\n            if ((lastSt.operation() != Statement.Op.LIMIT) || (lastSt.keyword() != Statement.Keyword.ELSE))\n                throw new IllegalArgumentException(\"The first group needs to end with an 'else' (or contain a single unconditional 'if' statement).\");\n\n        } else {\n            Statement firstSt = firstGroup.get(0);\n            if (((!\"true\".equals(firstSt.condition())) || (firstSt.operation() != Statement.Op.LIMIT)) || (firstSt.keyword() != Statement.Keyword.IF))\n                throw new IllegalArgumentException(\"The first group needs to contain a single unconditional 'if' statement (or end with an 'else').\");\n\n        }\n        Set<String> speedVariables = ValueExpressionVisitor.findVariables(customModel.getSpeed(), lookup);\n        List<Java.BlockStatement> speedStatements = createGetSpeedStatements(speedVariables, customModel, lookup);\n        Set<String> turnPenaltyVariables = ValueExpressionVisitor.findVariables(customModel.getTurnPenalty(), lookup);\n        List<Java.BlockStatement> turnPenaltyStatements = createGetTurnPenaltyStatements(turnPenaltyVariables, customModel, lookup);\n        // Create different class name, which is required only for debugging.\n        // TODO does it improve performance too? I.e. it could be that the JIT is confused if different classes\n        // have the same name and it mixes performance stats. See https://github.com/janino-compiler/janino/issues/137\n        long counter = longVal.incrementAndGet();\n        String classTemplate = createClassTemplate(counter, priorityVariables, speedVariables, turnPenaltyVariables, lookup, CustomModel.getAreasAsMap(customModel.getAreas()));\n        Java.CompilationUnit cu = ((Java.CompilationUnit) (new Parser(new Scanner(\"source\", new StringReader(classTemplate))).parseAbstractCompilationUnit()));\n        cu = injectStatements(priorityStatements, speedStatements, turnPenaltyStatements, cu);\n        SimpleCompiler sc = createCompiler(counter, cu);\n        return sc.getClassLoader().loadClass(\"com.graphhopper.routing.weighting.custom.JaninoCustomWeightingHelperSubclass\" + counter);\n    } catch (Exception ex) {\n        String errString = \"Cannot compile expression\";\n        throw new IllegalArgumentException((errString + \": \") + ex.getMessage(), ex);\n    }\n}", "/**\n * Create the class source file from the detected variables (priorityVariables and speedVariables). We assume that\n * these variables are safe although they are user input because we collected them from parsing via Janino. This\n * means that the source file is free from user input and could be directly compiled. Before we do this we still\n * have to inject that parsed and safe user expressions in a later step.\n */\nprivate static String createClassTemplate(long counter, Set<String> priorityVariables, Set<String> speedVariables, Set<String> turnPenaltyVariables, EncodedValueLookup lookup, Map<String, JsonFeature> areas) {\n    final StringBuilder importSourceCode = new StringBuilder(\"import com.graphhopper.routing.ev.*;\\n\");\n    importSourceCode.append(\"import java.util.Map;\\n\");\n    importSourceCode.append((\"import \" + CustomModel.class.getName()) + \";\\n\");\n    importSourceCode.append((\"import \" + BaseGraph.class.getName()) + \";\\n\");\n    importSourceCode.append((\"import \" + EdgeIntAccess.class.getName()) + \";\\n\");\n    final StringBuilder classSourceCode = new StringBuilder(100);\n    boolean includedAreaImports = false;\n    final StringBuilder initSourceCode = new StringBuilder(\"this.lookup = lookup;\\n\");\n    initSourceCode.append(\"this.customModel = customModel;\\n\");\n    Set<String> set = new HashSet<>();\n    for (String prioVar : priorityVariables)\n        set.add(prioVar.startsWith(BACKWARD_PREFIX) ? prioVar.substring(BACKWARD_PREFIX.length()) : prioVar);\n\n    for (String speedVar : speedVariables)\n        set.add(speedVar.startsWith(BACKWARD_PREFIX) ? speedVar.substring(BACKWARD_PREFIX.length()) : speedVar);\n\n    for (String speedVar : turnPenaltyVariables)\n        set.add(speedVar.startsWith(PREV_PREFIX) ? speedVar.substring(PREV_PREFIX.length()) : speedVar);\n\n    for (String arg : set) {\n        if (lookup.hasEncodedValue(arg)) {\n            EncodedValue enc = lookup.getEncodedValue(arg, EncodedValue.class);\n            classSourceCode.append((((\"protected \" + getInterface(enc)) + \" \") + arg) + \"_enc;\\n\");\n            initSourceCode.append((((((\"this.\" + arg) + \"_enc = (\") + getInterface(enc)) + \") lookup.getEncodedValue(\\\"\") + arg) + \"\\\", EncodedValue.class);\\n\");\n        } else if (arg.startsWith(IN_AREA_PREFIX)) {\n            if (!includedAreaImports) {\n                importSourceCode.append((\"import \" + BBox.class.getName()) + \";\\n\");\n                importSourceCode.append((\"import \" + GHUtility.class.getName()) + \";\\n\");\n                importSourceCode.append((\"import \" + PreparedPolygon.class.getName()) + \";\\n\");\n                importSourceCode.append((\"import \" + Polygonal.class.getName()) + \";\\n\");\n                importSourceCode.append((\"import \" + JsonFeature.class.getName()) + \";\\n\");\n                importSourceCode.append((\"import \" + Polygon.class.getName()) + \";\\n\");\n                includedAreaImports = true;\n            }\n            if (!JsonFeature.isValidId(arg))\n                throw new IllegalArgumentException(\"Area has invalid name: \" + arg);\n\n            String id = arg.substring(IN_AREA_PREFIX.length());\n            JsonFeature feature = areas.get(id);\n            if (feature == null)\n                throw new IllegalArgumentException((\"Area '\" + id) + \"' wasn't found\");\n\n            if (feature.getGeometry() == null)\n                throw new IllegalArgumentException((\"Area '\" + id) + \"' does not contain a geometry\");\n\n            if (!(feature.getGeometry() instanceof Polygonal))\n                throw new IllegalArgumentException(\"Currently only type=Polygon is supported for areas but was \" + feature.getGeometry().getGeometryType());\n\n            if (feature.getBBox() != null)\n                throw new IllegalArgumentException((\"Bounding box of area \" + id) + \" must be empty\");\n\n            classSourceCode.append((((\"protected \" + Polygon.class.getSimpleName()) + \" \") + arg) + \";\\n\");\n            initSourceCode.append((((\"JsonFeature feature_\" + id) + \" = (JsonFeature) areas.get(\\\"\") + id) + \"\\\");\\n\");\n            initSourceCode.append((((\"this.\" + arg) + \" = new Polygon(new PreparedPolygon((Polygonal) feature_\") + id) + \".getGeometry()));\\n\");\n        } else if (!arg.startsWith(IN_AREA_PREFIX))\n            throw new IllegalArgumentException(\"Variable not supported: \" + arg);\n\n    }\n    return (((((((((((((((((((((((((((((((((((\"\" + \"package com.graphhopper.routing.weighting.custom;\\n\") + \"import \") + CustomWeightingHelper.class.getName()) + \";\\n\") + \"import \") + EncodedValueLookup.class.getName()) + \";\\n\") + \"import \") + EdgeIteratorState.class.getName()) + \";\\n\") + importSourceCode) + \"\\npublic class JaninoCustomWeightingHelperSubclass\") + counter) + \" extends \") + CustomWeightingHelper.class.getSimpleName()) + \" {\\n\") + classSourceCode) + \"   @Override\\n\") + \"   public void init(CustomModel customModel, EncodedValueLookup lookup, Map<String, \") + JsonFeature.class.getName()) + \"> areas) {\\n\") + initSourceCode) + \"   }\\n\\n\") + // we need these placeholder methods so that the hooks in DeepCopier are invoked\n    \"   @Override\\n\") + \"   public double getPriority(EdgeIteratorState edge, boolean reverse) {\\n\") + \"      return 1; //will be overwritten by code injected in DeepCopier\\n\") + \"   }\\n\") + \"   @Override\\n\") + \"   public double getSpeed(EdgeIteratorState edge, boolean reverse) {\\n\") + \"      return 1; //will be overwritten by code injected in DeepCopier\\n\") + \"   }\\n\") + \"   @Override\\n\") + \"   public double getTurnPenalty(BaseGraph graph, EdgeIntAccess edgeIntAccess, int inEdge, int viaNode, int outEdge) {\\n\") + \"      return 1; //will be overwritten by code injected in DeepCopier\\n\") + \"   }\\n\") + \"}\";\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.minTo",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntIntScatterMap.getOrDefault",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.minTo" ],
    "fullMethods" : [ "@Override\npublic void minTo(int key, int value) {\n    // todo: optimize with map.indexOf(key) etc\n    map.put(key, Math.min(map.getOrDefault(key, -1), value));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.get",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntIntScatterMap.getOrDefault",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.get" ],
    "fullMethods" : [ "@Override\npublic int get(int key) {\n    return map.getOrDefault(key, -1);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.GHUtility.readCountries",
    "thirdPartyMethod" : "com.fasterxml.jackson.databind.ObjectMapper.<init>",
    "thirdPartyPackage" : "com.fasterxml.jackson.databind",
    "path" : [ "com.graphhopper.util.GHUtility.readCountries" ],
    "fullMethods" : [ "/**\n * Reads the country borders from the countries.geojson resource file\n */\npublic static List<CustomArea> readCountries() {\n    ObjectMapper objectMapper = new ObjectMapper();\n    objectMapper.registerModule(new JtsModule());\n    Set<String> enumSet = new HashSet<>(Country.values().length * 2);\n    for (Country c : Country.values()) {\n        if (c == Country.MISSING)\n            continue;\n\n        if (c.getStates().isEmpty())\n            enumSet.add(c.getAlpha2());\n        else\n            for (State s : c.getStates())\n                enumSet.add(s.getStateCode());\n\n\n    }\n    try (Reader reader = new InputStreamReader(GHUtility.class.getResourceAsStream(\"/com/graphhopper/countries/countries.geojson\"), StandardCharsets.UTF_8)) {\n        JsonFeatureCollection jsonFeatureCollection = objectMapper.readValue(reader, JsonFeatureCollection.class);\n        return // exclude areas not in the list of Country enums like FX => Metropolitan France\n        jsonFeatureCollection.getFeatures().stream().filter(customArea -> enumSet.contains(getIdOrPropertiesId(customArea))).map(f -> {\n            CustomArea ca = CustomArea.fromJsonFeature(f);\n            // the Feature does not include \"id\" but we expect it\n            if (f.getId() == null)\n                f.setId(getIdOrPropertiesId(f));\n\n            ca.getProperties().put(ISO_3166_2, f.getId());\n            return ca;\n        }).collect(Collectors.toList());\n    } catch (IOException e) {\n        throw new UncheckedIOException(e);\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.GraphHopper.resolveCustomAreas",
    "thirdPartyMethod" : "com.fasterxml.jackson.databind.ObjectMapper.<init>",
    "thirdPartyPackage" : "com.fasterxml.jackson.databind",
    "path" : [ "com.graphhopper.GraphHopper.resolveCustomAreas" ],
    "fullMethods" : [ "public static JsonFeatureCollection resolveCustomAreas(String customAreasDirectory) {\n    JsonFeatureCollection globalAreas = new JsonFeatureCollection();\n    if (!customAreasDirectory.isEmpty()) {\n        ObjectMapper mapper = new ObjectMapper().registerModule(new JtsModule());\n        try (DirectoryStream<Path> stream = Files.newDirectoryStream(Paths.get(customAreasDirectory), \"*.{geojson,json}\")) {\n            StreamSupport.stream(stream.spliterator(), false).sorted(Comparator.comparing(Path::toString)).forEach(customAreaFile -> {\n                try (BufferedReader reader = Files.newBufferedReader(customAreaFile, StandardCharsets.UTF_8)) {\n                    globalAreas.getFeatures().addAll(mapper.readValue(reader, JsonFeatureCollection.class).getFeatures());\n                } catch (IOException e) {\n                    throw new UncheckedIOException(e);\n                }\n            });\n            logger.info(((\"Will make \" + globalAreas.getFeatures().size()) + \" areas available to all custom profiles. Found in \") + customAreasDirectory);\n        } catch (IOException e) {\n            throw new UncheckedIOException(e);\n        }\n    }\n    return globalAreas;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.EncodedValueSerializer.serializeEncodedValue",
    "thirdPartyMethod" : "com.fasterxml.jackson.databind.ObjectMapper.<init>",
    "thirdPartyPackage" : "com.fasterxml.jackson.databind",
    "path" : [ "com.graphhopper.routing.ev.EncodedValueSerializer.serializeEncodedValue", "com.graphhopper.routing.ev.EncodedValueSerializer.<clinit>" ],
    "fullMethods" : [ "public static String serializeEncodedValue(EncodedValue encodedValue) {\n    try {\n        JsonNode tree = MAPPER.valueToTree(encodedValue);\n        return MAPPER.writeValueAsString(tree);\n    } catch (JsonProcessingException e) {\n        throw new IllegalStateException(((\"Could not serialize encoded value: \" + encodedValue) + \", error: \") + e.getMessage());\n    }\n}", "" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.MaxSpeedCalculator.createLegalDefaultSpeeds",
    "thirdPartyMethod" : "com.fasterxml.jackson.databind.ObjectMapper.<init>",
    "thirdPartyPackage" : "com.fasterxml.jackson.databind",
    "path" : [ "com.graphhopper.routing.util.MaxSpeedCalculator.createLegalDefaultSpeeds" ],
    "fullMethods" : [ "public static LegalDefaultSpeeds createLegalDefaultSpeeds() {\n    SpeedLimitsJson data;\n    try {\n        data = new ObjectMapper().readValue(MaxSpeedCalculator.class.getResource(\"legal_default_speeds.json\"), MaxSpeedCalculator.SpeedLimitsJson.class);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n    // pre-converts kmh, mph and \"walk\" into kmh\n    convertMaxspeed(data.speedLimitsByCountryCode.entrySet());\n    LegalDefaultSpeeds speeds = new LegalDefaultSpeeds(data.roadTypesByName, data.speedLimitsByCountryCode);\n    return speeds;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LMPreparationHandler.init",
    "thirdPartyMethod" : "com.fasterxml.jackson.databind.ObjectMapper.<init>",
    "thirdPartyPackage" : "com.fasterxml.jackson.databind",
    "path" : [ "com.graphhopper.routing.lm.LMPreparationHandler.init", "com.graphhopper.routing.lm.LMPreparationHandler.loadLandmarkSplittingFeatureCollection" ],
    "fullMethods" : [ "public void init(GraphHopperConfig ghConfig) {\n    // throw explicit error for deprecated configs\n    if (ghConfig.has(\"prepare.lm.weightings\")) {\n        throw new IllegalStateException(\"Use profiles_lm instead of prepare.lm.weightings, see #1922 and docs/core/profiles.md\");\n    }\n    setPreparationThreads(ghConfig.getInt(Parameters.Landmark.PREPARE + \"threads\", getPreparationThreads()));\n    setLMProfiles(ghConfig.getLMProfiles());\n    landmarkCount = ghConfig.getInt(Parameters.Landmark.COUNT, landmarkCount);\n    logDetails = ghConfig.getBool(Landmark.PREPARE + \"log_details\", false);\n    minNodes = ghConfig.getInt(Landmark.PREPARE + \"min_network_size\", -1);\n    for (String loc : ghConfig.getString(Landmark.PREPARE + \"suggestions_location\", \"\").split(\",\")) {\n        if (!loc.trim().isEmpty())\n            lmSuggestionsLocations.add(loc.trim());\n\n    }\n    if (!isEnabled())\n        return;\n\n    String splitAreaLocation = ghConfig.getString(Landmark.PREPARE + \"split_area_location\", \"\");\n    JsonFeatureCollection landmarkSplittingFeatureCollection = loadLandmarkSplittingFeatureCollection(splitAreaLocation);\n    if ((landmarkSplittingFeatureCollection != null) && (!landmarkSplittingFeatureCollection.getFeatures().isEmpty())) {\n        List<SplitArea> splitAreas = landmarkSplittingFeatureCollection.getFeatures().stream().map(SplitArea::fromJsonFeature).collect(Collectors.toList());\n        areaIndex = new AreaIndex<>(splitAreas);\n    }\n}", "private JsonFeatureCollection loadLandmarkSplittingFeatureCollection(String splitAreaLocation) {\n    ObjectMapper objectMapper = new ObjectMapper();\n    objectMapper.registerModule(new JtsModule());\n    URL builtinSplittingFile = LandmarkStorage.class.getResource(\"map.geo.json\");\n    try (Reader reader = (splitAreaLocation.isEmpty()) ? new InputStreamReader(builtinSplittingFile.openStream(), UTF_CS) : new InputStreamReader(new FileInputStream(splitAreaLocation), UTF_CS)) {\n        JsonFeatureCollection result = objectMapper.readValue(reader, JsonFeatureCollection.class);\n        if (splitAreaLocation.isEmpty()) {\n            LOGGER.info(\"Loaded built-in landmark splitting collection from {}\", builtinSplittingFile);\n        } else {\n            LOGGER.info(\"Loaded landmark splitting collection from {}\", splitAreaLocation);\n        }\n        return result;\n    } catch (IOException e) {\n        LOGGER.error(\"Problem while reading border map GeoJSON. Skipping this.\", e);\n        return null;\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.EncodedValueSerializer.deserializeEncodedValue",
    "thirdPartyMethod" : "com.fasterxml.jackson.databind.ObjectMapper.<init>",
    "thirdPartyPackage" : "com.fasterxml.jackson.databind",
    "path" : [ "com.graphhopper.routing.ev.EncodedValueSerializer.deserializeEncodedValue", "com.graphhopper.routing.ev.EncodedValueSerializer.<clinit>" ],
    "fullMethods" : [ "public static EncodedValue deserializeEncodedValue(String serializedEncodedValue) {\n    try {\n        JsonNode jsonNode = MAPPER.readTree(serializedEncodedValue);\n        return MAPPER.treeToValue(jsonNode, EncodedValue.class);\n    } catch (JsonProcessingException e) {\n        throw new IllegalStateException(((\"Could not deserialize encoded value: \" + serializedEncodedValue) + \", error: \") + e.getMessage());\n    }\n}", "" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Router.route",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Router.route" ],
    "fullMethods" : [ "public GHResponse route(GHRequest request) {\n    try {\n        checkNoLegacyParameters(request);\n        checkAtLeastOnePoint(request);\n        checkIfPointsAreInBoundsAndNotNull(request.getPoints());\n        checkHeadings(request);\n        checkPointHints(request);\n        checkCurbsides(request);\n        checkNoBlockArea(request);\n        checkCustomModel(request);\n        Solver solver = createSolver(request);\n        solver.checkRequest();\n        solver.init();\n        if (ROUND_TRIP.equalsIgnoreCase(request.getAlgorithm())) {\n            if (!(solver instanceof FlexSolver))\n                throw new IllegalArgumentException(\"algorithm=round_trip only works with a flexible algorithm\");\n\n            return routeRoundTrip(request, ((FlexSolver) (solver)));\n        } else if (ALT_ROUTE.equalsIgnoreCase(request.getAlgorithm())) {\n            return routeAlt(request, solver);\n        } else {\n            return routeVia(request, solver);\n        }\n    } catch (MultiplePointsNotFoundException ex) {\n        GHResponse ghRsp = new GHResponse();\n        for (IntCursor p : ex.getPointsNotFound()) {\n            ghRsp.addError(new PointNotFoundException(((\"Cannot find point \" + p.value) + \": \") + request.getPoints().get(p.value), p.value));\n        }\n        return ghRsp;\n    } catch (IllegalArgumentException ex) {\n        GHResponse ghRsp = new GHResponse();\n        ghRsp.addError(ex);\n        return ghRsp;\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.NodeBasedWitnessPathSearcher.init",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.NodeBasedWitnessPathSearcher.init", "com.graphhopper.routing.ch.NodeBasedWitnessPathSearcher.reset" ],
    "fullMethods" : [ "/**\n * Sets up a search for given start node and an ignored node. The shortest path tree will be re-used for different\n * target nodes until this method is called again.\n */\npublic void init(int startNode, int ignoreNode) {\n    reset();\n    this.ignoreNode = ignoreNode;\n    weights[startNode] = 0;\n    changedNodes.add(startNode);\n    heap.insert(0, startNode);\n}", "private void reset() {\n    for (IntCursor c : changedNodes)\n        weights[c.value] = Double.POSITIVE_INFINITY;\n\n    changedNodes.elementsCount = 0;\n    heap.clear();\n    ignoreNode = -1;\n    settledNodes = 0;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction" ],
    "fullMethods" : [ "/**\n * Converts an OSM restriction to (multiple) single 'no' restrictions to be fed into {@link RestrictionSetter}\n */\npublic static List<RestrictionSetter.Restriction> buildRestrictionsForOSMRestriction(BaseGraph baseGraph, RestrictionTopology topology, RestrictionType type) {\n    List<RestrictionSetter.Restriction> result = new ArrayList<>();\n    if (type == NO) {\n        if (topology.isViaWayRestriction()) {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges()) {\n                    IntArrayList edges = new IntArrayList(topology.getViaEdges().size() + 2);\n                    edges.add(fromEdge.value);\n                    edges.addAll(topology.getViaEdges());\n                    edges.add(toEdge.value);\n                    result.add(RestrictionSetter.createViaEdgeRestriction(edges));\n                }\n\n        } else {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges())\n                    result.add(RestrictionSetter.createViaNodeRestriction(fromEdge.value, topology.getViaNodes().get(0), toEdge.value));\n\n\n        }\n    } else if (type == ONLY) {\n        if ((topology.getFromEdges().size() > 1) || (topology.getToEdges().size() > 1))\n            throw new IllegalArgumentException(\"'Only' restrictions with multiple from- or to- edges are not supported\");\n\n        if (topology.isViaWayRestriction())\n            result.addAll(createRestrictionsForViaEdgeOnlyRestriction(baseGraph, topology));\n        else\n            result.addAll(createRestrictionsForViaNodeOnlyRestriction(baseGraph.createEdgeExplorer(), topology.getFromEdges().get(0), topology.getViaNodes().get(0), topology.getToEdges().get(0)));\n\n    } else\n        throw new IllegalArgumentException(\"Unexpected restriction type: \" + type);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryGraph.unfavorVirtualEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryGraph.unfavorVirtualEdges" ],
    "fullMethods" : [ "public void unfavorVirtualEdges(IntArrayList edgeIds) {\n    for (IntCursor c : edgeIds) {\n        unfavorVirtualEdge(c.value);\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions", "com.graphhopper.routing.util.parsers.RestrictionSetter.disableRedundantRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}", "private void disableRedundantRestrictions(List<InternalRestriction> restrictions, List<BitSet> encBits) {\n    for (int encIdx = 0; encIdx < turnRestrictionEncs.size(); encIdx++) {\n        // first we disable all duplicates\n        Set<InternalRestriction> uniqueRestrictions = new HashSet<>();\n        for (int i = 0; i < restrictions.size(); i++) {\n            if (!encBits.get(i).get(encIdx))\n                continue;\n\n            if (!uniqueRestrictions.add(restrictions.get(i)))\n                encBits.get(i).clear(encIdx);\n\n        }\n        // build an index of restrictions to quickly find all restrictions containing a given edge key\n        IntObjectScatterMap<List<InternalRestriction>> restrictionsByEdgeKeys = new IntObjectScatterMap<>();\n        for (int i = 0; i < restrictions.size(); i++) {\n            if (!encBits.get(i).get(encIdx))\n                continue;\n\n            InternalRestriction restriction = restrictions.get(i);\n            for (IntCursor edgeKey : restriction.edgeKeys) {\n                int idx = restrictionsByEdgeKeys.indexOf(edgeKey.value);\n                if (idx < 0) {\n                    List<InternalRestriction> list = new ArrayList<>();\n                    list.add(restriction);\n                    restrictionsByEdgeKeys.indexInsert(idx, edgeKey.value, list);\n                } else {\n                    restrictionsByEdgeKeys.indexGet(idx).add(restriction);\n                }\n            }\n        }\n        // Only keep restrictions that do not contain another restriction. For example, it would be unnecessary to restrict\n        // 6-8-2 when 6-8 is restricted already\n        for (int i = 0; i < restrictions.size(); i++) {\n            if (!encBits.get(i).get(encIdx))\n                continue;\n\n            if (containsAnotherRestriction(restrictions.get(i), restrictionsByEdgeKeys))\n                encBits.get(i).clear(encIdx);\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.isPermutation",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.isPermutation" ],
    "fullMethods" : [ "public static boolean isPermutation(IntArrayList arr) {\n    BitSet present = new BitSet(arr.size());\n    for (IntCursor e : arr) {\n        if ((e.value >= arr.size()) || (e.value < 0))\n            return false;\n\n        if (present.get(e.value))\n            return false;\n\n        present.set(e.value);\n    }\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.RoundTripRouting.calcPaths",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.RoundTripRouting.calcPaths", "com.graphhopper.routing.RoundTripRouting.RoundTripCalculator.calcPath" ],
    "fullMethods" : [ "public static Result calcPaths(List<Snap> snaps, FlexiblePathCalculator pathCalculator) {\n    RoundTripCalculator roundTripCalculator = new RoundTripCalculator(pathCalculator);\n    Result result = new Result(snaps.size() - 1);\n    Snap start = snaps.get(0);\n    for (int snapIndex = 1; snapIndex < snaps.size(); snapIndex++) {\n        // instead getClosestNode (which might be a virtual one and introducing unnecessary tails of the route)\n        // use next tower node -> getBaseNode or getAdjNode\n        // Later: remove potential route tail, maybe we can just enforce the heading at the start and when coming\n        // back, and for tower nodes it does not matter anyway\n        Snap startSnap = snaps.get(snapIndex - 1);\n        int startNode = (startSnap == start) ? startSnap.getClosestNode() : startSnap.getClosestEdge().getBaseNode();\n        Snap endSnap = snaps.get(snapIndex);\n        int endNode = (endSnap == start) ? endSnap.getClosestNode() : endSnap.getClosestEdge().getBaseNode();\n        Path path = roundTripCalculator.calcPath(startNode, endNode);\n        if (snapIndex == 1) {\n            result.wayPoints = new PointList(snaps.size(), path.graph.getNodeAccess().is3D());\n            result.wayPoints.add(path.graph.getNodeAccess(), startNode);\n        }\n        result.wayPoints.add(path.graph.getNodeAccess(), endNode);\n        result.visitedNodes += pathCalculator.getVisitedNodes();\n        result.paths.add(path);\n    }\n    return result;\n}", "Path calcPath(int from, int to) {\n    Path path = pathCalculator.calcPaths(from, to, new EdgeRestrictions()).get(0);\n    // add the edges of this path to the set of previous edges so they will be avoided from now, otherwise\n    // we do not get a nice 'round trip'. note that for this reason we cannot use CH for round-trips currently\n    for (IntCursor c : path.getEdges()) {\n        previousEdges.add(c.value);\n    }\n    return path;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHObjectIntHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.ObjectIntHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHObjectIntHashMap.<init>" ],
    "fullMethods" : [ "public GHObjectIntHashMap() {\n    super(10, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHObjectIntHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.ObjectIntHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHObjectIntHashMap.<init>" ],
    "fullMethods" : [ "public GHObjectIntHashMap(int capacity, double loadFactor) {\n    super(capacity, loadFactor, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHObjectIntHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.ObjectIntHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHObjectIntHashMap.<init>" ],
    "fullMethods" : [ "public GHObjectIntHashMap(int capacity) {\n    super(capacity, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHObjectIntHashMap.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.ObjectIntHashMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHObjectIntHashMap.<init>" ],
    "fullMethods" : [ "public GHObjectIntHashMap(int capacity, double loadFactor, HashOrderMixingStrategy hashOrderMixer) {\n    super(capacity, loadFactor, hashOrderMixer);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.has",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntIntScatterMap.containsKey",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.has" ],
    "fullMethods" : [ "@Override\npublic boolean has(int key) {\n    return map.containsKey(key);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.prepareForContraction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.sorting.IndirectComparator.AscendingIntComparator.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc.sorting.IndirectComparator",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.prepareForContraction", "com.graphhopper.routing.ch.CHPreparationGraph.OrigGraph.Builder.build" ],
    "fullMethods" : [ "public void prepareForContraction() {\n    checkNotReady();\n    origGraph = (edgeBased) ? origGraphBuilder.build() : null;\n    origGraphBuilder = null;\n    ready = true;\n}", "{\n    com.carrotsearch.hppc.IntArrayList $stack10, $stack11, $stack12, $stack2, $stack3, $stack7, $stack8, $stack9;\n    com.carrotsearch.hppc.sorting.IndirectComparator #l0;\n    com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator #l1;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph $stack13;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder this;\n    int $stack6;\n    int[] $stack4, sortOrder;\n    java.lang.Object $stack5;\n\n\n    this := @this: com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder;\n    $stack2 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack6 = $stack2.<com.carrotsearch.hppc.IntArrayList: int elementsCount>;\n    $stack5 = new com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator;\n    $stack3 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack4 = $stack3.<com.carrotsearch.hppc.IntArrayList: int[] buffer>;\n    #l1 = (com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator) $stack5;\n    specialinvoke #l1.<com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator: void <init>(int[])>($stack4);\n    #l0 = (com.carrotsearch.hppc.sorting.IndirectComparator) $stack5;\n    sortOrder = staticinvoke <com.carrotsearch.hppc.sorting.IndirectSort: int[] mergesort(int,int,com.carrotsearch.hppc.sorting.IndirectComparator)>(0, $stack6, #l0);\n    $stack7 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack7, sortOrder);\n    $stack8 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack8, sortOrder);\n    $stack9 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack9, sortOrder);\n    $stack13 = new com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph;\n    $stack12 = virtualinvoke this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList buildFirstEdgesByNode()>();\n    $stack11 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    $stack10 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    specialinvoke $stack13.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph: void <init>(com.carrotsearch.hppc.IntArrayList,com.carrotsearch.hppc.IntArrayList,com.carrotsearch.hppc.IntArrayList)>($stack12, $stack11, $stack10);\n\n    return $stack13;\n}\n" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.SplitArea.fromJsonFeature",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Geometry.getNumGeometries",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.routing.lm.SplitArea.fromJsonFeature" ],
    "fullMethods" : [ "public static SplitArea fromJsonFeature(JsonFeature j) {\n    List<Polygon> borders = new ArrayList<>();\n    for (int i = 0; i < j.getGeometry().getNumGeometries(); i++) {\n        Geometry geometry = j.getGeometry().getGeometryN(i);\n        if (geometry instanceof Polygon)\n            PolygonExtracter.getPolygons(geometry, borders);\n        else\n            throw new IllegalArgumentException(\"GeoJson features used to create split areas must be of type 'Polygon', but was: \" + geometry.getClass().getSimpleName());\n\n    }\n    return new SplitArea(borders);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.CustomArea.fromJsonFeature",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Geometry.getNumGeometries",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.routing.util.CustomArea.fromJsonFeature" ],
    "fullMethods" : [ "public static CustomArea fromJsonFeature(JsonFeature j) {\n    List<Polygon> borders = new ArrayList<>();\n    for (int i = 0; i < j.getGeometry().getNumGeometries(); i++) {\n        Geometry geometry = j.getGeometry().getGeometryN(i);\n        if (geometry instanceof Polygon) {\n            borders.add(((Polygon) (geometry)));\n        } else {\n            throw new IllegalArgumentException(\"Custom area features must be of type 'Polygon', but was: \" + geometry.getClass().getSimpleName());\n        }\n    }\n    return new CustomArea(j.getProperties(), borders);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.Polygon.toString",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Geometry.getNumGeometries",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.Polygon.toString" ],
    "fullMethods" : [ "@Override\npublic String toString() {\n    return (((\"polygon (\" + prepPolygon.getGeometry().getNumPoints()) + \" points,\") + prepPolygon.getGeometry().getNumGeometries()) + \" geometries)\";\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.EdgeResult.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.EdgeResult.<init>" ],
    "fullMethods" : [ "public EdgeResult(int numFrom, int numVia, int numTo) {\n    fromEdges = new IntArrayList(numFrom);\n    viaEdges = new IntArrayList(numVia);\n    toEdges = new IntArrayList(numTo);\n    nodes = new IntArrayList(numVia + 1);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction" ],
    "fullMethods" : [ "/**\n * Converts an OSM restriction to (multiple) single 'no' restrictions to be fed into {@link RestrictionSetter}\n */\npublic static List<RestrictionSetter.Restriction> buildRestrictionsForOSMRestriction(BaseGraph baseGraph, RestrictionTopology topology, RestrictionType type) {\n    List<RestrictionSetter.Restriction> result = new ArrayList<>();\n    if (type == NO) {\n        if (topology.isViaWayRestriction()) {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges()) {\n                    IntArrayList edges = new IntArrayList(topology.getViaEdges().size() + 2);\n                    edges.add(fromEdge.value);\n                    edges.addAll(topology.getViaEdges());\n                    edges.add(toEdge.value);\n                    result.add(RestrictionSetter.createViaEdgeRestriction(edges));\n                }\n\n        } else {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges())\n                    result.add(RestrictionSetter.createViaNodeRestriction(fromEdge.value, topology.getViaNodes().get(0), toEdge.value));\n\n\n        }\n    } else if (type == ONLY) {\n        if ((topology.getFromEdges().size() > 1) || (topology.getToEdges().size() > 1))\n            throw new IllegalArgumentException(\"'Only' restrictions with multiple from- or to- edges are not supported\");\n\n        if (topology.isViaWayRestriction())\n            result.addAll(createRestrictionsForViaEdgeOnlyRestriction(baseGraph, topology));\n        else\n            result.addAll(createRestrictionsForViaNodeOnlyRestriction(baseGraph.createEdgeExplorer(), topology.getFromEdges().get(0), topology.getViaNodes().get(0), topology.getToEdges().get(0)));\n\n    } else\n        throw new IllegalArgumentException(\"Unexpected restriction type: \" + type);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays", "com.graphhopper.reader.osm.WayToEdgeConverter.findEdgeChain" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to each other. For example for given\n * from-, via- and to-ways there can be multiple edges associated with each (because each way can be split into\n * multiple edges). We then need to find the from-edge that is connected with one of the via-edges which in turn\n * must be connected with one of the to-edges. We use DFS/backtracking to do this.\n * There can also be *multiple* via-ways, but the concept is the same.\n * Note that there can also be multiple from- or to-*ways*, but only one of each of them should be considered at a\n * time. In contrast to the via-ways there are only multiple from/to-ways, because of restrictions like no_entry or\n * no_exit where there can be multiple from- or to-members. So we need to find one edge-chain for each pair of from-\n * and to-ways.\n * Besides the edge IDs we also return the node IDs that connect the edges, so we can add turn restrictions at these\n * nodes later.\n */\npublic EdgeResult convertForViaWays(LongArrayList fromWays, LongArrayList viaWays, LongArrayList toWays) throws OSMRestrictionException {\n    if ((fromWays.isEmpty() || toWays.isEmpty()) || viaWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from-, via- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    List<IntArrayList> solutions = new ArrayList<>();\n    for (LongCursor fromWay : fromWays)\n        for (LongCursor toWay : toWays)\n            findEdgeChain(fromWay.value, viaWays, toWay.value, solutions);\n\n\n    if (solutions.size() < (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has disconnected member ways\");\n    else if (solutions.size() > (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has member ways that do not form a unique path\");\n\n    return buildResult(solutions, fromWays, viaWays, toWays);\n}", "private void findEdgeChain(long fromWay, LongArrayList viaWays, long toWay, List<IntArrayList> solutions) {\n    // For each edge chain there must be one edge associated with the from-way, at least one for each via-way and one\n    // associated with the to-way. We use DFS with backtracking to find all edge chains that connect an edge\n    // associated with the from-way with one associated with the to-way.\n    IntArrayList viaEdgesForViaWays = new IntArrayList(viaWays.size());\n    for (LongCursor c : viaWays) {\n        Iterator<IntCursor> iterator = edgesByWay.apply(c.value);\n        viaEdgesForViaWays.add(iterator.next().value);\n        iterator.forEachRemaining(i -> viaEdgesForViaWays.add(i.value));\n    }\n    IntArrayList toEdges = listFromIterator(edgesByWay.apply(toWay));\n    // the search starts at *every* from edge\n    edgesByWay.apply(fromWay).forEachRemaining(from -> {\n        EdgeIteratorState edge = baseGraph.getEdgeIteratorState(from.value, Integer.MIN_VALUE);\n        explore(viaEdgesForViaWays, toEdges, edge.getBaseNode(), 0, IntArrayList.from(edge.getEdge(), edge.getBaseNode()), solutions);\n        explore(viaEdgesForViaWays, toEdges, edge.getAdjNode(), 0, IntArrayList.from(edge.getEdge(), edge.getAdjNode()), solutions);\n    });\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.<init>", "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.initCollections" ],
    "fullMethods" : [ "public EdgeBasedWitnessPathSearcher(CHPreparationGraph prepareGraph) {\n    this.prepareGraph = prepareGraph;\n    outEdgeExplorer = prepareGraph.createOutEdgeExplorer();\n    origInEdgeExplorer = prepareGraph.createInOrigEdgeExplorer();\n    initStorage(2 * prepareGraph.getOriginalEdges());\n    initCollections();\n}", "private void initCollections() {\n    changedEdgeKeys = new IntArrayList(1000);\n    dijkstraHeap = new IntFloatBinaryHeap(1000);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.constant",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.constant" ],
    "fullMethods" : [ "/**\n * Creates an IntArrayList of a given size where each element is set to the given value\n */\npublic static IntArrayList constant(int size, int value) {\n    IntArrayList result = new IntArrayList(size);\n    Arrays.fill(result.buffer, value);\n    result.elementsCount = size;\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.zero",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.zero" ],
    "fullMethods" : [ "/**\n * Creates an IntArrayList filled with zeros\n */\npublic static IntArrayList zero(int size) {\n    IntArrayList result = new IntArrayList(size);\n    result.elementsCount = size;\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.index.InMemConstructionIndex.InMemLeafEntry.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.index.InMemConstructionIndex.InMemLeafEntry.<init>" ],
    "fullMethods" : [ "public InMemLeafEntry(int count) {\n    super(count);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.NodeResult.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.NodeResult.<init>" ],
    "fullMethods" : [ "public NodeResult(int numFrom, int numTo) {\n    fromEdges = new IntArrayList(numFrom);\n    toEdges = new IntArrayList(numTo);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.calcNodes",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.calcNodes" ],
    "fullMethods" : [ "/**\n *\n * @return the uncached node indices of the tower nodes in this path.\n */\npublic IntIndexedContainer calcNodes() {\n    final IntArrayList nodes = new IntArrayList(edgeIds.size() + 1);\n    if (edgeIds.isEmpty()) {\n        if (isFound()) {\n            nodes.add(endNode);\n        }\n        return nodes;\n    }\n    int tmpNode = getFromNode();\n    nodes.add(tmpNode);\n    forEveryEdge(new EdgeVisitor() {\n        @Override\n        public void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n            nodes.add(eb.getAdjNode());\n        }\n\n        @Override\n        public void finish() {\n        }\n    });\n    return nodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.range",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.range" ],
    "fullMethods" : [ "/**\n * Creates an IntArrayList filled with the integers [startIncl,endExcl[\n */\npublic static IntArrayList range(int startIncl, int endExcl) {\n    IntArrayList result = new IntArrayList(endExcl - startIncl);\n    result.elementsCount = endExcl - startIncl;\n    for (int i = 0; i < result.size(); ++i)\n        result.set(i, startIncl + i);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.subList",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.subList" ],
    "fullMethods" : [ "public static IntArrayList subList(IntArrayList list, int fromIndex, int toIndex) {\n    IntArrayList result = new IntArrayList(toIndex - fromIndex);\n    for (int i = fromIndex; i < toIndex; i++)\n        result.add(list.get(i));\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.HeadingResolver.getEdgesWithDifferentHeading",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.HeadingResolver.getEdgesWithDifferentHeading" ],
    "fullMethods" : [ "/**\n * Returns a list of edge IDs of edges adjacent to the given base node that do *not* have the same or a similar\n * heading as the given heading. If for example the tolerance is 45 degrees this method returns all edges for which\n * the absolute difference to the given heading is greater than 45 degrees. The heading of an edge is defined as\n * the direction of the first segment of an edge (adjacent and facing away from the base node).\n *\n * @param heading\n * \t\tnorth based azimuth, between 0 and 360 degrees\n * @see #setTolerance\n */\npublic IntArrayList getEdgesWithDifferentHeading(int baseNode, double heading) {\n    double xAxisAngle = AngleCalc.ANGLE_CALC.convertAzimuth2xaxisAngle(heading);\n    IntArrayList edges = new IntArrayList(1);\n    EdgeIterator iter = edgeExplorer.setBaseNode(baseNode);\n    while (iter.next()) {\n        PointList points = iter.fetchWayGeometry(FetchMode.ALL);\n        double orientation = AngleCalc.ANGLE_CALC.calcOrientation(points.getLat(0), points.getLon(0), points.getLat(1), points.getLon(1));\n        orientation = AngleCalc.ANGLE_CALC.alignOrientation(xAxisAngle, orientation);\n        double diff = Math.abs(orientation - xAxisAngle);\n        if (diff > toleranceRad)\n            edges.add(iter.getEdge());\n\n    } \n    return edges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build", "com.graphhopper.routing.querygraph.QueryOverlayBuilder.build", "com.graphhopper.routing.querygraph.QueryOverlay.<init>" ],
    "fullMethods" : [ "public static QueryOverlay build(int firstVirtualNodeId, int firstVirtualEdgeId, boolean is3D, List<Snap> snaps) {\n    return new QueryOverlayBuilder(firstVirtualNodeId, firstVirtualEdgeId, is3D).build(snaps);\n}", "private QueryOverlay build(List<Snap> resList) {\n    queryOverlay = new QueryOverlay(resList.size(), is3D);\n    buildVirtualEdges(resList);\n    buildEdgeChangesAtRealNodes();\n    return queryOverlay;\n}", "QueryOverlay(int numVirtualNodes, boolean is3D) {\n    this.virtualNodes = new PointList(numVirtualNodes, is3D);\n    this.virtualEdges = new ArrayList<>(numVirtualNodes * 2);\n    this.closestEdges = new IntArrayList(numVirtualNodes);\n    edgeChangesAtRealNodes = new GHIntObjectHashMap<>(numVirtualNodes * 3);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.invert",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.invert" ],
    "fullMethods" : [ "public static IntArrayList invert(IntArrayList list) {\n    IntArrayList result = new IntArrayList(list.size());\n    result.elementsCount = list.size();\n    for (int i = 0; i < result.elementsCount; ++i)\n        result.set(list.get(i), i);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.Polygon.<init>",
    "thirdPartyMethod" : "org.locationtech.jts.geom.impl.PackedCoordinateSequence.Double.<init>",
    "thirdPartyPackage" : "org.locationtech.jts.geom.impl.PackedCoordinateSequence",
    "path" : [ "com.graphhopper.util.shapes.Polygon.<init>" ],
    "fullMethods" : [ "public Polygon(double[] lats, double[] lons) {\n    if (lats.length != lons.length)\n        throw new IllegalArgumentException(((\"Points must be of equal length but was \" + lats.length) + \" vs. \") + lons.length);\n\n    if (lats.length == 0)\n        throw new IllegalArgumentException(\"Points must not be empty\");\n\n    Coordinate[] coordinates = new Coordinate[lats.length + 1];\n    for (int i = 0; i < lats.length; i++) {\n        coordinates[i] = new Coordinate(lons[i], lats[i]);\n    }\n    coordinates[lats.length] = coordinates[0];\n    this.prepPolygon = new PreparedPolygon(factory.createPolygon(new PackedCoordinateSequence.Double(coordinates, 2)));\n    this.rectangle = prepPolygon.getGeometry().isRectangle();\n    this.envelope = prepPolygon.getGeometry().getEnvelopeInternal();\n    this.bbox = BBox.fromEnvelope(envelope);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.<init>", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.ConnectedComponents.<init>" ],
    "fullMethods" : [ "/**\n * Like {@link #findComponents(Graph, EdgeTransitionFilter, boolean)}, but the search only starts at the\n * given edges. This does not mean the search cannot expand to other edges, but this can be controlled by the\n * edgeTransitionFilter. This method does not return single edge components (the excludeSingleEdgeComponents option is\n * set to true).\n */\npublic static ConnectedComponents findComponentsForStartEdges(Graph graph, EdgeTransitionFilter edgeTransitionFilter, IntContainer edges) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, true).findComponentsForStartEdges(edges);\n}", "private EdgeBasedTarjanSCC(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    this.graph = graph;\n    this.edgeTransitionFilter = edgeTransitionFilter;\n    this.explorer = graph.createEdgeExplorer();\n    tarjanStack = new IntArrayDeque();\n    dfsStackPQ = new LongArrayDeque();\n    dfsStackAdj = new IntArrayDeque();\n    components = new ConnectedComponents(excludeSingleEdgeComponents ? -1 : 2 * graph.getEdges());\n    this.excludeSingleEdgeComponents = excludeSingleEdgeComponents;\n}", "ConnectedComponents(int edgeKeys) {\n    components = new ArrayList<>();\n    singleEdgeComponents = new BitSet(Math.max(edgeKeys, 0));\n    if (!singleEdgeComponents.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    biggestComponent = new IntArrayList();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.<init>", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.ConnectedComponents.<init>" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param edgeTransitionFilter\n * \t\tOnly edge transitions accepted by this filter will be considered when we explore the graph.\n * \t\tIf a turn is not accepted the corresponding path will be ignored (edges that are only connected\n * \t\tby a path with such a turn will not be considered to belong to the same component)\n * @param excludeSingleEdgeComponents\n * \t\tif set to true components that only contain a single edge will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponents();\n}", "private EdgeBasedTarjanSCC(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    this.graph = graph;\n    this.edgeTransitionFilter = edgeTransitionFilter;\n    this.explorer = graph.createEdgeExplorer();\n    tarjanStack = new IntArrayDeque();\n    dfsStackPQ = new LongArrayDeque();\n    dfsStackAdj = new IntArrayDeque();\n    components = new ConnectedComponents(excludeSingleEdgeComponents ? -1 : 2 * graph.getEdges());\n    this.excludeSingleEdgeComponents = excludeSingleEdgeComponents;\n}", "ConnectedComponents(int edgeKeys) {\n    components = new ArrayList<>();\n    singleEdgeComponents = new BitSet(Math.max(edgeKeys, 0));\n    if (!singleEdgeComponents.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    biggestComponent = new IntArrayList();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.<init>" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponentsRecursive();\n}", "private TarjanSCC(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    this.graph = graph;\n    this.edgeFilter = edgeFilter;\n    explorer = graph.createEdgeExplorer(edgeFilter);\n    nodeIndex = new int[graph.getNodes()];\n    nodeLowLink = new int[graph.getNodes()];\n    Arrays.fill(nodeIndex, -1);\n    Arrays.fill(nodeLowLink, -1);\n    nodeOnStack = new BitSet(graph.getNodes());\n    if (!nodeOnStack.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    tarjanStack = new IntArrayDeque();\n    dfsStack = new LongArrayDeque();\n    components = new ConnectedComponents(excludeSingleNodeComponents ? -1 : graph.getNodes());\n    this.excludeSingleNodeComponents = excludeSingleNodeComponents;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.<init>" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param excludeSingleNodeComponents\n * \t\tif set to true components that only contain a single node will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponents();\n}", "private TarjanSCC(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    this.graph = graph;\n    this.edgeFilter = edgeFilter;\n    explorer = graph.createEdgeExplorer(edgeFilter);\n    nodeIndex = new int[graph.getNodes()];\n    nodeLowLink = new int[graph.getNodes()];\n    Arrays.fill(nodeIndex, -1);\n    Arrays.fill(nodeLowLink, -1);\n    nodeOnStack = new BitSet(graph.getNodes());\n    if (!nodeOnStack.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    tarjanStack = new IntArrayDeque();\n    dfsStack = new LongArrayDeque();\n    components = new ConnectedComponents(excludeSingleNodeComponents ? -1 : graph.getNodes());\n    this.excludeSingleNodeComponents = excludeSingleNodeComponents;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.BaseGraphNodesAndEdges.sortEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.BaseGraphNodesAndEdges.sortEdges" ],
    "fullMethods" : [ "public void sortEdges(IntUnaryOperator getNewEdgeForOldEdge) {\n    BitSet visited = new BitSet(getEdges());\n    for (int edge = 0; edge < getEdges(); edge++) {\n        if (visited.get(edge))\n            continue;\n\n        int curr = edge;\n        long pointer = toEdgePointer(curr);\n        int nodeA = getNodeA(pointer);\n        int nodeB = getNodeB(pointer);\n        int linkA = getLinkA(pointer);\n        int linkB = getLinkB(pointer);\n        int dist = edges.getInt(pointer + E_DIST);\n        int kv = getKeyValuesRef(pointer);\n        IntsRef flags = createEdgeFlags();\n        readFlags(pointer, flags);\n        long geo = getGeoRef(pointer);\n        do {\n            visited.set(curr);\n            int newEdge = getNewEdgeForOldEdge.applyAsInt(curr);\n            long newPointer = toEdgePointer(newEdge);\n            int tmpNodeA = getNodeA(newPointer);\n            int tmpNodeB = getNodeB(newPointer);\n            int tmpLinkA = getLinkA(newPointer);\n            int tmpLinkB = getLinkB(newPointer);\n            int tmpDist = edges.getInt(newPointer + E_DIST);\n            int tmpKV = getKeyValuesRef(newPointer);\n            IntsRef tmpFlags = createEdgeFlags();\n            readFlags(newPointer, tmpFlags);\n            long tmpGeo = getGeoRef(newPointer);\n            setNodeA(newPointer, nodeA);\n            setNodeB(newPointer, nodeB);\n            setLinkA(newPointer, linkA == (-1) ? -1 : getNewEdgeForOldEdge.applyAsInt(linkA));\n            setLinkB(newPointer, linkB == (-1) ? -1 : getNewEdgeForOldEdge.applyAsInt(linkB));\n            edges.setInt(newPointer + E_DIST, dist);\n            setKeyValuesRef(newPointer, kv);\n            writeFlags(newPointer, flags);\n            setGeoRef(newPointer, geo);\n            nodeA = tmpNodeA;\n            nodeB = tmpNodeB;\n            linkA = tmpLinkA;\n            linkB = tmpLinkB;\n            dist = tmpDist;\n            kv = tmpKV;\n            flags = tmpFlags;\n            geo = tmpGeo;\n            curr = newEdge;\n        } while (curr != edge );\n    }\n    // update edge references\n    for (int node = 0; node < getNodes(); node++) {\n        long pointer = toNodePointer(node);\n        setEdgeRef(pointer, getNewEdgeForOldEdge.applyAsInt(getEdgeRef(pointer)));\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.BaseGraphNodesAndEdges.relabelNodes",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.BaseGraphNodesAndEdges.relabelNodes" ],
    "fullMethods" : [ "public void relabelNodes(IntUnaryOperator getNewNodeForOldNode) {\n    for (int edge = 0; edge < getEdges(); edge++) {\n        long pointer = toEdgePointer(edge);\n        setNodeA(pointer, getNewNodeForOldNode.applyAsInt(getNodeA(pointer)));\n        setNodeB(pointer, getNewNodeForOldNode.applyAsInt(getNodeB(pointer)));\n    }\n    BitSet visited = new BitSet(getNodes());\n    for (int node = 0; node < getNodes(); node++) {\n        if (visited.get(node))\n            continue;\n\n        int curr = node;\n        long pointer = toNodePointer(node);\n        int edgeRef = getEdgeRef(pointer);\n        double lat = getLat(pointer);\n        double lon = getLon(pointer);\n        double ele = (withElevation()) ? getEle(pointer) : Double.NaN;\n        int tc = (withTurnCosts()) ? getTurnCostRef(pointer) : -1;\n        do {\n            visited.set(curr);\n            int newNode = getNewNodeForOldNode.applyAsInt(curr);\n            long newPointer = toNodePointer(newNode);\n            int tmpEdgeRef = getEdgeRef(newPointer);\n            double tmpLat = getLat(newPointer);\n            double tmpLon = getLon(newPointer);\n            double tmpEle = (withElevation()) ? getEle(newPointer) : Double.NaN;\n            int tmpTC = (withTurnCosts()) ? getTurnCostRef(newPointer) : -1;\n            setEdgeRef(newPointer, edgeRef);\n            setLat(newPointer, lat);\n            setLon(newPointer, lon);\n            if (withElevation())\n                setEle(newPointer, ele);\n\n            if (withTurnCosts())\n                setTurnCostRef(newPointer, tc);\n\n            edgeRef = tmpEdgeRef;\n            lat = tmpLat;\n            lon = tmpLon;\n            ele = tmpEle;\n            tc = tmpTC;\n            curr = newNode;\n        } while (curr != node );\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.<init>", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.ConnectedComponents.<init>" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeTransitionFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponentsRecursive();\n}", "private EdgeBasedTarjanSCC(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    this.graph = graph;\n    this.edgeTransitionFilter = edgeTransitionFilter;\n    this.explorer = graph.createEdgeExplorer();\n    tarjanStack = new IntArrayDeque();\n    dfsStackPQ = new LongArrayDeque();\n    dfsStackAdj = new IntArrayDeque();\n    components = new ConnectedComponents(excludeSingleEdgeComponents ? -1 : 2 * graph.getEdges());\n    this.excludeSingleEdgeComponents = excludeSingleEdgeComponents;\n}", "ConnectedComponents(int edgeKeys) {\n    components = new ArrayList<>();\n    singleEdgeComponents = new BitSet(Math.max(edgeKeys, 0));\n    if (!singleEdgeComponents.getClass().getName().contains(\"hppc\"))\n        throw new IllegalStateException(\"Was meant to be hppc BitSet\");\n\n    biggestComponent = new IntArrayList();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve" ],
    "fullMethods" : [ "public static void sortGraphAlongHilbertCurve(BaseGraph graph) {\n    logger.info(\"sorting graph along Hilbert curve...\");\n    StopWatch sw = StopWatch.started();\n    NodeAccess na = graph.getNodeAccess();\n    final int order = 31;// using 15 would allow us to use ints for sortIndices, but this would result in (marginally) slower routing\n\n    LongArrayList sortIndices = new LongArrayList();\n    for (int node = 0; node < graph.getNodes(); node++)\n        sortIndices.add(latLonToHilbertIndex(na.getLat(node), na.getLon(node), order));\n\n    int[] nodeOrder = IndirectSort.mergesort(0, graph.getNodes(), (nodeA, nodeB) -> Long.compare(sortIndices.get(nodeA), sortIndices.get(nodeB)));\n    EdgeExplorer explorer = graph.createEdgeExplorer();\n    int edges = graph.getEdges();\n    IntArrayList edgeOrder = new IntArrayList();\n    BitSet edgesFound = new BitSet(edges);\n    for (int node : nodeOrder) {\n        EdgeIterator iter = explorer.setBaseNode(node);\n        while (iter.next()) {\n            if (!edgesFound.get(iter.getEdge())) {\n                edgeOrder.add(iter.getEdge());\n                edgesFound.set(iter.getEdge());\n            }\n        } \n    }\n    IntArrayList newEdgesByOldEdges = ArrayUtil.invert(edgeOrder);\n    IntArrayList newNodesByOldNodes = IntArrayList.from(ArrayUtil.invert(nodeOrder));\n    logger.info(\"calculating sort order took: \" + sw.stop().getTimeString());\n    sortGraphForGivenOrdering(graph, newNodesByOldNodes, newEdgesByOldEdges);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.isPermutation",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.isPermutation" ],
    "fullMethods" : [ "public static boolean isPermutation(IntArrayList arr) {\n    BitSet present = new BitSet(arr.size());\n    for (IntCursor e : arr) {\n        if ((e.value >= arr.size()) || (e.value < 0))\n            return false;\n\n        if (present.get(e.value))\n            return false;\n\n        present.set(e.value);\n    }\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryGraph.apply",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.contains",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryGraph.apply" ],
    "fullMethods" : [ "@Override\npublic void apply(int node, QueryOverlay.EdgeChanges edgeChanges) {\n    List<EdgeIteratorState> virtualEdges = new ArrayList<>(edgeChanges.getAdditionalEdges());\n    EdgeIterator mainIter = mainExplorer.setBaseNode(node);\n    while (mainIter.next()) {\n        if (!edgeChanges.getRemovedEdges().contains(mainIter.getEdge())) {\n            virtualEdges.add(mainIter.detach(false));\n        }\n    } \n    virtualEdgesAtRealNodes.put(node, virtualEdges);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.apply",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.contains",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.apply" ],
    "fullMethods" : [ "@Override\npublic void apply(int node, QueryOverlay.EdgeChanges edgeChanges) {\n    List<RoutingCHEdgeIteratorState> virtualEdges = new ArrayList<>();\n    for (EdgeIteratorState v : edgeChanges.getAdditionalEdges()) {\n        assert v.getBaseNode() == node;\n        int edge = v.getEdge();\n        if (queryGraph.isVirtualEdge(edge)) {\n            edge = shiftVirtualEdgeIDForCH(edge);\n        }\n        virtualEdges.add(buildVirtualCHEdgeState(v, edge));\n    }\n    RoutingCHEdgeIterator iter = explorer.setBaseNode(node);\n    while (iter.next()) {\n        // shortcuts cannot be in the removed edge set because this was determined on the (base) query graph\n        if (iter.isShortcut()) {\n            virtualEdges.add(new VirtualCHEdgeIteratorState(iter.getEdge(), NO_EDGE, iter.getBaseNode(), iter.getAdjNode(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getSkippedEdge1(), iter.getSkippedEdge2(), iter.getWeight(false), iter.getWeight(true)));\n        } else if (!edgeChanges.getRemovedEdges().contains(iter.getOrigEdge())) {\n            virtualEdges.add(new VirtualCHEdgeIteratorState(iter.getEdge(), iter.getOrigEdge(), iter.getBaseNode(), iter.getAdjNode(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), NO_EDGE, NO_EDGE, iter.getWeight(false), iter.getWeight(true)));\n        }\n    } \n    virtualEdgesAtRealNodes.put(node, virtualEdges);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.getLast",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.getLast" ],
    "fullMethods" : [ "public static int getLast(IntArrayList list) {\n    if (list.isEmpty())\n        throw new IllegalArgumentException(\"Cannot get last element of an empty list\");\n\n    return list.get(list.size() - 1);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.RestrictionTopology.way",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.RestrictionTopology.way", "com.graphhopper.reader.osm.RestrictionTopology.<init>" ],
    "fullMethods" : [ "public static RestrictionTopology way(IntArrayList fromEdges, IntArrayList viaEdges, IntArrayList toEdges, IntArrayList viaNodes) {\n    return new RestrictionTopology(true, viaNodes, fromEdges, viaEdges, toEdges);\n}", "private RestrictionTopology(boolean isViaWayRestriction, IntArrayList viaNodes, IntArrayList fromEdges, IntArrayList viaEdges, IntArrayList toEdges) {\n    if ((fromEdges.size() > 1) && (toEdges.size() > 1))\n        throw new IllegalArgumentException(\"fromEdges and toEdges cannot be size > 1 at the same time\");\n\n    if (fromEdges.isEmpty() || toEdges.isEmpty())\n        throw new IllegalArgumentException(\"fromEdges and toEdges must not be empty\");\n\n    if ((!isViaWayRestriction) && (viaNodes.size() != 1))\n        throw new IllegalArgumentException(\"for node restrictions there must be exactly one via node\");\n\n    if ((!isViaWayRestriction) && (viaEdges != null))\n        throw new IllegalArgumentException(\"for node restrictions the viaEdges must be null\");\n\n    if (isViaWayRestriction && viaEdges.isEmpty())\n        throw new IllegalArgumentException(\"for way restrictions there must at least one via edge\");\n\n    if (isViaWayRestriction && (viaNodes.size() != (viaEdges.size() + 1)))\n        throw new IllegalArgumentException(\"for way restrictions there must be one via node more than there are via edges\");\n\n    this.isViaWayRestriction = isViaWayRestriction;\n    this.viaNodes = viaNodes;\n    this.fromEdges = fromEdges;\n    this.viaEdges = viaEdges;\n    this.toEdges = toEdges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.calcNodes",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.calcNodes" ],
    "fullMethods" : [ "/**\n *\n * @return the uncached node indices of the tower nodes in this path.\n */\npublic IntIndexedContainer calcNodes() {\n    final IntArrayList nodes = new IntArrayList(edgeIds.size() + 1);\n    if (edgeIds.isEmpty()) {\n        if (isFound()) {\n            nodes.add(endNode);\n        }\n        return nodes;\n    }\n    int tmpNode = getFromNode();\n    nodes.add(tmpNode);\n    forEveryEdge(new EdgeVisitor() {\n        @Override\n        public void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n            nodes.add(eb.getAdjNode());\n        }\n\n        @Override\n        public void finish() {\n        }\n    });\n    return nodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.CHPathCalculator.calcPaths",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.CHPathCalculator.calcPaths" ],
    "fullMethods" : [ "@Override\npublic List<Path> calcPaths(int from, int to, EdgeRestrictions edgeRestrictions) {\n    if (!edgeRestrictions.getUnfavoredEdges().isEmpty())\n        throw new IllegalArgumentException(\"Using unfavored edges is currently not supported for CH\");\n\n    EdgeToEdgeRoutingAlgorithm algo = createAlgo();\n    return calcPaths(from, to, edgeRestrictions, algo);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction", "com.graphhopper.reader.osm.OSMRestrictionConverter.createRestrictionsForViaEdgeOnlyRestriction" ],
    "fullMethods" : [ "/**\n * Converts an OSM restriction to (multiple) single 'no' restrictions to be fed into {@link RestrictionSetter}\n */\npublic static List<RestrictionSetter.Restriction> buildRestrictionsForOSMRestriction(BaseGraph baseGraph, RestrictionTopology topology, RestrictionType type) {\n    List<RestrictionSetter.Restriction> result = new ArrayList<>();\n    if (type == NO) {\n        if (topology.isViaWayRestriction()) {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges()) {\n                    IntArrayList edges = new IntArrayList(topology.getViaEdges().size() + 2);\n                    edges.add(fromEdge.value);\n                    edges.addAll(topology.getViaEdges());\n                    edges.add(toEdge.value);\n                    result.add(RestrictionSetter.createViaEdgeRestriction(edges));\n                }\n\n        } else {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges())\n                    result.add(RestrictionSetter.createViaNodeRestriction(fromEdge.value, topology.getViaNodes().get(0), toEdge.value));\n\n\n        }\n    } else if (type == ONLY) {\n        if ((topology.getFromEdges().size() > 1) || (topology.getToEdges().size() > 1))\n            throw new IllegalArgumentException(\"'Only' restrictions with multiple from- or to- edges are not supported\");\n\n        if (topology.isViaWayRestriction())\n            result.addAll(createRestrictionsForViaEdgeOnlyRestriction(baseGraph, topology));\n        else\n            result.addAll(createRestrictionsForViaNodeOnlyRestriction(baseGraph.createEdgeExplorer(), topology.getFromEdges().get(0), topology.getViaNodes().get(0), topology.getToEdges().get(0)));\n\n    } else\n        throw new IllegalArgumentException(\"Unexpected restriction type: \" + type);\n\n    return result;\n}", "private static List<RestrictionSetter.Restriction> createRestrictionsForViaEdgeOnlyRestriction(BaseGraph graph, RestrictionTopology topology) {\n    // For via-way ONLY restrictions we have to turn from the from-edge onto the first via-edge,\n    // continue with the next via-edge(s) and finally turn onto the to-edge. So we cannot branch\n    // out anywhere. If we don't start with the from-edge the restriction does not apply at all.\n    // c.f. https://github.com/valhalla/valhalla/discussions/4764\n    if (topology.getViaEdges().isEmpty())\n        throw new IllegalArgumentException(\"Via-edge restrictions must have at least one via-edge\");\n\n    final EdgeExplorer explorer = graph.createEdgeExplorer();\n    IntArrayList edges = collectEdges(topology);\n    List<RestrictionSetter.Restriction> result = createRestrictionsForViaNodeOnlyRestriction(explorer, edges.get(0), topology.getViaNodes().get(0), edges.get(1));\n    for (int i = 2; i < edges.size(); i++) {\n        EdgeIterator iter = explorer.setBaseNode(topology.getViaNodes().get(i - 1));\n        while (iter.next()) {\n            if ((iter.getEdge() != edges.get(i)) && // We deny u-turns within via-way 'only' restrictions unconditionally (see below), so no need\n            // to restrict them here as well\n            (iter.getEdge() != edges.get(i - 1))) {\n                IntArrayList restriction = new IntArrayList(i + 1);\n                for (int j = 0; j < i; j++)\n                    restriction.add(edges.get(j));\n\n                restriction.add(iter.getEdge());\n                // To prevent an exception in RestrictionSetter we need to prevent unambiguous\n                // restrictions like a-b-a. Maybe we even need to exclude other cases as well,\n                // but so far they did not occur.\n                if ((restriction.size() == 3) && (restriction.get(0) == restriction.get(restriction.size() - 1)))\n                    continue;\n\n                result.add(RestrictionSetter.createViaEdgeRestriction(restriction));\n            }\n        } \n    }\n    // explicitly deny all u-turns along the via-way 'only' restriction\n    // todo: currently disabled! we skip u-turn restrictions to improve reading performance,\n    // because so far they are ignored anyway! https://github.com/graphhopper/graphhopper/issues/2570\n    // for (int i = 0; i < edges.size() - 1; i++) {\n    // result.add(RestrictionSetter.createViaNodeRestriction(edges.get(i), topology.getViaNodes().get(i), edges.get(i)));\n    // }\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.RestrictionTopology.node",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.RestrictionTopology.node", "com.graphhopper.reader.osm.RestrictionTopology.<init>" ],
    "fullMethods" : [ "public static RestrictionTopology node(IntArrayList fromEdges, int viaNode, IntArrayList toEdges) {\n    return new RestrictionTopology(false, IntArrayList.from(viaNode), fromEdges, null, toEdges);\n}", "private RestrictionTopology(boolean isViaWayRestriction, IntArrayList viaNodes, IntArrayList fromEdges, IntArrayList viaEdges, IntArrayList toEdges) {\n    if ((fromEdges.size() > 1) && (toEdges.size() > 1))\n        throw new IllegalArgumentException(\"fromEdges and toEdges cannot be size > 1 at the same time\");\n\n    if (fromEdges.isEmpty() || toEdges.isEmpty())\n        throw new IllegalArgumentException(\"fromEdges and toEdges must not be empty\");\n\n    if ((!isViaWayRestriction) && (viaNodes.size() != 1))\n        throw new IllegalArgumentException(\"for node restrictions there must be exactly one via node\");\n\n    if ((!isViaWayRestriction) && (viaEdges != null))\n        throw new IllegalArgumentException(\"for node restrictions the viaEdges must be null\");\n\n    if (isViaWayRestriction && viaEdges.isEmpty())\n        throw new IllegalArgumentException(\"for way restrictions there must at least one via edge\");\n\n    if (isViaWayRestriction && (viaNodes.size() != (viaEdges.size() + 1)))\n        throw new IllegalArgumentException(\"for way restrictions there must be one via node more than there are via edges\");\n\n    this.isViaWayRestriction = isViaWayRestriction;\n    this.viaNodes = viaNodes;\n    this.fromEdges = fromEdges;\n    this.viaEdges = viaEdges;\n    this.toEdges = toEdges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.calcEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.calcEdges" ],
    "fullMethods" : [ "/**\n * Returns the list of all edges.\n */\npublic List<EdgeIteratorState> calcEdges() {\n    final List<EdgeIteratorState> edges = new ArrayList<>(edgeIds.size());\n    if (edgeIds.isEmpty())\n        return edges;\n\n    forEveryEdge(new EdgeVisitor() {\n        @Override\n        public void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n            edges.add(eb);\n        }\n\n        @Override\n        public void finish() {\n        }\n    });\n    return edges;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.calcPoints",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.calcPoints" ],
    "fullMethods" : [ "/**\n * This method calculated a list of points for this path\n * <p>\n *\n * @return the geometry of this path\n */\npublic PointList calcPoints() {\n    final PointList points = new PointList(edgeIds.size() + 1, nodeAccess.is3D());\n    if (edgeIds.isEmpty()) {\n        if (isFound()) {\n            points.add(nodeAccess, endNode);\n        }\n        return points;\n    }\n    int tmpNode = getFromNode();\n    points.add(nodeAccess, tmpNode);\n    forEveryEdge(new EdgeVisitor() {\n        @Override\n        public void next(EdgeIteratorState eb, int index, int prevEdgeId) {\n            PointList pl = eb.fetchWayGeometry(FetchMode.PILLAR_AND_ADJ);\n            for (int j = 0; j < pl.size(); j++) {\n                points.add(pl, j);\n            }\n        }\n\n        @Override\n        public void finish() {\n        }\n    });\n    return points;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ViaRouting.lookup",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.isEmpty",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ViaRouting.lookup" ],
    "fullMethods" : [ "/**\n *\n * @throws MultiplePointsNotFoundException\n * \t\tin case one or more points could not be resolved\n */\npublic static List<Snap> lookup(EncodedValueLookup lookup, List<GHPoint> points, EdgeFilter snapFilter, LocationIndex locationIndex, List<String> snapPreventions, List<String> pointHints, DirectedEdgeFilter directedSnapFilter, List<Double> headings) {\n    if (points.size() < 2)\n        throw new IllegalArgumentException(\"At least 2 points have to be specified, but was:\" + points.size());\n\n    final EnumEncodedValue<RoadClass> roadClassEnc = lookup.getEnumEncodedValue(RoadClass.KEY, RoadClass.class);\n    final EnumEncodedValue<RoadEnvironment> roadEnvEnc = lookup.getEnumEncodedValue(RoadEnvironment.KEY, RoadEnvironment.class);\n    EdgeFilter strictEdgeFilter = (snapPreventions.isEmpty()) ? snapFilter : new SnapPreventionEdgeFilter(snapFilter, roadClassEnc, roadEnvEnc, snapPreventions);\n    List<Snap> snaps = new ArrayList<>(points.size());\n    IntArrayList pointsNotFound = new IntArrayList();\n    for (int placeIndex = 0; placeIndex < points.size(); placeIndex++) {\n        GHPoint point = points.get(placeIndex);\n        Snap snap = null;\n        if ((placeIndex < headings.size()) && (!Double.isNaN(headings.get(placeIndex)))) {\n            if ((!pointHints.isEmpty()) && (!Helper.isEmpty(pointHints.get(placeIndex))))\n                throw new IllegalArgumentException((\"Cannot specify heading and point_hint at the same time. \" + \"Make sure you specify either an empty point_hint (String) or a NaN heading (double) for point \") + placeIndex);\n\n            snap = locationIndex.findClosest(point.lat, point.lon, new HeadingEdgeFilter(directedSnapFilter, headings.get(placeIndex), point));\n        } else if (!pointHints.isEmpty()) {\n            snap = locationIndex.findClosest(point.lat, point.lon, new NameSimilarityEdgeFilter(strictEdgeFilter, pointHints.get(placeIndex), point, 170));\n        } else if (!snapPreventions.isEmpty()) {\n            snap = locationIndex.findClosest(point.lat, point.lon, strictEdgeFilter);\n        }\n        if ((snap == null) || (!snap.isValid()))\n            snap = locationIndex.findClosest(point.lat, point.lon, snapFilter);\n\n        if (!snap.isValid())\n            pointsNotFound.add(placeIndex);\n\n        snaps.add(snap);\n    }\n    if (!pointsNotFound.isEmpty())\n        throw new MultiplePointsNotFoundException(pointsNotFound);\n\n    return snaps;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntScatterSet.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.initForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntSet.<init>" ],
    "fullMethods" : [ "/**\n * Like {@link #findComponents(Graph, EdgeTransitionFilter, boolean)}, but the search only starts at the\n * given edges. This does not mean the search cannot expand to other edges, but this can be controlled by the\n * edgeTransitionFilter. This method does not return single edge components (the excludeSingleEdgeComponents option is\n * set to true).\n */\npublic static ConnectedComponents findComponentsForStartEdges(Graph graph, EdgeTransitionFilter edgeTransitionFilter, IntContainer edges) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, true).findComponentsForStartEdges(edges);\n}", "private ConnectedComponents findComponentsForStartEdges(IntContainer startEdges) {\n    initForStartEdges(startEdges.size());\n    for (IntCursor edge : startEdges) {\n        // todo: using getEdgeIteratorState here is not efficient\n        EdgeIteratorState edgeState = graph.getEdgeIteratorState(edge.value, Integer.MIN_VALUE);\n        if (!edgeTransitionFilter.accept(NO_EDGE, edgeState))\n            continue;\n\n        findComponentsForEdgeState(edgeState);\n    }\n    return components;\n}", "private void initForStartEdges(int edges) {\n    edgeKeyIndex = new TarjanHashIntIntMap(2 * edges);\n    edgeKeyLowLink = new TarjanHashIntIntMap(2 * edges);\n    edgeKeyOnStack = new TarjanHashIntSet(2 * edges);\n}", "TarjanHashIntSet(int keys) {\n    set = new IntScatterSet(keys);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.ArrayEdgeIntAccess.setInt",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ev.ArrayEdgeIntAccess.setInt" ],
    "fullMethods" : [ "@Override\npublic void setInt(int edgeId, int index, int value) {\n    int arrIndex = (edgeId * intsPerEdge) + index;\n    if (arrIndex >= arr.size())\n        arr.resize(arrIndex + 1);\n\n    arr.set(arrIndex, value);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.<init>" ],
    "fullMethods" : [ "public InternalRestriction(IntArrayList viaNodes, IntArrayList edgeKeys) {\n    this.edgeKeys = edgeKeys;\n    this.viaNodes = viaNodes;\n    this.actualEdgeKeys = ArrayUtil.constant(edgeKeys.size(), -1);\n    this.actualEdgeKeys.set(0, edgeKeys.get(0));\n    this.actualEdgeKeys.set(edgeKeys.size() - 1, edgeKeys.get(edgeKeys.size() - 1));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.setShortcutForPrepareEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.setShortcutForPrepareEdge" ],
    "fullMethods" : [ "public void setShortcutForPrepareEdge(int prepareEdge, int shortcut) {\n    int index = prepareEdge - edges;\n    if (index >= shortcutsByPrepareEdges.size())\n        shortcutsByPrepareEdges.resize(index + 1);\n\n    shortcutsByPrepareEdges.set(index, shortcut);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.range",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.range" ],
    "fullMethods" : [ "/**\n * Creates an IntArrayList filled with the integers [startIncl,endExcl[\n */\npublic static IntArrayList range(int startIncl, int endExcl) {\n    IntArrayList result = new IntArrayList(endExcl - startIncl);\n    result.elementsCount = endExcl - startIncl;\n    for (int i = 0; i < result.size(); ++i)\n        result.set(i, startIncl + i);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.prepareForContraction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.prepareForContraction", "com.graphhopper.routing.ch.CHPreparationGraph.OrigGraph.Builder.build", "com.graphhopper.routing.ch.CHPreparationGraph.OrigGraph.Builder.buildFirstEdgesByNode" ],
    "fullMethods" : [ "public void prepareForContraction() {\n    checkNotReady();\n    origGraph = (edgeBased) ? origGraphBuilder.build() : null;\n    origGraphBuilder = null;\n    ready = true;\n}", "{\n    com.carrotsearch.hppc.IntArrayList $stack10, $stack11, $stack12, $stack2, $stack3, $stack7, $stack8, $stack9;\n    com.carrotsearch.hppc.sorting.IndirectComparator #l0;\n    com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator #l1;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph $stack13;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder this;\n    int $stack6;\n    int[] $stack4, sortOrder;\n    java.lang.Object $stack5;\n\n\n    this := @this: com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder;\n    $stack2 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack6 = $stack2.<com.carrotsearch.hppc.IntArrayList: int elementsCount>;\n    $stack5 = new com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator;\n    $stack3 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack4 = $stack3.<com.carrotsearch.hppc.IntArrayList: int[] buffer>;\n    #l1 = (com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator) $stack5;\n    specialinvoke #l1.<com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator: void <init>(int[])>($stack4);\n    #l0 = (com.carrotsearch.hppc.sorting.IndirectComparator) $stack5;\n    sortOrder = staticinvoke <com.carrotsearch.hppc.sorting.IndirectSort: int[] mergesort(int,int,com.carrotsearch.hppc.sorting.IndirectComparator)>(0, $stack6, #l0);\n    $stack7 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack7, sortOrder);\n    $stack8 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack8, sortOrder);\n    $stack9 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack9, sortOrder);\n    $stack13 = new com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph;\n    $stack12 = virtualinvoke this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList buildFirstEdgesByNode()>();\n    $stack11 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    $stack10 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    specialinvoke $stack13.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph: void <init>(com.carrotsearch.hppc.IntArrayList,com.carrotsearch.hppc.IntArrayList,com.carrotsearch.hppc.IntArrayList)>($stack12, $stack11, $stack10);\n\n    return $stack13;\n}\n", "{\n    com.carrotsearch.hppc.IntArrayList $stack7, $stack9, firstEdgesByNode;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder this;\n    int $stack10, $stack6, $stack8, edgeIndex, from, numEdges, numFroms;\n\n\n    this := @this: com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder;\n    $stack6 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxFrom>;\n    numFroms = $stack6 + 1;\n    $stack7 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    numEdges = virtualinvoke $stack7.<com.carrotsearch.hppc.IntArrayList: int size()>();\n    $stack8 = numFroms + 1;\n    firstEdgesByNode = staticinvoke <com.graphhopper.util.ArrayUtil: com.carrotsearch.hppc.IntArrayList zero(int)>($stack8);\n\n    if numFroms != 0 goto label1;\n    virtualinvoke firstEdgesByNode.<com.carrotsearch.hppc.IntArrayList: int set(int,int)>(0, numEdges);\n\n    return firstEdgesByNode;\n\n  label1:\n    edgeIndex = 0;\n    from = 0;\n\n  label2:\n    if from >= numFroms goto label5;\n\n  label3:\n    if edgeIndex >= numEdges goto label4;\n    $stack9 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack10 = virtualinvoke $stack9.<com.carrotsearch.hppc.IntArrayList: int get(int)>(edgeIndex);\n\n    if $stack10 >= from goto label4;\n    edgeIndex = edgeIndex + 1;\n\n    goto label3;\n\n  label4:\n    virtualinvoke firstEdgesByNode.<com.carrotsearch.hppc.IntArrayList: int set(int,int)>(from, edgeIndex);\n    from = from + 1;\n\n    goto label2;\n\n  label5:\n    virtualinvoke firstEdgesByNode.<com.carrotsearch.hppc.IntArrayList: int set(int,int)>(numFroms, numEdges);\n\n    return firstEdgesByNode;\n}\n" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.invert",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.invert" ],
    "fullMethods" : [ "public static IntArrayList invert(IntArrayList list) {\n    IntArrayList result = new IntArrayList(list.size());\n    result.elementsCount = list.size();\n    for (int i = 0; i < result.elementsCount; ++i)\n        result.set(list.get(i), i);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.GHUtility.readCountries",
    "thirdPartyMethod" : "com.bedatadriven.jackson.datatype.jts.JtsModule.<init>",
    "thirdPartyPackage" : "com.bedatadriven.jackson.datatype.jts",
    "path" : [ "com.graphhopper.util.GHUtility.readCountries" ],
    "fullMethods" : [ "/**\n * Reads the country borders from the countries.geojson resource file\n */\npublic static List<CustomArea> readCountries() {\n    ObjectMapper objectMapper = new ObjectMapper();\n    objectMapper.registerModule(new JtsModule());\n    Set<String> enumSet = new HashSet<>(Country.values().length * 2);\n    for (Country c : Country.values()) {\n        if (c == Country.MISSING)\n            continue;\n\n        if (c.getStates().isEmpty())\n            enumSet.add(c.getAlpha2());\n        else\n            for (State s : c.getStates())\n                enumSet.add(s.getStateCode());\n\n\n    }\n    try (Reader reader = new InputStreamReader(GHUtility.class.getResourceAsStream(\"/com/graphhopper/countries/countries.geojson\"), StandardCharsets.UTF_8)) {\n        JsonFeatureCollection jsonFeatureCollection = objectMapper.readValue(reader, JsonFeatureCollection.class);\n        return // exclude areas not in the list of Country enums like FX => Metropolitan France\n        jsonFeatureCollection.getFeatures().stream().filter(customArea -> enumSet.contains(getIdOrPropertiesId(customArea))).map(f -> {\n            CustomArea ca = CustomArea.fromJsonFeature(f);\n            // the Feature does not include \"id\" but we expect it\n            if (f.getId() == null)\n                f.setId(getIdOrPropertiesId(f));\n\n            ca.getProperties().put(ISO_3166_2, f.getId());\n            return ca;\n        }).collect(Collectors.toList());\n    } catch (IOException e) {\n        throw new UncheckedIOException(e);\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.GraphHopper.resolveCustomAreas",
    "thirdPartyMethod" : "com.bedatadriven.jackson.datatype.jts.JtsModule.<init>",
    "thirdPartyPackage" : "com.bedatadriven.jackson.datatype.jts",
    "path" : [ "com.graphhopper.GraphHopper.resolveCustomAreas" ],
    "fullMethods" : [ "public static JsonFeatureCollection resolveCustomAreas(String customAreasDirectory) {\n    JsonFeatureCollection globalAreas = new JsonFeatureCollection();\n    if (!customAreasDirectory.isEmpty()) {\n        ObjectMapper mapper = new ObjectMapper().registerModule(new JtsModule());\n        try (DirectoryStream<Path> stream = Files.newDirectoryStream(Paths.get(customAreasDirectory), \"*.{geojson,json}\")) {\n            StreamSupport.stream(stream.spliterator(), false).sorted(Comparator.comparing(Path::toString)).forEach(customAreaFile -> {\n                try (BufferedReader reader = Files.newBufferedReader(customAreaFile, StandardCharsets.UTF_8)) {\n                    globalAreas.getFeatures().addAll(mapper.readValue(reader, JsonFeatureCollection.class).getFeatures());\n                } catch (IOException e) {\n                    throw new UncheckedIOException(e);\n                }\n            });\n            logger.info(((\"Will make \" + globalAreas.getFeatures().size()) + \" areas available to all custom profiles. Found in \") + customAreasDirectory);\n        } catch (IOException e) {\n            throw new UncheckedIOException(e);\n        }\n    }\n    return globalAreas;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LMPreparationHandler.init",
    "thirdPartyMethod" : "com.bedatadriven.jackson.datatype.jts.JtsModule.<init>",
    "thirdPartyPackage" : "com.bedatadriven.jackson.datatype.jts",
    "path" : [ "com.graphhopper.routing.lm.LMPreparationHandler.init", "com.graphhopper.routing.lm.LMPreparationHandler.loadLandmarkSplittingFeatureCollection" ],
    "fullMethods" : [ "public void init(GraphHopperConfig ghConfig) {\n    // throw explicit error for deprecated configs\n    if (ghConfig.has(\"prepare.lm.weightings\")) {\n        throw new IllegalStateException(\"Use profiles_lm instead of prepare.lm.weightings, see #1922 and docs/core/profiles.md\");\n    }\n    setPreparationThreads(ghConfig.getInt(Parameters.Landmark.PREPARE + \"threads\", getPreparationThreads()));\n    setLMProfiles(ghConfig.getLMProfiles());\n    landmarkCount = ghConfig.getInt(Parameters.Landmark.COUNT, landmarkCount);\n    logDetails = ghConfig.getBool(Landmark.PREPARE + \"log_details\", false);\n    minNodes = ghConfig.getInt(Landmark.PREPARE + \"min_network_size\", -1);\n    for (String loc : ghConfig.getString(Landmark.PREPARE + \"suggestions_location\", \"\").split(\",\")) {\n        if (!loc.trim().isEmpty())\n            lmSuggestionsLocations.add(loc.trim());\n\n    }\n    if (!isEnabled())\n        return;\n\n    String splitAreaLocation = ghConfig.getString(Landmark.PREPARE + \"split_area_location\", \"\");\n    JsonFeatureCollection landmarkSplittingFeatureCollection = loadLandmarkSplittingFeatureCollection(splitAreaLocation);\n    if ((landmarkSplittingFeatureCollection != null) && (!landmarkSplittingFeatureCollection.getFeatures().isEmpty())) {\n        List<SplitArea> splitAreas = landmarkSplittingFeatureCollection.getFeatures().stream().map(SplitArea::fromJsonFeature).collect(Collectors.toList());\n        areaIndex = new AreaIndex<>(splitAreas);\n    }\n}", "private JsonFeatureCollection loadLandmarkSplittingFeatureCollection(String splitAreaLocation) {\n    ObjectMapper objectMapper = new ObjectMapper();\n    objectMapper.registerModule(new JtsModule());\n    URL builtinSplittingFile = LandmarkStorage.class.getResource(\"map.geo.json\");\n    try (Reader reader = (splitAreaLocation.isEmpty()) ? new InputStreamReader(builtinSplittingFile.openStream(), UTF_CS) : new InputStreamReader(new FileInputStream(splitAreaLocation), UTF_CS)) {\n        JsonFeatureCollection result = objectMapper.readValue(reader, JsonFeatureCollection.class);\n        if (splitAreaLocation.isEmpty()) {\n            LOGGER.info(\"Loaded built-in landmark splitting collection from {}\", builtinSplittingFile);\n        } else {\n            LOGGER.info(\"Loaded landmark splitting collection from {}\", splitAreaLocation);\n        }\n        return result;\n    } catch (IOException e) {\n        LOGGER.error(\"Problem while reading border map GeoJSON. Skipping this.\", e);\n        return null;\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LandmarkStorage.LandmarkExplorer.initLandmarkWeights",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.forEach",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.lm.LandmarkStorage.LandmarkExplorer.initLandmarkWeights" ],
    "fullMethods" : [ "public void initLandmarkWeights(final int lmIdx, int lmNodeId, final long rowSize, final int offset) {\n    IntObjectMap<SPTEntry> map = (reverse) ? bestWeightMapTo : bestWeightMapFrom;\n    final AtomicInteger maxedout = new AtomicInteger(0);\n    final Map.Entry<Double, Double> finalMaxWeight = new MapEntry<>(0.0, 0.0);\n    map.forEach(new IntObjectProcedure<SPTEntry>() {\n        @Override\n        public void apply(int nodeId, SPTEntry b) {\n            if (!lms.setWeight(((nodeId * rowSize) + (lmIdx * 4)) + offset, b.weight)) {\n                maxedout.incrementAndGet();\n                finalMaxWeight.setValue(Math.max(b.weight, finalMaxWeight.getValue()));\n            }\n        }\n    });\n    if ((((double) (maxedout.get())) / map.size()) > 0.1) {\n        LOGGER.warn(((((((((((((((\"landmark \" + lmIdx) + \" (\") + nodeAccess.getLat(lmNodeId)) + \",\") + nodeAccess.getLon(lmNodeId)) + \"): \") + \"too many weights were maxed out (\") + maxedout.get()) + \"/\") + map.size()) + \"). Use a bigger factor than \") + lms.factor) + \". For example use maximum_lm_weight: \") + (finalMaxWeight.getValue() * 1.2)) + \" in your LM profile definition\");\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryGraph.create",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.forEach",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryGraph.create", "com.graphhopper.routing.querygraph.QueryGraph.<init>", "com.graphhopper.routing.querygraph.QueryGraph.buildVirtualEdgesAtRealNodes" ],
    "fullMethods" : [ "public static QueryGraph create(BaseGraph graph, List<Snap> snaps) {\n    return new QueryGraph(graph, snaps);\n}", "private QueryGraph(BaseGraph graph, List<Snap> snaps) {\n    baseGraph = graph;\n    baseNodes = graph.getNodes();\n    baseEdges = graph.getEdges();\n    queryOverlay = QueryOverlayBuilder.build(graph, snaps);\n    nodeAccess = new ExtendedNodeAccess(graph.getNodeAccess(), queryOverlay.getVirtualNodes(), baseNodes);\n    turnCostStorage = baseGraph.getTurnCostStorage();\n    // build data structures holding the virtual edges at all real/virtual nodes that are modified compared to the\n    // mainGraph.\n    final EdgeExplorer mainExplorer = baseGraph.createEdgeExplorer();\n    virtualEdgesAtRealNodes = buildVirtualEdgesAtRealNodes(mainExplorer);\n    virtualEdgesAtVirtualNodes = buildVirtualEdgesAtVirtualNodes();\n}", "private IntObjectMap<List<EdgeIteratorState>> buildVirtualEdgesAtRealNodes(final EdgeExplorer mainExplorer) {\n    final IntObjectMap<List<EdgeIteratorState>> virtualEdgesAtRealNodes = new GHIntObjectHashMap<>(queryOverlay.getEdgeChangesAtRealNodes().size());\n    queryOverlay.getEdgeChangesAtRealNodes().forEach(new IntObjectProcedure<QueryOverlay.EdgeChanges>() {\n        @Override\n        public void apply(int node, QueryOverlay.EdgeChanges edgeChanges) {\n            List<EdgeIteratorState> virtualEdges = new ArrayList<>(edgeChanges.getAdditionalEdges());\n            EdgeIterator mainIter = mainExplorer.setBaseNode(node);\n            while (mainIter.next()) {\n                if (!edgeChanges.getRemovedEdges().contains(mainIter.getEdge())) {\n                    virtualEdges.add(mainIter.detach(false));\n                }\n            } \n            virtualEdgesAtRealNodes.put(node, virtualEdges);\n        }\n    });\n    return virtualEdgesAtRealNodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.forEach",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.<init>", "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.buildVirtualEdgesAtRealNodes" ],
    "fullMethods" : [ "public QueryRoutingCHGraph(RoutingCHGraph routingCHGraph, QueryGraph queryGraph) {\n    this.routingCHGraph = routingCHGraph;\n    this.weighting = routingCHGraph.getWeighting();\n    this.queryOverlay = queryGraph.getQueryOverlay();\n    this.queryGraph = queryGraph;\n    this.queryGraphWeighting = queryGraph.wrapWeighting(weighting);\n    virtualOutEdgesAtRealNodes = buildVirtualEdgesAtRealNodes(routingCHGraph.createOutEdgeExplorer());\n    virtualInEdgesAtRealNodes = buildVirtualEdgesAtRealNodes(routingCHGraph.createInEdgeExplorer());\n    virtualEdgesAtVirtualNodes = buildVirtualEdgesAtVirtualNodes();\n    nodes = queryGraph.getNodes();\n}", "private IntObjectMap<List<RoutingCHEdgeIteratorState>> buildVirtualEdgesAtRealNodes(final RoutingCHEdgeExplorer explorer) {\n    final IntObjectMap<List<RoutingCHEdgeIteratorState>> virtualEdgesAtRealNodes = new IntObjectHashMap<>(queryOverlay.getEdgeChangesAtRealNodes().size());\n    queryOverlay.getEdgeChangesAtRealNodes().forEach(new IntObjectProcedure<QueryOverlay.EdgeChanges>() {\n        @Override\n        public void apply(int node, QueryOverlay.EdgeChanges edgeChanges) {\n            List<RoutingCHEdgeIteratorState> virtualEdges = new ArrayList<>();\n            for (EdgeIteratorState v : edgeChanges.getAdditionalEdges()) {\n                assert v.getBaseNode() == node;\n                int edge = v.getEdge();\n                if (queryGraph.isVirtualEdge(edge)) {\n                    edge = shiftVirtualEdgeIDForCH(edge);\n                }\n                virtualEdges.add(buildVirtualCHEdgeState(v, edge));\n            }\n            RoutingCHEdgeIterator iter = explorer.setBaseNode(node);\n            while (iter.next()) {\n                // shortcuts cannot be in the removed edge set because this was determined on the (base) query graph\n                if (iter.isShortcut()) {\n                    virtualEdges.add(new VirtualCHEdgeIteratorState(iter.getEdge(), NO_EDGE, iter.getBaseNode(), iter.getAdjNode(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getSkippedEdge1(), iter.getSkippedEdge2(), iter.getWeight(false), iter.getWeight(true)));\n                } else if (!edgeChanges.getRemovedEdges().contains(iter.getOrigEdge())) {\n                    virtualEdges.add(new VirtualCHEdgeIteratorState(iter.getEdge(), iter.getOrigEdge(), iter.getBaseNode(), iter.getAdjNode(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), NO_EDGE, NO_EDGE, iter.getWeight(false), iter.getWeight(true)));\n                }\n            } \n            virtualEdgesAtRealNodes.put(node, virtualEdges);\n        }\n    });\n    return virtualEdgesAtRealNodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate",
    "thirdPartyMethod" : "org.locationtech.jts.triangulate.DelaunayTriangulationBuilder.setSites",
    "thirdPartyPackage" : "org.locationtech.jts.triangulate",
    "path" : [ "com.graphhopper.isochrone.algorithm.JTSTriangulator.triangulate" ],
    "fullMethods" : [ "public Result triangulate(Snap snap, QueryGraph queryGraph, ShortestPathTree shortestPathTree, ToDoubleFunction<ShortestPathTree.IsoLabel> fz, double tolerance) {\n    final NodeAccess na = queryGraph.getNodeAccess();\n    Collection<Coordinate> sites = new ArrayList<>();\n    shortestPathTree.search(snap.getClosestNode(), label -> {\n        double exploreValue = fz.applyAsDouble(label);\n        double lat = na.getLat(label.node);\n        double lon = na.getLon(label.node);\n        Coordinate site = new Coordinate(lon, lat);\n        site.z = exploreValue;\n        sites.add(site);\n        // add a pillar node to increase precision a bit for longer roads\n        if (label.parent != null) {\n            EdgeIteratorState edge = queryGraph.getEdgeIteratorState(label.edge, label.node);\n            PointList innerPoints = edge.fetchWayGeometry(FetchMode.PILLAR_ONLY);\n            if (innerPoints.size() > 0) {\n                int midIndex = innerPoints.size() / 2;\n                // For edge-based routing we might have explored the same edge in two different directions.\n                // Here we make sure we only include the **same** point twice instead of two different ones.\n                if (((innerPoints.size() % 2) == 0) && edge.get(EdgeIteratorState.REVERSE_STATE))\n                    midIndex -= 1;\n\n                double lat2 = innerPoints.getLat(midIndex);\n                double lon2 = innerPoints.getLon(midIndex);\n                Coordinate site2 = new Coordinate(lon2, lat2);\n                site2.z = exploreValue;\n                sites.add(site2);\n            }\n        }\n    });\n    if (sites.size() > (routerConfig.getMaxVisitedNodes() / 3))\n        throw new IllegalArgumentException((\"Too many nodes would be included in post processing (\" + sites.size()) + \"). Let us know if you need this increased.\");\n\n    // Sites may contain repeated coordinates. Especially for edge-based traversal, that's expected -- we visit\n    // each node multiple times.\n    // But that's okay, the triangulator de-dupes by itself, and it keeps the first z-value it sees, which is\n    // what we want.\n    DelaunayTriangulationBuilder triangulationBuilder = new DelaunayTriangulationBuilder();\n    triangulationBuilder.setSites(sites);\n    triangulationBuilder.setTolerance(tolerance);\n    Geometry convexHull = triangulationBuilder.getEdges(new GeometryFactory()).convexHull();\n    // If there's only one site (and presumably also if the convex hull is otherwise degenerated),\n    // the triangulation only contains the frame, and not the site within the frame. Not sure if I agree with that.\n    // See ConformingDelaunayTriangulator, it does include a buffer for the frame, but that buffer is zero\n    // in these cases.\n    // It leads to the following follow-up defect:\n    // computeIsoline fails (returns an empty Multipolygon). This is clearly wrong, since\n    // the idea is that every real (non-frame) vertex has positive-length-edges around it that can be traversed\n    // to get a non-empty polygon.\n    // So we exclude this case for now (it is indeed only a corner-case).\n    if (!(convexHull instanceof Polygon)) {\n        throw new IllegalArgumentException(\"Too few points found. \" + \"Please try a different 'point' or a larger 'time_limit'.\");\n    }\n    QuadEdgeSubdivision tin = triangulationBuilder.getSubdivision();\n    for (Vertex vertex : ((Collection<Vertex>) (tin.getVertices(true)))) {\n        if (tin.isFrameVertex(vertex)) {\n            vertex.setZ(Double.MAX_VALUE);\n        }\n    }\n    ReadableTriangulation triangulation = ReadableTriangulation.wrap(tin);\n    return new Result(triangulation, triangulation.getEdges());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntIntScatterMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.initForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanHashIntIntMap.<init>" ],
    "fullMethods" : [ "/**\n * Like {@link #findComponents(Graph, EdgeTransitionFilter, boolean)}, but the search only starts at the\n * given edges. This does not mean the search cannot expand to other edges, but this can be controlled by the\n * edgeTransitionFilter. This method does not return single edge components (the excludeSingleEdgeComponents option is\n * set to true).\n */\npublic static ConnectedComponents findComponentsForStartEdges(Graph graph, EdgeTransitionFilter edgeTransitionFilter, IntContainer edges) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, true).findComponentsForStartEdges(edges);\n}", "private ConnectedComponents findComponentsForStartEdges(IntContainer startEdges) {\n    initForStartEdges(startEdges.size());\n    for (IntCursor edge : startEdges) {\n        // todo: using getEdgeIteratorState here is not efficient\n        EdgeIteratorState edgeState = graph.getEdgeIteratorState(edge.value, Integer.MIN_VALUE);\n        if (!edgeTransitionFilter.accept(NO_EDGE, edgeState))\n            continue;\n\n        findComponentsForEdgeState(edgeState);\n    }\n    return components;\n}", "private void initForStartEdges(int edges) {\n    edgeKeyIndex = new TarjanHashIntIntMap(2 * edges);\n    edgeKeyLowLink = new TarjanHashIntIntMap(2 * edges);\n    edgeKeyOnStack = new TarjanHashIntSet(2 * edges);\n}", "TarjanHashIntIntMap(int keys) {\n    this.map = new IntIntScatterMap(keys);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LandmarkStorage.LandmarkExplorer.initLandmarkWeights",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.lm.LandmarkStorage.LandmarkExplorer.initLandmarkWeights" ],
    "fullMethods" : [ "public void initLandmarkWeights(final int lmIdx, int lmNodeId, final long rowSize, final int offset) {\n    IntObjectMap<SPTEntry> map = (reverse) ? bestWeightMapTo : bestWeightMapFrom;\n    final AtomicInteger maxedout = new AtomicInteger(0);\n    final Map.Entry<Double, Double> finalMaxWeight = new MapEntry<>(0.0, 0.0);\n    map.forEach(new IntObjectProcedure<SPTEntry>() {\n        @Override\n        public void apply(int nodeId, SPTEntry b) {\n            if (!lms.setWeight(((nodeId * rowSize) + (lmIdx * 4)) + offset, b.weight)) {\n                maxedout.incrementAndGet();\n                finalMaxWeight.setValue(Math.max(b.weight, finalMaxWeight.getValue()));\n            }\n        }\n    });\n    if ((((double) (maxedout.get())) / map.size()) > 0.1) {\n        LOGGER.warn(((((((((((((((\"landmark \" + lmIdx) + \" (\") + nodeAccess.getLat(lmNodeId)) + \",\") + nodeAccess.getLon(lmNodeId)) + \"): \") + \"too many weights were maxed out (\") + maxedout.get()) + \"/\") + map.size()) + \"). Use a bigger factor than \") + lms.factor) + \". For example use maximum_lm_weight: \") + (finalMaxWeight.getValue() * 1.2)) + \" in your LM profile definition\");\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryGraph.create",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryGraph.create", "com.graphhopper.routing.querygraph.QueryGraph.<init>", "com.graphhopper.routing.querygraph.QueryGraph.buildVirtualEdgesAtRealNodes" ],
    "fullMethods" : [ "public static QueryGraph create(BaseGraph graph, List<Snap> snaps) {\n    return new QueryGraph(graph, snaps);\n}", "private QueryGraph(BaseGraph graph, List<Snap> snaps) {\n    baseGraph = graph;\n    baseNodes = graph.getNodes();\n    baseEdges = graph.getEdges();\n    queryOverlay = QueryOverlayBuilder.build(graph, snaps);\n    nodeAccess = new ExtendedNodeAccess(graph.getNodeAccess(), queryOverlay.getVirtualNodes(), baseNodes);\n    turnCostStorage = baseGraph.getTurnCostStorage();\n    // build data structures holding the virtual edges at all real/virtual nodes that are modified compared to the\n    // mainGraph.\n    final EdgeExplorer mainExplorer = baseGraph.createEdgeExplorer();\n    virtualEdgesAtRealNodes = buildVirtualEdgesAtRealNodes(mainExplorer);\n    virtualEdgesAtVirtualNodes = buildVirtualEdgesAtVirtualNodes();\n}", "private IntObjectMap<List<EdgeIteratorState>> buildVirtualEdgesAtRealNodes(final EdgeExplorer mainExplorer) {\n    final IntObjectMap<List<EdgeIteratorState>> virtualEdgesAtRealNodes = new GHIntObjectHashMap<>(queryOverlay.getEdgeChangesAtRealNodes().size());\n    queryOverlay.getEdgeChangesAtRealNodes().forEach(new IntObjectProcedure<QueryOverlay.EdgeChanges>() {\n        @Override\n        public void apply(int node, QueryOverlay.EdgeChanges edgeChanges) {\n            List<EdgeIteratorState> virtualEdges = new ArrayList<>(edgeChanges.getAdditionalEdges());\n            EdgeIterator mainIter = mainExplorer.setBaseNode(node);\n            while (mainIter.next()) {\n                if (!edgeChanges.getRemovedEdges().contains(mainIter.getEdge())) {\n                    virtualEdges.add(mainIter.detach(false));\n                }\n            } \n            virtualEdgesAtRealNodes.put(node, virtualEdges);\n        }\n    });\n    return virtualEdgesAtRealNodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.<init>", "com.graphhopper.routing.querygraph.QueryRoutingCHGraph.buildVirtualEdgesAtRealNodes" ],
    "fullMethods" : [ "public QueryRoutingCHGraph(RoutingCHGraph routingCHGraph, QueryGraph queryGraph) {\n    this.routingCHGraph = routingCHGraph;\n    this.weighting = routingCHGraph.getWeighting();\n    this.queryOverlay = queryGraph.getQueryOverlay();\n    this.queryGraph = queryGraph;\n    this.queryGraphWeighting = queryGraph.wrapWeighting(weighting);\n    virtualOutEdgesAtRealNodes = buildVirtualEdgesAtRealNodes(routingCHGraph.createOutEdgeExplorer());\n    virtualInEdgesAtRealNodes = buildVirtualEdgesAtRealNodes(routingCHGraph.createInEdgeExplorer());\n    virtualEdgesAtVirtualNodes = buildVirtualEdgesAtVirtualNodes();\n    nodes = queryGraph.getNodes();\n}", "private IntObjectMap<List<RoutingCHEdgeIteratorState>> buildVirtualEdgesAtRealNodes(final RoutingCHEdgeExplorer explorer) {\n    final IntObjectMap<List<RoutingCHEdgeIteratorState>> virtualEdgesAtRealNodes = new IntObjectHashMap<>(queryOverlay.getEdgeChangesAtRealNodes().size());\n    queryOverlay.getEdgeChangesAtRealNodes().forEach(new IntObjectProcedure<QueryOverlay.EdgeChanges>() {\n        @Override\n        public void apply(int node, QueryOverlay.EdgeChanges edgeChanges) {\n            List<RoutingCHEdgeIteratorState> virtualEdges = new ArrayList<>();\n            for (EdgeIteratorState v : edgeChanges.getAdditionalEdges()) {\n                assert v.getBaseNode() == node;\n                int edge = v.getEdge();\n                if (queryGraph.isVirtualEdge(edge)) {\n                    edge = shiftVirtualEdgeIDForCH(edge);\n                }\n                virtualEdges.add(buildVirtualCHEdgeState(v, edge));\n            }\n            RoutingCHEdgeIterator iter = explorer.setBaseNode(node);\n            while (iter.next()) {\n                // shortcuts cannot be in the removed edge set because this was determined on the (base) query graph\n                if (iter.isShortcut()) {\n                    virtualEdges.add(new VirtualCHEdgeIteratorState(iter.getEdge(), NO_EDGE, iter.getBaseNode(), iter.getAdjNode(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), iter.getSkippedEdge1(), iter.getSkippedEdge2(), iter.getWeight(false), iter.getWeight(true)));\n                } else if (!edgeChanges.getRemovedEdges().contains(iter.getOrigEdge())) {\n                    virtualEdges.add(new VirtualCHEdgeIteratorState(iter.getEdge(), iter.getOrigEdge(), iter.getBaseNode(), iter.getAdjNode(), iter.getOrigEdgeKeyFirst(), iter.getOrigEdgeKeyLast(), NO_EDGE, NO_EDGE, iter.getWeight(false), iter.getWeight(true)));\n                }\n            } \n            virtualEdgesAtRealNodes.put(node, virtualEdges);\n        }\n    });\n    return virtualEdgesAtRealNodes;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LandmarkStorage.createLandmarks",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectMap.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.lm.LandmarkStorage.createLandmarks", "com.graphhopper.routing.lm.LandmarkStorage.estimateMaxWeight", "com.graphhopper.routing.lm.LandmarkStorage.LandmarkExplorer.getFromCount" ],
    "fullMethods" : [ "/**\n * This method calculates the landmarks and initial weightings to &amp; from them.\n */\npublic void createLandmarks() {\n    if (isInitialized())\n        throw new IllegalStateException(\"Initialize the landmark storage only once!\");\n\n    // fill 'from' and 'to' weights with maximum value\n    long maxBytes = ((long) (graph.getNodes())) * LM_ROW_LENGTH;\n    this.landmarkWeightDA.create(2000);\n    this.landmarkWeightDA.ensureCapacity(maxBytes);\n    for (long pointer = 0; pointer < maxBytes; pointer += 2) {\n        landmarkWeightDA.setShort(pointer, ((short) (SHORT_INFINITY)));\n    }\n    int[] empty = new int[landmarks];\n    Arrays.fill(empty, UNSET_SUBNETWORK);\n    landmarkIDs.add(empty);\n    byte[] subnetworks = new byte[graph.getNodes()];\n    Arrays.fill(subnetworks, ((byte) (UNSET_SUBNETWORK)));\n    String snKey = Subnetwork.key(lmConfig.getName());\n    // TODO We could use EdgeBasedTarjanSCC instead of node-based TarjanSCC here to get the small networks directly,\n    // instead of using the subnetworkEnc from PrepareRoutingSubnetworks.\n    if (!encodedValueLookup.hasEncodedValue(snKey))\n        throw new IllegalArgumentException(((\"EncodedValue '\" + snKey) + \"' does not exist. For Landmarks this is \") + \"currently required (also used in PrepareRoutingSubnetworks). See #2256\");\n\n    // Exclude edges that we previously marked in PrepareRoutingSubnetworks to avoid problems like \"connection not found\".\n    final BooleanEncodedValue edgeInSubnetworkEnc = encodedValueLookup.getBooleanEncodedValue(snKey);\n    final IntHashSet blockedEdges;\n    // We use the areaIndex to split certain areas from each other but do not permanently change the base graph\n    // so that other algorithms still can route through these regions. This is done to increase the density of\n    // landmarks for an area like Europe+Asia, which improves the query speed.\n    if (areaIndex != null) {\n        StopWatch sw = new StopWatch().start();\n        blockedEdges = findBorderEdgeIds(areaIndex);\n        if (logDetails)\n            LOGGER.info(((((\"Made \" + blockedEdges.size()) + \" edges inaccessible. Calculated country cut in \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n\n    } else {\n        blockedEdges = new IntHashSet();\n    }\n    EdgeFilter accessFilter = edge -> (!edge.get(edgeInSubnetworkEnc)) && (!blockedEdges.contains(edge.getEdge()));\n    EdgeFilter tarjanFilter = edge -> accessFilter.accept(edge) && Double.isFinite(weighting.calcEdgeWeight(edge, false));\n    StopWatch sw = new StopWatch().start();\n    ConnectedComponents graphComponents = TarjanSCC.findComponents(graph, tarjanFilter, true);\n    if (logDetails)\n        LOGGER.info(((((\"Calculated \" + graphComponents.getComponents().size()) + \" subnetworks via tarjan in \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n\n    String additionalInfo = \"\";\n    // guess the factor\n    if (factor <= 0) {\n        // A 'factor' is necessary to store the weight in just a short value but without losing too much precision.\n        // This factor is rather delicate to pick, we estimate it from an exploration with some \"test landmarks\",\n        // see estimateMaxWeight. If we pick the distance too big for small areas this could lead to (slightly)\n        // suboptimal routes as there will be too big rounding errors. But picking it too small is bad for performance\n        // e.g. for Germany at least 1500km is very important otherwise speed is at least twice as slow e.g. for 1000km\n        double maxWeight = estimateMaxWeight(graphComponents.getComponents(), accessFilter);\n        setMaximumWeight(maxWeight);\n        additionalInfo = (\", maxWeight:\" + maxWeight) + \" from quick estimation\";\n    }\n    if (logDetails)\n        LOGGER.info((((\"init landmarks for subnetworks with node count greater than \" + minimumNodes) + \" with factor:\") + factor) + additionalInfo);\n\n    int nodes = 0;\n    for (IntArrayList subnetworkIds : graphComponents.getComponents()) {\n        nodes += subnetworkIds.size();\n        if (subnetworkIds.size() < minimumNodes)\n            continue;\n\n        if (factor <= 0)\n            throw new IllegalStateException(((((((\"factor wasn't initialized \" + factor) + \", subnetworks:\") + graphComponents.getComponents().size()) + \", minimumNodes:\") + minimumNodes) + \", current size:\") + subnetworkIds.size());\n\n        int index = subnetworkIds.size() - 1;\n        // ensure start node is reachable from both sides and no subnetwork is associated\n        for (; index >= 0; index--) {\n            int nextStartNode = subnetworkIds.get(index);\n            if (subnetworks[nextStartNode] == UNSET_SUBNETWORK) {\n                if (logDetails) {\n                    GHPoint p = createPoint(graph, nextStartNode);\n                    LOGGER.info((((((((((\"start node: \" + nextStartNode) + \" (\") + p) + \") subnetwork \") + index) + \", subnetwork size: \") + subnetworkIds.size()) + \", \") + Helper.getMemInfo()) + (areaIndex == null ? \"\" : \" area:\" + areaIndex.query(p.lat, p.lon)));\n                }\n                if (createLandmarksForSubnetwork(nextStartNode, subnetworks, accessFilter))\n                    break;\n\n            }\n        }\n        if (index < 0)\n            LOGGER.warn(((((\"next start node not found in big enough network of size \" + subnetworkIds.size()) + \", first element is \") + subnetworkIds.get(0)) + \", \") + createPoint(graph, subnetworkIds.get(0)));\n\n    }\n    int subnetworkCount = landmarkIDs.size();\n    // store all landmark node IDs and one int for the factor itself.\n    this.landmarkWeightDA.ensureCapacity((maxBytes/* landmark weights */\n     + (((long) (subnetworkCount)) * landmarks))/* landmark mapping per subnetwork */\n     + 4);\n    // calculate offset to point into landmark mapping\n    long bytePos = maxBytes;\n    for (int[] landmarks : landmarkIDs) {\n        for (int lmNodeId : landmarks) {\n            landmarkWeightDA.setInt(bytePos, lmNodeId);\n            bytePos += 4L;\n        }\n    }\n    landmarkWeightDA.setHeader(0 * 4, graph.getNodes());\n    landmarkWeightDA.setHeader(1 * 4, this.landmarks);\n    landmarkWeightDA.setHeader(2 * 4, subnetworkCount);\n    if ((factor * DOUBLE_MLTPL) > Integer.MAX_VALUE)\n        throw new UnsupportedOperationException(\"landmark weight factor cannot be bigger than Integer.MAX_VALUE \" + (factor * DOUBLE_MLTPL));\n\n    landmarkWeightDA.setHeader(3 * 4, ((int) (Math.round(factor * DOUBLE_MLTPL))));\n    // serialize fast byte[] into DataAccess\n    subnetworkStorage.create(graph.getNodes());\n    for (int nodeId = 0; nodeId < subnetworks.length; nodeId++) {\n        subnetworkStorage.setSubnetwork(nodeId, subnetworks[nodeId]);\n    }\n    if (logDetails)\n        LOGGER.info(((\"Finished landmark creation. Subnetwork node count sum \" + nodes) + \" vs. nodes \") + graph.getNodes());\n\n    initialized = true;\n}", "/**\n * This method returns the maximum weight for the graph starting from the landmarks\n */\nprivate double estimateMaxWeight(List<IntArrayList> graphComponents, EdgeFilter accessFilter) {\n    double maxWeight = 0;\n    int searchedSubnetworks = 0;\n    Random random = new Random(0);\n    // the maximum weight can only be an approximation so there is only a tiny improvement when we would do this for\n    // all landmarks. See #2027 (1st commit) where only 1 landmark was sufficient when multiplied with 1.01 at the end\n    // TODO instead of calculating the landmarks again here we could store them in landmarkIDs and do this for all here\n    int[] tmpLandmarkNodeIds = new int[3];\n    for (IntArrayList subnetworkIds : graphComponents) {\n        if (subnetworkIds.size() < minimumNodes)\n            continue;\n\n        searchedSubnetworks++;\n        int maxRetries = Math.max(subnetworkIds.size(), 100);\n        for (int retry = 0; retry < maxRetries; retry++) {\n            int index = random.nextInt(subnetworkIds.size());\n            int nextStartNode = subnetworkIds.get(index);\n            LandmarkExplorer explorer = findLandmarks(tmpLandmarkNodeIds, nextStartNode, accessFilter, \"estimate \" + index);\n            if (explorer.getFromCount() < minimumNodes) {\n                LOGGER.error(((((((((\"method findLandmarks for \" + createPoint(graph, nextStartNode)) + \" (\") + nextStartNode) + \")\") + \" resulted in too few visited nodes: \") + explorer.getFromCount()) + \" vs expected minimum \") + minimumNodes) + \", see #2256\");\n                continue;\n            }\n            // starting\n            for (int lmIdx = 0; lmIdx < tmpLandmarkNodeIds.length; lmIdx++) {\n                int lmNodeId = tmpLandmarkNodeIds[lmIdx];\n                explorer = new LandmarkExplorer(graph, this, weighting, traversalMode, accessFilter, false);\n                explorer.setStartNode(lmNodeId);\n                explorer.runAlgo();\n                maxWeight = Math.max(maxWeight, explorer.getLastEntry().weight);\n            }\n            break;\n        }\n    }\n    if ((maxWeight <= 0) && (searchedSubnetworks > 0))\n        throw new IllegalStateException(((((\"max weight wasn't set although \" + searchedSubnetworks) + \" subnetworks were searched (total \") + graphComponents.size()) + \"), minimumNodes:\") + minimumNodes);\n\n    // we have to increase maxWeight slightly as it is only an approximation towards the maximum weight,\n    // especially when external landmarks are provided, but also because we do not traverse all landmarks\n    return maxWeight * 1.008;\n}", "int getFromCount() {\n    return bestWeightMapFrom.size();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectScatterMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.BridgePathFinder.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntObjectScatterMap.<init>",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.BridgePathFinder.<init>" ],
    "fullMethods" : [ "public BridgePathFinder(CHPreparationGraph graph) {\n    this.graph = graph;\n    outExplorer = graph.createOutEdgeExplorer();\n    origOutExplorer = graph.createOutOrigEdgeExplorer();\n    queue = new PriorityQueue<>();\n    map = new IntObjectScatterMap<>();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntContainer.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges" ],
    "fullMethods" : [ "/**\n * Like {@link #findComponents(Graph, EdgeTransitionFilter, boolean)}, but the search only starts at the\n * given edges. This does not mean the search cannot expand to other edges, but this can be controlled by the\n * edgeTransitionFilter. This method does not return single edge components (the excludeSingleEdgeComponents option is\n * set to true).\n */\npublic static ConnectedComponents findComponentsForStartEdges(Graph graph, EdgeTransitionFilter edgeTransitionFilter, IntContainer edges) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, true).findComponentsForStartEdges(edges);\n}", "private ConnectedComponents findComponentsForStartEdges(IntContainer startEdges) {\n    initForStartEdges(startEdges.size());\n    for (IntCursor edge : startEdges) {\n        // todo: using getEdgeIteratorState here is not efficient\n        EdgeIteratorState edgeState = graph.getEdgeIteratorState(edge.value, Integer.MIN_VALUE);\n        if (!edgeTransitionFilter.accept(NO_EDGE, edgeState))\n            continue;\n\n        findComponentsForEdgeState(edgeState);\n    }\n    return components;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.coll.GHIntHashSet.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntContainer.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.coll.GHIntHashSet.<init>" ],
    "fullMethods" : [ "public GHIntHashSet(int capacity) {\n    super(capacity, 0.75, DETERMINISTIC);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntContainer.size",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode" ],
    "fullMethods" : [ "@Override\npublic IntContainer contractNode(int node) {\n    activeStats = addingStats;\n    stats().stopWatch.start();\n    findAndHandlePrepareShortcuts(node, this::addShortcutsToPrepareGraph, ((int) (meanDegree * params.maxPollFactorContraction)), wpsStatsContr);\n    insertShortcuts(node);\n    IntContainer neighbors = prepareGraph.disconnect(node);\n    // We maintain an approximation of the mean degree which we update after every contracted node.\n    // We do it the same way as for node-based CH for now.\n    meanDegree = ((meanDegree * 2) + neighbors.size()) / 3;\n    updateHierarchyDepthsOfNeighbors(node, neighbors);\n    stats().stopWatch.stop();\n    return neighbors;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.contains",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.RoadDensityCalculator.calcRoadDensity" ],
    "fullMethods" : [ "/**\n *\n * @param radius\n * \t\tin meters\n * @param calcRoadFactor\n * \t\tweighting function. use this to define how different kinds of roads shall contribute to the calculated road density\n * @return the road density in the vicinity of the given edge, i.e. the weighted road length divided by the squared radius\n */\npublic double calcRoadDensity(EdgeIteratorState edge, double radius, ToDoubleFunction<EdgeIteratorState> calcRoadFactor) {\n    visited.clear();\n    deque.head = deque.tail = 0;\n    double totalRoadWeight = 0;\n    NodeAccess na = graph.getNodeAccess();\n    int baseNode = edge.getBaseNode();\n    int adjNode = edge.getAdjNode();\n    GHPoint center = new GHPoint(getLat(na, baseNode, adjNode), getLon(na, baseNode, adjNode));\n    deque.addLast(baseNode);\n    deque.addLast(adjNode);\n    visited.add(baseNode);\n    visited.add(adjNode);\n    // we just do a BFS search and sum up all the road lengths\n    final double radiusNormalized = DIST_PLANE.calcNormalizedDist(radius);\n    // for long tunnels or motorway sections where the distance between the exit points and the\n    // center is larger than the radius it is important to continue the search even outside the radius\n    final int minPolls = ((int) (radius / 2));\n    int polls = 0;\n    while (!deque.isEmpty()) {\n        int node = deque.removeFirst();\n        polls++;\n        double distance = DIST_PLANE.calcNormalizedDist(center.lat, center.lon, na.getLat(node), na.getLon(node));\n        if ((polls > minPolls) && (distance > radiusNormalized))\n            continue;\n\n        EdgeIterator iter = edgeExplorer.setBaseNode(node);\n        while (iter.next()) {\n            if (visited.contains(iter.getAdjNode()))\n                continue;\n\n            visited.add(iter.getAdjNode());\n            if (distance <= radiusNormalized)\n                totalRoadWeight += calcRoadFactor.applyAsDouble(iter);\n\n            deque.addLast(iter.getAdjNode());\n        } \n    } \n    return (totalRoadWeight / radius) / radius;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.BreadthFirstSearch.start",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.contains",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.BreadthFirstSearch.start", "com.graphhopper.reader.dem.EdgeElevationInterpolator.checkAdjacent" ],
    "fullMethods" : [ "@Override\npublic void start(EdgeExplorer explorer, int startNode) {\n    SimpleIntDeque fifo = new SimpleIntDeque();\n    GHBitSet visited = createBitSet();\n    visited.add(startNode);\n    fifo.push(startNode);\n    int current;\n    while (!fifo.isEmpty()) {\n        current = fifo.pop();\n        if (!goFurther(current))\n            continue;\n\n        EdgeIterator iter = explorer.setBaseNode(current);\n        while (iter.next()) {\n            int connectedId = iter.getAdjNode();\n            if (checkAdjacent(iter) && (!visited.contains(connectedId))) {\n                visited.add(connectedId);\n                fifo.push(connectedId);\n            }\n        } \n    } \n}", "@Override\nprotected boolean checkAdjacent(EdgeIteratorState edge) {\n    visitedEdgesIds.add(edge.getEdge());\n    final int baseNodeId = edge.getBaseNode();\n    boolean isInterpolatableEdge = isInterpolatableEdge(edge);\n    if (!isInterpolatableEdge) {\n        innerNodeIds.remove(baseNodeId);\n        outerNodeIds.add(baseNodeId);\n    } else if (!outerNodeIds.contains(baseNodeId)) {\n        innerNodeIds.add(baseNodeId);\n    }\n    return isInterpolatableEdge;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.AlternativeRoute.apply",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.contains",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.AlternativeRoute.apply" ],
    "fullMethods" : [ "@Override\npublic boolean apply(final int traversalId, final SPTEntry fromSPTEntry) {\n    SPTEntry toSPTEntry = bestWeightMapTo.get(traversalId);\n    if (toSPTEntry == null)\n        return true;\n\n    // Using the parent is required to avoid duplicate edge in Path.\n    // TODO we miss the turn cost weight (but at least we not duplicate the current edge weight)\n    if (traversalMode.isEdgeBased() && (toSPTEntry.parent != null))\n        toSPTEntry = toSPTEntry.parent;\n\n    // The alternative path is suboptimal if U-turn (after fromSPTEntry)\n    if (fromSPTEntry.edge == toSPTEntry.edge)\n        return true;\n\n    // (1) skip too long paths\n    final double weight = (fromSPTEntry.getWeightOfVisitedPath() + toSPTEntry.getWeightOfVisitedPath()) + weighting.calcTurnWeight(fromSPTEntry.edge, fromSPTEntry.adjNode, toSPTEntry.edge);\n    if (weight > maxWeight)\n        return true;\n\n    if (isBestPath(fromSPTEntry))\n        return true;\n\n    // For edge based traversal we need the next entry to find out the plateau start\n    SPTEntry tmpFromEntry = (traversalMode.isEdgeBased()) ? fromSPTEntry.parent : fromSPTEntry;\n    if ((tmpFromEntry == null) || (tmpFromEntry.parent == null)) {\n        // we can be here only if edge based and only if entry is not part of the best path\n        // e.g. when starting point has two edges and one is part of the best path the other edge is path of an alternative\n        assert traversalMode.isEdgeBased();\n    } else {\n        int nextToTraversalId = traversalMode.createTraversalId(graph.getEdgeIteratorState(tmpFromEntry.edge, tmpFromEntry.parent.adjNode), true);\n        SPTEntry correspondingToEntry = bestWeightMapTo.get(nextToTraversalId);\n        if (correspondingToEntry != null) {\n            if (traversalMode.isEdgeBased())\n                correspondingToEntry = correspondingToEntry.parent;\n\n            if (correspondingToEntry.edge == fromSPTEntry.edge)\n                return true;\n\n        }\n    }\n    // (3a) calculate plateau, we know we are at the beginning of the 'from'-side of\n    // the plateau A-B-C and go further to B\n    // where B is the next-'from' of A and B is also the previous-'to' of A.\n    // \n    // *<-A-B-C->*\n    // /    \\\n    // start    end\n    // \n    // extend plateau in only one direction necessary (A to B to ...) as we know\n    // that the from-SPTEntry is the start of the plateau or there is no plateau at all\n    // \n    double plateauWeight = 0;\n    SPTEntry prevToSPTEntry = toSPTEntry;\n    SPTEntry prevFrom = fromSPTEntry;\n    while (prevToSPTEntry.parent != null) {\n        int nextFromTraversalId = traversalMode.createTraversalId(graph.getEdgeIteratorState(prevToSPTEntry.edge, prevToSPTEntry.parent.adjNode), false);\n        SPTEntry otherFromEntry = bestWeightMapFrom.get(nextFromTraversalId);\n        // end of a plateau\n        if (((otherFromEntry == null) || (otherFromEntry.parent != prevFrom)) || (otherFromEntry.edge != prevToSPTEntry.edge))\n            break;\n\n        prevFrom = otherFromEntry;\n        plateauWeight += prevToSPTEntry.getWeightOfVisitedPath() - prevToSPTEntry.parent.getWeightOfVisitedPath();\n        prevToSPTEntry = prevToSPTEntry.parent;\n    } \n    if ((plateauWeight <= 0) || ((plateauWeight / weight) < minPlateauFactor))\n        return true;\n\n    if (fromSPTEntry.parent == null)\n        throw new IllegalStateException(\"not implemented yet. in case of an edge based traversal the parent of fromSPTEntry could be null\");\n\n    // (3b) calculate share\n    SPTEntry fromEE = getFirstShareEE(fromSPTEntry.parent, true);\n    SPTEntry toEE = getFirstShareEE(toSPTEntry.parent, false);\n    double shareWeight = fromEE.getWeightOfVisitedPath() + toEE.getWeightOfVisitedPath();\n    boolean smallShare = (shareWeight / bestWeight) < maxShareFactor;\n    if (smallShare) {\n        List<String> altNames = getAltNames(graph, fromSPTEntry);\n        double sortBy = calcSortBy(weightInfluence, weight, shareInfluence, shareWeight, plateauInfluence, plateauWeight);\n        double worstSortBy = getWorstSortBy();\n        // plateaus.add(new PlateauInfo(altName, plateauEdges));\n        if ((sortBy < worstSortBy) || (alternatives.size() < maxPaths)) {\n            Path path = DefaultBidirPathExtractor.extractPath(graph, weighting, fromSPTEntry, toSPTEntry, weight);\n            // for now do not add alternatives to set, if we do we need to remove then on alternatives.clear too (see below)\n            // AtomicInteger tid = addToMap(traversalIDMap, path);\n            // int tid = traversalMode.createTraversalId(path.calcEdges().get(0), false);\n            alternatives.add(new AlternativeInfo(sortBy, path, fromEE, toEE, shareWeight, altNames));\n            Collections.sort(alternatives, ALT_COMPARATOR);\n            if (alternatives.get(0) != bestAlt)\n                throw new IllegalStateException(((\"best path should be always first entry \" + bestAlt.path.getWeight()) + \" vs \") + alternatives.get(0).path.getWeight());\n\n            if (alternatives.size() > maxPaths)\n                alternatives.subList(maxPaths, alternatives.size()).clear();\n\n        }\n    }\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.weighting.AvoidEdgesWeighting.calcEdgeWeight",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntSet.contains",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.weighting.AvoidEdgesWeighting.calcEdgeWeight" ],
    "fullMethods" : [ "@Override\npublic double calcEdgeWeight(EdgeIteratorState edgeState, boolean reverse) {\n    double weight = superWeighting.calcEdgeWeight(edgeState, reverse);\n    if (avoidedEdges.contains(edgeState.getEdge()))\n        return weight * edgePenaltyFactor;\n\n    return weight;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.Polygon.getMinLon",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Envelope.getMinX",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.Polygon.getMinLon" ],
    "fullMethods" : [ "public double getMinLon() {\n    return envelope.getMinX();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.shapes.BBox.fromEnvelope",
    "thirdPartyMethod" : "org.locationtech.jts.geom.Envelope.getMinX",
    "thirdPartyPackage" : "org.locationtech.jts.geom",
    "path" : [ "com.graphhopper.util.shapes.BBox.fromEnvelope" ],
    "fullMethods" : [ "public static BBox fromEnvelope(Envelope envelope) {\n    return new BBox(envelope.getMinX(), envelope.getMaxX(), envelope.getMinY(), envelope.getMaxY());\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.<init>",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.<init>" ],
    "fullMethods" : [ "public InternalRestriction(IntArrayList viaNodes, IntArrayList edgeKeys) {\n    this.edgeKeys = edgeKeys;\n    this.viaNodes = viaNodes;\n    this.actualEdgeKeys = ArrayUtil.constant(edgeKeys.size(), -1);\n    this.actualEdgeKeys.set(0, edgeKeys.get(0));\n    this.actualEdgeKeys.set(edgeKeys.size() - 1, edgeKeys.get(edgeKeys.size() - 1));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.toString",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.toString" ],
    "fullMethods" : [ "@Override\npublic String toString() {\n    StringBuilder result = new StringBuilder();\n    for (int i = 0; i < viaNodes.size(); i++)\n        result.append(GHUtility.getEdgeFromEdgeKey(edgeKeys.get(i))).append(\"-(\").append(viaNodes.get(i)).append(\")-\");\n\n    return (result + \"\") + GHUtility.getEdgeFromEdgeKey(edgeKeys.get(edgeKeys.size() - 1));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.OSMRestrictionConverter.buildRestrictionsForOSMRestriction" ],
    "fullMethods" : [ "/**\n * Converts an OSM restriction to (multiple) single 'no' restrictions to be fed into {@link RestrictionSetter}\n */\npublic static List<RestrictionSetter.Restriction> buildRestrictionsForOSMRestriction(BaseGraph baseGraph, RestrictionTopology topology, RestrictionType type) {\n    List<RestrictionSetter.Restriction> result = new ArrayList<>();\n    if (type == NO) {\n        if (topology.isViaWayRestriction()) {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges()) {\n                    IntArrayList edges = new IntArrayList(topology.getViaEdges().size() + 2);\n                    edges.add(fromEdge.value);\n                    edges.addAll(topology.getViaEdges());\n                    edges.add(toEdge.value);\n                    result.add(RestrictionSetter.createViaEdgeRestriction(edges));\n                }\n\n        } else {\n            for (IntCursor fromEdge : topology.getFromEdges())\n                for (IntCursor toEdge : topology.getToEdges())\n                    result.add(RestrictionSetter.createViaNodeRestriction(fromEdge.value, topology.getViaNodes().get(0), toEdge.value));\n\n\n        }\n    } else if (type == ONLY) {\n        if ((topology.getFromEdges().size() > 1) || (topology.getToEdges().size() > 1))\n            throw new IllegalArgumentException(\"'Only' restrictions with multiple from- or to- edges are not supported\");\n\n        if (topology.isViaWayRestriction())\n            result.addAll(createRestrictionsForViaEdgeOnlyRestriction(baseGraph, topology));\n        else\n            result.addAll(createRestrictionsForViaNodeOnlyRestriction(baseGraph.createEdgeExplorer(), topology.getFromEdges().get(0), topology.getViaNodes().get(0), topology.getToEdges().get(0)));\n\n    } else\n        throw new IllegalArgumentException(\"Unexpected restriction type: \" + type);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgeConverter.convertForViaWays", "com.graphhopper.reader.osm.WayToEdgeConverter.buildResult" ],
    "fullMethods" : [ "/**\n * Finds the edge IDs associated with the given OSM ways that are adjacent to each other. For example for given\n * from-, via- and to-ways there can be multiple edges associated with each (because each way can be split into\n * multiple edges). We then need to find the from-edge that is connected with one of the via-edges which in turn\n * must be connected with one of the to-edges. We use DFS/backtracking to do this.\n * There can also be *multiple* via-ways, but the concept is the same.\n * Note that there can also be multiple from- or to-*ways*, but only one of each of them should be considered at a\n * time. In contrast to the via-ways there are only multiple from/to-ways, because of restrictions like no_entry or\n * no_exit where there can be multiple from- or to-members. So we need to find one edge-chain for each pair of from-\n * and to-ways.\n * Besides the edge IDs we also return the node IDs that connect the edges, so we can add turn restrictions at these\n * nodes later.\n */\npublic EdgeResult convertForViaWays(LongArrayList fromWays, LongArrayList viaWays, LongArrayList toWays) throws OSMRestrictionException {\n    if ((fromWays.isEmpty() || toWays.isEmpty()) || viaWays.isEmpty())\n        throw new IllegalArgumentException(\"There must be at least one from-, via- and to-way\");\n\n    if ((fromWays.size() > 1) && (toWays.size() > 1))\n        throw new IllegalArgumentException(\"There can only be multiple from- or to-ways, but not both\");\n\n    List<IntArrayList> solutions = new ArrayList<>();\n    for (LongCursor fromWay : fromWays)\n        for (LongCursor toWay : toWays)\n            findEdgeChain(fromWay.value, viaWays, toWay.value, solutions);\n\n\n    if (solutions.size() < (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has disconnected member ways\");\n    else if (solutions.size() > (fromWays.size() * toWays.size()))\n        throw new OSMRestrictionException(\"has member ways that do not form a unique path\");\n\n    return buildResult(solutions, fromWays, viaWays, toWays);\n}", "private static EdgeResult buildResult(List<IntArrayList> edgeChains, LongArrayList fromWays, LongArrayList viaWays, LongArrayList toWays) {\n    EdgeResult result = new EdgeResult(fromWays.size(), viaWays.size(), toWays.size());\n    // we get multiple edge chains, but they are expected to be identical except for their first or last members\n    IntArrayList firstChain = edgeChains.get(0);\n    result.fromEdges.add(firstChain.get(0));\n    for (int i = 1; i < (firstChain.size() - 3); i += 2) {\n        result.nodes.add(firstChain.get(i));\n        result.viaEdges.add(firstChain.get(i + 1));\n    }\n    result.nodes.add(firstChain.get(firstChain.size() - 2));\n    result.toEdges.add(firstChain.get(firstChain.size() - 1));\n    // We keep the first/last elements of all chains in case there are multiple from/to ways\n    List<IntArrayList> otherChains = edgeChains.subList(1, edgeChains.size());\n    if (fromWays.size() > 1) {\n        if (otherChains.stream().anyMatch(chain -> chain.get(chain.size() - 1) != firstChain.get(firstChain.size() - 1)))\n            throw new IllegalArgumentException(((((((\"edge chains were supposed to be the same except for their first elements, but got: \" + edgeChains) + \" - for: \") + fromWays) + \", \") + viaWays) + \", \") + toWays);\n\n        otherChains.forEach(chain -> result.fromEdges.add(chain.get(0)));\n    } else if (toWays.size() > 1) {\n        if (otherChains.stream().anyMatch(chain -> chain.get(0) != firstChain.get(0)))\n            throw new IllegalArgumentException(((((((\"edge chains were supposed to be the same except for their last elements, but got: \" + edgeChains) + \" - for: \") + fromWays) + \", \") + viaWays) + \", \") + toWays);\n\n        otherChains.forEach(chain -> result.toEdges.add(chain.get(chain.size() - 1)));\n    } else if (!otherChains.isEmpty())\n        throw new IllegalStateException(\"If there are multiple chains there must be either multiple from- or to-ways.\");\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.prepareForContraction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.prepareForContraction", "com.graphhopper.routing.ch.CHPreparationGraph.OrigGraph.Builder.build", "com.graphhopper.routing.ch.CHPreparationGraph.OrigGraph.Builder.buildFirstEdgesByNode" ],
    "fullMethods" : [ "public void prepareForContraction() {\n    checkNotReady();\n    origGraph = (edgeBased) ? origGraphBuilder.build() : null;\n    origGraphBuilder = null;\n    ready = true;\n}", "{\n    com.carrotsearch.hppc.IntArrayList $stack10, $stack11, $stack12, $stack2, $stack3, $stack7, $stack8, $stack9;\n    com.carrotsearch.hppc.sorting.IndirectComparator #l0;\n    com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator #l1;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph $stack13;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder this;\n    int $stack6;\n    int[] $stack4, sortOrder;\n    java.lang.Object $stack5;\n\n\n    this := @this: com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder;\n    $stack2 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack6 = $stack2.<com.carrotsearch.hppc.IntArrayList: int elementsCount>;\n    $stack5 = new com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator;\n    $stack3 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack4 = $stack3.<com.carrotsearch.hppc.IntArrayList: int[] buffer>;\n    #l1 = (com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator) $stack5;\n    specialinvoke #l1.<com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator: void <init>(int[])>($stack4);\n    #l0 = (com.carrotsearch.hppc.sorting.IndirectComparator) $stack5;\n    sortOrder = staticinvoke <com.carrotsearch.hppc.sorting.IndirectSort: int[] mergesort(int,int,com.carrotsearch.hppc.sorting.IndirectComparator)>(0, $stack6, #l0);\n    $stack7 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack7, sortOrder);\n    $stack8 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack8, sortOrder);\n    $stack9 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack9, sortOrder);\n    $stack13 = new com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph;\n    $stack12 = virtualinvoke this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList buildFirstEdgesByNode()>();\n    $stack11 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    $stack10 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    specialinvoke $stack13.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph: void <init>(com.carrotsearch.hppc.IntArrayList,com.carrotsearch.hppc.IntArrayList,com.carrotsearch.hppc.IntArrayList)>($stack12, $stack11, $stack10);\n\n    return $stack13;\n}\n", "{\n    com.carrotsearch.hppc.IntArrayList $stack7, $stack9, firstEdgesByNode;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder this;\n    int $stack10, $stack6, $stack8, edgeIndex, from, numEdges, numFroms;\n\n\n    this := @this: com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder;\n    $stack6 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: int maxFrom>;\n    numFroms = $stack6 + 1;\n    $stack7 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    numEdges = virtualinvoke $stack7.<com.carrotsearch.hppc.IntArrayList: int size()>();\n    $stack8 = numFroms + 1;\n    firstEdgesByNode = staticinvoke <com.graphhopper.util.ArrayUtil: com.carrotsearch.hppc.IntArrayList zero(int)>($stack8);\n\n    if numFroms != 0 goto label1;\n    virtualinvoke firstEdgesByNode.<com.carrotsearch.hppc.IntArrayList: int set(int,int)>(0, numEdges);\n\n    return firstEdgesByNode;\n\n  label1:\n    edgeIndex = 0;\n    from = 0;\n\n  label2:\n    if from >= numFroms goto label5;\n\n  label3:\n    if edgeIndex >= numEdges goto label4;\n    $stack9 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack10 = virtualinvoke $stack9.<com.carrotsearch.hppc.IntArrayList: int get(int)>(edgeIndex);\n\n    if $stack10 >= from goto label4;\n    edgeIndex = edgeIndex + 1;\n\n    goto label3;\n\n  label4:\n    virtualinvoke firstEdgesByNode.<com.carrotsearch.hppc.IntArrayList: int set(int,int)>(from, edgeIndex);\n    from = from + 1;\n\n    goto label2;\n\n  label5:\n    virtualinvoke firstEdgesByNode.<com.carrotsearch.hppc.IntArrayList: int set(int,int)>(numFroms, numEdges);\n\n    return firstEdgesByNode;\n}\n" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.querygraph.EdgeChangeBuilder.apply",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.querygraph.EdgeChangeBuilder.apply", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.addRemovedEdges", "com.graphhopper.routing.querygraph.EdgeChangeBuilder.getClosestEdge" ],
    "fullMethods" : [ "@Override\npublic void apply(int value) {\n    addRemovedEdges(value);\n}", "/**\n * Adds the ids of the removed edges at the real tower nodes. We need to do this such that we cannot 'skip'\n * virtual nodes by just using the original edges and also to prevent u-turns at the real nodes adjacent to the\n * virtual ones.\n */\nprivate void addRemovedEdges(int towerNode) {\n    if (isVirtualNode(towerNode))\n        throw new IllegalStateException(((\"Node should not be virtual:\" + towerNode) + \", \") + edgeChangesAtRealNodes);\n\n    QueryOverlay.EdgeChanges edgeChanges = edgeChangesAtRealNodes.get(towerNode);\n    List<EdgeIteratorState> existingEdges = edgeChanges.getAdditionalEdges();\n    IntArrayList removedEdges = edgeChanges.getRemovedEdges();\n    for (EdgeIteratorState existingEdge : existingEdges) {\n        removedEdges.add(getClosestEdge(existingEdge.getAdjNode()));\n    }\n}", "private int getClosestEdge(int node) {\n    return closestEdges.get(node - firstVirtualNodeId);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.index.LineIntIndex.store",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.index.LineIntIndex.store", "com.graphhopper.storage.index.LineIntIndex.store" ],
    "fullMethods" : [ "public void store(InMemConstructionIndex inMem) {\n    indexStructureInfo = IndexStructureInfo.create(bounds, minResolutionInMeter);\n    keyAlgo = indexStructureInfo.getKeyAlgo();\n    entries = indexStructureInfo.getEntries();\n    shifts = indexStructureInfo.getShifts();\n    dataAccess.create(64 * 1024);\n    try {\n        store(inMem.root, START_POINTER);\n    } catch (Exception ex) {\n        throw new IllegalStateException(\"Problem while storing location index. \" + Helper.getMemInfo(), ex);\n    }\n    initialized = true;\n}", "private int store(InMemConstructionIndex.InMemEntry entry, int intPointer) {\n    long pointer = ((long) (intPointer)) * 4;\n    if (entry.isLeaf()) {\n        InMemConstructionIndex.InMemLeafEntry leaf = ((InMemConstructionIndex.InMemLeafEntry) (entry));\n        IntArrayList entries = leaf.getResults();\n        int len = entries.size();\n        if (len == 0) {\n            return intPointer;\n        }\n        size += len;\n        intPointer++;\n        leafs++;\n        dataAccess.ensureCapacity(((long) ((intPointer + len) + 1)) * 4);\n        if (len == 1) {\n            // less disc space for single entries\n            dataAccess.setInt(pointer, (-entries.get(0)) - 1);\n        } else {\n            for (int index = 0; index < len; index++ , intPointer++) {\n                dataAccess.setInt(((long) (intPointer)) * 4, entries.get(index));\n            }\n            dataAccess.setInt(pointer, intPointer);\n        }\n    } else {\n        InMemConstructionIndex.InMemTreeEntry treeEntry = ((InMemConstructionIndex.InMemTreeEntry) (entry));\n        int len = treeEntry.subEntries.length;\n        intPointer += len;\n        for (int subCounter = 0; subCounter < len; subCounter++ , pointer += 4) {\n            InMemConstructionIndex.InMemEntry subEntry = treeEntry.subEntries[subCounter];\n            if (subEntry == null) {\n                continue;\n            }\n            dataAccess.ensureCapacity(((long) (intPointer + 1)) * 4);\n            int prevIntPointer = intPointer;\n            intPointer = store(subEntry, prevIntPointer);\n            if (intPointer == prevIntPointer) {\n                dataAccess.setInt(pointer, 0);\n            } else {\n                dataAccess.setInt(pointer, prevIntPointer);\n            }\n        }\n    }\n    return intPointer;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.OrigEdgeIteratorImpl.next",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.OrigEdgeIteratorImpl.next", "com.graphhopper.routing.ch.CHPreparationGraph.OrigEdgeIteratorImpl.hasAccess" ],
    "fullMethods" : [ "@Override\npublic boolean next() {\n    while (true) {\n        index++;\n        if (index >= endEdge)\n            return false;\n\n        if (hasAccess())\n            return true;\n\n    } \n}", "private boolean hasAccess() {\n    int e = (reverse) ? graph.keysAndBwdFlags.get(index) : graph.adjNodesAndFwdFlags.get(index);\n    return (e & 0b1) == 0b1;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.weighting.QueryGraphWeighting.calcTurnMillis",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.weighting.QueryGraphWeighting.calcTurnMillis", "com.graphhopper.routing.weighting.QueryGraphWeighting.getMinWeightAndOriginalEdges", "com.graphhopper.routing.weighting.QueryGraphWeighting.getOriginalEdge" ],
    "fullMethods" : [ "@Override\npublic long calcTurnMillis(int inEdge, int viaNode, int outEdge) {\n    // see calcTurnWeight\n    if (isVirtualNode(viaNode))\n        return 0;\n    else {\n        // we want the turn time given by the actual weighting for the edges with minimum weight\n        // (the same ones that would be selected when routing)\n        Result result = getMinWeightAndOriginalEdges(inEdge, viaNode, outEdge);\n        return weighting.calcTurnMillis(result.origInEdge, viaNode, result.origOutEdge);\n    }\n}", "private Result getMinWeightAndOriginalEdges(int inEdge, int viaNode, int outEdge) {\n    // to calculate the actual turn costs or detect u-turns we need to look at the original edge of each virtual\n    // edge, see #1593\n    Result result = new Result();\n    if (isVirtualEdge(inEdge) && isVirtualEdge(outEdge)) {\n        EdgeExplorer innerExplorer = graph.createEdgeExplorer();\n        graph.forEdgeAndCopiesOfEdge(graph.createEdgeExplorer(), viaNode, getOriginalEdge(inEdge), p -> {\n            graph.forEdgeAndCopiesOfEdge(innerExplorer, viaNode, getOriginalEdge(outEdge), q -> {\n                double w = weighting.calcTurnWeight(p, viaNode, q);\n                if (w < result.minTurnWeight) {\n                    result.origInEdge = p;\n                    result.origOutEdge = q;\n                    result.minTurnWeight = w;\n                }\n            });\n        });\n    } else if (isVirtualEdge(inEdge)) {\n        graph.forEdgeAndCopiesOfEdge(graph.createEdgeExplorer(), viaNode, getOriginalEdge(inEdge), e -> {\n            double w = weighting.calcTurnWeight(e, viaNode, outEdge);\n            if (w < result.minTurnWeight) {\n                result.origInEdge = e;\n                result.origOutEdge = outEdge;\n                result.minTurnWeight = w;\n            }\n        });\n    } else if (isVirtualEdge(outEdge)) {\n        graph.forEdgeAndCopiesOfEdge(graph.createEdgeExplorer(), viaNode, getOriginalEdge(outEdge), e -> {\n            double w = weighting.calcTurnWeight(inEdge, viaNode, e);\n            if (w < result.minTurnWeight) {\n                result.origInEdge = inEdge;\n                result.origOutEdge = e;\n                result.minTurnWeight = w;\n            }\n        });\n    } else {\n        result.origInEdge = inEdge;\n        result.origOutEdge = outEdge;\n        result.minTurnWeight = weighting.calcTurnWeight(inEdge, viaNode, outEdge);\n    }\n    return result;\n}", "private int getOriginalEdge(int edge) {\n    return closestEdges.get((edge - firstVirtualEdgeId) / 2);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.ArrayEdgeIntAccess.getInt",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ev.ArrayEdgeIntAccess.getInt" ],
    "fullMethods" : [ "@Override\npublic int getInt(int edgeId, int index) {\n    int arrIndex = (edgeId * intsPerEdge) + index;\n    return arrIndex >= arr.size() ? 0 : arr.get(arrIndex);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.TurnCostStorage.sortNodes",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.TurnCostStorage.sortNodes" ],
    "fullMethods" : [ "public void sortNodes() {\n    IntArrayList tcFroms = new IntArrayList();\n    IntArrayList tcTos = new IntArrayList();\n    IntArrayList tcFlags = new IntArrayList();\n    IntArrayList tcNexts = new IntArrayList();\n    for (int i = 0; i < turnCostsCount; i++) {\n        long pointer = toPointer(i);\n        tcFroms.add(turnCosts.getInt(pointer + TC_FROM));\n        tcTos.add(turnCosts.getInt(pointer + TC_TO));\n        tcFlags.add(turnCosts.getInt(pointer + TC_FLAGS));\n        tcNexts.add(turnCosts.getInt(pointer + TC_NEXT));\n    }\n    long turnCostsCountBefore = turnCostsCount;\n    turnCostsCount = 0;\n    for (int node = 0; node < baseGraph.getNodes(); node++) {\n        boolean firstForNode = true;\n        int turnCostIndex = baseGraph.getNodeAccess().getTurnCostIndex(node);\n        while (turnCostIndex != NO_TURN_ENTRY) {\n            if (firstForNode) {\n                baseGraph.getNodeAccess().setTurnCostIndex(node, turnCostsCount);\n            } else {\n                long prevPointer = toPointer(turnCostsCount - 1);\n                turnCosts.setInt(prevPointer + TC_NEXT, turnCostsCount);\n            }\n            long pointer = toPointer(turnCostsCount);\n            turnCosts.setInt(pointer + TC_FROM, tcFroms.get(turnCostIndex));\n            turnCosts.setInt(pointer + TC_TO, tcTos.get(turnCostIndex));\n            turnCosts.setInt(pointer + TC_FLAGS, tcFlags.get(turnCostIndex));\n            turnCosts.setInt(pointer + TC_NEXT, NO_TURN_ENTRY);\n            turnCostsCount++;\n            firstForNode = false;\n            turnCostIndex = tcNexts.get(turnCostIndex);\n        } \n    }\n    if (turnCostsCountBefore != turnCostsCount)\n        throw new IllegalStateException(((\"Turn cost count changed unexpectedly: \" + turnCostsCountBefore) + \" -> \") + turnCostsCount);\n\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.finishSearch",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.finishSearch", "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.reset", "com.graphhopper.routing.ch.EdgeBasedWitnessPathSearcher.resetShortestPathTree" ],
    "fullMethods" : [ "public void finishSearch() {\n    // update stats using values of last search\n    stats.numPolls += numPolls;\n    stats.maxPolls = Math.max(stats.maxPolls, numPolls);\n    stats.numExplored += changedEdgeKeys.size();\n    stats.maxExplored = Math.max(stats.maxExplored, changedEdgeKeys.size());\n    stats.numUpdates += numUpdates;\n    stats.maxUpdates = Math.max(stats.maxUpdates, numUpdates);\n    reset();\n}", "private void reset() {\n    numPolls = 0;\n    numUpdates = 0;\n    resetShortestPathTree();\n}", "private void resetShortestPathTree() {\n    for (int i = 0; i < changedEdgeKeys.size(); ++i)\n        resetEntry(changedEdgeKeys.get(i));\n\n    changedEdgeKeys.elementsCount = 0;\n    dijkstraHeap.clear();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.getFinalEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.getFinalEdge" ],
    "fullMethods" : [ "/**\n * Yields the final edge of the path\n */\npublic EdgeIteratorState getFinalEdge() {\n    return graph.getEdgeIteratorState(edgeIds.get(edgeIds.size() - 1), endNode);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgesMap.next",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgesMap.next" ],
    "fullMethods" : [ "@Override\npublic IntCursor next() {\n    cursor.index++;\n    cursor.value = edges.get(offsetBegin + cursor.index);\n    return cursor;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.getFromEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.getFromEdge" ],
    "fullMethods" : [ "public int getFromEdge() {\n    return GHUtility.getEdgeFromEdgeKey(edgeKeys.get(0));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.getShortcutForPrepareEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.getShortcutForPrepareEdge" ],
    "fullMethods" : [ "public int getShortcutForPrepareEdge(int prepareEdge) {\n    if (prepareEdge < edges)\n        return prepareEdge;\n\n    int index = prepareEdge - edges;\n    return shortcutsByPrepareEdges.get(index);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.Path.forEveryEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.Path.forEveryEdge" ],
    "fullMethods" : [ "/**\n * Iterates over all edges in this path sorted from start to end and calls the visitor callback\n * for every edge.\n * <p>\n *\n * @param visitor\n * \t\tcallback to handle every edge. The edge is decoupled from the iterator and can\n * \t\tbe stored.\n */\npublic void forEveryEdge(EdgeVisitor visitor) {\n    int tmpNode = getFromNode();\n    int len = edgeIds.size();\n    int prevEdgeId = EdgeIterator.NO_EDGE;\n    for (int i = 0; i < len; i++) {\n        EdgeIteratorState edgeBase = graph.getEdgeIteratorState(edgeIds.get(i), tmpNode);\n        if (edgeBase == null)\n            throw new IllegalStateException(((((((\"Edge \" + edgeIds.get(i)) + \" was empty when requested with node \") + tmpNode) + \", array index:\") + i) + \", edges:\") + edgeIds.size());\n\n        tmpNode = edgeBase.getBaseNode();\n        // more efficient swap, currently not implemented for virtual edges: visitor.next(edgeBase.detach(true), i);\n        edgeBase = graph.getEdgeIteratorState(edgeBase.getEdge(), tmpNode);\n        visitor.next(edgeBase, i, prevEdgeId);\n        prevEdgeId = edgeBase.getEdge();\n    }\n    visitor.finish();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.weighting.QueryGraphWeighting.calcTurnWeight",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.weighting.QueryGraphWeighting.calcTurnWeight", "com.graphhopper.routing.weighting.QueryGraphWeighting.getMinWeightAndOriginalEdges", "com.graphhopper.routing.weighting.QueryGraphWeighting.getOriginalEdge" ],
    "fullMethods" : [ "@Override\npublic double calcTurnWeight(int inEdge, int viaNode, int outEdge) {\n    if ((!EdgeIterator.Edge.isValid(inEdge)) || (!EdgeIterator.Edge.isValid(outEdge))) {\n        return 0;\n    }\n    if (isVirtualNode(viaNode)) {\n        if (isUTurn(inEdge, outEdge)) {\n            // do not allow u-turns at virtual nodes, otherwise the route depends on whether or not there are\n            // virtual via nodes, see #1672. note since we are turning between virtual edges here we need to compare\n            // the *virtual* edge ids (the orig edge would always be the same for all virtual edges at a virtual\n            // node), see #1593\n            return Double.POSITIVE_INFINITY;\n        } else {\n            return 0;\n        }\n    }\n    return getMinWeightAndOriginalEdges(inEdge, viaNode, outEdge).minTurnWeight;\n}", "private Result getMinWeightAndOriginalEdges(int inEdge, int viaNode, int outEdge) {\n    // to calculate the actual turn costs or detect u-turns we need to look at the original edge of each virtual\n    // edge, see #1593\n    Result result = new Result();\n    if (isVirtualEdge(inEdge) && isVirtualEdge(outEdge)) {\n        EdgeExplorer innerExplorer = graph.createEdgeExplorer();\n        graph.forEdgeAndCopiesOfEdge(graph.createEdgeExplorer(), viaNode, getOriginalEdge(inEdge), p -> {\n            graph.forEdgeAndCopiesOfEdge(innerExplorer, viaNode, getOriginalEdge(outEdge), q -> {\n                double w = weighting.calcTurnWeight(p, viaNode, q);\n                if (w < result.minTurnWeight) {\n                    result.origInEdge = p;\n                    result.origOutEdge = q;\n                    result.minTurnWeight = w;\n                }\n            });\n        });\n    } else if (isVirtualEdge(inEdge)) {\n        graph.forEdgeAndCopiesOfEdge(graph.createEdgeExplorer(), viaNode, getOriginalEdge(inEdge), e -> {\n            double w = weighting.calcTurnWeight(e, viaNode, outEdge);\n            if (w < result.minTurnWeight) {\n                result.origInEdge = e;\n                result.origOutEdge = outEdge;\n                result.minTurnWeight = w;\n            }\n        });\n    } else if (isVirtualEdge(outEdge)) {\n        graph.forEdgeAndCopiesOfEdge(graph.createEdgeExplorer(), viaNode, getOriginalEdge(outEdge), e -> {\n            double w = weighting.calcTurnWeight(inEdge, viaNode, e);\n            if (w < result.minTurnWeight) {\n                result.origInEdge = inEdge;\n                result.origOutEdge = e;\n                result.minTurnWeight = w;\n            }\n        });\n    } else {\n        result.origInEdge = inEdge;\n        result.origOutEdge = outEdge;\n        result.minTurnWeight = weighting.calcTurnWeight(inEdge, viaNode, outEdge);\n    }\n    return result;\n}", "private int getOriginalEdge(int edge) {\n    return closestEdges.get((edge - firstVirtualEdgeId) / 2);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.getLast",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.getLast" ],
    "fullMethods" : [ "public static int getLast(IntArrayList list) {\n    if (list.isEmpty())\n        throw new IllegalArgumentException(\"Cannot get last element of an empty list\");\n\n    return list.get(list.size() - 1);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.subList",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.subList" ],
    "fullMethods" : [ "public static IntArrayList subList(IntArrayList list, int fromIndex, int toIndex) {\n    IntArrayList result = new IntArrayList(toIndex - fromIndex);\n    for (int i = fromIndex; i < toIndex; i++)\n        result.add(list.get(i));\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.OrigEdgeIteratorImpl.getAdjNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.OrigEdgeIteratorImpl.getAdjNode" ],
    "fullMethods" : [ "@Override\npublic int getAdjNode() {\n    return graph.adjNodesAndFwdFlags.get(index) >>> 1;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.GHUtility.comparePaths",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.GHUtility.comparePaths", "com.graphhopper.util.GHUtility.pathsEqualExceptOneEdge" ],
    "fullMethods" : [ "public static List<String> comparePaths(Path refPath, Path path, int source, int target, long seed) {\n    List<String> strictViolations = new ArrayList<>();\n    double refWeight = refPath.getWeight();\n    double weight = path.getWeight();\n    if (Math.abs(refWeight - weight) > 0.01) {\n        LOGGER.warn(\"expected: \" + refPath.calcNodes());\n        LOGGER.warn(\"given:    \" + path.calcNodes());\n        LOGGER.warn(\"seed: \" + seed);\n        fail(((((((((\"wrong weight: \" + source) + \"->\") + target) + \"\\nexpected: \") + refWeight) + \"\\ngiven:    \") + weight) + \"\\nseed: \") + seed);\n    }\n    if (Math.abs(path.getDistance() - refPath.getDistance()) > 0.1) {\n        strictViolations.add(((((((\"wrong distance \" + source) + \"->\") + target) + \", expected: \") + refPath.getDistance()) + \", given: \") + path.getDistance());\n    }\n    if (Math.abs(path.getTime() - refPath.getTime()) > 50) {\n        strictViolations.add(((((((\"wrong time \" + source) + \"->\") + target) + \", expected: \") + refPath.getTime()) + \", given: \") + path.getTime());\n    }\n    IntIndexedContainer refNodes = refPath.calcNodes();\n    IntIndexedContainer pathNodes = path.calcNodes();\n    if (!refNodes.equals(pathNodes)) {\n        // sometimes there are paths including an edge a-c that has the same distance as the two edges a-b-c. in this\n        // case both options are valid best paths. we only check for this most simple and frequent case here...\n        if (path.getGraph() != refPath.getGraph())\n            fail(\"path and refPath graphs are different\");\n\n        if (!pathsEqualExceptOneEdge(path.getGraph(), refNodes, pathNodes))\n            strictViolations.add(((((((\"wrong nodes \" + source) + \"->\") + target) + \"\\nexpected: \") + refNodes) + \"\\ngiven:    \") + pathNodes);\n\n    }\n    return strictViolations;\n}", "/**\n * Sometimes the graph can contain edges like this:\n * A--C\n * \\-B|\n * where A-C is the same distance as A-B-C. In this case the shortest path is not well defined in terms of nodes.\n * This method checks if two node-paths are equal except for such an edge.\n */\nprivate static boolean pathsEqualExceptOneEdge(Graph graph, IntIndexedContainer p1, IntIndexedContainer p2) {\n    if (p1.equals(p2))\n        throw new IllegalArgumentException(\"paths are equal\");\n\n    if (Math.abs(p1.size() - p2.size()) != 1)\n        return false;\n\n    IntIndexedContainer shorterPath = (p1.size() < p2.size()) ? p1 : p2;\n    IntIndexedContainer longerPath = (p1.size() < p2.size()) ? p2 : p1;\n    if (shorterPath.size() < 2)\n        return false;\n\n    IntArrayList indicesWithDifferentNodes = new IntArrayList();\n    for (int i = 1; i < shorterPath.size(); i++) {\n        if (shorterPath.get(i - indicesWithDifferentNodes.size()) != longerPath.get(i)) {\n            indicesWithDifferentNodes.add(i);\n        }\n    }\n    if (indicesWithDifferentNodes.size() != 1)\n        return false;\n\n    int b = indicesWithDifferentNodes.get(0);\n    int a = b - 1;\n    int c = b + 1;\n    assert shorterPath.get(a) == longerPath.get(a);\n    assert shorterPath.get(b) != longerPath.get(b);\n    if (shorterPath.get(b) != longerPath.get(c))\n        return false;\n\n    double distABC = getMinDist(graph, longerPath.get(a), longerPath.get(b)) + getMinDist(graph, longerPath.get(b), longerPath.get(c));\n    double distAC = getMinDist(graph, shorterPath.get(a), longerPath.get(c));\n    if (Math.abs(distABC - distAC) > 0.1)\n        return false;\n\n    LOGGER.info(((((((((((\"Distance \" + shorterPath.get(a)) + \"-\") + longerPath.get(c)) + \" is the same as distance \") + longerPath.get(a)) + \"-\") + longerPath.get(b)) + \"-\") + longerPath.get(c)) + \" -> there are multiple possibilities \") + \"for shortest paths\");\n    return true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.OrigEdgeIteratorImpl.setBaseNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.OrigEdgeIteratorImpl.setBaseNode" ],
    "fullMethods" : [ "@Override\npublic PrepareGraphOrigEdgeIterator setBaseNode(int node) {\n    this.node = node;\n    index = graph.firstEdgesByNode.get(node) - 1;\n    endEdge = graph.firstEdgesByNode.get(node + 1);\n    return this;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.reader.osm.WayToEdgesMap.getEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.reader.osm.WayToEdgesMap.getEdges" ],
    "fullMethods" : [ "public Iterator<IntCursor> getEdges(long way) {\n    int idx = offsetIndexByWay.indexOf(way);\n    if (idx < 0)\n        return emptyIterator();\n\n    int offsetIndex = offsetIndexByWay.indexGet(idx);\n    // we reserved this, but did not put a value later\n    if (offsetIndex == RESERVED)\n        return emptyIterator();\n\n    int offsetBegin = offsets.get(offsetIndex);\n    int offsetEnd = ((offsetIndex + 1) < offsets.size()) ? offsets.get(offsetIndex + 1) : edges.size();\n    IntCursor cursor = new IntCursor();\n    cursor.index = -1;\n    return new Iterator<IntCursor>() {\n        @Override\n        public boolean hasNext() {\n            return ((offsetBegin + cursor.index) + 1) < offsetEnd;\n        }\n\n        @Override\n        public IntCursor next() {\n            cursor.index++;\n            cursor.value = edges.get(offsetBegin + cursor.index);\n            return cursor;\n        }\n    };\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.invert",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.invert" ],
    "fullMethods" : [ "public static IntArrayList invert(IntArrayList list) {\n    IntArrayList result = new IntArrayList(list.size());\n    result.elementsCount = list.size();\n    for (int i = 0; i < result.elementsCount; ++i)\n        result.set(list.get(i), i);\n\n    return result;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.OrigEdgeIteratorImpl.getOrigEdgeKeyFirst",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.OrigEdgeIteratorImpl.getOrigEdgeKeyFirst" ],
    "fullMethods" : [ "@Override\npublic int getOrigEdgeKeyFirst() {\n    return graph.keysAndBwdFlags.get(index) >>> 1;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.setRestrictions" ],
    "fullMethods" : [ "public void setRestrictions(List<Restriction> restrictions, List<BitSet> encBits) {\n    if (restrictions.size() != encBits.size())\n        throw new IllegalArgumentException(((\"There must be as many encBits as restrictions. Got: \" + encBits.size()) + \" and \") + restrictions.size());\n\n    List<InternalRestriction> internalRestrictions = restrictions.stream().map(this::convertToInternal).toList();\n    disableRedundantRestrictions(internalRestrictions, encBits);\n    LongIntMap artificialEdgeKeysByIncViaPairs = new LongIntScatterMap();\n    IntObjectMap<IntSet> artificialEdgesByEdge = new IntObjectScatterMap<>();\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3)\n            continue;\n\n        int incomingEdge = restriction.getFromEdge();\n        for (int j = 1; j < (restriction.getEdgeKeys().size() - 1); ++j) {\n            int viaEdgeKey = restriction.getEdgeKeys().get(j);\n            long key = BitUtil.LITTLE.toLong(incomingEdge, viaEdgeKey);\n            int artificialEdgeKey;\n            if (artificialEdgeKeysByIncViaPairs.containsKey(key)) {\n                artificialEdgeKey = artificialEdgeKeysByIncViaPairs.get(key);\n            } else {\n                int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n                EdgeIteratorState artificialEdgeState = baseGraph.copyEdge(viaEdge, true);\n                int artificialEdge = artificialEdgeState.getEdge();\n                if (artificialEdgesByEdge.containsKey(viaEdge)) {\n                    IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n                    artificialEdges.forEach(((IntProcedure) (a -> {\n                        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                            restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, a);\n\n                    })));\n                    artificialEdges.add(artificialEdge);\n                } else {\n                    IntSet artificialEdges = new IntScatterSet();\n                    artificialEdges.add(artificialEdge);\n                    artificialEdgesByEdge.put(viaEdge, artificialEdges);\n                }\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurnsBetweenEdges(turnRestrictionEnc, artificialEdgeState, viaEdge);\n\n                artificialEdgeKey = artificialEdgeState.getEdgeKey();\n                if (baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).get(REVERSE_STATE))\n                    artificialEdgeKey = GHUtility.reverseEdgeKey(artificialEdgeKey);\n\n                artificialEdgeKeysByIncViaPairs.put(key, artificialEdgeKey);\n            }\n            restriction.actualEdgeKeys.set(j, artificialEdgeKey);\n            incomingEdge = GHUtility.getEdgeFromEdgeKey(artificialEdgeKey);\n        }\n    }\n    artificialEdgeKeysByIncViaPairs.forEach(((LongIntProcedure) ((incViaPair, artificialEdgeKey) -> {\n        int incomingEdge = BitUtil.LITTLE.getIntLow(incViaPair);\n        int viaEdgeKey = BitUtil.LITTLE.getIntHigh(incViaPair);\n        int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n        int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getBaseNode();\n        // we restrict turning onto the original edge and all artificial edges except the one we created for this in-edge\n        // i.e. we force turning onto the artificial edge we created for this in-edge\n        for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n            restrictTurn(turnRestrictionEnc, incomingEdge, node, viaEdge);\n\n        IntSet artificialEdges = artificialEdgesByEdge.get(viaEdge);\n        artificialEdges.forEach(((IntProcedure) (a -> {\n            if (a != GHUtility.getEdgeFromEdgeKey(artificialEdgeKey))\n                for (BooleanEncodedValue turnRestrictionEnc : turnRestrictionEncs)\n                    restrictTurn(turnRestrictionEnc, incomingEdge, node, a);\n\n\n        })));\n    })));\n    for (int i = 0; i < internalRestrictions.size(); i++) {\n        if (encBits.get(i).cardinality() < 1)\n            continue;\n\n        InternalRestriction restriction = internalRestrictions.get(i);\n        if (restriction.getEdgeKeys().size() < 3) {\n            IntSet fromEdges = artificialEdgesByEdge.getOrDefault(restriction.getFromEdge(), new IntScatterSet());\n            fromEdges.add(restriction.getFromEdge());\n            IntSet toEdges = artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), new IntScatterSet());\n            toEdges.add(restriction.getToEdge());\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    fromEdges.forEach(((IntProcedure) (from -> toEdges.forEach(((IntProcedure) (to -> {\n                        restrictTurn(turnRestrictionEnc, from, restriction.getViaNodes().get(0), to);\n                    }))))));\n                }\n            }\n        } else {\n            int viaEdgeKey = restriction.getActualEdgeKeys().get(restriction.getActualEdgeKeys().size() - 2);\n            int viaEdge = GHUtility.getEdgeFromEdgeKey(viaEdgeKey);\n            int node = baseGraph.getEdgeIteratorStateForKey(viaEdgeKey).getAdjNode();\n            // For via-edge restrictions we deny turning from the from-edge onto the via-edge,\n            // but allow turning onto the artificial edge(s) instead (see above). Then we deny\n            // turning from the artificial edge onto the to-edge here.\n            for (int j = 0; j < turnRestrictionEncs.size(); j++) {\n                BooleanEncodedValue turnRestrictionEnc = turnRestrictionEncs.get(j);\n                if (encBits.get(i).get(j)) {\n                    restrictTurn(turnRestrictionEnc, viaEdge, node, restriction.getToEdge());\n                    // also restrict the turns to the artificial edges corresponding to the to-edge\n                    artificialEdgesByEdge.getOrDefault(restriction.getToEdge(), EMPTY_SET).forEach(((IntProcedure) (toEdge -> restrictTurn(turnRestrictionEnc, viaEdge, node, toEdge))));\n                }\n            }\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LandmarkStorage.createLandmarks",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.lm.LandmarkStorage.createLandmarks" ],
    "fullMethods" : [ "/**\n * This method calculates the landmarks and initial weightings to &amp; from them.\n */\npublic void createLandmarks() {\n    if (isInitialized())\n        throw new IllegalStateException(\"Initialize the landmark storage only once!\");\n\n    // fill 'from' and 'to' weights with maximum value\n    long maxBytes = ((long) (graph.getNodes())) * LM_ROW_LENGTH;\n    this.landmarkWeightDA.create(2000);\n    this.landmarkWeightDA.ensureCapacity(maxBytes);\n    for (long pointer = 0; pointer < maxBytes; pointer += 2) {\n        landmarkWeightDA.setShort(pointer, ((short) (SHORT_INFINITY)));\n    }\n    int[] empty = new int[landmarks];\n    Arrays.fill(empty, UNSET_SUBNETWORK);\n    landmarkIDs.add(empty);\n    byte[] subnetworks = new byte[graph.getNodes()];\n    Arrays.fill(subnetworks, ((byte) (UNSET_SUBNETWORK)));\n    String snKey = Subnetwork.key(lmConfig.getName());\n    // TODO We could use EdgeBasedTarjanSCC instead of node-based TarjanSCC here to get the small networks directly,\n    // instead of using the subnetworkEnc from PrepareRoutingSubnetworks.\n    if (!encodedValueLookup.hasEncodedValue(snKey))\n        throw new IllegalArgumentException(((\"EncodedValue '\" + snKey) + \"' does not exist. For Landmarks this is \") + \"currently required (also used in PrepareRoutingSubnetworks). See #2256\");\n\n    // Exclude edges that we previously marked in PrepareRoutingSubnetworks to avoid problems like \"connection not found\".\n    final BooleanEncodedValue edgeInSubnetworkEnc = encodedValueLookup.getBooleanEncodedValue(snKey);\n    final IntHashSet blockedEdges;\n    // We use the areaIndex to split certain areas from each other but do not permanently change the base graph\n    // so that other algorithms still can route through these regions. This is done to increase the density of\n    // landmarks for an area like Europe+Asia, which improves the query speed.\n    if (areaIndex != null) {\n        StopWatch sw = new StopWatch().start();\n        blockedEdges = findBorderEdgeIds(areaIndex);\n        if (logDetails)\n            LOGGER.info(((((\"Made \" + blockedEdges.size()) + \" edges inaccessible. Calculated country cut in \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n\n    } else {\n        blockedEdges = new IntHashSet();\n    }\n    EdgeFilter accessFilter = edge -> (!edge.get(edgeInSubnetworkEnc)) && (!blockedEdges.contains(edge.getEdge()));\n    EdgeFilter tarjanFilter = edge -> accessFilter.accept(edge) && Double.isFinite(weighting.calcEdgeWeight(edge, false));\n    StopWatch sw = new StopWatch().start();\n    ConnectedComponents graphComponents = TarjanSCC.findComponents(graph, tarjanFilter, true);\n    if (logDetails)\n        LOGGER.info(((((\"Calculated \" + graphComponents.getComponents().size()) + \" subnetworks via tarjan in \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n\n    String additionalInfo = \"\";\n    // guess the factor\n    if (factor <= 0) {\n        // A 'factor' is necessary to store the weight in just a short value but without losing too much precision.\n        // This factor is rather delicate to pick, we estimate it from an exploration with some \"test landmarks\",\n        // see estimateMaxWeight. If we pick the distance too big for small areas this could lead to (slightly)\n        // suboptimal routes as there will be too big rounding errors. But picking it too small is bad for performance\n        // e.g. for Germany at least 1500km is very important otherwise speed is at least twice as slow e.g. for 1000km\n        double maxWeight = estimateMaxWeight(graphComponents.getComponents(), accessFilter);\n        setMaximumWeight(maxWeight);\n        additionalInfo = (\", maxWeight:\" + maxWeight) + \" from quick estimation\";\n    }\n    if (logDetails)\n        LOGGER.info((((\"init landmarks for subnetworks with node count greater than \" + minimumNodes) + \" with factor:\") + factor) + additionalInfo);\n\n    int nodes = 0;\n    for (IntArrayList subnetworkIds : graphComponents.getComponents()) {\n        nodes += subnetworkIds.size();\n        if (subnetworkIds.size() < minimumNodes)\n            continue;\n\n        if (factor <= 0)\n            throw new IllegalStateException(((((((\"factor wasn't initialized \" + factor) + \", subnetworks:\") + graphComponents.getComponents().size()) + \", minimumNodes:\") + minimumNodes) + \", current size:\") + subnetworkIds.size());\n\n        int index = subnetworkIds.size() - 1;\n        // ensure start node is reachable from both sides and no subnetwork is associated\n        for (; index >= 0; index--) {\n            int nextStartNode = subnetworkIds.get(index);\n            if (subnetworks[nextStartNode] == UNSET_SUBNETWORK) {\n                if (logDetails) {\n                    GHPoint p = createPoint(graph, nextStartNode);\n                    LOGGER.info((((((((((\"start node: \" + nextStartNode) + \" (\") + p) + \") subnetwork \") + index) + \", subnetwork size: \") + subnetworkIds.size()) + \", \") + Helper.getMemInfo()) + (areaIndex == null ? \"\" : \" area:\" + areaIndex.query(p.lat, p.lon)));\n                }\n                if (createLandmarksForSubnetwork(nextStartNode, subnetworks, accessFilter))\n                    break;\n\n            }\n        }\n        if (index < 0)\n            LOGGER.warn(((((\"next start node not found in big enough network of size \" + subnetworkIds.size()) + \", first element is \") + subnetworkIds.get(0)) + \", \") + createPoint(graph, subnetworkIds.get(0)));\n\n    }\n    int subnetworkCount = landmarkIDs.size();\n    // store all landmark node IDs and one int for the factor itself.\n    this.landmarkWeightDA.ensureCapacity((maxBytes/* landmark weights */\n     + (((long) (subnetworkCount)) * landmarks))/* landmark mapping per subnetwork */\n     + 4);\n    // calculate offset to point into landmark mapping\n    long bytePos = maxBytes;\n    for (int[] landmarks : landmarkIDs) {\n        for (int lmNodeId : landmarks) {\n            landmarkWeightDA.setInt(bytePos, lmNodeId);\n            bytePos += 4L;\n        }\n    }\n    landmarkWeightDA.setHeader(0 * 4, graph.getNodes());\n    landmarkWeightDA.setHeader(1 * 4, this.landmarks);\n    landmarkWeightDA.setHeader(2 * 4, subnetworkCount);\n    if ((factor * DOUBLE_MLTPL) > Integer.MAX_VALUE)\n        throw new UnsupportedOperationException(\"landmark weight factor cannot be bigger than Integer.MAX_VALUE \" + (factor * DOUBLE_MLTPL));\n\n    landmarkWeightDA.setHeader(3 * 4, ((int) (Math.round(factor * DOUBLE_MLTPL))));\n    // serialize fast byte[] into DataAccess\n    subnetworkStorage.create(graph.getNodes());\n    for (int nodeId = 0; nodeId < subnetworks.length; nodeId++) {\n        subnetworkStorage.setSubnetwork(nodeId, subnetworks[nodeId]);\n    }\n    if (logDetails)\n        LOGGER.info(((\"Finished landmark creation. Subnetwork node count sum \" + nodes) + \" vs. nodes \") + graph.getNodes());\n\n    initialized = true;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.getToEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntArrayList.get",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.util.parsers.RestrictionSetter.InternalRestriction.getToEdge" ],
    "fullMethods" : [ "public int getToEdge() {\n    return GHUtility.getEdgeFromEdgeKey(edgeKeys.get(edgeKeys.size() - 1));\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.GHUtility.readCountries",
    "thirdPartyMethod" : "com.fasterxml.jackson.databind.ObjectMapper.registerModule",
    "thirdPartyPackage" : "com.fasterxml.jackson.databind",
    "path" : [ "com.graphhopper.util.GHUtility.readCountries" ],
    "fullMethods" : [ "/**\n * Reads the country borders from the countries.geojson resource file\n */\npublic static List<CustomArea> readCountries() {\n    ObjectMapper objectMapper = new ObjectMapper();\n    objectMapper.registerModule(new JtsModule());\n    Set<String> enumSet = new HashSet<>(Country.values().length * 2);\n    for (Country c : Country.values()) {\n        if (c == Country.MISSING)\n            continue;\n\n        if (c.getStates().isEmpty())\n            enumSet.add(c.getAlpha2());\n        else\n            for (State s : c.getStates())\n                enumSet.add(s.getStateCode());\n\n\n    }\n    try (Reader reader = new InputStreamReader(GHUtility.class.getResourceAsStream(\"/com/graphhopper/countries/countries.geojson\"), StandardCharsets.UTF_8)) {\n        JsonFeatureCollection jsonFeatureCollection = objectMapper.readValue(reader, JsonFeatureCollection.class);\n        return // exclude areas not in the list of Country enums like FX => Metropolitan France\n        jsonFeatureCollection.getFeatures().stream().filter(customArea -> enumSet.contains(getIdOrPropertiesId(customArea))).map(f -> {\n            CustomArea ca = CustomArea.fromJsonFeature(f);\n            // the Feature does not include \"id\" but we expect it\n            if (f.getId() == null)\n                f.setId(getIdOrPropertiesId(f));\n\n            ca.getProperties().put(ISO_3166_2, f.getId());\n            return ca;\n        }).collect(Collectors.toList());\n    } catch (IOException e) {\n        throw new UncheckedIOException(e);\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.GraphHopper.resolveCustomAreas",
    "thirdPartyMethod" : "com.fasterxml.jackson.databind.ObjectMapper.registerModule",
    "thirdPartyPackage" : "com.fasterxml.jackson.databind",
    "path" : [ "com.graphhopper.GraphHopper.resolveCustomAreas" ],
    "fullMethods" : [ "public static JsonFeatureCollection resolveCustomAreas(String customAreasDirectory) {\n    JsonFeatureCollection globalAreas = new JsonFeatureCollection();\n    if (!customAreasDirectory.isEmpty()) {\n        ObjectMapper mapper = new ObjectMapper().registerModule(new JtsModule());\n        try (DirectoryStream<Path> stream = Files.newDirectoryStream(Paths.get(customAreasDirectory), \"*.{geojson,json}\")) {\n            StreamSupport.stream(stream.spliterator(), false).sorted(Comparator.comparing(Path::toString)).forEach(customAreaFile -> {\n                try (BufferedReader reader = Files.newBufferedReader(customAreaFile, StandardCharsets.UTF_8)) {\n                    globalAreas.getFeatures().addAll(mapper.readValue(reader, JsonFeatureCollection.class).getFeatures());\n                } catch (IOException e) {\n                    throw new UncheckedIOException(e);\n                }\n            });\n            logger.info(((\"Will make \" + globalAreas.getFeatures().size()) + \" areas available to all custom profiles. Found in \") + customAreasDirectory);\n        } catch (IOException e) {\n            throw new UncheckedIOException(e);\n        }\n    }\n    return globalAreas;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LMPreparationHandler.init",
    "thirdPartyMethod" : "com.fasterxml.jackson.databind.ObjectMapper.registerModule",
    "thirdPartyPackage" : "com.fasterxml.jackson.databind",
    "path" : [ "com.graphhopper.routing.lm.LMPreparationHandler.init", "com.graphhopper.routing.lm.LMPreparationHandler.loadLandmarkSplittingFeatureCollection" ],
    "fullMethods" : [ "public void init(GraphHopperConfig ghConfig) {\n    // throw explicit error for deprecated configs\n    if (ghConfig.has(\"prepare.lm.weightings\")) {\n        throw new IllegalStateException(\"Use profiles_lm instead of prepare.lm.weightings, see #1922 and docs/core/profiles.md\");\n    }\n    setPreparationThreads(ghConfig.getInt(Parameters.Landmark.PREPARE + \"threads\", getPreparationThreads()));\n    setLMProfiles(ghConfig.getLMProfiles());\n    landmarkCount = ghConfig.getInt(Parameters.Landmark.COUNT, landmarkCount);\n    logDetails = ghConfig.getBool(Landmark.PREPARE + \"log_details\", false);\n    minNodes = ghConfig.getInt(Landmark.PREPARE + \"min_network_size\", -1);\n    for (String loc : ghConfig.getString(Landmark.PREPARE + \"suggestions_location\", \"\").split(\",\")) {\n        if (!loc.trim().isEmpty())\n            lmSuggestionsLocations.add(loc.trim());\n\n    }\n    if (!isEnabled())\n        return;\n\n    String splitAreaLocation = ghConfig.getString(Landmark.PREPARE + \"split_area_location\", \"\");\n    JsonFeatureCollection landmarkSplittingFeatureCollection = loadLandmarkSplittingFeatureCollection(splitAreaLocation);\n    if ((landmarkSplittingFeatureCollection != null) && (!landmarkSplittingFeatureCollection.getFeatures().isEmpty())) {\n        List<SplitArea> splitAreas = landmarkSplittingFeatureCollection.getFeatures().stream().map(SplitArea::fromJsonFeature).collect(Collectors.toList());\n        areaIndex = new AreaIndex<>(splitAreas);\n    }\n}", "private JsonFeatureCollection loadLandmarkSplittingFeatureCollection(String splitAreaLocation) {\n    ObjectMapper objectMapper = new ObjectMapper();\n    objectMapper.registerModule(new JtsModule());\n    URL builtinSplittingFile = LandmarkStorage.class.getResource(\"map.geo.json\");\n    try (Reader reader = (splitAreaLocation.isEmpty()) ? new InputStreamReader(builtinSplittingFile.openStream(), UTF_CS) : new InputStreamReader(new FileInputStream(splitAreaLocation), UTF_CS)) {\n        JsonFeatureCollection result = objectMapper.readValue(reader, JsonFeatureCollection.class);\n        if (splitAreaLocation.isEmpty()) {\n            LOGGER.info(\"Loaded built-in landmark splitting collection from {}\", builtinSplittingFile);\n        } else {\n            LOGGER.info(\"Loaded landmark splitting collection from {}\", splitAreaLocation);\n        }\n        return result;\n    } catch (IOException e) {\n        LOGGER.error(\"Problem while reading border map GeoJSON. Skipping this.\", e);\n        return null;\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.calcSortOrder",
    "thirdPartyMethod" : "com.carrotsearch.hppc.sorting.IndirectSort.mergesort",
    "thirdPartyPackage" : "com.carrotsearch.hppc.sorting",
    "path" : [ "com.graphhopper.util.ArrayUtil.calcSortOrder" ],
    "fullMethods" : [ "/**\n * This method calculates the sort order of the first {@param length} element-pairs given by two arrays.\n * The order is chosen such that it sorts the element-pairs first by the first and second by the second array.\n * The input arrays are not manipulated by this method.\n *\n * @param length\n * \t\tmust not be larger than either of the two input array lengths.\n * @return an array x of length {@param length}. e.g. if this method returns x = {2, 0, 1} it means that that\nthe element-pair with index 2 comes first in the order and so on\n */\npublic static int[] calcSortOrder(final int[] arr1, final int[] arr2, int length) {\n    if ((arr1.length < length) || (arr2.length < length))\n        throw new IllegalArgumentException(\"Arrays must not be shorter than given length\");\n\n    IndirectComparator comp = (indexA, indexB) -> {\n        final int arr1cmp = Integer.compare(arr1[indexA], arr1[indexB]);\n        return arr1cmp != 0 ? arr1cmp : Integer.compare(arr2[indexA], arr2[indexB]);\n    };\n    return IndirectSort.mergesort(0, length, comp);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.CHPreparationGraph.prepareForContraction",
    "thirdPartyMethod" : "com.carrotsearch.hppc.sorting.IndirectSort.mergesort",
    "thirdPartyPackage" : "com.carrotsearch.hppc.sorting",
    "path" : [ "com.graphhopper.routing.ch.CHPreparationGraph.prepareForContraction", "com.graphhopper.routing.ch.CHPreparationGraph.OrigGraph.Builder.build" ],
    "fullMethods" : [ "public void prepareForContraction() {\n    checkNotReady();\n    origGraph = (edgeBased) ? origGraphBuilder.build() : null;\n    origGraphBuilder = null;\n    ready = true;\n}", "{\n    com.carrotsearch.hppc.IntArrayList $stack10, $stack11, $stack12, $stack2, $stack3, $stack7, $stack8, $stack9;\n    com.carrotsearch.hppc.sorting.IndirectComparator #l0;\n    com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator #l1;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph $stack13;\n    com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder this;\n    int $stack6;\n    int[] $stack4, sortOrder;\n    java.lang.Object $stack5;\n\n\n    this := @this: com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder;\n    $stack2 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack6 = $stack2.<com.carrotsearch.hppc.IntArrayList: int elementsCount>;\n    $stack5 = new com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator;\n    $stack3 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    $stack4 = $stack3.<com.carrotsearch.hppc.IntArrayList: int[] buffer>;\n    #l1 = (com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator) $stack5;\n    specialinvoke #l1.<com.carrotsearch.hppc.sorting.IndirectComparator$AscendingIntComparator: void <init>(int[])>($stack4);\n    #l0 = (com.carrotsearch.hppc.sorting.IndirectComparator) $stack5;\n    sortOrder = staticinvoke <com.carrotsearch.hppc.sorting.IndirectSort: int[] mergesort(int,int,com.carrotsearch.hppc.sorting.IndirectComparator)>(0, $stack6, #l0);\n    $stack7 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList fromNodes>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack7, sortOrder);\n    $stack8 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack8, sortOrder);\n    $stack9 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    staticinvoke <com.graphhopper.routing.ch.CHPreparationGraph: void sortAndTrim(com.carrotsearch.hppc.IntArrayList,int[])>($stack9, sortOrder);\n    $stack13 = new com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph;\n    $stack12 = virtualinvoke this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList buildFirstEdgesByNode()>();\n    $stack11 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList toNodesAndFwdFlags>;\n    $stack10 = this.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph$Builder: com.carrotsearch.hppc.IntArrayList keysAndBwdFlags>;\n    specialinvoke $stack13.<com.graphhopper.routing.ch.CHPreparationGraph$OrigGraph: void <init>(com.carrotsearch.hppc.IntArrayList,com.carrotsearch.hppc.IntArrayList,com.carrotsearch.hppc.IntArrayList)>($stack12, $stack11, $stack10);\n\n    return $stack13;\n}\n" ]
  }, {
    "entryPoint" : "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve",
    "thirdPartyMethod" : "com.carrotsearch.hppc.sorting.IndirectSort.mergesort",
    "thirdPartyPackage" : "com.carrotsearch.hppc.sorting",
    "path" : [ "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve" ],
    "fullMethods" : [ "public static void sortGraphAlongHilbertCurve(BaseGraph graph) {\n    logger.info(\"sorting graph along Hilbert curve...\");\n    StopWatch sw = StopWatch.started();\n    NodeAccess na = graph.getNodeAccess();\n    final int order = 31;// using 15 would allow us to use ints for sortIndices, but this would result in (marginally) slower routing\n\n    LongArrayList sortIndices = new LongArrayList();\n    for (int node = 0; node < graph.getNodes(); node++)\n        sortIndices.add(latLonToHilbertIndex(na.getLat(node), na.getLon(node), order));\n\n    int[] nodeOrder = IndirectSort.mergesort(0, graph.getNodes(), (nodeA, nodeB) -> Long.compare(sortIndices.get(nodeA), sortIndices.get(nodeB)));\n    EdgeExplorer explorer = graph.createEdgeExplorer();\n    int edges = graph.getEdges();\n    IntArrayList edgeOrder = new IntArrayList();\n    BitSet edgesFound = new BitSet(edges);\n    for (int node : nodeOrder) {\n        EdgeIterator iter = explorer.setBaseNode(node);\n        while (iter.next()) {\n            if (!edgesFound.get(iter.getEdge())) {\n                edgeOrder.add(iter.getEdge());\n                edgesFound.set(iter.getEdge());\n            }\n        } \n    }\n    IntArrayList newEdgesByOldEdges = ArrayUtil.invert(edgeOrder);\n    IntArrayList newNodesByOldNodes = IntArrayList.from(ArrayUtil.invert(nodeOrder));\n    logger.info(\"calculating sort order took: \" + sw.stop().getTimeString());\n    sortGraphForGivenOrdering(graph, newNodesByOldNodes, newEdgesByOldEdges);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntContainer.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges" ],
    "fullMethods" : [ "/**\n * Like {@link #findComponents(Graph, EdgeTransitionFilter, boolean)}, but the search only starts at the\n * given edges. This does not mean the search cannot expand to other edges, but this can be controlled by the\n * edgeTransitionFilter. This method does not return single edge components (the excludeSingleEdgeComponents option is\n * set to true).\n */\npublic static ConnectedComponents findComponentsForStartEdges(Graph graph, EdgeTransitionFilter edgeTransitionFilter, IntContainer edges) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, true).findComponentsForStartEdges(edges);\n}", "private ConnectedComponents findComponentsForStartEdges(IntContainer startEdges) {\n    initForStartEdges(startEdges.size());\n    for (IntCursor edge : startEdges) {\n        // todo: using getEdgeIteratorState here is not efficient\n        EdgeIteratorState edgeState = graph.getEdgeIteratorState(edge.value, Integer.MIN_VALUE);\n        if (!edgeTransitionFilter.accept(NO_EDGE, edgeState))\n            continue;\n\n        findComponentsForEdgeState(edgeState);\n    }\n    return components;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntContainer.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.EdgeBasedNodeContractor.contractNode", "com.graphhopper.routing.ch.EdgeBasedNodeContractor.updateHierarchyDepthsOfNeighbors" ],
    "fullMethods" : [ "@Override\npublic IntContainer contractNode(int node) {\n    activeStats = addingStats;\n    stats().stopWatch.start();\n    findAndHandlePrepareShortcuts(node, this::addShortcutsToPrepareGraph, ((int) (meanDegree * params.maxPollFactorContraction)), wpsStatsContr);\n    insertShortcuts(node);\n    IntContainer neighbors = prepareGraph.disconnect(node);\n    // We maintain an approximation of the mean degree which we update after every contracted node.\n    // We do it the same way as for node-based CH for now.\n    meanDegree = ((meanDegree * 2) + neighbors.size()) / 3;\n    updateHierarchyDepthsOfNeighbors(node, neighbors);\n    stats().stopWatch.stop();\n    return neighbors;\n}", "private void updateHierarchyDepthsOfNeighbors(int node, IntContainer neighbors) {\n    int level = hierarchyDepths[node];\n    for (IntCursor n : neighbors) {\n        if (n.value == node)\n            continue;\n\n        hierarchyDepths[n.value] = Math.max(hierarchyDepths[n.value], level + 1);\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ch.PrepareContractionHierarchies.doWork",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntContainer.iterator",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ch.PrepareContractionHierarchies.doWork", "com.graphhopper.routing.ch.PrepareContractionHierarchies.runGraphContraction", "com.graphhopper.routing.ch.PrepareContractionHierarchies.contractNodesUsingHeuristicNodeOrdering" ],
    "fullMethods" : [ "public Result doWork() {\n    if (prepared)\n        throw new IllegalStateException(\"Call doWork only once!\");\n\n    prepared = true;\n    if (!graph.isFrozen()) {\n        throw new IllegalStateException(\"Given BaseGraph has not been frozen yet\");\n    }\n    if (chStore.getShortcuts() > 0) {\n        throw new IllegalStateException(\"Given CHStore already contains shortcuts\");\n    }\n    allSW.start();\n    initFromGraph();\n    runGraphContraction();\n    allSW.stop();\n    logFinalGraphStats();\n    return new Result(chConfig, chStore, nodeContractor.getAddedShortcutsCount(), lazyUpdateSW.getCurrentSeconds(), periodicUpdateSW.getCurrentSeconds(), neighborUpdateSW.getCurrentSeconds(), allSW.getMillis());\n}", "private void runGraphContraction() {\n    if (nodes < 1)\n        return;\n\n    setMaxLevelOnAllNodes();\n    if (nodeOrderingProvider != null) {\n        contractNodesUsingFixedNodeOrdering();\n    } else {\n        contractNodesUsingHeuristicNodeOrdering();\n    }\n}", "private void contractNodesUsingHeuristicNodeOrdering() {\n    StopWatch sw = new StopWatch().start();\n    logger.info(\"Building initial queue of nodes to be contracted: {} nodes, {}\", nodes, getMemInfo());\n    // note that we update the priorities before preparing the node contractor. this does not make much sense,\n    // but has always been like that and changing it would possibly require retuning the contraction parameters\n    updatePrioritiesOfRemainingNodes();\n    logger.info(\"Finished building queue, took: {}s, {}\", sw.stop().getSeconds(), getMemInfo());\n    final int initSize = sortedNodes.size();\n    int level = 0;\n    checkCounter = 0;\n    final long logSize = (params.getLogMessagesPercentage() == 0) ? Long.MAX_VALUE : Math.round(Math.max(10, initSize * (params.getLogMessagesPercentage() / 100.0)));\n    // specifies after how many contracted nodes the queue of remaining nodes is rebuilt. this takes time but the\n    // more often we do this the more up-to-date the node priorities will be\n    // todo: instead of using a fixed interval size maybe try adjusting it depending on the number of remaining\n    // nodes ?\n    final long periodicUpdatesCount = (params.getPeriodicUpdatesPercentage() == 0) ? Long.MAX_VALUE : Math.round(Math.max(10, initSize * (params.getPeriodicUpdatesPercentage() / 100.0)));\n    int updateCounter = 0;\n    // enable lazy updates for last x percentage of nodes. lazy updates make preparation slower but potentially\n    // keep node priorities more up to date, possibly resulting in a better preparation.\n    final long lastNodesLazyUpdates = Math.round(initSize * (params.getLastNodesLazyUpdatePercentage() / 100.0));\n    // according to paper \"Polynomial-time Construction of Contraction Hierarchies for Multi-criteria Objectives\" by Funke and Storandt\n    // we don't need to wait for all nodes to be contracted\n    final long nodesToAvoidContract = Math.round(initSize * ((100 - params.getNodesContractedPercentage()) / 100.0));\n    // Recompute priority of (the given percentage of) uncontracted neighbors. Doing neighbor updates takes additional\n    // time during preparation but keeps node priorities more up to date. this potentially improves query time and\n    // reduces number of shortcuts.\n    final boolean neighborUpdate = params.getNeighborUpdatePercentage() != 0;\n    while (!sortedNodes.isEmpty()) {\n        stopIfInterrupted();\n        // periodically update priorities of ALL nodes\n        if ((checkCounter > 0) && ((checkCounter % periodicUpdatesCount) == 0)) {\n            updatePrioritiesOfRemainingNodes();\n            updateCounter++;\n            if (sortedNodes.isEmpty())\n                throw new IllegalStateException(\"Cannot prepare as no unprepared nodes where found. Called preparation twice?\");\n\n        }\n        if ((checkCounter % logSize) == 0) {\n            logHeuristicStats(updateCounter);\n        }\n        checkCounter++;\n        int polledNode = sortedNodes.poll();\n        if ((!sortedNodes.isEmpty()) && (sortedNodes.size() < lastNodesLazyUpdates)) {\n            lazyUpdateSW.start();\n            float priority = calculatePriority(polledNode);\n            if (priority > sortedNodes.peekValue()) {\n                // current node got more important => insert as new value and contract it later\n                sortedNodes.push(polledNode, priority);\n                lazyUpdateSW.stop();\n                continue;\n            }\n            lazyUpdateSW.stop();\n        }\n        // contract node v!\n        IntContainer neighbors = contractNode(polledNode, level);\n        level++;\n        // skipped nodes are already set to maxLevel\n        if (sortedNodes.size() < nodesToAvoidContract)\n            break;\n\n        int neighborCount = 0;\n        // there might be multiple edges going to the same neighbor nodes -> only calculate priority once per node\n        for (IntCursor neighbor : neighbors) {\n            if ((neighborUpdate && ((params.getMaxNeighborUpdates() < 0) || (neighborCount < params.getMaxNeighborUpdates()))) && (rand.nextInt(100) < params.getNeighborUpdatePercentage())) {\n                neighborCount++;\n                neighborUpdateSW.start();\n                float priority = calculatePriority(neighbor.value);\n                sortedNodes.update(neighbor.value, priority);\n                neighborUpdateSW.stop();\n            }\n        }\n    } \n    nodeContractor.finishContraction();\n    logHeuristicStats(updateCounter);\n    logger.info((((((((((((((((((\"new shortcuts: \" + nf(nodeContractor.getAddedShortcutsCount())) + \", initSize:\") + nf(initSize)) + \", \") + chConfig.getWeighting()) + \", periodic:\") + params.getPeriodicUpdatesPercentage()) + \", lazy:\") + params.getLastNodesLazyUpdatePercentage()) + \", neighbor:\") + params.getNeighborUpdatePercentage()) + \", \") + getTimesAsString()) + \", lazy-overhead: \") + ((int) (100 * ((checkCounter / ((double) (initSize))) - 1)))) + \"%\") + \", \") + Helper.getMemInfo());\n    // Preparation works only once so we can release temporary data.\n    // The preparation object itself has to be intact to create the algorithm.\n    _close();\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.index.LineIntIndex.onEdge",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.index.LineIntIndex.onEdge" ],
    "fullMethods" : [ "@Override\npublic void onEdge(int edgeId) {\n    if (set.add(edgeId))\n        function.onEdge(edgeId);\n\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.lm.LandmarkStorage.createLandmarks",
    "thirdPartyMethod" : "com.carrotsearch.hppc.IntHashSet.add",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.lm.LandmarkStorage.createLandmarks", "com.graphhopper.routing.lm.LandmarkStorage.findBorderEdgeIds" ],
    "fullMethods" : [ "/**\n * This method calculates the landmarks and initial weightings to &amp; from them.\n */\npublic void createLandmarks() {\n    if (isInitialized())\n        throw new IllegalStateException(\"Initialize the landmark storage only once!\");\n\n    // fill 'from' and 'to' weights with maximum value\n    long maxBytes = ((long) (graph.getNodes())) * LM_ROW_LENGTH;\n    this.landmarkWeightDA.create(2000);\n    this.landmarkWeightDA.ensureCapacity(maxBytes);\n    for (long pointer = 0; pointer < maxBytes; pointer += 2) {\n        landmarkWeightDA.setShort(pointer, ((short) (SHORT_INFINITY)));\n    }\n    int[] empty = new int[landmarks];\n    Arrays.fill(empty, UNSET_SUBNETWORK);\n    landmarkIDs.add(empty);\n    byte[] subnetworks = new byte[graph.getNodes()];\n    Arrays.fill(subnetworks, ((byte) (UNSET_SUBNETWORK)));\n    String snKey = Subnetwork.key(lmConfig.getName());\n    // TODO We could use EdgeBasedTarjanSCC instead of node-based TarjanSCC here to get the small networks directly,\n    // instead of using the subnetworkEnc from PrepareRoutingSubnetworks.\n    if (!encodedValueLookup.hasEncodedValue(snKey))\n        throw new IllegalArgumentException(((\"EncodedValue '\" + snKey) + \"' does not exist. For Landmarks this is \") + \"currently required (also used in PrepareRoutingSubnetworks). See #2256\");\n\n    // Exclude edges that we previously marked in PrepareRoutingSubnetworks to avoid problems like \"connection not found\".\n    final BooleanEncodedValue edgeInSubnetworkEnc = encodedValueLookup.getBooleanEncodedValue(snKey);\n    final IntHashSet blockedEdges;\n    // We use the areaIndex to split certain areas from each other but do not permanently change the base graph\n    // so that other algorithms still can route through these regions. This is done to increase the density of\n    // landmarks for an area like Europe+Asia, which improves the query speed.\n    if (areaIndex != null) {\n        StopWatch sw = new StopWatch().start();\n        blockedEdges = findBorderEdgeIds(areaIndex);\n        if (logDetails)\n            LOGGER.info(((((\"Made \" + blockedEdges.size()) + \" edges inaccessible. Calculated country cut in \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n\n    } else {\n        blockedEdges = new IntHashSet();\n    }\n    EdgeFilter accessFilter = edge -> (!edge.get(edgeInSubnetworkEnc)) && (!blockedEdges.contains(edge.getEdge()));\n    EdgeFilter tarjanFilter = edge -> accessFilter.accept(edge) && Double.isFinite(weighting.calcEdgeWeight(edge, false));\n    StopWatch sw = new StopWatch().start();\n    ConnectedComponents graphComponents = TarjanSCC.findComponents(graph, tarjanFilter, true);\n    if (logDetails)\n        LOGGER.info(((((\"Calculated \" + graphComponents.getComponents().size()) + \" subnetworks via tarjan in \") + sw.stop().getSeconds()) + \"s, \") + Helper.getMemInfo());\n\n    String additionalInfo = \"\";\n    // guess the factor\n    if (factor <= 0) {\n        // A 'factor' is necessary to store the weight in just a short value but without losing too much precision.\n        // This factor is rather delicate to pick, we estimate it from an exploration with some \"test landmarks\",\n        // see estimateMaxWeight. If we pick the distance too big for small areas this could lead to (slightly)\n        // suboptimal routes as there will be too big rounding errors. But picking it too small is bad for performance\n        // e.g. for Germany at least 1500km is very important otherwise speed is at least twice as slow e.g. for 1000km\n        double maxWeight = estimateMaxWeight(graphComponents.getComponents(), accessFilter);\n        setMaximumWeight(maxWeight);\n        additionalInfo = (\", maxWeight:\" + maxWeight) + \" from quick estimation\";\n    }\n    if (logDetails)\n        LOGGER.info((((\"init landmarks for subnetworks with node count greater than \" + minimumNodes) + \" with factor:\") + factor) + additionalInfo);\n\n    int nodes = 0;\n    for (IntArrayList subnetworkIds : graphComponents.getComponents()) {\n        nodes += subnetworkIds.size();\n        if (subnetworkIds.size() < minimumNodes)\n            continue;\n\n        if (factor <= 0)\n            throw new IllegalStateException(((((((\"factor wasn't initialized \" + factor) + \", subnetworks:\") + graphComponents.getComponents().size()) + \", minimumNodes:\") + minimumNodes) + \", current size:\") + subnetworkIds.size());\n\n        int index = subnetworkIds.size() - 1;\n        // ensure start node is reachable from both sides and no subnetwork is associated\n        for (; index >= 0; index--) {\n            int nextStartNode = subnetworkIds.get(index);\n            if (subnetworks[nextStartNode] == UNSET_SUBNETWORK) {\n                if (logDetails) {\n                    GHPoint p = createPoint(graph, nextStartNode);\n                    LOGGER.info((((((((((\"start node: \" + nextStartNode) + \" (\") + p) + \") subnetwork \") + index) + \", subnetwork size: \") + subnetworkIds.size()) + \", \") + Helper.getMemInfo()) + (areaIndex == null ? \"\" : \" area:\" + areaIndex.query(p.lat, p.lon)));\n                }\n                if (createLandmarksForSubnetwork(nextStartNode, subnetworks, accessFilter))\n                    break;\n\n            }\n        }\n        if (index < 0)\n            LOGGER.warn(((((\"next start node not found in big enough network of size \" + subnetworkIds.size()) + \", first element is \") + subnetworkIds.get(0)) + \", \") + createPoint(graph, subnetworkIds.get(0)));\n\n    }\n    int subnetworkCount = landmarkIDs.size();\n    // store all landmark node IDs and one int for the factor itself.\n    this.landmarkWeightDA.ensureCapacity((maxBytes/* landmark weights */\n     + (((long) (subnetworkCount)) * landmarks))/* landmark mapping per subnetwork */\n     + 4);\n    // calculate offset to point into landmark mapping\n    long bytePos = maxBytes;\n    for (int[] landmarks : landmarkIDs) {\n        for (int lmNodeId : landmarks) {\n            landmarkWeightDA.setInt(bytePos, lmNodeId);\n            bytePos += 4L;\n        }\n    }\n    landmarkWeightDA.setHeader(0 * 4, graph.getNodes());\n    landmarkWeightDA.setHeader(1 * 4, this.landmarks);\n    landmarkWeightDA.setHeader(2 * 4, subnetworkCount);\n    if ((factor * DOUBLE_MLTPL) > Integer.MAX_VALUE)\n        throw new UnsupportedOperationException(\"landmark weight factor cannot be bigger than Integer.MAX_VALUE \" + (factor * DOUBLE_MLTPL));\n\n    landmarkWeightDA.setHeader(3 * 4, ((int) (Math.round(factor * DOUBLE_MLTPL))));\n    // serialize fast byte[] into DataAccess\n    subnetworkStorage.create(graph.getNodes());\n    for (int nodeId = 0; nodeId < subnetworks.length; nodeId++) {\n        subnetworkStorage.setSubnetwork(nodeId, subnetworks[nodeId]);\n    }\n    if (logDetails)\n        LOGGER.info(((\"Finished landmark creation. Subnetwork node count sum \" + nodes) + \" vs. nodes \") + graph.getNodes());\n\n    initialized = true;\n}", "/**\n * This method makes edges crossing the specified border inaccessible to split a bigger area into smaller subnetworks.\n * This is important for the world wide use case to limit the maximum distance and also to detect unreasonable routes faster.\n */\nprotected IntHashSet findBorderEdgeIds(AreaIndex<SplitArea> areaIndex) {\n    AllEdgesIterator allEdgesIterator = graph.getAllEdges();\n    IntHashSet inaccessible = new IntHashSet();\n    while (allEdgesIterator.next()) {\n        int adjNode = allEdgesIterator.getAdjNode();\n        List<SplitArea> areas = areaIndex.query(na.getLat(adjNode), na.getLon(adjNode));\n        SplitArea areaAdj = (areas.isEmpty()) ? null : areas.get(0);\n        int baseNode = allEdgesIterator.getBaseNode();\n        areas = areaIndex.query(na.getLat(baseNode), na.getLon(baseNode));\n        SplitArea areaBase = (areas.isEmpty()) ? null : areas.get(0);\n        if (areaAdj != areaBase) {\n            inaccessible.add(allEdgesIterator.getEdge());\n        }\n    } \n    return inaccessible;\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForStartEdges", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForEdgeState", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.startSearch", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Like {@link #findComponents(Graph, EdgeTransitionFilter, boolean)}, but the search only starts at the\n * given edges. This does not mean the search cannot expand to other edges, but this can be controlled by the\n * edgeTransitionFilter. This method does not return single edge components (the excludeSingleEdgeComponents option is\n * set to true).\n */\npublic static ConnectedComponents findComponentsForStartEdges(Graph graph, EdgeTransitionFilter edgeTransitionFilter, IntContainer edges) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, true).findComponentsForStartEdges(edges);\n}", "private ConnectedComponents findComponentsForStartEdges(IntContainer startEdges) {\n    initForStartEdges(startEdges.size());\n    for (IntCursor edge : startEdges) {\n        // todo: using getEdgeIteratorState here is not efficient\n        EdgeIteratorState edgeState = graph.getEdgeIteratorState(edge.value, Integer.MIN_VALUE);\n        if (!edgeTransitionFilter.accept(NO_EDGE, edgeState))\n            continue;\n\n        findComponentsForEdgeState(edgeState);\n    }\n    return components;\n}", "private void findComponentsForEdgeState(EdgeIteratorState edge) {\n    int edgeKeyFwd = createEdgeKey(edge, false);\n    if (!edgeKeyIndex.has(edgeKeyFwd))\n        pushFindComponentForEdgeKey(edgeKeyFwd, edge.getAdjNode());\n\n    startSearch();\n    // We need to start the search for both edge keys of this edge, but its important to check if the second\n    // has already been found by the first search. So we cannot simply push them both and start the search once.\n    int edgeKeyBwd = createEdgeKey(edge, true);\n    if (!edgeKeyIndex.has(edgeKeyBwd))\n        pushFindComponentForEdgeKey(edgeKeyBwd, edge.getAdjNode());\n\n    startSearch();\n}", "private void startSearch() {\n    while (hasNext()) {\n        pop();\n        switch (dfsState) {\n            case BUILD_COMPONENT :\n                buildComponent(p);\n                break;\n            case UPDATE :\n                edgeKeyLowLink.minTo(p, edgeKeyLowLink.get(q));\n                break;\n            case HANDLE_NEIGHBOR :\n                if (edgeKeyIndex.has(q) && edgeKeyOnStack.contains(q))\n                    edgeKeyLowLink.minTo(p, edgeKeyIndex.get(q));\n\n                if (!edgeKeyIndex.has(q)) {\n                    // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                    pushUpdateLowLinks(p, q);\n                    pushFindComponentForEdgeKey(q, adj);\n                }\n                break;\n            case FIND_COMPONENT :\n                setupNextEdgeKey(p);\n                // we push buildComponent first so it will run *after* we finished traversing the edges\n                pushBuildComponent(p);\n                final int edge = getEdgeFromEdgeKey(p);\n                EdgeIterator it = explorer.setBaseNode(adj);\n                while (it.next()) {\n                    if (!edgeTransitionFilter.accept(edge, it))\n                        continue;\n\n                    int q = createEdgeKey(it, false);\n                    pushHandleNeighbor(p, q, it.getAdjNode());\n                } \n                break;\n            default :\n                throw new IllegalStateException(\"Unknown state: \" + dfsState);\n        }\n    } \n}", "private void buildComponent(int p) {\n    if (edgeKeyLowLink.get(p) == edgeKeyIndex.get(p)) {\n        if (tarjanStack.getLast() == p) {\n            tarjanStack.removeLast();\n            edgeKeyOnStack.remove(p);\n            components.numComponents++;\n            components.numEdgeKeys++;\n            if (!excludeSingleEdgeComponents)\n                components.singleEdgeComponents.set(p);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int q = tarjanStack.removeLast();\n                component.add(q);\n                edgeKeyOnStack.remove(q);\n                if (q == p)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numEdgeKeys += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsForEdgeState", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.startSearch", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param edgeTransitionFilter\n * \t\tOnly edge transitions accepted by this filter will be considered when we explore the graph.\n * \t\tIf a turn is not accepted the corresponding path will be ignored (edges that are only connected\n * \t\tby a path with such a turn will not be considered to belong to the same component)\n * @param excludeSingleEdgeComponents\n * \t\tif set to true components that only contain a single edge will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponents();\n}", "private ConnectedComponents findComponents() {\n    initForEntireGraph();\n    AllEdgesIterator iter = graph.getAllEdges();\n    while (iter.next()) {\n        findComponentsForEdgeState(iter);\n    } \n    return components;\n}", "private void findComponentsForEdgeState(EdgeIteratorState edge) {\n    int edgeKeyFwd = createEdgeKey(edge, false);\n    if (!edgeKeyIndex.has(edgeKeyFwd))\n        pushFindComponentForEdgeKey(edgeKeyFwd, edge.getAdjNode());\n\n    startSearch();\n    // We need to start the search for both edge keys of this edge, but its important to check if the second\n    // has already been found by the first search. So we cannot simply push them both and start the search once.\n    int edgeKeyBwd = createEdgeKey(edge, true);\n    if (!edgeKeyIndex.has(edgeKeyBwd))\n        pushFindComponentForEdgeKey(edgeKeyBwd, edge.getAdjNode());\n\n    startSearch();\n}", "private void startSearch() {\n    while (hasNext()) {\n        pop();\n        switch (dfsState) {\n            case BUILD_COMPONENT :\n                buildComponent(p);\n                break;\n            case UPDATE :\n                edgeKeyLowLink.minTo(p, edgeKeyLowLink.get(q));\n                break;\n            case HANDLE_NEIGHBOR :\n                if (edgeKeyIndex.has(q) && edgeKeyOnStack.contains(q))\n                    edgeKeyLowLink.minTo(p, edgeKeyIndex.get(q));\n\n                if (!edgeKeyIndex.has(q)) {\n                    // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                    pushUpdateLowLinks(p, q);\n                    pushFindComponentForEdgeKey(q, adj);\n                }\n                break;\n            case FIND_COMPONENT :\n                setupNextEdgeKey(p);\n                // we push buildComponent first so it will run *after* we finished traversing the edges\n                pushBuildComponent(p);\n                final int edge = getEdgeFromEdgeKey(p);\n                EdgeIterator it = explorer.setBaseNode(adj);\n                while (it.next()) {\n                    if (!edgeTransitionFilter.accept(edge, it))\n                        continue;\n\n                    int q = createEdgeKey(it, false);\n                    pushHandleNeighbor(p, q, it.getAdjNode());\n                } \n                break;\n            default :\n                throw new IllegalStateException(\"Unknown state: \" + dfsState);\n        }\n    } \n}", "private void buildComponent(int p) {\n    if (edgeKeyLowLink.get(p) == edgeKeyIndex.get(p)) {\n        if (tarjanStack.getLast() == p) {\n            tarjanStack.removeLast();\n            edgeKeyOnStack.remove(p);\n            components.numComponents++;\n            components.numEdgeKeys++;\n            if (!excludeSingleEdgeComponents)\n                components.singleEdgeComponents.set(p);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int q = tarjanStack.removeLast();\n                component.add(q);\n                edgeKeyOnStack.remove(q);\n                if (q == p)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numEdgeKeys += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponentForNode", "com.graphhopper.routing.subnetwork.TarjanSCC.setupNextNode" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponentsRecursive();\n}", "private ConnectedComponents findComponentsRecursive() {\n    for (int node = 0; node < graph.getNodes(); node++) {\n        if (nodeIndex[node] == (-1)) {\n            findComponentForNode(node);\n        }\n    }\n    return components;\n}", "private void findComponentForNode(int v) {\n    setupNextNode(v);\n    // we have to create a new explorer on each iteration because of the nested edge iterations\n    EdgeExplorer explorer = graph.createEdgeExplorer(edgeFilter);\n    EdgeIterator iter = explorer.setBaseNode(v);\n    while (iter.next()) {\n        int w = iter.getAdjNode();\n        if (nodeIndex[w] == (-1)) {\n            findComponentForNode(w);\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n        } else if (nodeOnStack.get(w))\n            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n    } \n    buildComponent(v);\n}", "private void setupNextNode(int v) {\n    nodeIndex[v] = currIndex;\n    nodeLowLink[v] = currIndex;\n    currIndex++;\n    tarjanStack.addLast(v);\n    nodeOnStack.set(v);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.findComponents", "com.graphhopper.routing.subnetwork.TarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm using an explicit stack.\n *\n * @param excludeSingleNodeComponents\n * \t\tif set to true components that only contain a single node will not be\n * \t\treturned when calling {@link #findComponents} or {@link #findComponentsRecursive()},\n * \t\twhich can be useful to save some memory.\n */\npublic static ConnectedComponents findComponents(Graph graph, EdgeFilter edgeFilter, boolean excludeSingleNodeComponents) {\n    return new TarjanSCC(graph, edgeFilter, excludeSingleNodeComponents).findComponents();\n}", "private ConnectedComponents findComponents() {\n    for (int node = 0; node < graph.getNodes(); ++node) {\n        if (nodeIndex[node] != (-1))\n            continue;\n\n        pushFindComponentForNode(node);\n        while (hasNext()) {\n            pop();\n            switch (dfsState) {\n                case BUILD_COMPONENT :\n                    buildComponent(v);\n                    break;\n                case UPDATE :\n                    nodeLowLink[v] = Math.min(nodeLowLink[v], nodeLowLink[w]);\n                    break;\n                case HANDLE_NEIGHBOR :\n                    {\n                        if ((nodeIndex[w] != (-1)) && nodeOnStack.get(w))\n                            nodeLowLink[v] = Math.min(nodeLowLink[v], nodeIndex[w]);\n\n                        if (nodeIndex[w] == (-1)) {\n                            // we are pushing updateLowLinks first so it will run *after* findComponent finishes\n                            pushUpdateLowLinks(v, w);\n                            pushFindComponentForNode(w);\n                        }\n                        break;\n                    }\n                case FIND_COMPONENT :\n                    {\n                        setupNextNode(v);\n                        // we push buildComponent first so it will run *after* we finished traversing the edges\n                        pushBuildComponent(v);\n                        EdgeIterator iter = explorer.setBaseNode(v);\n                        while (iter.next()) {\n                            pushHandleNeighbor(v, iter.getAdjNode());\n                        } \n                        break;\n                    }\n                default :\n                    throw new IllegalStateException(\"Unknown state: \" + dfsState);\n            }\n        } \n    }\n    return components;\n}", "private void buildComponent(int v) {\n    if (nodeLowLink[v] == nodeIndex[v]) {\n        if (tarjanStack.getLast() == v) {\n            tarjanStack.removeLast();\n            nodeOnStack.clear(v);\n            components.numComponents++;\n            components.numNodes++;\n            if (!excludeSingleNodeComponents)\n                components.singleNodeComponents.set(v);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int w = tarjanStack.removeLast();\n                component.add(w);\n                nodeOnStack.clear(w);\n                if (w == v)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numNodes += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.BaseGraphNodesAndEdges.sortEdges",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.BaseGraphNodesAndEdges.sortEdges" ],
    "fullMethods" : [ "public void sortEdges(IntUnaryOperator getNewEdgeForOldEdge) {\n    BitSet visited = new BitSet(getEdges());\n    for (int edge = 0; edge < getEdges(); edge++) {\n        if (visited.get(edge))\n            continue;\n\n        int curr = edge;\n        long pointer = toEdgePointer(curr);\n        int nodeA = getNodeA(pointer);\n        int nodeB = getNodeB(pointer);\n        int linkA = getLinkA(pointer);\n        int linkB = getLinkB(pointer);\n        int dist = edges.getInt(pointer + E_DIST);\n        int kv = getKeyValuesRef(pointer);\n        IntsRef flags = createEdgeFlags();\n        readFlags(pointer, flags);\n        long geo = getGeoRef(pointer);\n        do {\n            visited.set(curr);\n            int newEdge = getNewEdgeForOldEdge.applyAsInt(curr);\n            long newPointer = toEdgePointer(newEdge);\n            int tmpNodeA = getNodeA(newPointer);\n            int tmpNodeB = getNodeB(newPointer);\n            int tmpLinkA = getLinkA(newPointer);\n            int tmpLinkB = getLinkB(newPointer);\n            int tmpDist = edges.getInt(newPointer + E_DIST);\n            int tmpKV = getKeyValuesRef(newPointer);\n            IntsRef tmpFlags = createEdgeFlags();\n            readFlags(newPointer, tmpFlags);\n            long tmpGeo = getGeoRef(newPointer);\n            setNodeA(newPointer, nodeA);\n            setNodeB(newPointer, nodeB);\n            setLinkA(newPointer, linkA == (-1) ? -1 : getNewEdgeForOldEdge.applyAsInt(linkA));\n            setLinkB(newPointer, linkB == (-1) ? -1 : getNewEdgeForOldEdge.applyAsInt(linkB));\n            edges.setInt(newPointer + E_DIST, dist);\n            setKeyValuesRef(newPointer, kv);\n            writeFlags(newPointer, flags);\n            setGeoRef(newPointer, geo);\n            nodeA = tmpNodeA;\n            nodeB = tmpNodeB;\n            linkA = tmpLinkA;\n            linkB = tmpLinkB;\n            dist = tmpDist;\n            kv = tmpKV;\n            flags = tmpFlags;\n            geo = tmpGeo;\n            curr = newEdge;\n        } while (curr != edge );\n    }\n    // update edge references\n    for (int node = 0; node < getNodes(); node++) {\n        long pointer = toNodePointer(node);\n        setEdgeRef(pointer, getNewEdgeForOldEdge.applyAsInt(getEdgeRef(pointer)));\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.storage.BaseGraphNodesAndEdges.relabelNodes",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.storage.BaseGraphNodesAndEdges.relabelNodes" ],
    "fullMethods" : [ "public void relabelNodes(IntUnaryOperator getNewNodeForOldNode) {\n    for (int edge = 0; edge < getEdges(); edge++) {\n        long pointer = toEdgePointer(edge);\n        setNodeA(pointer, getNewNodeForOldNode.applyAsInt(getNodeA(pointer)));\n        setNodeB(pointer, getNewNodeForOldNode.applyAsInt(getNodeB(pointer)));\n    }\n    BitSet visited = new BitSet(getNodes());\n    for (int node = 0; node < getNodes(); node++) {\n        if (visited.get(node))\n            continue;\n\n        int curr = node;\n        long pointer = toNodePointer(node);\n        int edgeRef = getEdgeRef(pointer);\n        double lat = getLat(pointer);\n        double lon = getLon(pointer);\n        double ele = (withElevation()) ? getEle(pointer) : Double.NaN;\n        int tc = (withTurnCosts()) ? getTurnCostRef(pointer) : -1;\n        do {\n            visited.set(curr);\n            int newNode = getNewNodeForOldNode.applyAsInt(curr);\n            long newPointer = toNodePointer(newNode);\n            int tmpEdgeRef = getEdgeRef(newPointer);\n            double tmpLat = getLat(newPointer);\n            double tmpLon = getLon(newPointer);\n            double tmpEle = (withElevation()) ? getEle(newPointer) : Double.NaN;\n            int tmpTC = (withTurnCosts()) ? getTurnCostRef(newPointer) : -1;\n            setEdgeRef(newPointer, edgeRef);\n            setLat(newPointer, lat);\n            setLon(newPointer, lon);\n            if (withElevation())\n                setEle(newPointer, ele);\n\n            if (withTurnCosts())\n                setTurnCostRef(newPointer, tc);\n\n            edgeRef = tmpEdgeRef;\n            lat = tmpLat;\n            lon = tmpLon;\n            ele = tmpEle;\n            tc = tmpTC;\n            curr = newNode;\n        } while (curr != node );\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.ev.ExternalBooleanEncodedValue.setBool",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.ev.ExternalBooleanEncodedValue.setBool" ],
    "fullMethods" : [ "@Override\npublic void setBool(boolean reverse, int edgeId, EdgeIntAccess edgeIntAccess, boolean value) {\n    // it'll grow as we go\n    if (value)\n        bits.set(getIndex(edgeId, reverse));\n    else\n        bits.clear(getIndex(edgeId, reverse));\n\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentsRecursive", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.findComponentForEdgeKey", "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.buildComponent" ],
    "fullMethods" : [ "/**\n * Runs Tarjan's algorithm in a recursive way. Doing it like this requires a large stack size for large graphs,\n * which can be set like `-Xss1024M`. Usually the version using an explicit stack ({@link #findComponents()}) should be\n * preferred. However, this recursive implementation is easier to understand.\n *\n * @see #findComponents(Graph, EdgeTransitionFilter, boolean)\n */\npublic static ConnectedComponents findComponentsRecursive(Graph graph, EdgeTransitionFilter edgeTransitionFilter, boolean excludeSingleEdgeComponents) {\n    return new EdgeBasedTarjanSCC(graph, edgeTransitionFilter, excludeSingleEdgeComponents).findComponentsRecursive();\n}", "private ConnectedComponents findComponentsRecursive() {\n    initForEntireGraph();\n    AllEdgesIterator iter = graph.getAllEdges();\n    while (iter.next()) {\n        int edgeKeyFwd = createEdgeKey(iter, false);\n        if (!edgeKeyIndex.has(edgeKeyFwd))\n            findComponentForEdgeKey(edgeKeyFwd, iter.getAdjNode());\n\n        int edgeKeyBwd = createEdgeKey(iter, true);\n        if (!edgeKeyIndex.has(edgeKeyBwd))\n            findComponentForEdgeKey(edgeKeyBwd, iter.getAdjNode());\n\n    } \n    return components;\n}", "private void findComponentForEdgeKey(int p, int adjNode) {\n    setupNextEdgeKey(p);\n    // we have to create a new explorer on each iteration because of the nested edge iterations\n    final int edge = getEdgeFromEdgeKey(p);\n    EdgeExplorer explorer = graph.createEdgeExplorer();\n    EdgeIterator iter = explorer.setBaseNode(adjNode);\n    while (iter.next()) {\n        if (!edgeTransitionFilter.accept(edge, iter))\n            continue;\n\n        int q = createEdgeKey(iter, false);\n        handleNeighbor(p, q, iter.getAdjNode());\n    } \n    buildComponent(p);\n}", "private void buildComponent(int p) {\n    if (edgeKeyLowLink.get(p) == edgeKeyIndex.get(p)) {\n        if (tarjanStack.getLast() == p) {\n            tarjanStack.removeLast();\n            edgeKeyOnStack.remove(p);\n            components.numComponents++;\n            components.numEdgeKeys++;\n            if (!excludeSingleEdgeComponents)\n                components.singleEdgeComponents.set(p);\n\n        } else {\n            IntArrayList component = new IntArrayList();\n            while (true) {\n                int q = tarjanStack.removeLast();\n                component.add(q);\n                edgeKeyOnStack.remove(q);\n                if (q == p)\n                    break;\n\n            } \n            component.trimToSize();\n            assert component.size() > 1;\n            components.numComponents++;\n            components.numEdgeKeys += component.size();\n            components.components.add(component);\n            if (component.size() > components.biggestComponent.size())\n                components.biggestComponent = component;\n\n        }\n    }\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanArrayIntSet.add",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.routing.subnetwork.EdgeBasedTarjanSCC.TarjanArrayIntSet.add" ],
    "fullMethods" : [ "@Override\npublic void add(int key) {\n    set.set(key);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.GraphHopper.sortGraphAlongHilbertCurve" ],
    "fullMethods" : [ "public static void sortGraphAlongHilbertCurve(BaseGraph graph) {\n    logger.info(\"sorting graph along Hilbert curve...\");\n    StopWatch sw = StopWatch.started();\n    NodeAccess na = graph.getNodeAccess();\n    final int order = 31;// using 15 would allow us to use ints for sortIndices, but this would result in (marginally) slower routing\n\n    LongArrayList sortIndices = new LongArrayList();\n    for (int node = 0; node < graph.getNodes(); node++)\n        sortIndices.add(latLonToHilbertIndex(na.getLat(node), na.getLon(node), order));\n\n    int[] nodeOrder = IndirectSort.mergesort(0, graph.getNodes(), (nodeA, nodeB) -> Long.compare(sortIndices.get(nodeA), sortIndices.get(nodeB)));\n    EdgeExplorer explorer = graph.createEdgeExplorer();\n    int edges = graph.getEdges();\n    IntArrayList edgeOrder = new IntArrayList();\n    BitSet edgesFound = new BitSet(edges);\n    for (int node : nodeOrder) {\n        EdgeIterator iter = explorer.setBaseNode(node);\n        while (iter.next()) {\n            if (!edgesFound.get(iter.getEdge())) {\n                edgeOrder.add(iter.getEdge());\n                edgesFound.set(iter.getEdge());\n            }\n        } \n    }\n    IntArrayList newEdgesByOldEdges = ArrayUtil.invert(edgeOrder);\n    IntArrayList newNodesByOldNodes = IntArrayList.from(ArrayUtil.invert(nodeOrder));\n    logger.info(\"calculating sort order took: \" + sw.stop().getTimeString());\n    sortGraphForGivenOrdering(graph, newNodesByOldNodes, newEdgesByOldEdges);\n}" ]
  }, {
    "entryPoint" : "com.graphhopper.util.ArrayUtil.isPermutation",
    "thirdPartyMethod" : "com.carrotsearch.hppc.BitSet.set",
    "thirdPartyPackage" : "com.carrotsearch.hppc",
    "path" : [ "com.graphhopper.util.ArrayUtil.isPermutation" ],
    "fullMethods" : [ "public static boolean isPermutation(IntArrayList arr) {\n    BitSet present = new BitSet(arr.size());\n    for (IntCursor e : arr) {\n        if ((e.value >= arr.size()) || (e.value < 0))\n            return false;\n\n        if (present.get(e.value))\n            return false;\n\n        present.set(e.value);\n    }\n    return true;\n}" ]
  } ]
}